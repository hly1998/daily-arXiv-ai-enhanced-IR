<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 10]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [AIRwaves at CheckThat! 2025: Retrieving Scientific Sources for Implicit Claims on Social Media with Dual Encoders and Neural Re-Ranking](https://arxiv.org/abs/2509.19509)
*Cem Ashbaugh,Leon Baumgärtner,Tim Gress,Nikita Sidorov,Daniel Werner*

Main category: cs.IR

TL;DR: 研究通过结合密集检索与神经重排序器，显著提升社交媒体科学主张与原始出版物的对接效果，提供了一种实用的证据检索解决方案。


<details>
  <summary>Details</summary>
Motivation: 在社交媒体上链接隐含的科学主张到其原始出版物对于基于证据的事实核查和学术讨论至关重要，但受到词汇稀疏、查询非常短以及领域特定语言的阻碍。

Method: 本文采用了一个两阶段检索管道：(i) 第一个阶段使用基于E5-large的双编码器，经过批内和挖掘的硬负样本微调，并通过分块标记和丰富的文档元数据进行强化；(ii) 使用SciBERT交叉编码器进行神经重排序阶段。

Result: 优化的稀疏检索基线（BM25）在金标准盲测集上达到MRR@5 = 0.5025。通过引入两阶段检索管道，使用神经表示代替纯词汇匹配，性能提高至MRR@5 = 0.6174，完整管道进一步提高至MRR@5 = 0.6828。

Conclusion: 通过结合密集检索与神经重排序器，可以为推文到研究的匹配提供一个强大且高效的解决方案，并为未来的证据检索流程提供一种实用的蓝图。

Abstract: Linking implicit scientific claims made on social media to their original
publications is crucial for evidence-based fact-checking and scholarly
discourse, yet it is hindered by lexical sparsity, very short queries, and
domain-specific language. Team AIRwaves ranked second in Subtask 4b of the
CLEF-2025 CheckThat! Lab with an evidence-retrieval approach that markedly
outperforms the competition baseline. The optimized sparse-retrieval
baseline(BM25) achieves MRR@5 = 0.5025 on the gold label blind test set. To
surpass this baseline, a two-stage retrieval pipeline is introduced: (i) a
first stage that uses a dual encoder based on E5-large, fine-tuned using
in-batch and mined hard negatives and enhanced through chunked tokenization and
rich document metadata; and (ii) a neural re-ranking stage using a SciBERT
cross-encoder. Replacing purely lexical matching with neural representations
lifts performance to MRR@5 = 0.6174, and the complete pipeline further improves
to MRR@5 = 0.6828. The findings demonstrate that coupling dense retrieval with
neural re-rankers delivers a powerful and efficient solution for tweet-to-study
matching and provides a practical blueprint for future evidence-retrieval
pipelines.

</details>


### [2] [Learning Contextual Retrieval for Robust Conversational Search](https://arxiv.org/abs/2509.19700)
*Seunghan Yang,Juntae Lee,Jihwan Bang,Kyuhong Shim,Minsoo Kim,Simyung Chang*

Main category: cs.IR

TL;DR: 提出了一种名为ContextualRetriever的新型LLM检索器，通过直接纳入对话上下文来增强检索效果，显著提升性能且无额外推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有的检索工具在处理多轮对话时往往难以理解用户意图，因为用户在对话中经常使用缩写和改变话题。虽然查询重写技术可以提高查询的清晰度，但往往会增加计算成本。而基于LLM的检索器虽然表现良好，但在多轮对话中并未针对用户意图进行优化，常常无法应对话题漂移或上下文模糊的问题。

Method: 引入一种新的上下文感知嵌入机制来在对话历史中突出当前查询，以及基于高质量重写查询的意图指导监督，采用一种保留基础LLM生成能力的训练策略。

Result: ContextualRetriever显著优于现有方法，并且没有增加任何推理开销。

Conclusion: ContextualRetriever能够通过直接引入对话上下文来提高检索效率和准确性，并解决其他方法在处理多轮对话面临的性能瓶颈。

Abstract: Effective conversational search demands a deep understanding of user intent
across multiple dialogue turns. Users frequently use abbreviations and shift
topics in the middle of conversations, posing challenges for conventional
retrievers. While query rewriting techniques improve clarity, they often incur
significant computational cost due to additional autoregressive steps.
Moreover, although LLM-based retrievers demonstrate strong performance, they
are not explicitly optimized to track user intent in multi-turn settings, often
failing under topic drift or contextual ambiguity. To address these
limitations, we propose ContextualRetriever, a novel LLM-based retriever that
directly incorporates conversational context into the retrieval process. Our
approach introduces: (1) a context-aware embedding mechanism that highlights
the current query within the dialogue history; (2) intent-guided supervision
based on high-quality rewritten queries; and (3) a training strategy that
preserves the generative capabilities of the base LLM. Extensive evaluations
across multiple conversational search benchmarks demonstrate that
ContextualRetriever significantly outperforms existing methods while incurring
no additional inference overhead.

</details>


### [3] [FusedANN: Convexified Hybrid ANN via Attribute-Vector Fusion](https://arxiv.org/abs/2509.19767)
*Alireza Heidari,Wei Zhang,Ying Xiong*

Main category: cs.IR

TL;DR: FusedANN是一种结合属性过滤和向量相似性的新方法，以提高查询吞吐量和召回率而不依赖特殊索引。


<details>
  <summary>Details</summary>
Motivation: 目前的解决方案在召回率、速度和灵活性之间进行权衡，依赖于不可靠的索引技术，这些技术无法扩展。

Method: 我们引入了一种几何框架FusedANN（融合属性-向量最近邻），将过滤提升为ANN优化约束，并通过类似拉格朗日的放松引入了一个凸融合空间。该方法通过基于transformer的凸化技术，将属性和向量联合嵌入，将硬过滤器转化为连续的加权惩罚，在启用高效近似搜索的同时保留top-k语义。

Result: FusedANN可以在高选择性时简化为精确过滤，当精确匹配不足时，优雅地放宽到语义上最近的属性，并保留下游ANN的alpha近似保证。

Conclusion: FusedANN为生产提供了明确的误差范围和参数选择规则，建立了符号约束与向量相似性之间的可扩展且可验证的桥梁，为大型、混合和动态NLP/ML工作负载解锁了新一代过滤检索系统。

Abstract: Vector search powers transformers technology, but real-world use demands
hybrid queries that combine vector similarity with attribute filters (e.g.,
"top document in category X, from 2023"). Current solutions trade off recall,
speed, and flexibility, relying on fragile index hacks that don't scale. We
introduce FusedANN (Fused Attribute-Vector Nearest Neighbor), a geometric
framework that elevates filtering to ANN optimization constraints and
introduces a convex fused space via a Lagrangian-like relaxation. Our method
jointly embeds attributes and vectors through transformer-based
convexification, turning hard filters into continuous, weighted penalties that
preserve top-k semantics while enabling efficient approximate search. We prove
that FusedANN reduces to exact filtering under high selectivity, gracefully
relaxes to semantically nearest attributes when exact matches are insufficient,
and preserves downstream ANN alpha-approximation guarantees. Empirically,
FusedANN improves query throughput by eliminating brittle filtering stages,
achieving superior recall-latency tradeoffs on standard hybrid benchmarks
without specialized index hacks, delivering up to 3 times higher throughput and
better recall than state-of-the-art hybrid and graph-based systems.
Theoretically, we provide explicit error bounds and parameter selection rules
that make FusedANN practical for production. This establishes a principled,
scalable, and verifiable bridge between symbolic constraints and vector
similarity, unlocking a new generation of filtered retrieval systems for large,
hybrid, and dynamic NLP/ML workloads.

</details>


### [4] [Adaptive User Interest Modeling via Conditioned Denoising Diffusion For Click-Through Rate Prediction](https://arxiv.org/abs/2509.19876)
*Qihang Zhao,Xiaoyang Zheng,Ben Chen,Zhongbo Sun,Chenyi Lei*

Main category: cs.IR

TL;DR: 提出了一种新方法CDP，通过去噪过程生成动态上下文相关的用户兴趣表示，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在搜索系统中，用户行为序列类似于“兴趣化石”，真实意图受到曝光偏差、类别漂移和背景噪音的影响。传统方法往往忽视了噪音与真实兴趣之间有机缠绕的问题，同时它们输出静态的、与上下文无关的表示，无法适应在不同查询-用户-项目-上下文条件下的动态意图变化。

Method: 提出了一种名为Contextual Diffusion Purifier (CDP)的方法，该方法将类别过滤后的行为视为“受污染的观察”，通过正向加噪和条件反向去噪过程进行处理，以生成纯净的、与上下文相关的兴趣表示。这种表示能够在不同场景下动态演化。

Result: 通过广泛的离线和在线实验，表明CDP方法在性能上优于现有的先进方法。

Conclusion: CDP能够有效解决用户行为序列中存在的噪音和意图动态变化的问题，生成更准确的兴趣表示。

Abstract: User behavior sequences in search systems resemble "interest fossils",
capturing genuine intent yet eroded by exposure bias, category drift, and
contextual noise. Current methods predominantly follow an "identify-aggregate"
paradigm, assuming sequences immutably reflect user preferences while
overlooking the organic entanglement of noise and genuine interest. Moreover,
they output static, context-agnostic representations, failing to adapt to
dynamic intent shifts under varying Query-User-Item-Context conditions.
  To resolve this dual challenge, we propose the Contextual Diffusion Purifier
(CDP). By treating category-filtered behaviors as "contaminated observations",
CDP employs a forward noising and conditional reverse denoising process guided
by cross-interaction features (Query x User x Item x Context), controllably
generating pure, context-aware interest representations that dynamically evolve
with scenarios. Extensive offline/online experiments demonstrate the
superiority of CDP over state-of-the-art methods.

</details>


### [5] [Documentation Retrieval Improves Planning Language Generation](https://arxiv.org/abs/2509.19931)
*Renxiang Wang,Li Zhang*

Main category: cs.IR

TL;DR: 轻量级流程显著提高强大LLM在低资源规划领域的性能，从0%提升至80%。


<details>
  <summary>Details</summary>
Motivation: 由于大多数开放源码模型在规划语言生成方面的性能较差，低资源语言限制了其效能，因此寻找改善方法。

Method: 整合文档检索、模块化代码生成和错误细化的轻量级流程，以提高规划语言生成性能。

Result: 使用Llama-4-Maverick等模型的轻量级流程，将BlocksWorld领域的计划正确性从0%提高到80%以上，但复杂领域中语义错误仍难以消除。

Conclusion: 尽管在BlocksWorld领域的计划正确性显著提高，但在更复杂领域中语义错误仍存在，这表明当前模型在推理能力方面的局限性。

Abstract: Certain strong LLMs have shown promise for zero-shot formal planning by
generating planning languages like PDDL. Yet, performance of most open-source
models under 50B parameters has been reported to be close to zero due to the
low-resource nature of these languages. We significantly improve their
performance via a series of lightweight pipelines that integrates documentation
retrieval with modular code generation and error refinement. With models like
Llama-4-Maverick, our best pipeline improves plan correctness from 0\% to over
80\% on the common BlocksWorld domain. However, while syntactic errors are
substantially reduced, semantic errors persist in more challenging domains,
revealing fundamental limitations in current models' reasoning
capabilities.\footnote{Our code and data can be found at
https://github.com/Nangxxxxx/PDDL-RAG

</details>


### [6] [Multimodal-enhanced Federated Recommendation: A Group-wise Fusion Approach](https://arxiv.org/abs/2509.19955)
*Chunxu Zhang,Weipeng Zhang,Guodong Long,Zhiheng Xue,Riting Xia,Bo Yang*

Main category: cs.IR

TL;DR: 提出了一种新的多模态融合机制GFMFR，能够提高联邦推荐系统的性能，并优化多模态特征的集成。


<details>
  <summary>Details</summary>
Motivation: 目前，多模态特征的集成在联邦推荐领域仍面临着效率、分布异质性和精细化对齐等挑战。

Method: GFMFR将多模态表示学习转移到服务器端，并采用高容量编码器生成表达性表示，以减轻客户端负担。同时，利用一种群组感知的项目表示融合方法，实现相似用户间的精细化知识共享，并保留个性化偏好。

Result: GFMFR在五个公共基准数据集上，始终优于现有多模态联邦推荐系统。

Conclusion: GFMFR能够通过增加对多模态特征的支持，无缝集成到现有的联邦推荐系统中，显著提升其性能。

Abstract: Federated Recommendation (FR) is a new learning paradigm to tackle the
learn-to-rank problem in a privacy-preservation manner. How to integrate
multi-modality features into federated recommendation is still an open
challenge in terms of efficiency, distribution heterogeneity, and fine-grained
alignment. To address these challenges, we propose a novel multimodal fusion
mechanism in federated recommendation settings (GFMFR). Specifically, it
offloads multimodal representation learning to the server, which stores item
content and employs a high-capacity encoder to generate expressive
representations, alleviating client-side overhead. Moreover, a group-aware item
representation fusion approach enables fine-grained knowledge sharing among
similar users while retaining individual preferences. The proposed fusion loss
could be simply plugged into any existing federated recommender systems
empowering their capability by adding multi-modality features. Extensive
experiments on five public benchmark datasets demonstrate that GFMFR
consistently outperforms state-of-the-art multimodal FR baselines.

</details>


### [7] [Cascade! Human in the loop shortcomings can increase the risk of failures in recommender systems](https://arxiv.org/abs/2509.20099)
*Wm. Matthew Kennedy,Nishanshi Shukla,Cigdem Patlak,Blake Chambers,Theodora Skeadas,Tuesday,Kingsley Owadara,Aayush Dhanotiya*

Main category: cs.IR

TL;DR: 研究表明，“人类在环”推荐系统设计中的监督可能导致系统失败，提出了两项建议以改善监督。


<details>
  <summary>Details</summary>
Motivation: 旨在揭示由于推荐系统设计中“人类监督”所带来的未充分描述的风险，以及展示人类监督可能导致的系统“级联”或“复合”失败的可能性。

Method: 分析推荐系统中的人类监督和信息环境之间相互影响的风险，以及“人类在环”实践中的局限性。

Result: 发现人类监督可能导致推荐系统中的“级联”或“复合”失败，并探讨了三种常见部署环境中的独特动态如何增加这些风险。

Conclusion: 需要对推荐系统中的人类监督进行更深入的探讨，以理解其潜在风险，并实施建议以确保社会责任。

Abstract: Recommender systems are among the most commonly deployed systems today.
Systems design approaches to AI-powered recommender systems have done well to
urge recommender system developers to follow more intentional data collection,
curation, and management procedures. So too has the "human-in-the-loop"
paradigm been widely adopted, primarily to address the issue of accountability.
However, in this paper, we take the position that human oversight in
recommender system design also entails novel risks that have yet to be fully
described. These risks are "codetermined" by the information context in which
such systems are often deployed. Furthermore, new knowledge of the shortcomings
of "human-in-the-loop" practices to deliver meaningful oversight of other AI
systems suggest that they may also be inadequate for achieving socially
responsible recommendations. We review how the limitations of human oversight
may increase the chances of a specific kind of failure: a "cascade" or
"compound" failure. We then briefly explore how the unique dynamics of three
common deployment contexts can make humans in the loop more likely to fail in
their oversight duties. We then conclude with two recommendations.

</details>


### [8] [Intelligent Algorithm Selection for Recommender Systems: Meta-Learning via in-depth algorithm feature engineering](https://arxiv.org/abs/2509.20134)
*Jarne Mathi Decker*

Main category: cs.IR

TL;DR: 尽管算法特征提升了元学习者的Top-1选择精准度，但在Top-3选择上表现不佳，用户特征仍是预测性能的主要因素。


<details>
  <summary>Details</summary>
Motivation: 由于“无免费午餐”定理，无法为所有用户找到最佳的推荐算法，这产生了显著的算法选择问题。

Method: 通过构建全面的特征集来显式表征推荐算法，包括静态代码度量、抽象语法树属性、行为性能标志和高层次概念特征。

Result: 使用用户和算法特征的元学习者在NDCG@10上的表现为0.143，较单一最佳算法基线（0.128）有11.7%的统计显著性提升，但总体表现未超过仅使用用户特征的元学习者（0.144）。

Conclusion: 用户特征在推荐系统的算法选择中具有压倒性的预测能力，而充分利用算法特征来增强整体性能仍然极具挑战性。

Abstract: The "No Free Lunch" theorem dictates that no single recommender algorithm is
optimal for all users, creating a significant Algorithm Selection Problem.
Standard meta-learning approaches aim to solve this by selecting an algorithm
based on user features, but treat the fundamentally diverse algorithms
themselves as equivalent, "black-box" choices. This thesis investigates the
impact of overcoming this limitation by engineering a comprehensive feature set
to explicitly characterize the algorithms themselves. We combine static code
metrics, Abstract Syntax Tree properties, behavioral performance landmarks, and
high-level conceptual features. We evaluate two meta-learners across five
datasets: a baseline using only user features and our proposed model using both
user and algorithm features. Our results show that the meta-learner augmented
with algorithm features achieves an average NDCG@10 of 0.143, a statistically
significant improvement of 11.7% over the Single Best Algorithm baseline
(0.128). However, we found that the inclusion of algorithm features did not
lead to an improvement in overall NDCG@10 over the meta learner using only user
features (0.144). While adding algorithm features to the meta-learner did
improve its Top-1 selection accuracy (+16.1%), this was counterbalanced by
leading to a lower Top-3 accuracy (-10.7%). We conclude that for the per-user
algorithm selection task in recommender systems, the predictive power of user
features is overwhelmingly dominant. While algorithm features improve selection
precision, unlocking their potential to boost overall performance remains a
non-trivial challenge.

</details>


### [9] [Multimodal Representation-disentangled Information Bottleneck for Multimodal Recommendation](https://arxiv.org/abs/2509.20225)
*Hui Wang,Jinghui Qin,Wushao Wen,Qingling Li,Shanshan Zhong,Zhongzhan Huang*

Main category: cs.IR

TL;DR: 文章提出了一种多模态信息解耦瓶颈框架MRdIB，通过信息压缩和分解，优化多模态推荐系统表现。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态推荐系统在整合多种信息源时，经常会受到冗余和不相关信息的干扰，导致系统性能下降。为了解决这一问题，需要一种能够有效过滤噪声，同时建模模态间复杂关系的方法。

Method: 提出了一种名为MRdIB的新框架。首先使用多模态信息瓶颈压缩输入表示，从而有效过滤与任务无关的噪声，同时保留丰富的语义信息。然后基于与推荐目标的关系，将信息分解为独特、冗余和协同组件，通过对这些组件设定约束条件，优化学习目标，指导模型学习更强大且具备解耦能力的表示。

Result: 通过在多个竞争模型和三个基准数据集上的广泛实验，证明了MRdIB在提升多模态推荐系统方面的有效性和灵活性。

Conclusion: MRdIB框架通过独特、冗余和协同信息的学习目标优化，解决了多模态推荐系统中的噪声过滤和信息解耦问题，提升了推荐性能。

Abstract: Multimodal data has significantly advanced recommendation systems by
integrating diverse information sources to model user preferences and item
characteristics. However, these systems often struggle with redundant and
irrelevant information, which can degrade performance. Most existing methods
either fuse multimodal information directly or use rigid architectural
separation for disentanglement, failing to adequately filter noise and model
the complex interplay between modalities. To address these challenges, we
propose a novel framework, the Multimodal Representation-disentangled
Information Bottleneck (MRdIB). Concretely, we first employ a Multimodal
Information Bottleneck to compress the input representations, effectively
filtering out task-irrelevant noise while preserving rich semantic information.
Then, we decompose the information based on its relationship with the
recommendation target into unique, redundant, and synergistic components. We
achieve this decomposition with a series of constraints: a unique information
learning objective to preserve modality-unique signals, a redundant information
learning objective to minimize overlap, and a synergistic information learning
objective to capture emergent information. By optimizing these objectives,
MRdIB guides a model to learn more powerful and disentangled representations.
Extensive experiments on several competitive models and three benchmark
datasets demonstrate the effectiveness and versatility of our MRdIB in
enhancing multimodal recommendation.

</details>


### [10] [Muse-it: A Tool for Analyzing Music Discourse on Reddit](https://arxiv.org/abs/2509.20228)
*Jatin Agarwala,George Paul,Nemani Harsha Vardhan,Vinoo Alluri*

Main category: cs.IR

TL;DR: 本文介绍了Muse-it，一个能够高效收集和分析Reddit音乐相关讨论的平台，帮助音乐研究人员探索在线自然音乐参与。


<details>
  <summary>Details</summary>
Motivation: 由于社交媒体平台如Reddit上存在大量自然音乐讨论数据，且传统音乐研究难以处理如此大规模数据，亟需实施新的技术来解析这些数据。

Method: 开发了Muse-it平台，能够检索和处理Reddit上的音乐相关讨论数据，支持主题建模、时间趋势分析和聚类分析，并具有动态可视化功能。

Result: Muse-it平台能够为音乐研究人员提供便捷的工具来获取和分析Reddit上的音乐自然讨论，包括音乐相关外链和详细的曲目级元数据。

Conclusion: Muse-it平台简化了音乐研究人员从Reddit获取和分析大规模音乐相关讨论数据的过程，为理解在线音乐参与提供了新的视角和方法。

Abstract: Music engagement spans diverse interactions with music, from selection and
emotional response to its impact on behavior, identity, and social connections.
Social media platforms provide spaces where such engagement can be observed in
natural, unprompted conversations. Advances in natural language processing
(NLP) and big data analytics make it possible to analyze these discussions at
scale, extending music research to broader contexts. Reddit, in particular,
offers anonymity that encourages diverse participation and yields rich
discourse on music in ecological settings. Yet the scale of this data requires
tools to extract, process, and analyze it effectively. We present Muse-it, a
platform that retrieves comprehensive Reddit data centered on user-defined
queries. It aggregates posts from across subreddits, supports topic modeling,
temporal trend analysis, and clustering, and enables efficient study of
large-scale discourse. Muse-it also identifies music-related hyperlinks (e.g.,
Spotify), retrieves track-level metadata such as artist, album, release date,
genre, popularity, and lyrics, and links these to the discussions. An
interactive interface provides dynamic visualizations of the collected data.
Muse-it thus offers an accessible way for music researchers to gather and
analyze big data, opening new avenues for understanding music engagement as it
naturally unfolds online.

</details>
