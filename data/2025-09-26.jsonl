{"id": "2509.20617", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.20617", "abs": "https://arxiv.org/abs/2509.20617", "authors": ["Eric Fithian", "Kirill Skobelev"], "title": "DELM: a Python toolkit for Data Extraction with Language Models", "comment": null, "summary": "Large Language Models (LLMs) have become powerful tools for annotating\nunstructured data. However, most existing workflows rely on ad hoc scripts,\nmaking reproducibility, robustness, and systematic evaluation difficult. To\naddress these challenges, we introduce DELM (Data Extraction with Language\nModels), an open-source Python toolkit designed for rapid experimental\niteration of LLM-based data extraction pipelines and for quantifying the\ntrade-offs between them. DELM minimizes boilerplate code and offers a modular\nframework with structured outputs, built-in validation, flexible data-loading\nand scoring strategies, and efficient batch processing. It also includes robust\nsupport for working with LLM APIs, featuring retry logic, result caching,\ndetailed cost tracking, and comprehensive configuration management. We showcase\nDELM's capabilities through two case studies: one featuring a novel prompt\noptimization algorithm, and another illustrating how DELM quantifies trade-offs\nbetween cost and coverage when selecting keywords to decide which paragraphs to\npass to an LLM. DELM is available at\n\\href{https://github.com/Center-for-Applied-AI/delm}{\\texttt{github.com/Center-for-Applied-AI/delm}}."}
{"id": "2509.20769", "categories": ["cs.IR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.20769", "abs": "https://arxiv.org/abs/2509.20769", "authors": ["Tuo Zhang", "Yuechun Sun", "Ruiliang Liu"], "title": "Provenance Analysis of Archaeological Artifacts via Multimodal RAG Systems", "comment": null, "summary": "In this work, we present a retrieval-augmented generation (RAG)-based system\nfor provenance analysis of archaeological artifacts, designed to support expert\nreasoning by integrating multimodal retrieval and large vision-language models\n(VLMs). The system constructs a dual-modal knowledge base from reference texts\nand images, enabling raw visual, edge-enhanced, and semantic retrieval to\nidentify stylistically similar objects. Retrieved candidates are synthesized by\nthe VLM to generate structured inferences, including chronological,\ngeographical, and cultural attributions, alongside interpretive justifications.\nWe evaluate the system on a set of Eastern Eurasian Bronze Age artifacts from\nthe British Museum. Expert evaluation demonstrates that the system produces\nmeaningful and interpretable outputs, offering scholars concrete starting\npoints for analysis and significantly alleviating the cognitive burden of\nnavigating vast comparative corpora."}
{"id": "2509.20804", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.20804", "abs": "https://arxiv.org/abs/2509.20804", "authors": ["Meng Yuan", "Justin Zobel"], "title": "Performance Consistency of Learning Methods for Information Retrieval Tasks", "comment": null, "summary": "A range of approaches have been proposed for estimating the accuracy or\nrobustness of the measured performance of IR methods. One is to use\nbootstrapping of test sets, which, as we confirm, provides an estimate of\nvariation in performance. For IR methods that rely on a seed, such as those\nthat involve machine learning, another approach is to use a random set of seeds\nto examine performance variation. Using three different IR tasks we have used\nsuch randomness to examine a range of traditional statistical learning models\nand transformer-based learning models. While the statistical models are stable,\nthe transformer models show huge variation as seeds are changed. In 9 of 11\ncases the F1-scores (in the range 0.0--1.0) had a standard deviation of over\n0.075; while 7 of 11 precision values (also in the range 0.0--1.0) had a\nstandard deviation of over 0.125. This is in a context where differences of\nless than 0.02 have been used as evidence of method improvement. Our findings\nhighlight the vulnerability of transformer models to training instabilities and\nmoreover raise questions about the reliability of previous results, thus\nunderscoring the need for rigorous evaluation practices."}
{"id": "2509.20883", "categories": ["cs.IR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.20883", "abs": "https://arxiv.org/abs/2509.20883", "authors": ["Hua Zong", "Qingtao Zeng", "Zhengxiong Zhou", "Zhihua Han", "Zhensong Yan", "Mingjie Liu", "Hechen Sun", "Jiawei Liu", "Yiwen Hu", "Qi Wang", "YiHan Xian", "Wenjie Guo", "Houyuan Xiang", "Zhiyuan Zeng", "Xiangrong Sheng", "Bencheng Yan", "Nan Hu", "Yuheng Huang", "Jinqing Lian", "Ziru Xu", "Yan Zhang", "Ju Huang", "Siran Yang", "Huimin Yi", "Jiamang Wang", "Pengjie Wang", "Han Zhu", "Jian Wu", "Dan Ou", "Jian Xu", "Haihong Tang", "Yuning Jiang", "Bo Zheng", "Lin Qu"], "title": "RecIS: Sparse to Dense, A Unified Training Framework for Recommendation Models", "comment": null, "summary": "In this paper, we propose RecIS, a unified Sparse-Dense training framework\ndesigned to achieve two primary goals: 1. Unified Framework To create a Unified\nsparse-dense training framework based on the PyTorch ecosystem that meets the\ntraining needs of industrial-grade recommendation models that integrated with\nlarge models. 2.System Optimization To optimize the sparse component, offering\nsuperior efficiency over the TensorFlow-based recommendation models. The dense\ncomponent, meanwhile, leverages existing optimization technologies within the\nPyTorch ecosystem. Currently, RecIS is being used in Alibaba for numerous\nlarge-model enhanced recommendation training tasks, and some traditional sparse\nmodels have also begun training in it."}
{"id": "2509.20904", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.20904", "abs": "https://arxiv.org/abs/2509.20904", "authors": ["Kairui Fu", "Tao Zhang", "Shuwen Xiao", "Ziyang Wang", "Xinming Zhang", "Chenchi Zhang", "Yuliang Yan", "Junjun Zheng", "Yu Li", "Zhihong Chen", "Jian Wu", "Xiangheng Kong", "Shengyu Zhang", "Kun Kuang", "Yuning Jiang", "Bo Zheng"], "title": "FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial Datasets", "comment": null, "summary": "Semantic identifiers (SIDs) have gained increasing attention in generative\nretrieval (GR) due to their meaningful semantic discriminability. However,\ncurrent research on SIDs faces three main challenges: (1) the absence of\nlarge-scale public datasets with multimodal features, (2) limited investigation\ninto optimization strategies for SID generation, which typically rely on costly\nGR training for evaluation, and (3) slow online convergence in industrial\ndeployment. To address these challenges, we propose FORGE, a comprehensive\nbenchmark for FOrming semantic identifieR in Generative rEtrieval with\nindustrial datasets. Specifically, FORGE is equipped with a dataset comprising\n14 billion user interactions and multimodal features of 250 million items\nsampled from Taobao, one of the biggest e-commerce platforms in China.\nLeveraging this dataset, FORGE explores several optimizations to enhance the\nSID construction and validates their effectiveness via offline experiments\nacross different settings and tasks. Further online analysis conducted on our\nplatform, which serves over 300 million users daily, reveals a 0.35% increase\nin transaction count, highlighting the practical impact of our method.\nRegarding the expensive SID validation accompanied by the full training of GRs,\nwe propose two novel metrics of SID that correlate positively with\nrecommendation performance, enabling convenient evaluations without any GR\ntraining. For real-world applications, FORGE introduces an offline pretraining\nschema that reduces online convergence by half. The code and data are available\nat https://github.com/selous123/al_sid."}
{"id": "2509.20940", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.20940", "abs": "https://arxiv.org/abs/2509.20940", "authors": ["Su Liu", "Bin Bi", "Jan Bakus", "Paritosh Kumar Velalam", "Vijay Yella", "Vinod Hegde"], "title": "Markup Language Modeling for Web Document Understanding", "comment": null, "summary": "Web information extraction (WIE) is an important part of many e-commerce\nsystems, supporting tasks like customer analysis and product recommendation. In\nthis work, we look at the problem of building up-to-date product databases by\nextracting detailed information from shopping review websites. We fine-tuned\nMarkupLM on product data gathered from review sites of different sizes and then\ndeveloped a variant we call MarkupLM++, which extends predictions to internal\nnodes of the DOM tree. Our experiments show that using larger and more diverse\ntraining sets improves extraction accuracy overall. We also find that including\ninternal nodes helps with some product attributes, although it leads to a\nslight drop in overall performance. The final model reached a precision of\n0.906, recall of 0.724, and an F1 score of 0.805."}
{"id": "2509.20989", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.20989", "abs": "https://arxiv.org/abs/2509.20989", "authors": ["Zhangchi Zhu", "Wei Zhang"], "title": "Rejuvenating Cross-Entropy Loss in Knowledge Distillation for Recommender Systems", "comment": null, "summary": "This paper analyzes Cross-Entropy (CE) loss in knowledge distillation (KD)\nfor recommender systems. KD for recommender systems targets at distilling\nrankings, especially among items most likely to be preferred, and can only be\ncomputed on a small subset of items. Considering these features, we reveal the\nconnection between CE loss and NDCG in the field of KD. We prove that when\nperforming KD on an item subset, minimizing CE loss maximizes the lower bound\nof NDCG, only if an assumption of closure is satisfied. It requires that the\nitem subset consists of the student's top items. However, this contradicts our\ngoal of distilling rankings of the teacher's top items. We empirically\ndemonstrate the vast gap between these two kinds of top items. To bridge the\ngap between our goal and theoretical support, we propose Rejuvenated\nCross-Entropy for Knowledge Distillation (RCE-KD). It splits the top items\ngiven by the teacher into two subsets based on whether they are highly ranked\nby the student. For the subset that defies the condition, a sampling strategy\nis devised to use teacher-student collaboration to approximate our assumption\nof closure. We also combine the losses on the two subsets adaptively. Extensive\nexperiments demonstrate the effectiveness of our method. Our code is available\nat https://anonymous.4open.science/r/RCE-KD."}
{"id": "2509.21179", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.21179", "abs": "https://arxiv.org/abs/2509.21179", "authors": ["Huimin Yan", "Longfei Xu", "Junjie Sun", "Ni Ou", "Wei Luo", "Xing Tan", "Ran Cheng", "Kaikui Liu", "Xiangxiang Chu"], "title": "IntSR: An Integrated Generative Framework for Search and Recommendation", "comment": null, "summary": "Generative recommendation has emerged as a promising paradigm, demonstrating\nremarkable results in both academic benchmarks and industrial applications.\nHowever, existing systems predominantly focus on unifying retrieval and ranking\nwhile neglecting the integration of search and recommendation (S&R) tasks. What\nmakes search and recommendation different is how queries are formed: search\nuses explicit user requests, while recommendation relies on implicit user\ninterests. As for retrieval versus ranking, the distinction comes down to\nwhether the queries are the target items themselves. Recognizing the query as\ncentral element, we propose IntSR, an integrated generative framework for S&R.\nIntSR integrates these disparate tasks using distinct query modalities. It also\naddresses the increased computational complexity associated with integrated S&R\nbehaviors and the erroneous pattern learning introduced by a dynamically\nchanging corpus. IntSR has been successfully deployed across various scenarios\nin Amap, leading to substantial improvements in digital asset's GMV(+3.02%),\nPOI recommendation's CTR(+2.76%), and travel mode suggestion's ACC(+5.13%)."}
{"id": "2509.21317", "categories": ["cs.IR", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.21317", "abs": "https://arxiv.org/abs/2509.21317", "authors": ["Jiakai Tang", "Yujie Luo", "Xunke Xi", "Fei Sun", "Xueyang Feng", "Sunhao Dai", "Chao Yi", "Dian Chen", "Zhujin Gao", "Yang Li", "Xu Chen", "Wen Chen", "Jian Wu", "Yuning Jiang", "Bo Zheng"], "title": "Interactive Recommendation Agent with Active User Commands", "comment": "Under Review", "summary": "Traditional recommender systems rely on passive feedback mechanisms that\nlimit users to simple choices such as like and dislike. However, these\ncoarse-grained signals fail to capture users' nuanced behavior motivations and\nintentions. In turn, current systems cannot also distinguish which specific\nitem attributes drive user satisfaction or dissatisfaction, resulting in\ninaccurate preference modeling. These fundamental limitations create a\npersistent gap between user intentions and system interpretations, ultimately\nundermining user satisfaction and harming system effectiveness.\n  To address these limitations, we introduce the Interactive Recommendation\nFeed (IRF), a pioneering paradigm that enables natural language commands within\nmainstream recommendation feeds. Unlike traditional systems that confine users\nto passive implicit behavioral influence, IRF empowers active explicit control\nover recommendation policies through real-time linguistic commands. To support\nthis paradigm, we develop RecBot, a dual-agent architecture where a Parser\nAgent transforms linguistic expressions into structured preferences and a\nPlanner Agent dynamically orchestrates adaptive tool chains for on-the-fly\npolicy adjustment. To enable practical deployment, we employ\nsimulation-augmented knowledge distillation to achieve efficient performance\nwhile maintaining strong reasoning capabilities. Through extensive offline and\nlong-term online experiments, RecBot shows significant improvements in both\nuser satisfaction and business outcomes."}
