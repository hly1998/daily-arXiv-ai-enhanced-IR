{"id": "2508.20289", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.20289", "abs": "https://arxiv.org/abs/2508.20289", "authors": ["Tonmoy Hasan", "Razvan Bunescu"], "title": "A Survey of Affective Recommender Systems: Modeling Attitudes, Emotions, and Moods for Personalization", "comment": null, "summary": "Affective Recommender Systems are an emerging class of intelligent systems\nthat aim to enhance personalization by aligning recommendations with users'\naffective states. Reflecting a growing interest, a number of surveys have been\npublished in this area, however they lack an organizing taxonomy grounded in\npsychology and they often study only specific types of affective states or\napplication domains. This survey addresses these limitations by providing a\ncomprehensive, systematic review of affective recommender systems across\ndiverse domains. Drawing from Scherer's typology of affective states, we\nintroduce a classification scheme that organizes systems into four main\ncategories: attitude aware, emotion aware, mood aware, and hybrid. We further\ndocument affective signal extraction techniques, system architectures, and\napplication areas, highlighting key trends, limitations, and open challenges.\nAs future research directions, we emphasize hybrid models that leverage\nmultiple types of affective states across different modalities, the development\nof large-scale affect-aware datasets, and the need to replace the folk\nvocabulary of affective states with a more precise terminology grounded in\ncognitive and social psychology. Through its systematic review of existing\nresearch and challenges, this survey aims to serve as a comprehensive reference\nand a useful guide for advancing academic research and industry applications in\naffect-driven personalization.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u5173\u4e8e\u60c5\u611f\u63a8\u8350\u7cfb\u7edf\u7684\u5168\u9762\u7cfb\u7edf\u56de\u987e\uff0c\u5f15\u5165\u4e86\u65b0\u7684\u5206\u7c7b\u65b9\u6848\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7684\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u76ee\u524d\u7684\u60c5\u611f\u63a8\u8350\u7cfb\u7edf\u7814\u7a76\u7f3a\u4e4f\u57fa\u4e8e\u5fc3\u7406\u5b66\u7684\u5206\u7c7b\uff0c\u4e14\u7814\u7a76\u8f83\u4e3a\u7247\u9762\uff0c\u4ec5\u5173\u6ce8\u7279\u5b9a\u60c5\u611f\u72b6\u6001\u6216\u5e94\u7528\u9886\u57df\u3002", "method": "\u901a\u8fc7\u5206\u6790Scherer\u7684\u60c5\u611f\u72b6\u6001\u5206\u7c7b\u6cd5\uff0c\u5efa\u7acb\u4e00\u4e2a\u5206\u7c7b\u7cfb\u7edf\uff0c\u5c06\u60c5\u611f\u63a8\u8350\u7cfb\u7edf\u5206\u4e3a\u6001\u5ea6\u611f\u77e5\u3001\u60c5\u611f\u611f\u77e5\u3001\u60c5\u7eea\u611f\u77e5\u548c\u6df7\u5408\u578b\u56db\u5927\u7c7b\u3002", "result": "\u5c55\u793a\u60c5\u611f\u4fe1\u53f7\u63d0\u53d6\u6280\u672f\u3001\u7cfb\u7edf\u67b6\u6784\u548c\u5e94\u7528\u9886\u57df\uff0c\u5e76\u6307\u660e\u5173\u952e\u8d8b\u52bf\u3001\u9650\u5236\u548c\u5f00\u653e\u6027\u6311\u6218\u3002", "conclusion": "\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u5f00\u53d1\u5927\u89c4\u6a21\u60c5\u611f\u611f\u77e5\u6570\u636e\u96c6\u548c\u4f7f\u7528\u66f4\u7cbe\u786e\u7684\u5fc3\u7406\u5b66\u672f\u8bed\u3002\u65e8\u5728\u4e3a\u63a8\u52a8\u5b66\u672f\u7814\u7a76\u548c\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u60c5\u611f\u9a71\u52a8\u4e2a\u6027\u5316\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2508.20312", "categories": ["cs.IR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.20312", "abs": "https://arxiv.org/abs/2508.20312", "authors": ["Ben Kabongo", "Vincent Guigue", "Pirmin Lemberger"], "title": "ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations", "comment": "10 pages, 3 figures, 6 Tables", "summary": "Collaborative filtering drives many successful recommender systems but\nstruggles with fine-grained user-item interactions and explainability. As users\nincreasingly seek transparent recommendations, generating textual explanations\nthrough language models has become a critical research area. Existing methods\nemploy either RNNs or Transformers. However, RNN-based approaches fail to\nleverage the capabilities of pre-trained Transformer models, whereas\nTransformer-based methods often suffer from suboptimal adaptation and neglect\naspect modeling, which is crucial for personalized explanations. We propose\nELIXIR (Efficient and LIghtweight model for eXplaIning Recommendations), a\nmulti-task model combining rating prediction with personalized review\ngeneration. ELIXIR jointly learns global and aspect-specific representations of\nusers and items, optimizing overall rating, aspect-level ratings, and review\ngeneration, with personalized attention to emphasize aspect importance. Based\non a T5-small (60M) model, we demonstrate the effectiveness of our aspect-based\narchitecture in guiding text generation in a personalized context, where\nstate-of-the-art approaches exploit much larger models but fail to match user\npreferences as well. Experimental results on TripAdvisor and RateBeer\ndemonstrate that ELIXIR significantly outperforms strong baseline models,\nespecially in review generation.", "AI": {"tldr": "ELIXIR\u662f\u4e00\u79cd\u7ed3\u5408\u8bc4\u5206\u9884\u6d4b\u4e0e\u4e2a\u6027\u5316\u8bc4\u8bba\u751f\u6210\u7684\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u5728\u591a\u4efb\u52a1\u5b66\u4e60\u4e0b\u6709\u6548\u63d0\u9ad8\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6587\u672c\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u968f\u7740\u7528\u6237\u5bf9\u63a8\u8350\u900f\u660e\u5ea6\u9700\u6c42\u7684\u589e\u52a0\uff0c\u751f\u6210\u6587\u672c\u89e3\u91ca\u7684\u4efb\u52a1\u53d8\u5f97\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u6a21\u578b\u6548\u679c\u4e0d\u4f73\u548c\u5ffd\u89c6\u5173\u952e\u65b9\u9762\u5efa\u6a21\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aELIXIR\u7684\u591a\u4efb\u52a1\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u7ed3\u5408\u8bc4\u5206\u9884\u6d4b\u4e0e\u4e2a\u6027\u5316\u8bc4\u8bba\u751f\u6210\uff0c\u901a\u8fc7\u540c\u65f6\u5b66\u4e60\u7528\u6237\u548c\u9879\u76ee\u7684\u5168\u5c40\u548c\u65b9\u9762\u7279\u5b9a\u8868\u793a\u6765\u4f18\u5316\u8bc4\u5206\u548c\u8bc4\u8bba\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cELIXIR\u5728TripAdvisor\u548cRateBeer\u5e73\u53f0\u4e0a\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u5c24\u5176\u662f\u5728\u8bc4\u8bba\u751f\u6210\u65b9\u9762\u3002", "conclusion": "ELIXIR\u6709\u6548\u7ed3\u5408\u4e86\u591a\u4efb\u52a1\u5b66\u4e60\u6765\u63d0\u9ad8\u4e2a\u6027\u5316\u63a8\u8350\u89e3\u91ca\u7684\u8d28\u91cf\uff0c\u5229\u7528\u66f4\u8f7b\u91cf\u7ea7\u7684\u6a21\u578b\u5728\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2508.20359", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.20359", "abs": "https://arxiv.org/abs/2508.20359", "authors": ["Shijia Wang", "Tianpei Ouyang", "Qiang Xiao", "Dongjing Wang", "Yintao Ren", "Songpei Xu", "Da Guo", "Chuanjiang Luo"], "title": "Progressive Semantic Residual Quantization for Multimodal-Joint Interest Modeling in Music Recommendation", "comment": null, "summary": "In music recommendation systems, multimodal interest learning is pivotal,\nwhich allows the model to capture nuanced preferences, including textual\nelements such as lyrics and various musical attributes such as different\ninstruments and melodies. Recently, methods that incorporate multimodal content\nfeatures through semantic IDs have achieved promising results. However,\nexisting methods suffer from two critical limitations: 1) intra-modal semantic\ndegradation, where residual-based quantization processes gradually decouple\ndiscrete IDs from original content semantics, leading to semantic drift; and 2)\ninter-modal modeling gaps, where traditional fusion strategies either overlook\nmodal-specific details or fail to capture cross-modal correlations, hindering\ncomprehensive user interest modeling. To address these challenges, we propose a\nnovel multimodal recommendation framework with two stages. In the first stage,\nour Progressive Semantic Residual Quantization (PSRQ) method generates\nmodal-specific and modal-joint semantic IDs by explicitly preserving the prefix\nsemantic feature. In the second stage, to model multimodal interest of users, a\nMulti-Codebook Cross-Attention (MCCA) network is designed to enable the model\nto simultaneously capture modal-specific interests and perceive cross-modal\ncorrelations. Extensive experiments on multiple real-world datasets demonstrate\nthat our framework outperforms state-of-the-art baselines. This framework has\nbeen deployed on one of China's largest music streaming platforms, and online\nA/B tests confirm significant improvements in commercial metrics, underscoring\nits practical value for industrial-scale recommendation systems.", "AI": {"tldr": "\u9488\u5bf9\u97f3\u4e50\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u591a\u6a21\u6001\u5174\u8da3\u5b66\u4e60\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u6e10\u8fdb\u8bed\u4e49\u6b8b\u5dee\u91cf\u5316\u548c\u591a\u7801\u7c3f\u4ea4\u53c9\u6ce8\u610f\u7f51\u7edc\u6765\u63d0\u9ad8\u63a8\u8350\u6548\u679c\uff0c\u5e76\u5728\u5b9e\u9645\u5e73\u53f0\u4e0a\u8bc1\u5b9e\u4e86\u5176\u5546\u4e1a\u4ef7\u503c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u8bed\u4e49\u6f02\u79fb\u548c\u6a21\u6001\u5efa\u6a21\u7f3a\u9677\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u7528\u6237\u5174\u8da3\u5efa\u6a21\u4e0d\u591f\u5168\u9762\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u63a8\u8350\u6846\u67b6\u3002", "method": "\u4e3a\u4e86\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u672c\u6587\u5728\u7b2c\u4e00\u9636\u6bb5\u91c7\u7528\u4e86\u6e10\u8fdb\u8bed\u4e49\u6b8b\u5dee\u91cf\u5316\uff08PSRQ\uff09\u65b9\u6cd5\uff0c\u4ee5\u751f\u6210\u7279\u5b9a\u6a21\u6001\u548c\u6a21\u6001\u8054\u5408\u7684\u8bed\u4e49ID\uff0c\u5e76\u5728\u7b2c\u4e8c\u9636\u6bb5\u5229\u7528\u591a\u7801\u7c3f\u4ea4\u53c9\u6ce8\u610f\uff08MCCA\uff09\u7f51\u7edc\u6765\u6355\u6349\u6a21\u6001\u7279\u5b9a\u5174\u8da3\u548c\u8de8\u6a21\u6001\u5173\u8054\u3002", "result": "\u901a\u8fc7\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u672c\u6587\u7684\u6846\u67b6\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u51c6\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u5df2\u5728\u4e2d\u56fd\u6700\u5927\u7684\u97f3\u4e50\u6d41\u5a92\u4f53\u5e73\u53f0\u4e4b\u4e00\u4e0a\u90e8\u7f72\uff0c\u7ebf\u4e0aA/B\u6d4b\u8bd5\u7ed3\u679c\u663e\u793a\u5546\u7528\u6307\u6807\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u591a\u6a21\u6001\u63a8\u8350\u6846\u67b6\u5728\u97f3\u4e50\u63a8\u8350\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6027\u80fd\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7528\u6237\u5174\u8da3\u7684\u6355\u6349\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5de5\u4e1a\u89c4\u6a21\u7684\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2508.20399", "categories": ["cs.IR", "68T50", "H.3.3; I.2.7"], "pdf": "https://arxiv.org/pdf/2508.20399", "abs": "https://arxiv.org/abs/2508.20399", "authors": ["Harshit Mishra", "Sucheta Soundarajan"], "title": "A Case Study of Balanced Query Recommendation on Wikipedia", "comment": "Accepted at FAccTRec 2025 workshop at recsys 2025", "summary": "Modern IR systems are an extremely important tool for seeking information. In\naddition to search, such systems include a number of query reformulation\nmethods, such as query expansion and query recommendations, to provide high\nquality results. However, results returned by such methods sometimes exhibit\nundesirable or wrongful bias with respect to protected categories such as\ngender or race. Our earlier work considered the problem of balanced query\nrecommendation, where instead of re-ranking a list of results based on fairness\nmeasures, the goal was to suggest queries that are relevant to a user's search\nquery but exhibit less bias than the original query. In this work, we present a\ncase study of BalancedQR using an extension of BalancedQR that handles biases\nin multiple dimensions. It employs a Pareto front approach that finds balanced\nqueries, optimizing for multiple objectives such as gender bias and regional\nbias, along with the relevance of returned results. We evaluate the extended\nversion of BalancedQR on a Wikipedia dataset.Our results demonstrate the\neffectiveness of our extension to BalancedQR framework and highlight the\nsignificant impact of subtle query wording,linguistic choice on retrieval.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5904\u7406\u591a\u7ef4\u5ea6\u504f\u89c1\u7684\u8054\u5408\u67e5\u8be2\u63a8\u8350\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u51cf\u5c11\u6027\u522b\u548c\u533a\u57df\u504f\u89c1\u65b9\u9762\u53d6\u5f97\u4e86\u826f\u597d\u7684\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u67e5\u8be2\u63a8\u8350\u8fc7\u7a0b\u4e2d\u56e0\u6027\u522b\u6216\u79cd\u65cf\u7b49\u53d7\u4fdd\u62a4\u7c7b\u522b\u5bfc\u81f4\u7684\u4e0d\u5f53\u504f\u89c1\u95ee\u9898\uff0c\u63d0\u4f9b\u66f4\u516c\u5e73\u7684\u67e5\u8be2\u5efa\u8bae\u3002", "method": "\u4f7f\u7528Pareto front\u65b9\u6cd5\u4ee5\u4f18\u5316\u6027\u522b\u548c\u533a\u57df\u504f\u89c1\u4e3a\u76ee\u6807\uff0c\u8fdb\u884c\u591a\u76ee\u6807\u4f18\u5316\u4ee5\u53d1\u73b0\u5e73\u8861\u67e5\u8be2\uff0c\u4ece\u800c\u51cf\u5c11\u504f\u89c1\u3002", "result": "\u5728Wikipedia\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6269\u5c55\u7248BalancedQR\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u67e5\u8be2\u63aa\u8f9e\u548c\u8bed\u8a00\u9009\u62e9\u5bf9\u68c0\u7d22\u7684\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u6269\u5c55\u7248BalancedQR\u6846\u67b6\u5728\u5904\u7406\u591a\u7ef4\u5ea6\u504f\u89c1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u67e5\u8be2\u63a8\u8350\u8fc7\u7a0b\u4e2d\u7684\u6027\u522b\u548c\u533a\u57df\u504f\u89c1\uff0c\u540c\u65f6\u4fdd\u6301\u7ed3\u679c\u7684\u76f8\u5173\u6027\u3002"}}
{"id": "2508.20400", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20400", "abs": "https://arxiv.org/abs/2508.20400", "authors": ["Yijia Sun", "Shanshan Huang", "Linxiao Che", "Haitao Lu", "Qiang Luo", "Kun Gai", "Guorui Zhou"], "title": "MPFormer: Adaptive Framework for Industrial Multi-Task Personalized Sequential Retriever", "comment": "CIKM 2025", "summary": "Modern industrial recommendation systems encounter a core challenge of\nmulti-stage optimization misalignment: a significant semantic gap exists\nbetween the multi-objective optimization paradigm widely used in the ranking\nphase and the single-objective modeling in the retrieve phase. Although the\nmainstream industry solution achieves multi-objective coverage through parallel\nmulti-path single-objective retrieval, this approach leads to linear growth of\ntraining and serving resources with the number of objectives and has inherent\nlimitations in handling loosely coupled objectives. This paper proposes the\nMPFormer, a dynamic multi-task Transformer framework, which systematically\naddresses the aforementioned issues through three innovative mechanisms. First,\nan objective-conditioned transformer that jointly encodes user behavior\nsequences and multi-task semantics through learnable attention modulation;\nsecond, personalized target weights are introduced to achieve dynamic\nadjustment of retrieval results; finally, user personalization information is\nincorporated into token representations and the Transformer structure to\nfurther enhance the model's representation ability. This framework has been\nsuccessfully integrated into Kuaishou short video recommendation system, stably\nserving over 400 million daily active users. It significantly improves user\ndaily engagement and system operational efficiency. Practical deployment\nverification shows that, compared with traditional solutions, it effectively\noptimizes the iterative paradigm of multi-objective retrieval while maintaining\nservice response speed, providing a scalable multi-objective solution for\nindustrial recommendation systems.", "AI": {"tldr": "MPFormer\u6846\u67b6\u89e3\u51b3\u4e86\u591a\u76ee\u6807\u68c0\u7d22\u7684\u8bed\u4e49\u5dee\u8ddd\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u63a8\u8350\u7cfb\u7edf\u6548\u7387\u548c\u7528\u6237\u53c2\u4e0e\u5ea6\uff0c\u5df2\u5728\u5feb\u624b\u77ed\u89c6\u9891\u63a8\u8350\u7cfb\u7edf\u4e2d\u6210\u529f\u5e94\u7528\u3002", "motivation": "\u73b0\u4ee3\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u5728\u6392\u540d\u548c\u68c0\u7d22\u9636\u6bb5\u5b58\u5728\u591a\u9636\u6bb5\u4f18\u5316\u672a\u5bf9\u9f50\u7684\u95ee\u9898\uff0c\u591a\u91cd\u76ee\u6807\u4f18\u5316\u4e0e\u5355\u76ee\u6807\u5efa\u6a21\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u8bed\u4e49\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u591a\u4efb\u52a1Transformer\u6846\u67b6MPFormer\uff0c\u901a\u8fc7\u4e09\u4e2a\u521b\u65b0\u673a\u5236\u89e3\u51b3\u95ee\u9898\uff1a\u76ee\u6807\u6761\u4ef6Transformer\uff0c\u5171\u540c\u7f16\u7801\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u548c\u591a\u4efb\u52a1\u8bed\u4e49\uff1b\u5f15\u5165\u4e2a\u6027\u5316\u76ee\u6807\u6743\u91cd\uff0c\u5b9e\u73b0\u52a8\u6001\u8c03\u6574\u68c0\u7d22\u7ed3\u679c\uff1b\u5c06\u7528\u6237\u4e2a\u6027\u5316\u4fe1\u606f\u6574\u5408\u5230\u4ee4\u724c\u8868\u793a\u548cTransformer\u7ed3\u6784\u4e2d\u3002", "result": "\u8be5\u6846\u67b6\u5df2\u6210\u529f\u96c6\u6210\u5230\u5feb\u624b\u77ed\u89c6\u9891\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u7a33\u5b9a\u670d\u52a1\u8d85\u8fc74\u4ebf\u6bcf\u65e5\u6d3b\u8dc3\u7528\u6237\uff0c\u663e\u8457\u63d0\u9ad8\u7528\u6237\u65e5\u5e38\u4e92\u52a8\u548c\u7cfb\u7edf\u8fd0\u8425\u6548\u7387\u3002\u5b9e\u8df5\u90e8\u7f72\u9a8c\u8bc1\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u89e3\u51b3\u65b9\u6848\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u6709\u6548\u4f18\u5316\u4e86\u591a\u76ee\u6807\u68c0\u7d22\u7684\u8fed\u4ee3\u8303\u5f0f\u3002", "conclusion": "MPFormer\u6846\u67b6\u6709\u6548\u4f18\u5316\u4e86\u591a\u76ee\u6807\u68c0\u7d22\u8fed\u4ee3\u8303\u5f0f\uff0c\u5e76\u5728\u4fdd\u6301\u670d\u52a1\u54cd\u5e94\u901f\u5ea6\u7684\u540c\u65f6\uff0c\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.20401", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.20401", "abs": "https://arxiv.org/abs/2508.20401", "authors": ["Alexandre Andre", "Gauthier Roy", "Eva Dyer", "Kai Wang"], "title": "Revealing Potential Biases in LLM-Based Recommender Systems in the Cold Start Setting", "comment": "In Proceedings of 2nd Workshop on Evaluating and Applying\n  Recommendation Systems with Large Language Models (EARL) at RecSys 2025 (EARL\n  2025)", "summary": "Large Language Models (LLMs) are increasingly used for recommendation tasks\ndue to their general-purpose capabilities. While LLMs perform well in\nrich-context settings, their behavior in cold-start scenarios, where only\nlimited signals such as age, gender, or language are available, raises fairness\nconcerns because they may rely on societal biases encoded during pretraining.\nWe introduce a benchmark specifically designed to evaluate fairness in\nzero-context recommendation. Our modular pipeline supports configurable\nrecommendation domains and sensitive attributes, enabling systematic and\nflexible audits of any open-source LLM. Through evaluations of state-of-the-art\nmodels (Gemma 3 and Llama 3.2), we uncover consistent biases across\nrecommendation domains (music, movies, and colleges) including gendered and\ncultural stereotypes. We also reveal a non-linear relationship between model\nsize and fairness, highlighting the need for nuanced analysis.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u5728\u96f6\u4e0a\u4e0b\u6587\u63a8\u8350\u4e2d\uff0cLLM\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u53d1\u73b0\u5176\u5728\u97f3\u4e50\u3001\u7535\u5f71\u548c\u5927\u5b66\u9886\u57df\u4e2d\u5b58\u5728\u6027\u522b\u548c\u6587\u5316\u504f\u89c1\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u8350\u4efb\u52a1\u4e2d\u7684\u666e\u904d\u4f7f\u7528\u5f15\u53d1\u4e86\u5173\u6ce8\uff0c\u7279\u522b\u662f\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e2d\uff0c\u6a21\u578b\u53ef\u80fd\u4f9d\u8d56\u4e8e\u9884\u8bad\u7ec3\u671f\u95f4\u7f16\u7801\u7684\u793e\u4f1a\u504f\u89c1\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684\u7ba1\u9053\u7cfb\u7edf\uff0c\u652f\u6301\u53ef\u914d\u7f6e\u7684\u63a8\u8350\u9886\u57df\u548c\u654f\u611f\u5c5e\u6027\uff0c\u4ece\u800c\u7cfb\u7edf\u5730\u5ba1\u67e5\u4efb\u4f55\u5f00\u6e90\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u7ecf\u8fc7\u5bf9\u5148\u8fdb\u6a21\u578bGemma 3\u548cLlama 3.2\u7684\u8bc4\u4f30\uff0c\u53d1\u73b0\u8fd9\u4e9b\u6a21\u578b\u5728\u63a8\u8350\u9886\u57df\uff08\u97f3\u4e50\u3001\u7535\u5f71\u548c\u5927\u5b66\uff09\u4e2d\u5b58\u5728\u4e00\u81f4\u7684\u6027\u522b\u548c\u6587\u5316\u504f\u89c1\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u63ed\u793a\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u51b7\u542f\u52a8\u63a8\u8350\u573a\u666f\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u96f6\u4e0a\u4e0b\u6587\u63a8\u8350\u4e2d\uff0c\u5305\u62ec\u6027\u522b\u548c\u6587\u5316\u504f\u89c1\u3002"}}
{"id": "2508.20408", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.20408", "abs": "https://arxiv.org/abs/2508.20408", "authors": ["Haoyu Wu", "Qingcheng Zeng", "Kaize Ding"], "title": "Fact or Facsimile? Evaluating the Factual Robustness of Modern Retrievers", "comment": "Proceedings of the 34th ACM International Conference on Information\n  and Knowledge Management", "summary": "Dense retrievers and rerankers are central to retrieval-augmented generation\n(RAG) pipelines, where accurately retrieving factual information is crucial for\nmaintaining system trustworthiness and defending against RAG poisoning.\nHowever, little is known about how much factual competence these components\ninherit or lose from the large language models (LLMs) they are based on. We\npair 12 publicly released embedding checkpoints with their original base LLMs\nand evaluate both sets on a factuality benchmark. Across every model evaluated,\nthe embedding variants achieve markedly lower accuracy than their bases, with\nabsolute drops ranging from 12 to 43 percentage points (median 28 pts) and\ntypical retriever accuracies collapsing into the 25-35 % band versus the 60-70\n% attained by the generative models. This degradation intensifies under a more\ndemanding condition: when the candidate pool per question is expanded from four\noptions to one thousand, the strongest retriever's top-1 accuracy falls from 33\n% to 26 %, revealing acute sensitivity to distractor volume. Statistical tests\nfurther show that, for every embedding model, cosine-similarity scores between\nqueries and correct completions are significantly higher than those for\nincorrect ones (p < 0.01), indicating decisions driven largely by surface-level\nsemantic proximity rather than factual reasoning. To probe this weakness, we\nemployed GPT-4.1 to paraphrase each correct completion, creating a rewritten\ntest set that preserved factual truth while masking lexical cues, and observed\nthat over two-thirds of previously correct predictions flipped to wrong,\nreducing overall accuracy to roughly one-third of its original level. Taken\ntogether, these findings reveal a systematic trade-off introduced by\ncontrastive learning for retrievers: gains in semantic retrieval are paid for\nwith losses in parametric factual knowledge......", "AI": {"tldr": "\u5d4c\u5165\u6a21\u578b\u663e\u8457\u635f\u5931\u4e86\u6765\u81ea\u57fa\u7840\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e8b\u5b9e\u77e5\u8bc6\uff0c\u5c3d\u7ba1\u8bed\u4e49\u68c0\u7d22\u6709\u6539\u5584\uff0c\u4f46\u4e8b\u5b9e\u63a8\u7406\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u5bf9\u5e72\u6270\u9879\u654f\u611f\u3002", "motivation": "\u4e86\u89e3\u6784\u5efa\u5728\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u7840\u4e0a\u7684\u91cd\u6392\u5668\u4e0e\u68c0\u7d22\u5668\u5728\u4e8b\u5b9e\u80fd\u529b\u7ee7\u627f\u65b9\u9762\u7684\u8868\u73b0\uff0c\u4ee5\u52a0\u5f3aRAG\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u5e76\u9632\u6b62\u4e2d\u6bd2\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u8bc4\u4f3012\u4e2a\u516c\u5f00\u53d1\u5e03\u7684\u5d4c\u5165\u68c0\u67e5\u70b9\u4e0e\u5176\u539f\u59cb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5e76\u4f7f\u7528\u4e8b\u5b9e\u6027\u57fa\u51c6\u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u6bd4\u8f83\u5206\u6790\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5d4c\u5165\u53d8\u4f53\u5728\u4e8b\u5b9e\u68c0\u7d22\u7684\u51c6\u786e\u6027\u663e\u8457\u4f4e\u4e8e\u5176\u57fa\u7840\u6a21\u578b\uff0c\u5c24\u5176\u5728\u589e\u52a0\u5e72\u6270\u9879\u65f6\uff0c\u8868\u73b0\u4e0b\u964d\u66f4\u4e3a\u660e\u663e\u3002\u8bed\u4e49\u76f8\u4f3c\u6027\u5f97\u5206\u7684\u63a8\u52a8\u4e0b\uff0c\u9884\u6d4b\u4e3b\u8981\u7531\u8868\u5c42\u8bed\u4e49\u76f8\u8fd1\u6027\u51b3\u5b9a\u800c\u975e\u4e8b\u5b9e\u63a8\u7406\uff0c\u5e76\u4e14\u5728\u6d88\u9664\u8bcd\u6c47\u63d0\u793a\u540e\uff0c\u51c6\u786e\u7387\u5927\u5e45\u4e0b\u964d\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u7528\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u91cd\u6392\u5668\u4e0e\u68c0\u7d22\u5668\u7ee7\u627f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u7684\u4e8b\u5b9e\u80fd\u529b\u5b58\u5728\u663e\u8457\u635f\u5931\u3002\u5c3d\u7ba1\u5728\u8bed\u4e49\u68c0\u7d22\u65b9\u9762\u6709\u6240\u63d0\u5347\uff0c\u4f46\u5b83\u4eec\u5728\u68c0\u7d22\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002"}}
{"id": "2508.20427", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20427", "abs": "https://arxiv.org/abs/2508.20427", "authors": ["Yongqiang Han", "Kai Cheng", "Kefan Wang", "Enhong Chen"], "title": "Rethinking Purity and Diversity in Multi-Behavior Sequential Recommendation from the Frequency Perspective", "comment": null, "summary": "In recommendation systems, users often exhibit multiple behaviors, such as\nbrowsing, clicking, and purchasing. Multi-behavior sequential recommendation\n(MBSR) aims to consider these different behaviors in an integrated manner to\nimprove the recommendation performance of the target behavior. However, some\nbehavior data will also bring inevitable noise to the modeling of user\ninterests. Some research efforts focus on data denoising from the frequency\ndomain perspective to improve the accuracy of user preference prediction. These\nstudies indicate that low-frequency information tends to be valuable and\nreliable, while high-frequency information is often associated with noise. In\nthis paper, we argue that high-frequency information is by no means\ninsignificant. Further experimental results highlight that low frequency\ncorresponds to the purity of user interests, while high frequency corresponds\nto the diversity of user interests. Building upon this finding, we proposed our\nmodel PDB4Rec, which efficiently extracts information across various frequency\nbands and their relationships, and introduces Boostrapping Balancer mechanism\nto balance their contributions for improved recommendation performance.\nSufficient experiments on real-world datasets demonstrate the effectiveness and\nefficiency of our model.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51faPDB4Rec\u6a21\u578b\uff0c\u901a\u8fc7\u5904\u7406\u9891\u7387\u4fe1\u606f\u5e76\u4f18\u5316\u63a8\u8350\u6027\u80fd\uff0c\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u7684\u591a\u884c\u4e3a\u5e8f\u5217\u63a8\u8350\u53ef\u80fd\u7531\u4e8e\u884c\u4e3a\u6570\u636e\u566a\u58f0\u5f71\u54cd\u7528\u6237\u5174\u8da3\u5efa\u6a21\u51c6\u786e\u5ea6\uff0c\u9700\u8981\u66f4\u597d\u5730\u5904\u7406\u6570\u636e\u566a\u58f0\u3002", "method": "\u63d0\u51fa\u6a21\u578bPDB4Rec\uff0c\u5229\u7528\u9891\u7387\u6bb5\u6570\u636e\u5e76\u7ed3\u5408\u5f15\u5bfc\u5e73\u8861\u673a\u5236\u6765\u63d0\u9ad8\u63a8\u8350\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660ePDB4Rec\u6a21\u578b\u5728\u5904\u7406\u9891\u7387\u4fe1\u606f\u548c\u4f18\u5316\u63a8\u8350\u6027\u80fd\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6a21\u578bPDB4Rec\uff0c\u901a\u8fc7\u5904\u7406\u4e0d\u540c\u9891\u6bb5\u7684\u4fe1\u606f\u6765\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u3002\u5b9e\u9a8c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2508.20496", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.20496", "abs": "https://arxiv.org/abs/2508.20496", "authors": ["Peter Muellner", "Anna Schreuer", "Simone Kopeinik", "Bernhard Wieser", "Dominik Kowald"], "title": "Multistakeholder Fairness in Tourism: What can Algorithms learn from Tourism Management?", "comment": "Accepted for publication in Frontiers in Big Data", "summary": "Algorithmic decision-support systems, i.e., recommender systems, are popular\ndigital tools that help tourists decide which places and attractions to\nexplore. However, algorithms often unintentionally direct tourist streams in a\nway that negatively affects the environment, local communities, or other\nstakeholders. This issue can be partly attributed to the computer science\ncommunity's limited understanding of the complex relationships and trade-offs\namong stakeholders in the real world.\n  In this work, we draw on the practical findings and methods from tourism\nmanagement to inform research on multistakeholder fairness in algorithmic\ndecision-support. Leveraging a semi-systematic literature review, we synthesize\nliterature from tourism management as well as literature from computer science.\nOur findings suggest that tourism management actively tries to identify the\nspecific needs of stakeholders and utilizes qualitative, inclusive and\nparticipatory methods to study fairness from a normative and holistic research\nperspective. In contrast, computer science lacks sufficient understanding of\nthe stakeholder needs and primarily considers fairness through descriptive\nfactors, such as measureable discrimination, while heavily relying on few\nmathematically formalized fairness criteria that fail to capture the\nmultidimensional nature of fairness in tourism.\n  With the results of this work, we aim to illustrate the shortcomings of\npurely algorithmic research and stress the potential and particular need for\nfuture interdisciplinary collaboration. We believe such a collaboration is a\nfundamental and necessary step to enhance algorithmic decision-support systems\ntowards understanding and supporting true multistakeholder fairness in tourism.", "AI": {"tldr": "\u672c\u7814\u7a76\u7ed3\u5408\u65c5\u6e38\u7ba1\u7406\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u6587\u732e\uff0c\u5f3a\u8c03\u8de8\u5b66\u79d1\u5408\u4f5c\u4ee5\u6539\u8fdb\u7b97\u6cd5\u63a8\u8350\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u3002", "motivation": "\u5f53\u524d\u63a8\u8350\u7cfb\u7edf\u53ef\u80fd\u5bf9\u73af\u5883\u548c\u5f53\u5730\u793e\u533a\u9020\u6210\u8d1f\u9762\u5f71\u54cd\uff0c\u4e9f\u9700\u89e3\u51b3\u7b97\u6cd5\u5728\u65c5\u6e38\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u4e0d\u516c\u5e73\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u534a\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u5c06\u65c5\u6e38\u7ba1\u7406\u4e0e\u8ba1\u7b97\u673a\u79d1\u5b66\u7684\u6587\u732e\u7ed3\u5408\uff0c\u5206\u6790\u7b97\u6cd5\u51b3\u7b56\u652f\u6301\u7684\u591a\u5229\u76ca\u76f8\u5173\u8005\u516c\u5e73\u6027\u3002", "result": "\u65c5\u6e38\u7ba1\u7406\u9886\u57df\u5c1d\u8bd5\u8bc6\u522b\u5229\u76ca\u76f8\u5173\u8005\u9700\u6c42\u5e76\u4ece\u89c4\u8303\u6027\u548c\u6574\u4f53\u7814\u7a76\u89d2\u5ea6\u4f7f\u7528\u5b9a\u6027\u3001\u5305\u5bb9\u548c\u53c2\u4e0e\u6027\u65b9\u6cd5\u7814\u7a76\u516c\u5e73\u6027\uff0c\u800c\u8ba1\u7b97\u673a\u79d1\u5b66\u9886\u57df\u5219\u7f3a\u4e4f\u5bf9\u5229\u76ca\u76f8\u5173\u8005\u9700\u6c42\u7684\u7406\u89e3\u3002", "conclusion": "\u63a8\u52a8\u8de8\u5b66\u79d1\u5408\u4f5c\uff0c\u63d0\u5347\u7b97\u6cd5\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u5728\u65c5\u6e38\u9886\u57df\u4e2d\u7684\u591a\u5229\u76ca\u76f8\u5173\u8005\u516c\u5e73\u6027\u3002"}}
{"id": "2508.20543", "categories": ["cs.IR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.20543", "abs": "https://arxiv.org/abs/2508.20543", "authors": ["Apurva Kulkarni", "Chandrashekar Ramanathan", "Vinu E Venugopal"], "title": "Enhancing Semantic Document Retrieval- Employing Group Steiner Tree Algorithm with Domain Knowledge Enrichment", "comment": null, "summary": "Retrieving pertinent documents from various data sources with diverse\ncharacteristics poses a significant challenge for Document Retrieval Systems.\nThe complexity of this challenge is further compounded when accounting for the\nsemantic relationship between data and domain knowledge. While existing\nretrieval systems using semantics (usually represented as Knowledge Graphs\ncreated from open-access resources and generic domain knowledge) hold promise\nin delivering relevant outcomes, their precision may be compromised due to the\nabsence of domain-specific information and reliance on outdated knowledge\nsources. In this research, the primary focus is on two key contributions- a)\nthe development of a versatile algorithm- 'Semantic-based Concept Retrieval\nusing Group Steiner Tree' that incorporates domain information to enhance\nsemantic-aware knowledge representation and data access, and b) the practical\nimplementation of the proposed algorithm within a document retrieval system\nusing real-world data. To assess the effectiveness of the SemDR system,\nresearch work conducts performance evaluations using a benchmark consisting of\n170 real-world search queries. Rigorous evaluation and verification by domain\nexperts are conducted to ensure the validity and accuracy of the results. The\nexperimental findings demonstrate substantial advancements when compared to the\nbaseline systems, with precision and accuracy achieving levels of 90% and 82%\nrespectively, signifying promising improvements.", "AI": {"tldr": "\u5f00\u53d1\u5e76\u5b9e\u65bd\u4e86\u4e00\u79cd\u65b0\u7684\u6587\u6863\u68c0\u7d22\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u7cbe\u786e\u5ea6\u548c\u51c6\u786e\u5ea6\uff0c\u7cbe\u786e\u5ea6\u548c\u51c6\u786e\u5ea6\u5206\u522b\u8fbe\u5230\u4e8690%\u548c82%\u3002", "motivation": "\u89e3\u51b3\u6587\u4ef6\u68c0\u7d22\u7cfb\u7edf\u5728\u4ece\u591a\u79cd\u6570\u636e\u6e90\u4e2d\u68c0\u7d22\u76f8\u5173\u6587\u4ef6\u65f6\u6240\u9047\u5230\u7684\u590d\u6742\u95ee\u9898\uff0c\u7279\u522b\u662f\u5176\u8bed\u4e49\u5173\u7cfb\u548c\u9886\u57df\u77e5\u8bc6\u7684\u6311\u6218\u3002\u73b0\u6709\u68c0\u7d22\u7cfb\u7edf\u7684\u7cbe\u786e\u5ea6\u53ef\u80fd\u53d7\u5230\u7f3a\u4e4f\u9886\u57df\u4fe1\u606f\u548c\u4f9d\u8d56\u8fc7\u65f6\u77e5\u8bc6\u6765\u6e90\u7684\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u901a\u7528\u7b97\u6cd5'\u57fa\u4e8e\u8bed\u4e49\u7684\u6982\u5ff5\u68c0\u7d22\u4f7f\u7528\u7ec4\u5408\u65af\u5766\u7eb3\u6811'\uff0c\u8be5\u7b97\u6cd5\u6574\u5408\u9886\u57df\u4fe1\u606f\u4ee5\u589e\u5f3a\u8bed\u4e49\u611f\u77e5\u7684\u77e5\u8bc6\u8868\u793a\u548c\u6570\u636e\u8bbf\u95ee\uff0c\u5e76\u5728\u6587\u6863\u68c0\u7d22\u7cfb\u7edf\u4e2d\u5b9e\u65bd\u8be5\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u4f7f\u7528170\u4e2a\u771f\u5b9e\u4e16\u754c\u641c\u7d22\u67e5\u8be2\u7684\u57fa\u51c6\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u4e0e\u57fa\u7ebf\u7cfb\u7edf\u76f8\u6bd4\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u5c55\uff0c\u7cbe\u786e\u5ea6\u548c\u51c6\u786e\u5ea6\u5206\u522b\u8fbe\u5230\u4e8690%\u548c82%\u3002", "conclusion": "\u8be5\u7814\u7a76\u5728\u5f00\u53d1\u548c\u5b9e\u65bd\u65b0\u7684\u6587\u6863\u68c0\u7d22\u7b97\u6cd5\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u63d0\u9ad8\u4e86\u68c0\u7d22\u7cfb\u7edf\u7684\u7cbe\u786e\u5ea6\u548c\u51c6\u786e\u5ea6\u3002\u901a\u8fc7\u9886\u57df\u4e13\u5bb6\u9a8c\u8bc1\u548c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u4f18\u4e8e\u57fa\u7ebf\u7cfb\u7edf\u3002"}}
{"id": "2508.20582", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.20582", "abs": "https://arxiv.org/abs/2508.20582", "authors": ["Weitao Jia", "Shuo Yin", "Zhoufutu Wen", "Han Wang", "Zehui Dai", "Kun Zhang", "Zhenyu Li", "Tao Zeng", "Xiaohui Lv"], "title": "SUMMA: A Multimodal Large Language Model for Advertisement Summarization", "comment": null, "summary": "Understanding multimodal video ads is crucial for improving query-ad matching\nand relevance ranking on short video platforms, enhancing advertising\neffectiveness and user experience. However, the effective utilization of\nmultimodal information with high commercial value still largely constrained by\nreliance on highly compressed video embeddings-has long been inadequate. To\naddress this, we propose SUMMA (the abbreviation of Summarizing MultiModal\nAds), a multimodal model that automatically processes video ads into summaries\nhighlighting the content of highest commercial value, thus improving their\ncomprehension and ranking in Douyin search-advertising systems. SUMMA is\ndeveloped via a two-stage training strategy-multimodal supervised fine-tuning\nfollowed by reinforcement learning with a mixed reward mechanism-on\ndomain-specific data containing video frames and ASR/OCR transcripts,\ngenerating commercially valuable and explainable summaries. We integrate\nSUMMA-generated summaries into our production pipeline, directly enhancing the\ncandidate retrieval and relevance ranking stages in real search-advertising\nsystems. Both offline and online experiments show substantial improvements over\nbaselines, with online results indicating a statistically significant 1.5%\nincrease in advertising revenue. Our work establishes a novel paradigm for\ncondensing multimodal information into representative texts, effectively\naligning visual ad content with user query intent in retrieval and\nrecommendation scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86SUMMA\u591a\u6a21\u6001\u6a21\u578b\uff0c\u901a\u8fc7\u6458\u8981\u63d0\u5347\u5e7f\u544a\u5185\u5bb9\u7406\u89e3\u548c\u6392\u540d\uff0c\u63d0\u9ad8\u5e7f\u544a\u6536\u5165\u3002", "motivation": "\u63d0\u5347\u77ed\u89c6\u9891\u5e73\u53f0\u4e0a\u7684\u5e7f\u544a\u67e5\u8be2\u5339\u914d\u548c\u76f8\u5173\u6027\u6392\u5e8f\uff0c\u4ee5\u6539\u5584\u5e7f\u544a\u6548\u679c\u548c\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u901a\u8fc7\u89c6\u9891\u5e27\u548c\u8bed\u97f3\u8bc6\u522b/\u5149\u5b66\u5b57\u7b26\u8bc6\u522b\u6587\u672c\u8fdb\u884c\u591a\u6a21\u6001\u76d1\u7763\u5fae\u8c03\uff0c\u7136\u540e\u4f7f\u7528\u5e26\u6709\u6df7\u5408\u5956\u52b1\u673a\u5236\u7684\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u4e8c\u9636\u6bb5\u8bad\u7ec3\u3002", "result": "\u5728\u7ebf\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5e7f\u544a\u6536\u5165\u663e\u8457\u589e\u52a0\u4e861.5%\uff0c\u540c\u65f6\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u5747\u663e\u793a\u6548\u679c\u4f18\u4e8e\u57fa\u51c6\u3002", "conclusion": "SUMMA\u6a21\u578b\u5b9e\u73b0\u4e86\u5c06\u591a\u6a21\u6001\u89c6\u9891\u5e7f\u544a\u5185\u5bb9\u6d53\u7f29\u4e3a\u5177\u6709\u9ad8\u5546\u4e1a\u4ef7\u503c\u7684\u6458\u8981\uff0c\u5e76\u7528\u4e8e\u63d0\u5347\u641c\u7d22\u5e7f\u544a\u7cfb\u7edf\u7684\u6548\u679c\u3002"}}
{"id": "2508.20587", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.20587", "abs": "https://arxiv.org/abs/2508.20587", "authors": ["Jyoti Narwariya", "Priyanka Gupta", "Muskan Gupta", "Jyotsana Khatri", "Lovekesh Vig"], "title": "SemSR: Semantics aware robust Session-based Recommendations", "comment": "Accepted at EARL workshop @RecSys'25, Prague, Czech Republic", "summary": "Session-based recommendation (SR) models aim to recommend items to anonymous\nusers based on their behavior during the current session. While various SR\nmodels in the literature utilize item sequences to predict the next item, they\noften fail to leverage semantic information from item titles or descriptions\nimpeding session intent identification and interpretability. Recent research\nhas explored Large Language Models (LLMs) as promising approaches to enhance\nsession-based recommendations, with both prompt-based and fine-tuning based\nmethods being widely investigated. However, prompt-based methods struggle to\nidentify optimal prompts that elicit correct reasoning and lack task-specific\nfeedback at test time, resulting in sub-optimal recommendations. Fine-tuning\nmethods incorporate domain-specific knowledge but incur significant\ncomputational costs for implementation and maintenance. In this paper, we\npresent multiple approaches to utilize LLMs for session-based recommendation:\n(i) in-context LLMs as recommendation agents, (ii) LLM-generated\nrepresentations for semantic initialization of deep learning SR models, and\n(iii) integration of LLMs with data-driven SR models. Through comprehensive\nexperiments on two real-world publicly available datasets, we demonstrate that\nLLM-based methods excel at coarse-level retrieval (high recall values), while\ntraditional data-driven techniques perform well at fine-grained ranking (high\nMean Reciprocal Rank values). Furthermore, the integration of LLMs with\ndata-driven SR models significantly out performs both standalone LLM approaches\nand data-driven deep learning models, as well as baseline SR models, in terms\nof both Recall and MRR metrics.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u4f1a\u8bdd\u63a8\u8350\uff0c\u5b9e\u73b0\u9ad8\u53ec\u56de\u548c\u6392\u5e8f\u6027\u80fd\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u4f1a\u8bdd\u63a8\u8350\u6a21\u578b\u5e38\u65e0\u6cd5\u6709\u6548\u5229\u7528\u7b80\u5355\u7269\u54c1\u6807\u9898\u6216\u63cf\u8ff0\u4e2d\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u5f71\u54cd\u4e86\u4f1a\u8bdd\u610f\u56fe\u7684\u8bc6\u522b\u53ca\u53ef\u89e3\u91ca\u6027\u3002\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u5e76\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u5229\u7528LLMs\u7684\u65b9\u6cd5\u7528\u4e8e\u4f1a\u8bdd\u63a8\u8350\uff0c\u5305\u62ec\uff1aLLMs\u7684\u4e0a\u4e0b\u6587\u63a8\u8350\u4ee3\u7406\u3001\u7528\u4e8e\u6df1\u5ea6\u5b66\u4e60SR\u6a21\u578b\u8bed\u4e49\u521d\u59cb\u5316\u7684LLMs\u751f\u6210\u8868\u793a\uff0c\u4ee5\u53caLLMs\u4e0e\u6570\u636e\u9a71\u52a8\u7684SR\u6a21\u578b\u76f8\u7ed3\u5408\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u516c\u5f00\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86LLMs\u65b9\u6cd5\u5728\u7c97\u7ea7\u68c0\u7d22\uff08\u9ad8\u53ec\u56de\u503c\uff09\u4e0a\u7684\u4f18\u52bf\uff0c\u800c\u4f20\u7edf\u6570\u636e\u9a71\u52a8\u6280\u672f\u5728\u7ec6\u7c92\u5ea6\u6392\u5e8f\uff08\u9ad8\u5e73\u5747\u5012\u6570\u6392\u540d\u503c\uff09\u4e0a\u8868\u73b0\u826f\u597d\u3002\u6b64\u5916\uff0c\u5c06LLMs\u4e0e\u6570\u636e\u9a71\u52a8SR\u6a21\u578b\u7ed3\u5408\u7684\u65b9\u5f0f\u663e\u8457\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528LLMs\u7684\u65b9\u6cd5\u548c\u6570\u636e\u9a71\u52a8\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "conclusion": "\u5728\u4f1a\u8bdd\u63a8\u8350\u4e2d\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u6570\u636e\u9a71\u52a8\u7684SR\u6a21\u578b\u80fd\u591f\u663e\u8457\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2508.20778", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.20778", "abs": "https://arxiv.org/abs/2508.20778", "authors": ["Xinhao Huang", "Zhibo Ren", "Yipeng Yu", "Ying Zhou", "Zulong Chen", "Zeyi Wen"], "title": "SEAL: Structure and Element Aware Learning to Improve Long Structured Document Retrieval", "comment": "Accepted at EMNLP 2025 Main Conference", "summary": "In long structured document retrieval, existing methods typically fine-tune\npre-trained language models (PLMs) using contrastive learning on datasets\nlacking explicit structural information. This practice suffers from two\ncritical issues: 1) current methods fail to leverage structural features and\nelement-level semantics effectively, and 2) the lack of datasets containing\nstructural metadata. To bridge these gaps, we propose \\our, a novel contrastive\nlearning framework. It leverages structure-aware learning to preserve semantic\nhierarchies and masked element alignment for fine-grained semantic\ndiscrimination. Furthermore, we release \\dataset, a long structured document\nretrieval dataset with rich structural annotations. Extensive experiments on\nboth released and industrial datasets across various modern PLMs, along with\nonline A/B testing, demonstrate consistent performance improvements, boosting\nNDCG@10 from 73.96\\% to 77.84\\% on BGE-M3. The resources are available at\nhttps://github.com/xinhaoH/SEAL.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7ed3\u6784\u611f\u77e5\u5b66\u4e60\u7684\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\\our\uff0c\u5e76\u53d1\u5e03\u4e86\u5305\u542b\u4e30\u5bcc\u7ed3\u6784\u6ce8\u91ca\u7684\u6570\u636e\u96c6\\dataset\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6587\u6863\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u5229\u7528\u7ed3\u6784\u7279\u5f81\u548c\u5143\u7d20\u5c42\u8bed\u4e49\uff0c\u5e76\u4e14\u7f3a\u4e4f\u5305\u542b\u7ed3\u6784\u5143\u6570\u636e\u7684\u6570\u636e\u96c6\u3002", "method": "\u4f7f\u7528\\our\u7684\u7ed3\u6784\u611f\u77e5\u5b66\u4e60\u548c\u906e\u853d\u5143\u7d20\u5bf9\u9f50\u6280\u672f\u6765\u7ec6\u5316\u8bed\u4e49\u533a\u5206\u3002\u5e76\u63d0\u4f9b\u4e00\u4e2a\u540d\u4e3a\\dataset\u7684\u65b0\u7684\u68c0\u7d22\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u4e30\u5bcc\u7684\u7ed3\u6784\u6ce8\u91ca\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u4e2a\u73b0\u4ee3\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u5747\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5c06BGE-M3\u4e0a\u7684NDCG@10\u4ece73.96%\u63d0\u5347\u81f377.84%\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\\our\uff0c\u7528\u4e8e\u957f\u7ed3\u6784\u6587\u6863\u68c0\u7d22\uff0c\u80fd\u591f\u6709\u6548\u5229\u7528\u7ed3\u6784\u7279\u5f81\u5e76\u4fdd\u6301\u8bed\u4e49\u5c42\u6b21\u3002"}}
{"id": "2508.20798", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.20798", "abs": "https://arxiv.org/abs/2508.20798", "authors": ["Zechun Niu", "Lang Mei", "Liu Yang", "Ziyuan Zhao", "Qiang Yan", "Jiaxin Mao", "Ji-Rong Wen"], "title": "Addressing Personalized Bias for Unbiased Learning to Rank", "comment": "Accepted by CIKM 2025", "summary": "Unbiased learning to rank (ULTR), which aims to learn unbiased ranking models\nfrom biased user behavior logs, plays an important role in Web search. Previous\nresearch on ULTR has studied a variety of biases in users' clicks, such as\nposition bias, presentation bias, and outlier bias. However, existing work\noften assumes that the behavior logs are collected from an ``average'' user,\nneglecting the differences between different users in their search and browsing\nbehaviors. In this paper, we introduce personalized factors into the ULTR\nframework, which we term the user-aware ULTR problem. Through a formal causal\nanalysis of this problem, we demonstrate that existing user-oblivious methods\nare biased when different users have different preferences over queries and\npersonalized propensities of examining documents. To address such a\npersonalized bias, we propose a novel user-aware inverse-propensity-score\nestimator for learning-to-rank objectives. Specifically, our approach models\nthe distribution of user browsing behaviors for each query and aggregates\nuser-weighted examination probabilities to determine propensities. We\ntheoretically prove that the user-aware estimator is unbiased under some mild\nassumptions and shows lower variance compared to the straightforward way of\ncalculating a user-dependent propensity for each impression. Finally, we\nempirically verify the effectiveness of our user-aware estimator by conducting\nextensive experiments on two semi-synthetic datasets and a real-world dataset.", "AI": {"tldr": "\u5f15\u5165\u7528\u6237\u56e0\u7d20\u5230\u65e0\u504f\u5b66\u4e60\u6392\u5e8f\u6846\u67b6\u4e2d\uff0c\u63d0\u51fa\u7528\u6237\u611f\u77e5\u4f30\u8ba1\u5668\u4ee5\u964d\u4f4e\u504f\u5dee\u4e0e\u65b9\u5dee\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u65e0\u504f\u5b66\u4e60\u6392\u5e8f\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u884c\u4e3a\u65e5\u5fd7\u662f\u4ece\u201c\u5e73\u5747\u201d\u7528\u6237\u6536\u96c6\u7684\uff0c\u5ffd\u7565\u4e86\u4e0d\u540c\u7528\u6237\u5728\u641c\u7d22\u548c\u6d4f\u89c8\u884c\u4e3a\u4e0a\u7684\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u7528\u6237\u611f\u77e5\u9006\u503e\u5411\u5f97\u5206\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u5bf9\u6bcf\u4e2a\u67e5\u8be2\u7684\u7528\u6237\u6d4f\u89c8\u884c\u4e3a\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u805a\u5408\u7528\u6237\u52a0\u6743\u7684\u68c0\u67e5\u6982\u7387\u4ee5\u786e\u5b9a\u503e\u5411\u6027\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u7528\u6237\u611f\u77e5\u4f30\u8ba1\u5668\u5728\u4e00\u4e9b\u6e29\u548c\u5047\u8bbe\u4e0b\u662f\u65e0\u504f\u7684\uff0c\u5e76\u4e14\u4e0e\u76f4\u63a5\u8ba1\u7b97\u7528\u6237\u4f9d\u8d56\u503e\u5411\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u65b9\u5dee\u66f4\u4f4e\u3002\u901a\u8fc7\u5bf9\u4e24\u4e2a\u534a\u5408\u6210\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u7528\u6237\u611f\u77e5\u4f30\u8ba1\u5668\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4e2a\u6027\u5316\u56e0\u7d20\u5728\u65e0\u504f\u6392\u5e8f\u5b66\u4e60\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u901a\u8fc7\u5f15\u5165\u7528\u6237\u611f\u77e5\u6846\u67b6\uff0c\u53ef\u4ee5\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u504f\u5dee\u95ee\u9898\u3002"}}
{"id": "2508.20865", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.20865", "abs": "https://arxiv.org/abs/2508.20865", "authors": ["Zhuoxing Wei", "Qi Liu", "Qingchen Xie"], "title": "Deep Multiple Quantization Network on Long Behavior Sequence for Click-Through Rate Prediction", "comment": "5 pages, 1 figures, SIGIR 2025", "summary": "In Click-Through Rate (CTR) prediction, the long behavior sequence,\ncomprising the user's long period of historical interactions with items has a\nvital influence on assessing the user's interest in the candidate item.\nExisting approaches strike efficiency and effectiveness through a two-stage\nparadigm: first retrieving hundreds of candidate-related items and then\nextracting interest intensity vector through target attention. However, we\nargue that the discrepancy in target attention's relevance distribution between\nthe retrieved items and the full long behavior sequence inevitably leads to a\nperformance decline. To alleviate the discrepancy, we propose the Deep Multiple\nQuantization Network (DMQN) to process long behavior sequence end-to-end\nthrough compressing the long behavior sequence. Firstly, the entire spectrum of\nlong behavior sequence will be quantized into multiple codeword sequences based\non multiple independent codebooks. Hierarchical Sequential Transduction Unit is\nincorporated to facilitate the interaction of reduced codeword sequences. Then,\nattention between the candidate and multiple codeword sequences will output the\ninterest vector. To enable online serving, intermediate representations of the\ncodeword sequences are cached, significantly reducing latency. Our extensive\nexperiments on both industrial and public datasets confirm the effectiveness\nand efficiency of DMQN. The A/B test in our advertising system shows that DMQN\nimproves CTR by 3.5% and RPM by 2.0%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6df1\u5ea6\u591a\u91cf\u5316\u7f51\u7edc(DMQN)\u4ee5\u7aef\u5230\u7aef\u5904\u7406\u957f\u884c\u4e3a\u5e8f\u5217\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86CTR\u9884\u6d4b\u7684\u6548\u679c\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u76ee\u6807\u6ce8\u610f\u529b\u4e0e\u5b8c\u6574\u957f\u884c\u4e3a\u5e8f\u5217\u4e2d\u7684\u76f8\u5173\u6027\u5206\u5e03\u5b58\u5728\u5dee\u5f02\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u6df1\u5ea6\u591a\u91cf\u5316\u7f51\u7edc(DMQN)\uff0c\u901a\u8fc7\u591a\u91cd\u72ec\u7acb\u4ee3\u7801\u672c\u5c06\u957f\u884c\u4e3a\u5e8f\u5217\u91cf\u5316\u4e3a\u591a\u4e2a\u4ee3\u7801\u5b57\u5e8f\u5217\uff0c\u5e76\u4f7f\u7528\u5c42\u6b21\u5316\u5e8f\u5217\u4f20\u9012\u5355\u5143\u4fc3\u8fdb\u4ee3\u7801\u5b57\u5e8f\u5217\u95f4\u7684\u4ea4\u4e92\uff0c\u6700\u7ec8\u751f\u6210\u5174\u8da3\u5411\u91cf\u3002", "result": "\u901a\u8fc7\u5de5\u4e1a\u548c\u516c\u5171\u6570\u636e\u96c6\u7684\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1DMQN\u7684\u6709\u6548\u6027\u548c\u6548\u7387\uff0cA/B\u6d4b\u8bd5\u8868\u660eDMQN\u63d0\u9ad8CTR 3.5%\u548cRPM 2.0%\u3002", "conclusion": "DMQN\u80fd\u591f\u7f13\u89e3\u76ee\u6807\u6ce8\u610f\u529b\u76f8\u5173\u6027\u5206\u5e03\u7684\u5dee\u5f02\uff0c\u63d0\u5347CTR\u9884\u6d4b\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2508.20900", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.20900", "abs": "https://arxiv.org/abs/2508.20900", "authors": ["Guorui Zhou", "Hengrui Hu", "Hongtao Cheng", "Huanjie Wang", "Jiaxin Deng", "Jinghao Zhang", "Kuo Cai", "Lejian Ren", "Lu Ren", "Liao Yu", "Pengfei Zheng", "Qiang Luo", "Qianqian Wang", "Qigen Hu", "Rui Huang", "Ruiming Tang", "Shiyao Wang", "Shujie Yang", "Tao Wu", "Wuchao Li", "Xinchen Luo", "Xingmei Wang", "Yi Su", "Yunfan Wu", "Zexuan Cheng", "Zhanyu Liu", "Zixing Zhang", "Bin Zhang", "Boxuan Wang", "Chaoyi Ma", "Chengru Song", "Chenhui Wang", "Chenglong Chu", "Di Wang", "Dongxue Meng", "Dunju Zang", "Fan Yang", "Fangyu Zhang", "Feng Jiang", "Fuxing Zhang", "Gang Wang", "Guowang Zhang", "Han Li", "Honghui Bao", "Hongyang Cao", "Jiaming Huang", "Jiapeng Chen", "Jiaqiang Liu", "Jinghui Jia", "Kun Gai", "Lantao Hu", "Liang Zeng", "Qiang Wang", "Qidong Zhou", "Rongzhou Zhang", "Shengzhe Wang", "Shihui He", "Shuang Yang", "Siyang Mao", "Sui Huang", "Tiantian He", "Tingting Gao", "Wei Yuan", "Xiao Liang", "Xiaoxiao Xu", "Xugang Liu", "Yan Wang", "Yang Zhou", "Yi Wang", "Yiwu Liu", "Yue Song", "Yufei Zhang", "Yunfeng Zhao", "Zhixin Ling", "Ziming Li"], "title": "OneRec-V2 Technical Report", "comment": null, "summary": "Recent breakthroughs in generative AI have transformed recommender systems\nthrough end-to-end generation. OneRec reformulates recommendation as an\nautoregressive generation task, achieving high Model FLOPs Utilization. While\nOneRec-V1 has shown significant empirical success in real-world deployment, two\ncritical challenges hinder its scalability and performance: (1) inefficient\ncomputational allocation where 97.66% of resources are consumed by sequence\nencoding rather than generation, and (2) limitations in reinforcement learning\nrelying solely on reward models.\n  To address these challenges, we propose OneRec-V2, featuring: (1) Lazy\nDecoder-Only Architecture: Eliminates encoder bottlenecks, reducing total\ncomputation by 94% and training resources by 90%, enabling successful scaling\nto 8B parameters. (2) Preference Alignment with Real-World User Interactions:\nIncorporates Duration-Aware Reward Shaping and Adaptive Ratio Clipping to\nbetter align with user preferences using real-world feedback.\n  Extensive A/B tests on Kuaishou demonstrate OneRec-V2's effectiveness,\nimproving App Stay Time by 0.467%/0.741% while balancing multi-objective\nrecommendations. This work advances generative recommendation scalability and\nalignment with real-world feedback, representing a step forward in the\ndevelopment of end-to-end recommender systems.", "AI": {"tldr": "OneRec-V2 enhances scalability and alignment in generative recommendation systems by innovating its architecture and learning from user interactions, overcoming previous computational and alignment challenges.", "motivation": "This research is motivated by the need to overcome the inefficiencies and limitations in scalability and real-world applicability in OneRec-V1, primarily due to computational allocation issues and reinforcement learning limitations relying solely on reward models.", "method": "OneRec-V2 introduces a Lazy Decoder-Only Architecture to eliminate encoder bottlenecks and reduces computational resources significantly. It also incorporates Duration-Aware Reward Shaping and Adaptive Ratio Clipping for better alignment with user preferences.", "result": "The implementation of OneRec-V2 led to a significant improvement in App Stay Time by 0.467%/0.741% during extensive A/B testing on Kuaishou, demonstrating its effectiveness and balance in multi-objective recommendations.", "conclusion": "OneRec-V2 significantly improves the scalability and performance of generative recommendation systems by addressing previous inefficiencies and aligning recommendations with real-world user interactions."}}
{"id": "2508.20945", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.20945", "abs": "https://arxiv.org/abs/2508.20945", "authors": ["Manuel V. Loureiro", "Steven Derby", "Aleksei Medvedev", "Alejandro Ariza-Casabona", "Gonzalo Fiz Pontiveros", "Tri Kurniawan Wijaya"], "title": "Efficient Large-Scale Cross-Domain Sequential Recommendation with Dynamic State Representations", "comment": "4 pages", "summary": "Recently, autoregressive recommendation models (ARMs), such as Meta's HSTU\nmodel, have emerged as a major breakthrough over traditional Deep Learning\nRecommendation Models (DLRMs), exhibiting the highly sought-after scaling law\nbehaviour. However, when applied to multi-domain scenarios, the transformer\narchitecture's attention maps become a computational bottleneck, as they attend\nto all items across every domain. To tackle this challenge, systems must\nefficiently balance inter and intra-domain knowledge transfer. In this work, we\nintroduce a novel approach for scalable multi-domain recommendation systems by\nreplacing full inter-domain attention with two innovative mechanisms: 1)\nTransition-Aware Positional Embeddings (TAPE): We propose novel positional\nembeddings that account for domain-transition specific information. This allows\nattention to be focused solely on intra-domain items, effectively reducing the\nunnecessary computational cost associated with attending to irrelevant domains.\n2) Dynamic Domain State Representation (DDSR): We introduce a dynamic state\nrepresentation for each domain, which is stored and accessed during subsequent\ntoken predictions. This enables the efficient transfer of relevant domain\ninformation without relying on full attention maps. Our method offers a\nscalable solution to the challenges posed by large-scale, multi-domain\nrecommendation systems and demonstrates significant improvements in retrieval\ntasks by separately modelling and combining inter- and intra-domain\nrepresentations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u591a\u57df\u63a8\u8350\u7cfb\u7edf\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u521b\u65b0\u673a\u5236\u51cf\u5c11\u8ba1\u7b97\u74f6\u9888\uff0c\u63d0\u9ad8\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u56de\u5f52\u63a8\u8350\u6a21\u578b\u5728\u591a\u57df\u573a\u666f\u4e2d\u5b58\u5728\u6ce8\u610f\u529b\u56fe\u8ba1\u7b97\u74f6\u9888\uff0c\u9700\u9ad8\u6548\u5904\u7406\u57df\u95f4\u548c\u57df\u5185\u77e5\u8bc6\u8f6c\u79fb\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u521b\u65b0\u673a\u5236\uff1a\u8fc7\u6e21\u611f\u77e5\u4f4d\u7f6e\u5d4c\u5165\uff08TAPE\uff09\u548c\u52a8\u6001\u57df\u72b6\u6001\u8868\u793a\uff08DDSR\uff09\uff0c\u5206\u522b\u5904\u7406\u57df\u5185\u548c\u8de8\u57df\u4fe1\u606f\u7684\u8f6c\u79fb\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u591a\u57df\u63a8\u8350\u7cfb\u7edf\u4e2d\u53d6\u5f97\u663e\u8457\u7684\u68c0\u7d22\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u66ff\u6362\u5b8c\u6574\u8de8\u57df\u6ce8\u610f\u529b\u673a\u5236\uff0c\u89e3\u51b3\u591a\u57df\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\uff0c\u63d0\u9ad8\u68c0\u7d22\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2508.21038", "categories": ["cs.IR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.21038", "abs": "https://arxiv.org/abs/2508.21038", "authors": ["Orion Weller", "Michael Boratko", "Iftekhar Naim", "Jinhyuk Lee"], "title": "On the Theoretical Limitations of Embedding-Based Retrieval", "comment": null, "summary": "Vector embeddings have been tasked with an ever-increasing set of retrieval\ntasks over the years, with a nascent rise in using them for reasoning,\ninstruction-following, coding, and more. These new benchmarks push embeddings\nto work for any query and any notion of relevance that could be given. While\nprior works have pointed out theoretical limitations of vector embeddings,\nthere is a common assumption that these difficulties are exclusively due to\nunrealistic queries, and those that are not can be overcome with better\ntraining data and larger models. In this work, we demonstrate that we may\nencounter these theoretical limitations in realistic settings with extremely\nsimple queries. We connect known results in learning theory, showing that the\nnumber of top-k subsets of documents capable of being returned as the result of\nsome query is limited by the dimension of the embedding. We empirically show\nthat this holds true even if we restrict to k=2, and directly optimize on the\ntest set with free parameterized embeddings. We then create a realistic dataset\ncalled LIMIT that stress tests models based on these theoretical results, and\nobserve that even state-of-the-art models fail on this dataset despite the\nsimple nature of the task. Our work shows the limits of embedding models under\nthe existing single vector paradigm and calls for future research to develop\nmethods that can resolve this fundamental limitation.", "AI": {"tldr": "\u5d4c\u5165\u6a21\u578b\u5728\u5355\u77e2\u91cf\u8303\u5f0f\u4e0b\u5b58\u5728\u7406\u8bba\u9650\u5236\uff0c\u90e8\u5206\u60c5\u51b5\u4e0b\u4e0d\u5207\u5b9e\u9645\u67e5\u8be2\u4e4b\u5916\u7684\u7b80\u5355\u67e5\u8be2\u4e5f\u4f1a\u9047\u5230\u8fd9\u4e00\u95ee\u9898\u3002\u5373\u4f7f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u65e0\u6cd5\u5904\u7406LIMIT\u6570\u636e\u96c6\u4e2d\u7b80\u5355\u4efb\u52a1\u3002", "motivation": "\u968f\u7740\u5d4c\u5165\u7684\u5e94\u7528\u573a\u666f\u6269\u5c55\u5230\u63a8\u7406\u3001\u4efb\u52a1\u6307\u5bfc\u7b49\uff0c\u5bf9\u4efb\u610f\u67e5\u8be2\u7684\u76f8\u5173\u6027\u8fdb\u884c\u5904\u7406\u6210\u4e3a\u5d4c\u5165\u7684\u4e00\u9879\u91cd\u8981\u4efb\u52a1\u3002\u7136\u800c\uff0c\u7406\u8bba\u4e0a\u7684\u9650\u5236\u53ef\u80fd\u4e0d\u662f\u4ec5\u7531\u4e0d\u5207\u5b9e\u9645\u7684\u67e5\u8be2\u5bfc\u81f4\u7684\uff0c\u66f4\u597d\u7684\u8bad\u7ec3\u6570\u636e\u548c\u6a21\u578b\u89c4\u6a21\u53ef\u80fd\u65e0\u6cd5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5c06\u5b66\u4e60\u7406\u8bba\u4e2d\u7684\u5df2\u77e5\u7ed3\u679c\u4e0e\u5b9e\u9645\u67e5\u8be2\u76f8\u7ed3\u5408\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u9650\u5236\u7684\u5b58\u5728\uff0c\u5e76\u521b\u9020\u4e86\u4e00\u4e2a\u540d\u4e3aLIMIT\u7684\u6570\u636e\u96c6\u8fdb\u884c\u6a21\u578b\u7684\u538b\u529b\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u5c55\u793a\u5373\u4f7f\u5728k=2\u7684\u9650\u5236\u4e0b\uff0c\u8fd9\u79cd\u7406\u8bba\u9650\u5236\u4f9d\u7136\u6709\u6548\uff0c\u5e76\u4e14\u5373\u4fbf\u76f4\u63a5\u5728\u6d4b\u8bd5\u96c6\u4e0a\u4f18\u5316\u53c2\u6570\u5316\u5d4c\u5165\uff0c\u6a21\u578b\u4e5f\u96be\u4ee5\u5e94\u5bf9\u3002\u5373\u4fbf\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5728LIMIT\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4e5f\u4e0d\u4f73\u3002", "conclusion": "\u5d4c\u5165\u6a21\u578b\u5728\u73b0\u6709\u7684\u5355\u77e2\u91cf\u8303\u5f0f\u4e0b\u5b58\u5728\u9650\u5236\uff0c\u672a\u6765\u7684\u7814\u7a76\u9700\u8981\u5f00\u53d1\u80fd\u591f\u89e3\u51b3\u8fd9\u4e00\u57fa\u672c\u9650\u5236\u7684\u65b9\u6cd5\u3002"}}
