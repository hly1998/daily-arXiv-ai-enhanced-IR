<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 6]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [REALM: Recursive Relevance Modeling for LLM-based Document Re-Ranking](https://arxiv.org/abs/2508.18379)
*Pinhuan Wang,Zhiqiu Xia,Chunhua Liao,Feiyi Wang,Hang Liu*

Main category: cs.IR

TL;DR: REALM通过不确定性感知和递归贝叶斯优化，提升了排名效率，领先于其他方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基于方法存在排名不确定性、不稳定的top-k恢复和高额令牌成本等显著限制。

Method: 提出一个不确定性感知的重排序框架，使用递归贝叶斯更新来建模和优化LLM导出的相关性，重新排排名。

Result: 实验结果表明REALM实现了更高效的排名。

Conclusion: REALM优于现有的先进重排序器，大幅减少了令牌使用和延迟，成为现代信息检索系统中的下一代重排序器。

Abstract: Large Language Models (LLMs) have shown strong capabilities in document
re-ranking, a key component in modern Information Retrieval (IR) systems.
However, existing LLM-based approaches face notable limitations, including
ranking uncertainty, unstable top-k recovery, and high token cost due to
token-intensive prompting. To effectively address these limitations, we propose
REALM, an uncertainty-aware re-ranking framework that models LLM-derived
relevance as Gaussian distributions and refines them through recursive Bayesian
updates. By explicitly capturing uncertainty and minimizing redundant queries,
REALM achieves better rankings more efficiently. Experimental results
demonstrate that our REALM surpasses state-of-the-art re-rankers while
significantly reducing token usage and latency, promoting it as the
next-generation re-ranker for modern IR systems.

</details>


### [2] [DenseRec: Revisiting Dense Content Embeddings for Sequential Transformer-based Recommendation](https://arxiv.org/abs/2508.18442)
*Jan Malte Lichtenberg,Antonio De Candia,Matteo Ruffini*

Main category: cs.IR

TL;DR: DenseRec通过双路径嵌入方法改善了冷启动问题，在实验中超过了ID-only模型表现。


<details>
  <summary>Details</summary>
Motivation: 传统的基于Transformer的推荐系统依赖于项目ID嵌入，在动态项目目录环境中容易遭遇冷启动问题。需要有效解决该问题的方法。

Method: DenseRec采用了双路径嵌入方法，在训练期间从密集嵌入空间学习到ID嵌入空间的线性投影。

Result: DenseRec在三个真实世界数据集上的实验中表现优于SASRec基线模型，即使在未进行额外超参数调节且使用紧凑嵌入模型的情况下。

Conclusion: DenseRec提供了一种有效的方法，通过在训练过程中学习从密集嵌入空间到ID嵌入空间的线性投影，使得在无需特殊嵌入模型或复杂基础设施的情况下，实现对以前未见物品的无缝泛化。

Abstract: Transformer-based sequential recommenders, such as SASRec or BERT4Rec,
typically rely solely on learned item ID embeddings, making them vulnerable to
the item cold-start problem, particularly in environments with dynamic item
catalogs. While dense content embeddings from pre-trained models offer
potential solutions, direct integration into transformer-based recommenders has
consistently underperformed compared to ID-only approaches. We revisit this
integration challenge and propose DenseRec, a simple yet effective method that
introduces a dual-path embedding approach. DenseRec learns a linear projection
from the dense embedding space into the ID embedding space during training,
enabling seamless generalization to previously unseen items without requiring
specialized embedding models or complex infrastructure. In experiments on three
real-world datasets, we find DenseRec to consistently outperform an ID-only
SASRec baseline, even without additional hyperparameter tuning and while using
compact embedding models. Our analysis suggests improvements primarily arise
from better sequence representations in the presence of unseen items,
positioning DenseRec as a practical and robust solution for cold-start
sequential recommendation.

</details>


### [3] [Extracting Information from Scientific Literature via Visual Table Question Answering Models](https://arxiv.org/abs/2508.18661)
*Dongyoun Kim,Hyung-do Choi,Youngsun Jang,John Kim*

Main category: cs.IR

TL;DR: 研究评估了处理科学文档中表格数据的三种方法，结果显示保持表格结构完整性的处理方式在信息提取效果上更具优势。


<details>
  <summary>Details</summary>
Motivation: 研究旨在提升科学文档中表格数据的处理效果，以改善提取性问答能力并开发系统综述软件工具。

Method: 研究评估了三种方法：(1)光学字符识别（OCR），(2)文档视觉问答的预训练模型，(3)表格检测和结构识别，用以从表格和文本内容中提取和整合关键信息以回答提取性问题。进行探索性实验以评估这些方法的效果。

Result: 研究结果表明，保持表格结构的处理方法在代表和组织表格内容方面优于其他方法，特别是在识别文档中符号和标注时显得尤为关键。

Conclusion: 研究强调在科学文档的表格数据处理过程中，保持表格的结构完整性对提高信息提取的准确性和可靠性至关重要。

Abstract: This study explores three approaches to processing table data in scientific
papers to enhance extractive question answering and develop a software tool for
the systematic review process. The methods evaluated include: (1) Optical
Character Recognition (OCR) for extracting information from documents, (2)
Pre-trained models for document visual question answering, and (3) Table
detection and structure recognition to extract and merge key information from
tables with textual content to answer extractive questions. In exploratory
experiments, we augmented ten sample test documents containing tables and
relevant content against RF- EMF-related scientific papers with seven
predefined extractive question-answer pairs. The results indicate that
approaches preserving table structure outperform the others, particularly in
representing and organizing table content. Accurately recognizing specific
notations and symbols within the documents emerged as a critical factor for
improved results. Our study concludes that preserving the structural integrity
of tables is essential for enhancing the accuracy and reliability of extractive
question answering in scientific documents.

</details>


### [4] [Membership Inference Attacks on LLM-based Recommender Systems](https://arxiv.org/abs/2508.18665)
*Jiajie He,Yuechun Gu,Min-Chun Chen,Keke Chen*

Main category: cs.IR

TL;DR: 研究了在LLM基础上的推荐系统面临的隐私攻击风险，设计了四种会员推断攻击并验证了它们的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）在推荐系统中的应用带来了灵活性，但用户隐私信息可能会面临新的攻击风险，而这一问题尚未得到研究。

Method: 设计了四种会员推断攻击（MIA），分别是直接询问、幻想、相似性和投毒攻击。

Result: 实验结果显示出会员推断攻击在LLM RecSys系统上的现实威胁，尤其是直接询问和投毒攻击具有明显的优势。

Conclusion: 通过评估实验确定了LLM RecSys系统在隐私攻击下的现实威胁，尤其是直接询问和投毒攻击展现出了显著的攻击优势。

Abstract: Large language models (LLMs) based Recommender Systems (RecSys) can flexibly
adapt recommendation systems to different domains. It utilizes in-context
learning (ICL), i.e., the prompts, to customize the recommendation functions,
which include sensitive historical user-specific item interactions, e.g.,
implicit feedback like clicked items or explicit product reviews. Such private
information may be exposed to novel privacy attack. However, no study has been
done on this important issue. We design four membership inference attacks
(MIAs), aiming to reveal whether victims' historical interactions have been
used by system prompts. They are \emph{direct inquiry, hallucination,
similarity, and poisoning attacks}, each of which utilizes the unique features
of LLMs or RecSys. We have carefully evaluated them on three LLMs that have
been used to develop ICL-LLM RecSys and two well-known RecSys benchmark
datasets. The results confirm that the MIA threat on LLM RecSys is realistic:
direct inquiry and poisoning attacks showing significantly high attack
advantages. We have also analyzed the factors affecting these attacks, such as
the number of shots in system prompts and the position of the victim in the
shots.

</details>


### [5] [Taming the One-Epoch Phenomenon in Online Recommendation System by Two-stage Contrastive ID Pre-training](https://arxiv.org/abs/2508.18700)
*Yi-Ping Hsu,Po-Wei Wang,Chantat Eksombatchai,Jiajing Xu*

Main category: cs.IR

TL;DR: 提出一种两阶段训练策略，通过预训练来扩展数据覆盖，解决ID嵌入的过拟合问题，并提高推荐系统的性能。


<details>
  <summary>Details</summary>
Motivation: ID嵌入在大规模在线推荐系统中广泛应用，但由于数据分布的长尾效应，常导致过拟合。这种现象限制了训练时期，通常仅限于单个周期，即所谓的“一周期问题”。

Method: 提出了一种新的两阶段训练策略，在训练前阶段使用对比损失的简化模型进行预训练，从而扩展数据覆盖范围。

Result: 我们的离线实验显示，在预训练期间进行多周期训练不会导致过拟合，在进行复杂的下游推荐任务微调时，所得嵌入改善了在线泛化。在Pinterest进行了现场流量测试，取得了显著的全站参与度提升。

Conclusion: 使用两阶段训练策略可以克服ID嵌入的“一周期问题”，并提升推荐系统在复杂任务中的泛化能力。

Abstract: ID-based embeddings are widely used in web-scale online recommendation
systems. However, their susceptibility to overfitting, particularly due to the
long-tail nature of data distributions, often limits training to a single
epoch, a phenomenon known as the "one-epoch problem." This challenge has driven
research efforts to optimize performance within the first epoch by enhancing
convergence speed or feature sparsity. In this study, we introduce a novel
two-stage training strategy that incorporates a pre-training phase using a
minimal model with contrastive loss, enabling broader data coverage for the
embedding system. Our offline experiments demonstrate that multi-epoch training
during the pre-training phase does not lead to overfitting, and the resulting
embeddings improve online generalization when fine-tuned for more complex
downstream recommendation tasks. We deployed the proposed system in live
traffic at Pinterest, achieving significant site-wide engagement gains.

</details>


### [6] [Optimization of Latent-Space Compression using Game-Theoretic Techniques for Transformer-Based Vector Search](https://arxiv.org/abs/2508.18877)
*Kushagra Agrawal,Nisharg Nargund,Oishani Banerjee*

Main category: cs.IR

TL;DR: 提出了一种基于博弈论的潜在空间压缩框架，提高了向量搜索的效率和语义效用，并在与FAISS的比较中展示了其优势。


<details>
  <summary>Details</summary>
Motivation: 高维潜在表示使得现代信息检索系统的可扩展性和效率受到限制，因此需要优化潜在空间压缩。

Method: 提出了一个博弈论框架，将压缩策略建模为检索准确性和存储效率之间的零和游戏。

Result: 相较于FAISS，提出的方法在平均相似度和效用方面显著更高，但查询时间略有增加。

Conclusion: 使用博弈论框架优化潜在空间压缩可以提高向量搜索的效率和语义效用。

Abstract: Vector similarity search plays a pivotal role in modern information retrieval
systems, especially when powered by transformer-based embeddings. However, the
scalability and efficiency of such systems are often hindered by the high
dimensionality of latent representations. In this paper, we propose a novel
game-theoretic framework for optimizing latent-space compression to enhance
both the efficiency and semantic utility of vector search. By modeling the
compression strategy as a zero-sum game between retrieval accuracy and storage
efficiency, we derive a latent transformation that preserves semantic
similarity while reducing redundancy. We benchmark our method against FAISS, a
widely-used vector search library, and demonstrate that our approach achieves a
significantly higher average similarity (0.9981 vs. 0.5517) and utility (0.8873
vs. 0.5194), albeit with a modest increase in query time. This trade-off
highlights the practical value of game-theoretic latent compression in
high-utility, transformer-based search applications. The proposed system can be
seamlessly integrated into existing LLM pipelines to yield more semantically
accurate and computationally efficient retrieval.

</details>
