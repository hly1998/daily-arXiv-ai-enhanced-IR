{"id": "2508.11670", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11670", "abs": "https://arxiv.org/abs/2508.11670", "authors": ["Bongsu Kim"], "title": "RRRA: Resampling and Reranking through a Retriever Adapter", "comment": "8 pages, 4 figures, submitted to AAAI 2026", "summary": "In dense retrieval, effective training hinges on selecting high quality hard\nnegatives while avoiding false negatives. Recent methods apply heuristics based\non positive document scores to identify hard negatives, improving both\nperformance and interpretability. However, these global, example agnostic\nstrategies often miss instance specific false negatives. To address this, we\npropose a learnable adapter module that monitors Bi-Encoder representations to\nestimate the likelihood that a hard negative is actually a false negative. This\nprobability is modeled dynamically and contextually, enabling fine-grained,\nquery specific judgments. The predicted scores are used in two downstream\ncomponents: (1) resampling, where negatives are reweighted during training, and\n(2) reranking, where top-k retrieved documents are reordered at inference.\nEmpirical results on standard benchmarks show that our adapter-enhanced\nframework consistently outperforms strong Bi-Encoder baselines, underscoring\nthe benefit of explicit false negative modeling in dense retrieval.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u63d0\u9ad8\u7a20\u5bc6\u68c0\u7d22\u8bad\u7ec3\u6548\u679c\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u9002\u914d\u5668\u6a21\u5757\u6765\u8bc6\u522b\u548c\u5904\u7406\u5047\u8d1f\u6837\u672c\uff0c\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u6539\u5584\u7a20\u5bc6\u68c0\u7d22\u4e2d\u7684\u8bad\u7ec3\u8d28\u91cf\uff0c\u901a\u8fc7\u9009\u62e9\u9ad8\u8d28\u91cf\u7684\u96be\u8d1f\u6837\u672c\u5e76\u907f\u514d\u5047\u8d1f\u6837\u672c\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u5b66\u4e60\u7684\u9002\u914d\u6a21\u5757\uff0c\u5b83\u53ef\u4ee5\u76d1\u63a7\u53cc\u7f16\u7801\u5668\u7684\u8868\u793a\u6765\u4f30\u7b97\u96be\u8d1f\u6837\u672c\u662f\u5047\u8d1f\u6837\u672c\u7684\u53ef\u80fd\u6027\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u589e\u5f3a\u9002\u914d\u5668\u7684\u6846\u67b6\u6301\u7eed\u4f18\u4e8e\u5f3a\u5927\u7684\u53cc\u7f16\u7801\u5668\u57fa\u7ebf\uff0c\u8fd9\u8bf4\u660e\u5728\u7a20\u5bc6\u68c0\u7d22\u4e2d\u660e\u786e\u5efa\u6a21\u5047\u8d1f\u6837\u672c\u7684\u4f18\u52bf\u3002", "conclusion": "\u660e\u786e\u7684\u5047\u8d1f\u6837\u672c\u5efa\u6a21\u786e\u5b9e\u53ef\u4ee5\u63d0\u9ad8\u7a20\u5bc6\u68c0\u7d22\u7684\u8868\u73b0\u3002"}}
{"id": "2508.11671", "categories": ["cs.IR", "cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.11671", "abs": "https://arxiv.org/abs/2508.11671", "authors": ["Ronald Carvalho Boadana", "Ademir Guimar\u00e3es da Costa Junior", "Ricardo Rios", "F\u00e1bio Santos da Silva"], "title": "LLM-Based Intelligent Agents for Music Recommendation: A Comparison with Classical Content-Based Filtering", "comment": "12 pages, in Portuguese language, 2 figures, 5 tables, 3 formulas. To\n  be published in the Proceedings of the Encontro Nacional de Intelig\\^encia\n  Artificial e Computacional (ENIAC 2025)", "summary": "The growing availability of music on streaming platforms has led to\ninformation overload for users. To address this issue and enhance the user\nexperience, increasingly sophisticated recommendation systems have been\nproposed. This work investigates the use of Large Language Models (LLMs) from\nthe Gemini and LLaMA families, combined with intelligent agents, in a\nmulti-agent personalized music recommendation system. The results are compared\nwith a traditional content-based recommendation model, considering user\nsatisfaction, novelty, and computational efficiency. LLMs achieved satisfaction\nrates of up to \\textit{89{,}32\\%}, indicating their promising potential in\nmusic recommendation systems.", "AI": {"tldr": "\u5f15\u5165Gemini\u548cLLaMA\u7cfb\u5217\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u667a\u80fd\u4ee3\u7406\u4ee5\u6539\u5584\u97f3\u4e50\u63a8\u8350\u7cfb\u7edf\uff0c\u5b9e\u9a8c\u663e\u793a\u7528\u6237\u6ee1\u610f\u5ea6\u9ad8\u8fbe89.32%\u3002", "motivation": "\u7531\u4e8e\u97f3\u4e50\u5728\u6d41\u5a92\u4f53\u5e73\u53f0\u4e0a\u7684\u53ef\u7528\u6027\u4e0d\u65ad\u589e\u52a0\uff0c\u7528\u6237\u9762\u4e34\u4fe1\u606f\u8fc7\u8f7d\u7684\u95ee\u9898\u3002", "method": "\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u6765\u81eaGemini\u548cLLaMA\u7cfb\u5217\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u7ed3\u5408\u667a\u80fd\u4ee3\u7406\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u4e2a\u6027\u5316\u97f3\u4e50\u63a8\u8350\u7cfb\u7edf\u3002", "result": "LLMs\u5728\u7528\u6237\u6ee1\u610f\u5ea6\u3001\u521b\u65b0\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u5185\u5bb9\u63a8\u8350\u6a21\u578b\uff0c\u7528\u6237\u6ee1\u610f\u7387\u53ef\u8fbe\u523089.32%\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0cLLMs\u5728\u97f3\u4e50\u63a8\u8350\u7cfb\u7edf\u4e2d\u5177\u6709\u5f88\u5927\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.11784", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.11784", "abs": "https://arxiv.org/abs/2508.11784", "authors": ["Zabir Al Nazi", "Vagelis Hristidis", "Aaron Lawson McLean", "Jannat Ara Meem", "Md Taukir Azam Chowdhury"], "title": "Ontology-Guided Query Expansion for Biomedical Document Retrieval using Large Language Models", "comment": null, "summary": "Effective Question Answering (QA) on large biomedical document collections\nrequires effective document retrieval techniques. The latter remains a\nchallenging task due to the domain-specific vocabulary and semantic ambiguity\nin user queries. We propose BMQExpander, a novel ontology-aware query expansion\npipeline that combines medical knowledge - definitions and relationships - from\nthe UMLS Metathesaurus with the generative capabilities of large language\nmodels (LLMs) to enhance retrieval effectiveness. We implemented several\nstate-of-the-art baselines, including sparse and dense retrievers, query\nexpansion methods, and biomedical-specific solutions. We show that BMQExpander\nhas superior retrieval performance on three popular biomedical Information\nRetrieval (IR) benchmarks: NFCorpus, TREC-COVID, and SciFact - with\nimprovements of up to 22.1% in NDCG@10 over sparse baselines and up to 6.5%\nover the strongest baseline. Further, BMQExpander generalizes robustly under\nquery perturbation settings, in contrast to supervised baselines, achieving up\nto 15.7% improvement over the strongest baseline. As a side contribution, we\npublish our paraphrased benchmarks. Finally, our qualitative analysis shows\nthat BMQExpander has fewer hallucinations compared to other LLM-based query\nexpansion baselines.", "AI": {"tldr": "BMQExpander\u901a\u8fc7\u7ed3\u5408\u533b\u5b66\u77e5\u8bc6\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6781\u5927\u63d0\u9ad8\u4e86\u751f\u7269\u533b\u5b66\u6587\u6863\u7684\u68c0\u7d22\u6548\u7387\uff0c\u8868\u73b0\u4f18\u4e8e\u591a\u79cd\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6709\u6548\u7684\u95ee\u7b54\u7cfb\u7edf\u9700\u8981\u6709\u6548\u7684\u6587\u6863\u68c0\u7d22\u6280\u672f\uff0c\u800c\u751f\u7269\u533b\u5b66\u9886\u57df\u7684\u7279\u5b9a\u8bcd\u6c47\u548c\u8bed\u4e49\u6a21\u7cca\u6027\u4f7f\u8fd9\u4e00\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e86BMQExpander\uff0c\u4e00\u79cd\u7ed3\u5408UMLS Meta\u8bcd\u5e93\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u65b0\u578b\u672c\u4f53\u611f\u77e5\u67e5\u8be2\u6269\u5c55\u7ba1\u9053\u3002", "result": "\u5728NFCorpus\u3001TREC-COVID\u548cSciFact\u4e09\u4e2a\u751f\u7269\u533b\u5b66\u4fe1\u606f\u68c0\u7d22\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBMQExpander\u6bd4\u7a00\u758f\u57fa\u7ebf\u63d0\u9ad8\u4e8622.1%\uff0c\u6bd4\u6700\u5f3a\u57fa\u7ebf\u63d0\u9ad8\u4e866.5%\u3002\u5728\u67e5\u8be2\u6270\u52a8\u8bbe\u7f6e\u4e0b\uff0cBMQExpander\u8f83\u5f3a\u57fa\u7ebf\u63d0\u9ad8\u4e8615.7%\u3002", "conclusion": "BMQExpander\u5728\u751f\u7269\u533b\u5b66\u4fe1\u606f\u68c0\u7d22\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u8f83\u597d\u7684\u901a\u7528\u6027\uff0c\u5e76\u5728\u67e5\u8be2\u6269\u5c55\u4e2d\u4ea7\u751f\u8f83\u5c11\u7684\u5e7b\u89c9\u3002"}}
{"id": "2508.11977", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11977", "abs": "https://arxiv.org/abs/2508.11977", "authors": ["Zida Liang", "Changfa Wu", "Dunxian Huang", "Weiqiang Sun", "Ziyang Wang", "Yuliang Yan", "Jian Wu", "Yuning Jiang", "Bo Zheng", "Ke Chen", "Silu Zhou", "Yu Zhang"], "title": "TBGRecall: A Generative Retrieval Model for E-commerce Recommendation Scenarios", "comment": "Both authors contributed equally to this research. Work done during\n  internship at Alibaba. Corresponding author: Dunxian Huang\n  (dunxian.hdx@alibaba-inc.com). Affiliations: (1) Shanghai Jiaotong\n  University, Shanghai, China; (2) Alibaba Inc", "summary": "Recommendation systems are essential tools in modern e-commerce, facilitating\npersonalized user experiences by suggesting relevant products. Recent\nadvancements in generative models have demonstrated potential in enhancing\nrecommendation systems; however, these models often exhibit limitations in\noptimizing retrieval tasks, primarily due to their reliance on autoregressive\ngeneration mechanisms. Conventional approaches introduce sequential\ndependencies that impede efficient retrieval, as they are inherently unsuitable\nfor generating multiple items without positional constraints within a single\nrequest session. To address these limitations, we propose TBGRecall, a\nframework integrating Next Session Prediction (NSP), designed to enhance\ngenerative retrieval models for e-commerce applications. Our framework\nreformulation involves partitioning input samples into multi-session sequences,\nwhere each sequence comprises a session token followed by a set of item tokens,\nand then further incorporate multiple optimizations tailored to the generative\ntask in retrieval scenarios. In terms of training methodology, our pipeline\nintegrates limited historical data pre-training with stochastic partial\nincremental training, significantly improving training efficiency and\nemphasizing the superiority of data recency over sheer data volume. Our\nextensive experiments, conducted on public benchmarks alongside a large-scale\nindustrial dataset from TaoBao, show TBGRecall outperforms the state-of-the-art\nrecommendation methods, and exhibits a clear scaling law trend. Ultimately, NSP\nrepresents a significant advancement in the effectiveness of generative\nrecommendation systems for e-commerce applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u96c6\u6210\u4e0b\u4e00\u4f1a\u8bdd\u9884\u6d4b\u7684\u63a8\u8350\u6846\u67b6TBGRecall\uff0c\u5c55\u793a\u4e86\u5176\u5728\u7535\u5b50\u5546\u52a1\u5e94\u7528\u4e2d\u8d85\u8d8a\u73b0\u6709\u63a8\u8350\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\uff0c\u51cf\u5c11\u751f\u6210\u6a21\u578b\u5728\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faTBGRecall\u6846\u67b6\uff0c\u878d\u5408\u4e0b\u4e00\u4f1a\u8bdd\u9884\u6d4b\uff08NSP\uff09\uff0c\u901a\u8fc7\u5c06\u8f93\u5165\u6837\u672c\u5206\u5272\u4e3a\u591a\u4f1a\u8bdd\u5e8f\u5217\u5e76\u8fd0\u7528\u589e\u91cf\u8bad\u7ec3\u65b9\u6cd5\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002", "result": "TBGRecall\u5728\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u548c\u5927\u89c4\u6a21\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u63a8\u8350\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u660e\u663e\u7684\u7f29\u653e\u89c4\u5f8b\u8d8b\u52bf\u3002", "conclusion": "NSP\u663e\u8457\u63d0\u5347\u4e86\u7535\u5b50\u5546\u52a1\u751f\u6210\u63a8\u8350\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.11978", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.11978", "abs": "https://arxiv.org/abs/2508.11978", "authors": ["Viacheslav Yusupov", "Maxim Rakhuba", "Evgeny Frolov"], "title": "Leveraging Geometric Insights in Hyperbolic Triplet Loss for Improved Recommendations", "comment": null, "summary": "Recent studies have demonstrated the potential of hyperbolic geometry for\ncapturing complex patterns from interaction data in recommender systems. In\nthis work, we introduce a novel hyperbolic recommendation model that uses\ngeometrical insights to improve representation learning and increase\ncomputational stability at the same time. We reformulate the notion of\nhyperbolic distances to unlock additional representation capacity over\nconventional Euclidean space and learn more expressive user and item\nrepresentations. To better capture user-items interactions, we construct a\ntriplet loss that models ternary relations between users and their\ncorresponding preferred and nonpreferred choices through a mix of pairwise\ninteraction terms driven by the geometry of data. Our hyperbolic approach not\nonly outperforms existing Euclidean and hyperbolic models but also reduces\npopularity bias, leading to more diverse and personalized recommendations.", "AI": {"tldr": "\u4f7f\u7528\u53cc\u66f2\u51e0\u4f55\u6784\u5efa\u7684\u65b0\u63a8\u8350\u6a21\u578b\u901a\u8fc7\u51e0\u4f55\u6570\u636e\u7684\u4e09\u5143\u5173\u7cfb\u635f\u5931\u63d0\u9ad8\u4e86\u8868\u793a\u5b66\u4e60\u7684\u80fd\u529b\uff0c\u5e76\u51cf\u5c11\u6d41\u884c\u6027\u504f\u501a\uff0c\u63d0\u4f9b\u66f4\u4e2a\u6027\u5316\u7684\u63a8\u8350\u3002", "motivation": "\u5229\u7528\u53cc\u66f2\u51e0\u4f55\u53ef\u4ee5\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u66f4\u597d\u5730\u6355\u6349\u4e92\u52a8\u6570\u636e\u4e2d\u7684\u590d\u6742\u6a21\u5f0f\uff0c\u63d0\u9ad8\u8868\u793a\u5b66\u4e60\u7684\u80fd\u529b\u548c\u8ba1\u7b97\u7a33\u5b9a\u6027\u3002", "method": "\u91cd\u65b0\u5b9a\u4e49\u53cc\u66f2\u8ddd\u79bb\u4ee5\u63d0\u9ad8\u8868\u793a\u80fd\u529b\uff1b\u4f7f\u7528\u4e09\u5143\u5173\u7cfb\u635f\u5931\u5c06\u7528\u6237\u4e0e\u5176\u504f\u597d\u548c\u975e\u504f\u597d\u9009\u62e9\u7684\u4e09\u5143\u5173\u7cfb\u8fdb\u884c\u5efa\u6a21\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u6349\u7528\u6237\u9879\u76ee\u4ea4\u4e92\u3002", "result": "\u53cc\u66f2\u65b9\u6cd5\u4e0d\u4ec5\u4f18\u4e8e\u73b0\u6709\u7684\u6b27\u51e0\u91cc\u5f97\u548c\u53cc\u66f2\u6a21\u578b\uff0c\u8fd8\u51cf\u5c11\u4e86\u6d41\u884c\u6027\u504f\u501a\uff0c\u5e26\u6765\u4e86\u66f4\u591a\u6837\u5316\u548c\u4e2a\u6027\u5316\u7684\u63a8\u8350\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53cc\u66f2\u63a8\u8350\u6a21\u578b\uff0c\u5728\u63d0\u9ad8\u8868\u793a\u5b66\u4e60\u7684\u540c\u65f6\u589e\u52a0\u4e86\u8ba1\u7b97\u7a33\u5b9a\u6027\uff0c\u901a\u8fc7\u6539\u53d8\u53cc\u66f2\u8ddd\u79bb\u7684\u5b9a\u4e49\u63d0\u9ad8\u4e86\u8868\u793a\u80fd\u529b\uff0c\u80fd\u591f\u5b66\u4e60\u66f4\u5177\u8868\u8fbe\u529b\u7684\u7528\u6237\u548c\u9879\u76ee\u8868\u793a\u3002"}}
{"id": "2508.12353", "categories": ["cs.IR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.12353", "abs": "https://arxiv.org/abs/2508.12353", "authors": ["Marcel Gregoriadis", "Jingwei Kang", "Johan Pouwelse"], "title": "A Large-Scale Web Search Dataset for Federated Online Learning to Rank", "comment": "Accepted at CIKM 2025", "summary": "The centralized collection of search interaction logs for training ranking\nmodels raises significant privacy concerns. Federated Online Learning to Rank\n(FOLTR) offers a privacy-preserving alternative by enabling collaborative model\ntraining without sharing raw user data. However, benchmarks in FOLTR are\nlargely based on random partitioning of classical learning-to-rank datasets,\nsimulated user clicks, and the assumption of synchronous client participation.\nThis oversimplifies real-world dynamics and undermines the realism of\nexperimental results. We present AOL4FOLTR, a large-scale web search dataset\nwith 2.6 million queries from 10,000 users. Our dataset addresses key\nlimitations of existing benchmarks by including user identifiers, real click\ndata, and query timestamps, enabling realistic user partitioning, behavior\nmodeling, and asynchronous federated learning scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u7f51\u7edc\u641c\u7d22\u6570\u636e\u96c6AOL4FOLTR\uff0c\u6539\u5584\u4e86\u8054\u90a6\u5728\u7ebf\u5b66\u4e60\u6392\u540d\u7684\u73b0\u5b9e\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u96c6\u4e2d\u6536\u96c6\u641c\u7d22\u4ea4\u4e92\u65e5\u5fd7\u8fdb\u884c\u6392\u540d\u6a21\u578b\u8bad\u7ec3\u4f1a\u5f15\u53d1\u663e\u8457\u7684\u9690\u79c1\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86AOL4FOLTR\uff0c\u4e00\u4e2a\u5305\u542b260\u4e07\u6b21\u67e5\u8be2\u3001\u6d89\u53ca1\u4e07\u540d\u7528\u6237\u7684\u5927\u89c4\u6a21\u7f51\u7edc\u641c\u7d22\u6570\u636e\u96c6\uff0c\u5305\u542b\u7528\u6237\u6807\u8bc6\u7b26\u3001\u771f\u5b9e\u70b9\u51fb\u6570\u636e\u548c\u67e5\u8be2\u65f6\u95f4\u6233\u3002", "result": "AOL4FOLTR\u6570\u636e\u96c6\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7684\u5173\u952e\u9650\u5236\uff0c\u53ef\u4ee5\u8fdb\u884c\u771f\u5b9e\u7684\u7528\u6237\u5206\u533a\u3001\u884c\u4e3a\u5efa\u6a21\u548c\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u573a\u666f\u3002", "conclusion": "AOL4FOLTR\u63d0\u4f9b\u4e86\u66f4\u73b0\u5b9e\u7684\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4fc3\u8fdb\u4e86\u9690\u79c1\u4fdd\u62a4\u7684\u8054\u90a6\u5728\u7ebf\u5b66\u4e60\u6392\u540d\u7814\u7a76\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.12365", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.12365", "abs": "https://arxiv.org/abs/2508.12365", "authors": ["Chenhe Dong", "Shaowei Yao", "Pengkun Jiao", "Jianhui Yang", "Yiming Jin", "Zerui Huang", "Xiaojiang Zhou", "Dan Ou", "Haihong Tang"], "title": "TaoSR1: The Thinking Model for E-commerce Relevance Search", "comment": null, "summary": "Query-product relevance prediction is a core task in e-commerce search.\nBERT-based models excel at semantic matching but lack complex reasoning\ncapabilities. While Large Language Models (LLMs) are explored, most still use\ndiscriminative fine-tuning or distill to smaller models for deployment. We\npropose a framework to directly deploy LLMs for this task, addressing key\nchallenges: Chain-of-Thought (CoT) error accumulation, discriminative\nhallucination, and deployment feasibility. Our framework, TaoSR1, involves\nthree stages: (1) Supervised Fine-Tuning (SFT) with CoT to instill reasoning;\n(2) Offline sampling with a pass@N strategy and Direct Preference Optimization\n(DPO) to improve generation quality; and (3) Difficulty-based dynamic sampling\nwith Group Relative Policy Optimization (GRPO) to mitigate discriminative\nhallucination. Additionally, post-CoT processing and a cumulative\nprobability-based partitioning method enable efficient online deployment.\nTaoSR1 significantly outperforms baselines on offline datasets and achieves\nsubstantial gains in online side-by-side human evaluations, introducing a novel\nparadigm for applying CoT reasoning to relevance classification.", "AI": {"tldr": "TaoSR1 is a framework for deploying LLMs directly in relevance prediction, with three strategic stages to enhance reasoning, generation quality, and mitigate hallucination, leading to better performance than existing models.", "motivation": "To address the limitations of BERT-based models in semantic matching due to lack of complex reasoning capabilities and to improve the feasibility of deploying Large Language Models directly for relevance prediction in e-commerce search, overcoming issues like error accumulation and hallucination.", "method": "The proposed TaoSR1 framework includes three stages: (1) Supervised Fine-Tuning with Chain-of-Thought (CoT) that instills reasoning; (2) Offline sampling with a pass@N strategy and Direct Preference Optimization for improved generation quality; and (3) Difficulty-based dynamic sampling with Group Relative Policy Optimization to mitigate discriminative hallucination, combined with post-CoT processing and cumulative probability-based partitioning for efficient online deployment.", "result": "The TaoSR1 framework achieves significant improvements over baseline models in relevance prediction tasks, both in offline datasets and in online human evaluations, showing the effectiveness of its strategic stages and techniques.", "conclusion": "TaoSR1 framework significantly outperforms existing models both offline and in human evaluations online, providing a novel approach to LLM deployment in relevance classification."}}
{"id": "2508.12377", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.12377", "abs": "https://arxiv.org/abs/2508.12377", "authors": ["Yang Xu", "Zuliang Yang", "Kai Ming Ting"], "title": "Contrastive Multi-View Graph Hashing", "comment": null, "summary": "Multi-view graph data, which both captures node attributes and rich\nrelational information from diverse sources, is becoming increasingly prevalent\nin various domains. The effective and efficient retrieval of such data is an\nimportant task. Although multi-view hashing techniques have offered a paradigm\nfor fusing diverse information into compact binary codes, they typically assume\nattributes-based inputs per view. This makes them unsuitable for multi-view\ngraph data, where effectively encoding and fusing complex topological\ninformation from multiple heterogeneous graph views to generate unified binary\nembeddings remains a significant challenge. In this work, we propose\nContrastive Multi-view Graph Hashing (CMGHash), a novel end-to-end framework\ndesigned to learn unified and discriminative binary embeddings from multi-view\ngraph data. CMGHash learns a consensus node representation space using a\ncontrastive multi-view graph loss, which aims to pull $k$-nearest neighbors\nfrom all graphs closer while pushing away negative pairs, i.e., non-neighbor\nnodes. Moreover, we impose binarization constraints on this consensus space,\nenabling its conversion to a corresponding binary embedding space at minimal\ncost. Extensive experiments on several benchmark datasets demonstrate that\nCMGHash significantly outperforms existing approaches in terms of retrieval\naccuracy.", "AI": {"tldr": "CMGHash improves multi-view graph data retrieval by learning unified binary embeddings, significantly outperforming current methods in retrieval accuracy.", "motivation": "The motivation is the challenge of effectively encoding and fusing complex topological information from multiple heterogeneous graph views to create unified binary embeddings for multi-view graph data retrieval.", "method": "The method proposed is Contrastive Multi-view Graph Hashing (CMGHash), which is an end-to-end framework for learning unified binary embeddings from multi-view graph data. It uses a contrastive multi-view graph loss to learn a consensus node representation space, pulling $k$-nearest neighbors closer and pushing away non-neighbor nodes. Binarization constraints are then imposed for conversion to binary embedding space.", "result": "Experiments on several benchmark datasets show that CMGHash achieves superior retrieval accuracy compared to existing methods.", "conclusion": "CMGHash significantly outperforms existing approaches in terms of retrieval accuracy for multi-view graph data."}}
{"id": "2508.12645", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.12645", "abs": "https://arxiv.org/abs/2508.12645", "authors": ["Hongyang Liu", "Zhu Sun", "Tianjun Wei", "Yan Wang", "Jiajie Zhu", "Xinghua Qu"], "title": "Diagnostic-Guided Dynamic Profile Optimization for LLM-based User Simulators in Sequential Recommendation", "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled realistic user\nsimulators for developing and evaluating recommender systems (RSs). However,\nexisting LLM-based simulators for RSs face two major limitations: (1) static\nand single-step prompt-based inference that leads to inaccurate and incomplete\nuser profile construction; (2) unrealistic and single-round\nrecommendation-feedback interaction pattern that fails to capture real-world\nscenarios. To address these limitations, we propose DGDPO (Diagnostic-Guided\nDynamic Profile Optimization), a novel framework that constructs user profile\nthrough a dynamic and iterative optimization process to enhance the simulation\nfidelity. Specifically, DGDPO incorporates two core modules within each\noptimization loop: firstly, a specialized LLM-based diagnostic module,\ncalibrated through our novel training strategy, accurately identifies specific\ndefects in the user profile. Subsequently, a generalized LLM-based treatment\nmodule analyzes the diagnosed defect and generates targeted suggestions to\nrefine the profile. Furthermore, unlike existing LLM-based user simulators that\nare limited to single-round interactions, we are the first to integrate DGDPO\nwith sequential recommenders, enabling a bidirectional evolution where user\nprofiles and recommendation strategies adapt to each other over multi-round\ninteractions. Extensive experiments conducted on three real-world datasets\ndemonstrate the effectiveness of our proposed framework.", "AI": {"tldr": "DGDPO\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u4f18\u5316\u548c\u591a\u8f6e\u4ea4\u4e92\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u63a8\u8350\u7cfb\u7edf\u6a21\u62df\u5668\u7684\u4e3b\u8981\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u7684\u7528\u6237\u6a21\u62df\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u7528\u6237\u6a21\u62df\u5668\u5b58\u5728\u5bf9\u7528\u6237\u753b\u50cf\u6784\u5efa\u4e0d\u51c6\u786e\u548c\u5355\u4e00\u8f6e\u53cd\u9988\u4ea4\u4e92\u4e0d\u771f\u5b9e\u7684\u95ee\u9898\u3002", "method": "\u6211\u4eec\u7684\u65b9\u6cd5\u7ed3\u5408\u4e86\u4e00\u4e2a\u4e13\u95e8\u7684LLM\u8bca\u65ad\u6a21\u5757\u548c\u4e00\u4e2a\u901a\u7528\u7684LLM\u5904\u7406\u6a21\u5757\uff0c\u901a\u8fc7\u591a\u8f6e\u4ea4\u4e92\u8fc7\u7a0b\u4f18\u5316\u7528\u6237\u753b\u50cf\u3002", "result": "\u901a\u8fc7\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u6211\u4eec\u6240\u63d0\u51fa\u7684\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDGDPO\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u548c\u8fed\u4ee3\u4f18\u5316\u8fc7\u7a0b\u6765\u589e\u5f3a\u63a8\u8350\u7cfb\u7edf\u4e2d\u7528\u6237\u6a21\u62df\u7684\u51c6\u786e\u6027\u548c\u5b8c\u6574\u6027\u3002"}}
{"id": "2508.12665", "categories": ["cs.IR", "H.3.3"], "pdf": "https://arxiv.org/pdf/2508.12665", "abs": "https://arxiv.org/abs/2508.12665", "authors": ["Xu Zhao", "Ruibo Ma", "Jiaqi Chen", "Weiqi Zhao", "Ping Yang", "Yao Hu"], "title": "Multi-Granularity Distribution Modeling for Video Watch Time Prediction via Exponential-Gaussian Mixture Network", "comment": "Accepted as oral full paper by RecSys'2025 conference", "summary": "Accurate watch time prediction is crucial for enhancing user engagement in\nstreaming short-video platforms, although it is challenged by complex\ndistribution characteristics across multi-granularity levels. Through\nsystematic analysis of real-world industrial data, we uncover two critical\nchallenges in watch time prediction from a distribution aspect: (1)\ncoarse-grained skewness induced by a significant concentration of quick-skips1,\n(2) fine-grained diversity arising from various user-video interaction\npatterns. Consequently, we assume that the watch time follows the\nExponential-Gaussian Mixture (EGM) distribution, where the exponential and\nGaussian components respectively characterize the skewness and diversity.\nAccordingly, an Exponential-Gaussian Mixture Network (EGMN) is proposed for the\nparameterization of EGM distribution, which consists of two key modules: a\nhidden representation encoder and a mixture parameter generator. We conducted\nextensive offline experiments on public datasets and online A/B tests on the\nindustrial short-video feeding scenario of Xiaohongshu App to validate the\nsuperiority of EGMN compared with existing state-of-the-art methods.\nRemarkably, comprehensive experimental results have proven that EGMN exhibits\nexcellent distribution fitting ability across coarse-to-fine-grained levels. We\nopen source related code on Github: https://github.com/BestActionNow/EGMN.", "AI": {"tldr": "\u63d0\u51fa\u4e86EGM\u5206\u5e03\u4e0eEGMN\u7f51\u7edc\uff0c\u4ee5\u89e3\u51b3\u77ed\u89c6\u9891\u5e73\u53f0\u89c2\u770b\u65f6\u95f4\u9884\u6d4b\u4e2d\u7684\u5206\u5e03\u504f\u659c\u548c\u591a\u6837\u6027\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eEGMN\u5177\u6709\u6781\u4f73\u7684\u5206\u5e03\u62df\u5408\u80fd\u529b\u3002", "motivation": "\u51c6\u786e\u7684\u89c2\u770b\u65f6\u95f4\u9884\u6d4b\u5bf9\u4e8e\u63d0\u5347\u7528\u6237\u53c2\u4e0e\u5ea6\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4e5f\u9762\u4e34\u7740\u591a\u7c92\u5ea6\u7ea7\u522b\u4e0a\u7684\u590d\u6742\u5206\u5e03\u7279\u5f81\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6307\u6570-\u9ad8\u65af\u6df7\u5408\u7f51\u7edc\uff08EGMN\uff09\u8fdb\u884cEGM\u5206\u5e03\u53c2\u6570\u5316\uff0c\u5176\u4e2d\u5305\u62ec\u9690\u85cf\u8868\u793a\u7f16\u7801\u5668\u548c\u6df7\u5408\u53c2\u6570\u751f\u6210\u5668\u4e24\u4e2a\u5173\u952e\u6a21\u5757\u3002", "result": "\u901a\u8fc7\u5728\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u79bb\u7ebf\u5b9e\u9a8c\u548c\u5728\u5c0f\u7ea2\u4e66\u5e94\u7528\u4e0a\u7684\u5728\u7ebfA/B\u6d4b\u8bd5\u9a8c\u8bc1\u4e86EGMN\u76f8\u8f83\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "EGMN\u5728\u7c97\u7c92\u5ea6\u5230\u7ec6\u7c92\u5ea6\u6c34\u5e73\u4e0a\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u5206\u5e03\u62df\u5408\u80fd\u529b\u3002"}}
{"id": "2508.12706", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12706", "abs": "https://arxiv.org/abs/2508.12706", "authors": ["Yongchun Zhu", "Guanyu Jiang", "Jingwu Chen", "Feng Zhang", "Xiao Yang", "Zuotao Liu"], "title": "Asymmetric Diffusion Recommendation Model", "comment": "Accepted by CIKM2025", "summary": "Recently, motivated by the outstanding achievements of diffusion models, the\ndiffusion process has been employed to strengthen representation learning in\nrecommendation systems. Most diffusion-based recommendation models typically\nutilize standard Gaussian noise in symmetric forward and reverse processes in\ncontinuous data space. Nevertheless, the samples derived from recommendation\nsystems inhabit a discrete data space, which is fundamentally different from\nthe continuous one. Moreover, Gaussian noise has the potential to corrupt\npersonalized information within latent representations. In this work, we\npropose a novel and effective method, named Asymmetric Diffusion Recommendation\nModel (AsymDiffRec), which learns forward and reverse processes in an\nasymmetric manner. We define a generalized forward process that simulates the\nmissing features in real-world recommendation samples. The reverse process is\nthen performed in an asymmetric latent feature space. To preserve personalized\ninformation within the latent representation, a task-oriented optimization\nstrategy is introduced. In the serving stage, the raw sample with missing\nfeatures is regarded as a noisy input to generate a denoising and robust\nrepresentation for the final prediction. By equipping base models with\nAsymDiffRec, we conduct online A/B tests, achieving improvements of +0.131% and\n+0.166% in terms of users' active days and app usage duration respectively.\nAdditionally, the extended offline experiments also demonstrate improvements.\nAsymDiffRec has been implemented in the Douyin Music App.", "AI": {"tldr": "AsymDiffRec\u4e0d\u5bf9\u79f0\u6269\u6563\u6a21\u578b\u63d0\u9ad8\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u8868\u73b0\uff0c\u5728Douyin\u97f3\u4e50\u5e94\u7528\u4e2d\u5b9e\u73b0\u5e76\u53d6\u5f97\u4e86\u7528\u6237\u6d3b\u8dc3\u5ea6\u548c\u4f7f\u7528\u65f6\u957f\u7684\u63d0\u5347\u3002", "motivation": "\u53d7\u5230\u6269\u6563\u6a21\u578b\u6210\u5c31\u7684\u6fc0\u52b1\uff0c\u5c1d\u8bd5\u5728\u79bb\u6563\u6570\u636e\u7a7a\u95f4\u4e2d\u589e\u5f3a\u63a8\u8350\u7cfb\u7edf\u7684\u8868\u793a\u5b66\u4e60\uff0c\u540c\u65f6\u907f\u514d\u9ad8\u65af\u566a\u58f0\u5bf9\u4e2a\u6027\u5316\u4fe1\u606f\u7684\u7834\u574f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u5bf9\u79f0\u6269\u6563\u63a8\u8350\u6a21\u578b\uff08AsymDiffRec\uff09\uff0c\u901a\u8fc7\u4e0d\u5bf9\u79f0\u65b9\u5f0f\u5b66\u4e60\u6b63\u5411\u548c\u9006\u5411\u8fc7\u7a0b\uff0c\u6a21\u62df\u63a8\u8350\u6837\u672c\u4e2d\u7684\u7f3a\u5931\u7279\u5f81\uff0c\u91c7\u7528\u4efb\u52a1\u5bfc\u5411\u7684\u4f18\u5316\u7b56\u7565\u63d0\u9ad8\u9690\u6027\u7279\u5f81\u7a7a\u95f4\u7684\u4e2a\u6027\u5316\u4fe1\u606f\u4fdd\u7559\u3002", "result": "\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\uff0c\u7528\u6237\u6d3b\u8dc3\u5929\u6570\u548c\u5e94\u7528\u4f7f\u7528\u65f6\u957f\u5206\u522b\u63d0\u5347\u4e860.131%\u548c0.166%\uff1b\u79bb\u7ebf\u5b9e\u9a8c\u4e5f\u663e\u793a\u4e86\u6027\u80fd\u7684\u6539\u5584\u3002\u8be5\u65b9\u6cd5\u5df2\u5728Douyin\u97f3\u4e50\u5e94\u7528\u4e2d\u5b9e\u73b0\u3002", "conclusion": "AsymDiffRec\u65b9\u6cd5\u901a\u8fc7\u4e0d\u5bf9\u79f0\u7684\u6269\u6563\u6a21\u578b\u5b66\u4e60\u589e\u5f3a\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u8868\u73b0\uff0c\u6210\u529f\u63d0\u9ad8\u4e86\u7528\u6237\u6d3b\u8dc3\u5ea6\u548c\u5e94\u7528\u4f7f\u7528\u65f6\u957f\u3002"}}
{"id": "2508.12752", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.12752", "abs": "https://arxiv.org/abs/2508.12752", "authors": ["Wenlin Zhang", "Xiaopeng Li", "Yingyi Zhang", "Pengyue Jia", "Yichao Wang", "Huifeng Guo", "Yong Liu", "Xiangyu Zhao"], "title": "Deep Research: A Survey of Autonomous Research Agents", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has driven the\ndevelopment of agentic systems capable of autonomously performing complex\ntasks. Despite their impressive capabilities, LLMs remain constrained by their\ninternal knowledge boundaries. To overcome these limitations, the paradigm of\ndeep research has been proposed, wherein agents actively engage in planning,\nretrieval, and synthesis to generate comprehensive and faithful analytical\nreports grounded in web-based evidence. In this survey, we provide a systematic\noverview of the deep research pipeline, which comprises four core stages:\nplanning, question developing, web exploration, and report generation. For each\nstage, we analyze the key technical challenges and categorize representative\nmethods developed to address them. Furthermore, we summarize recent advances in\noptimization techniques and benchmarks tailored for deep research. Finally, we\ndiscuss open challenges and promising research directions, aiming to chart a\nroadmap toward building more capable and trustworthy deep research agents.", "AI": {"tldr": "\u8be5\u8c03\u67e5\u63d0\u4f9b\u4e86\u6df1\u5ea6\u7814\u7a76\u7ba1\u9053\u7684\u7cfb\u7edf\u6982\u8ff0\uff0c\u5206\u6790\u4e86\u6280\u672f\u6311\u6218\uff0c\u603b\u7ed3\u4e86\u4f18\u5316\u548c\u57fa\u51c6\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u4e3a\u4e86\u514b\u670dLLMs\u5728\u5185\u90e8\u77e5\u8bc6\u754c\u9650\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u6df1\u5ea6\u7814\u7a76\u7684\u8303\u5f0f\uff0c\u4ee5\u4fbf\u901a\u8fc7\u7f51\u7edc\u8bc1\u636e\u751f\u6210\u5168\u9762\u548c\u5fe0\u5b9e\u7684\u5206\u6790\u62a5\u544a\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u7efc\u8ff0\u7684\u65b9\u6cd5\uff0c\u4ece\u89c4\u5212\u3001\u95ee\u9898\u5f00\u53d1\u3001\u7f51\u7edc\u63a2\u7d22\u548c\u62a5\u544a\u751f\u6210\u56db\u4e2a\u9636\u6bb5\u5206\u6790\u73b0\u6709\u6280\u672f\u6311\u6218\u548c\u5206\u7c7b\u65b9\u6cd5\u3002", "result": "\u63d0\u4f9b\u4e86\u6df1\u5ea6\u7814\u7a76\u7ba1\u9053\u7684\u7cfb\u7edf\u6982\u8ff0\uff0c\u5206\u7c7b\u4e86\u4ee3\u8868\u6027\u6280\u672f\uff0c\u5e76\u603b\u7ed3\u4e86\u4f18\u5316\u6280\u672f\u548c\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u5c55\u3002\u63a2\u8ba8\u4e86\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u6982\u8ff0\u4e86\u6df1\u5ea6\u7814\u7a76\u7ba1\u9053\u7684\u6838\u5fc3\u9636\u6bb5\uff0c\u5e76\u5206\u6790\u4e86\u6bcf\u4e2a\u9636\u6bb5\u7684\u6280\u672f\u6311\u6218\u548c\u65b9\u6cd5\u3002\u603b\u7ed3\u4e86\u8fd1\u671f\u4f18\u5316\u6280\u672f\u7684\u8fdb\u5c55\uff0c\u4ee5\u53ca\u6df1\u5ea6\u7814\u7a76\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u63a2\u8ba8\u4e86\u5f00\u653e\u6027\u95ee\u9898\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.13019", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.13019", "abs": "https://arxiv.org/abs/2508.13019", "authors": ["Lucien Heitz", "Runze Li", "Oana Inel", "Abraham Bernstein"], "title": "Informfully Recommenders -- Reproducibility Framework for Diversity-aware Intra-session Recommendations", "comment": "10 pages", "summary": "Norm-aware recommender systems have gained increased attention, especially\nfor diversity optimization. The recommender systems community has\nwell-established experimentation pipelines that support reproducible\nevaluations by facilitating models' benchmarking and comparisons against\nstate-of-the-art methods. However, to the best of our knowledge, there is\ncurrently no reproducibility framework to support thorough norm-driven\nexperimentation at the pre-processing, in-processing, post-processing, and\nevaluation stages of the recommender pipeline. To address this gap, we present\nInformfully Recommenders, a first step towards a normative reproducibility\nframework that focuses on diversity-aware design built on Cornac. Our extension\nprovides an end-to-end solution for implementing and experimenting with\nnormative and general-purpose diverse recommender systems that cover 1) dataset\npre-processing, 2) diversity-optimized models, 3) dedicated intrasession item\nre-ranking, and 4) an extensive set of diversity metrics. We demonstrate the\ncapabilities of our extension through an extensive offline experiment in the\nnews domain.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aInformfully Recommenders\u7684\u5e73\u53f0\uff0c\u652f\u6301\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u591a\u6837\u6027\u4f18\u5316\uff0c\u586b\u8865\u4e86\u7f3a\u4e4f\u89c4\u8303\u9a71\u52a8\u5b9e\u9a8c\u6846\u67b6\u7684\u7a7a\u767d\u3002", "motivation": "\u5f53\u524d\u63a8\u8350\u7cfb\u7edf\u9886\u57df\u7f3a\u4e4f\u4e00\u4e2a\u5168\u9762\u7684\u89c4\u8303\u9a71\u52a8\u5b9e\u9a8c\u6846\u67b6\uff0c\u65e0\u6cd5\u652f\u6301\u5728\u63a8\u8350\u7ba1\u9053\u7684\u4e0d\u540c\u9636\u6bb5\u8fdb\u884c\u5b9e\u9a8c\u3002", "method": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u540d\u4e3aInformfully Recommenders\u7684\u5ef6\u4f38\u5e73\u53f0\uff0c\u63d0\u4f9b\u4ece\u6570\u636e\u96c6\u9884\u5904\u7406\u5230\u591a\u6837\u6027\u4f18\u5316\u7684\u6a21\u578b\u3001\u4e13\u7528\u7684\u4f1a\u8bdd\u5185\u9879\u76ee\u91cd\u65b0\u6392\u540d\u548c\u5e7f\u6cdb\u7684\u591a\u6837\u6027\u5ea6\u91cf\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u901a\u8fc7\u65b0\u95fb\u9886\u57df\u7684\u5e7f\u6cdb\u79bb\u7ebf\u5b9e\u9a8c\u5c55\u793a\u4e86\u8be5\u6269\u5c55\u7684\u529f\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aInformfully Recommenders\u7684\u5e73\u53f0\uff0c\u7528\u4e8e\u652f\u6301\u591a\u6837\u6027\u8bbe\u8ba1\u5e76\u5efa\u7acb\u5728Cornac\u4e4b\u4e0a\uff0c\u4ee5\u586b\u8865\u63a8\u8350\u7cfb\u7edf\u4e2d\u7f3a\u4e4f\u89c4\u8303\u9a71\u52a8\u5b9e\u9a8c\u6846\u67b6\u7684\u7a7a\u767d\u3002"}}
{"id": "2508.13035", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.13035", "abs": "https://arxiv.org/abs/2508.13035", "authors": ["Runze Li", "Lucien Heitz", "Oana Inel", "Abraham Bernstein"], "title": "D-RDW: Diversity-Driven Random Walks for News Recommender Systems", "comment": "6 pages", "summary": "This paper introduces Diversity-Driven RandomWalks (D-RDW), a lightweight\nalgorithm and re-ranking technique that generates diverse news recommendations.\nD-RDW is a societal recommender, which combines the diversification\ncapabilities of the traditional random walk algorithms with customizable target\ndistributions of news article properties. In doing so, our model provides a\ntransparent approach for editors to incorporate norms and values into the\nrecommendation process. D-RDW shows enhanced performance across key diversity\nmetrics that consider the articles' sentiment and political party mentions when\ncompared to state-of-the-art neural models. Furthermore, D-RDW proves to be\nmore computationally efficient than existing approaches.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u7528\u4e8e\u751f\u6210\u591a\u6837\u5316\u65b0\u95fb\u63a8\u8350\u7684D-RDW\u7b97\u6cd5\uff0c\u5176\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u795e\u7ecf\u6a21\u578b\uff0c\u5e76\u4e14\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002", "motivation": "\u9700\u8981\u4e00\u79cd\u900f\u660e\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u5c06\u7f16\u8f91\u7684\u89c4\u8303\u548c\u4ef7\u503c\u89c2\u6574\u5408\u5230\u65b0\u95fb\u63a8\u8350\u8fc7\u7a0b\u4e2d\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86D-RDW\u7b97\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7b97\u6cd5\u548c\u91cd\u6392\u5e8f\u6280\u672f\uff0c\u7ed3\u5408\u4e86\u4f20\u7edf\u968f\u673a\u6e38\u8d70\u7b97\u6cd5\u7684\u591a\u6837\u5316\u80fd\u529b\u548c\u65b0\u95fb\u6587\u7ae0\u5c5e\u6027\u7684\u53ef\u5b9a\u5236\u76ee\u6807\u5206\u5e03\u3002", "result": "D-RDW\u7b97\u6cd5\u4e0e\u6700\u5148\u8fdb\u7684\u795e\u7ecf\u6a21\u578b\u76f8\u6bd4\uff0c\u5728\u6587\u7ae0\u60c5\u611f\u548c\u653f\u6cbb\u515a\u6d3e\u63d0\u53ca\u7b49\u591a\u6837\u6027\u6307\u6807\u4e0a\u8868\u73b0\u66f4\u4f73\uff0c\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "D-RDW\u7b97\u6cd5\u80fd\u591f\u751f\u6210\u591a\u6837\u5316\u7684\u65b0\u95fb\u63a8\u8350\uff0c\u5e76\u5728\u591a\u9879\u591a\u6837\u6027\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u8f83\u9ad8\u3002"}}
{"id": "2508.13064", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13064", "abs": "https://arxiv.org/abs/2508.13064", "authors": ["Seongeun Ryu", "Yunyong Ko", "Sang-Wook Kim"], "title": "Is This News Still Interesting to You?: Lifetime-aware Interest Matching for News Recommendation", "comment": "10 pages, 7 figures, 4 tables, accepted at ACM International\n  Conference on Information and Knowledge Management (CIKM)", "summary": "Personalized news recommendation aims to deliver news articles aligned with\nusers' interests, serving as a key solution to alleviate the problem of\ninformation overload on online news platforms. While prior work has improved\ninterest matching through refined representations of news and users, the\nfollowing time-related challenges remain underexplored: (C1) leveraging the age\nof clicked news to infer users' interest persistence, and (C2) modeling the\nvarying lifetime of news across topics and users. To jointly address these\nchallenges, we propose a novel Lifetime-aware Interest Matching framework for\nnEws recommendation, named LIME, which incorporates three key strategies: (1)\nUser-Topic lifetime-aware age representation to capture the relative age of\nnews with respect to a user-topic pair, (2) Candidate-aware lifetime attention\nfor generating temporally aligned user representation, and (3) Freshness-guided\ninterest refinement for prioritizing valid candidate news at prediction time.\nExtensive experiments on two real-world datasets demonstrate that LIME\nconsistently outperforms a wide range of state-of-the-art news recommendation\nmethods, and its model agnostic strategies significantly improve recommendation\naccuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86LIME\u6846\u67b6\uff0c\u901a\u8fc7\u7528\u6237-\u4e3b\u9898\u751f\u547d\u671f\u611f\u77e5\u3001\u5019\u9009\u611f\u77e5\u7684\u5bff\u547d\u6ce8\u610f\u673a\u5236\u53ca\u65b0\u9c9c\u5ea6\u6307\u5bfc\u7684\u5174\u8da3\u7ec6\u5316\u7b56\u7565\uff0c\u6539\u5584\u65b0\u95fb\u63a8\u8350\u7684\u5174\u8da3\u5339\u914d\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u5728\u7ebf\u65b0\u95fb\u5e73\u53f0\u7684\u4fe1\u606f\u8fc7\u8f7d\u95ee\u9898\uff0c\u4e2a\u6027\u5316\u65b0\u95fb\u63a8\u8350\u81f4\u529b\u4e8e\u63d0\u4f9b\u7b26\u5408\u7528\u6237\u5174\u8da3\u7684\u65b0\u95fb\u6587\u7ae0\u3002\u5c3d\u7ba1\u4e4b\u524d\u7684\u7814\u7a76\u901a\u8fc7\u7cbe\u7ec6\u5316\u7684\u65b0\u95fb\u548c\u7528\u6237\u8868\u793a\u6539\u8fdb\u4e86\u5174\u8da3\u5339\u914d\uff0c\u4f46\u5728\u65f6\u95f4\u76f8\u5173\u7684\u6311\u6218\u65b9\u9762\uff08\u5982\u7528\u6237\u5174\u8da3\u7684\u6301\u4e45\u6027\u548c\u65b0\u95fb\u5728\u4e0d\u540c\u4e3b\u9898\u548c\u7528\u6237\u95f4\u7684\u5bff\u547d\u53d8\u5f02\uff09\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u540d\u4e3aLIME\uff08Lifetime-aware Interest Matching for nEws recommendation\uff09\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u7b56\u7565\u5171\u540c\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff1a\uff081\uff09\u7528\u6237-\u4e3b\u9898\u751f\u547d\u671f\u611f\u77e5\u7684\u5e74\u9f84\u8868\u793a\uff0c\u4ee5\u6355\u6349\u4e0e\u7528\u6237-\u4e3b\u9898\u5bf9\u76f8\u5173\u7684\u65b0\u95fb\u76f8\u5bf9\u5e74\u9f84\uff0c\uff082\uff09\u5019\u9009\u611f\u77e5\u7684\u5bff\u547d\u6ce8\u610f\u673a\u5236\uff0c\u7528\u4e8e\u751f\u6210\u65f6\u95f4\u5bf9\u9f50\u7684\u7528\u6237\u8868\u793a\uff0c\uff083\uff09\u4ee5\u65b0\u9c9c\u5ea6\u6307\u5bfc\u7684\u5174\u8da3\u7ec6\u5316\u673a\u5236\u5728\u9884\u6d4b\u65f6\u4f18\u5148\u9009\u62e9\u6709\u6548\u7684\u5019\u9009\u65b0\u95fb\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cLIME\u59cb\u7ec8\u4f18\u4e8e\u591a\u79cd\u5148\u8fdb\u7684\u65b0\u95fb\u63a8\u8350\u65b9\u6cd5\uff0c\u5176\u6a21\u578b\u65e0\u5173\u7684\u7b56\u7565\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u8350\u51c6\u786e\u6027\u3002", "conclusion": "LIME\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u7528\u6237\u5174\u8da3\u6301\u4e45\u6027\u63a8\u65ad\u548c\u4e0d\u540c\u4e3b\u9898\u53ca\u7528\u6237\u95f4\u65b0\u95fb\u5bff\u547d\u53d8\u5f02\u95ee\u9898\uff0c\u8f83\u73b0\u6709\u65b9\u6cd5\u5728\u63a8\u8350\u51c6\u786e\u6027\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u4f18\u52bf\u3002"}}
