<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 13]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [On-Premise AI for the Newsroom: Evaluating Small Language Models for Investigative Document Search](https://arxiv.org/abs/2509.25494)
*Nick Hagar,Nicholas Diakopoulos,Jeremy Gilbert*

Main category: cs.IR

TL;DR: 记者中心的方法使用小型、可本地部署的语言模型，旨在提高透明度和编辑控制，通过一个包含五个阶段的流程来完善LLM驱动的文档搜索。


<details>
  <summary>Details</summary>
Motivation: 调查记者需要处理大量文档集合，而大型语言模型（LLMs）与检索增强生成（RAG）能力能够加速发现文档的过程。然而，由于幻觉风险、验证负担和数据隐私问题，新闻编辑室的采用仍然有限。

Method: 采用一种以记者为中心的方法，通过五个阶段的流程，包括语料库总结、搜索计划、并行线程执行、质量评估和综合，利用小型、可本地部署的语言模型以确保数据安全和审计完整性。

Result: 通过评估三个量化模型（Gemma 3 12B、Qwen 3 14B 和 GPT-OSS 20B）在两个语料库上的表现，发现可靠性存在显著差异。此外，所有模型在标准桌面硬件上运行良好，展示了资源受限新闻编辑室的可行性。但是，系统性挑战依然存在，包括多阶段合成中的错误传播，以及因训练数据与语料库内容重叠导致的性能显著变化。

Conclusion: 有效的新闻编辑室AI部署需要谨慎选择模型和设计系统，同时需要人类的监督以维护准确性和责任性标准。

Abstract: Investigative journalists routinely confront large document collections.
Large language models (LLMs) with retrieval-augmented generation (RAG)
capabilities promise to accelerate the process of document discovery, but
newsroom adoption remains limited due to hallucination risks, verification
burden, and data privacy concerns. We present a journalist-centered approach to
LLM-powered document search that prioritizes transparency and editorial control
through a five-stage pipeline -- corpus summarization, search planning,
parallel thread execution, quality evaluation, and synthesis -- using small,
locally-deployable language models that preserve data security and maintain
complete auditability through explicit citation chains. Evaluating three
quantized models (Gemma 3 12B, Qwen 3 14B, and GPT-OSS 20B) on two corpora, we
find substantial variation in reliability. All models achieved high citation
validity and ran effectively on standard desktop hardware (e.g., 24 GB of
memory), demonstrating feasibility for resource-constrained newsrooms. However,
systematic challenges emerged, including error propagation through multi-stage
synthesis and dramatic performance variation based on training data overlap
with corpus content. These findings suggest that effective newsroom AI
deployment requires careful model selection and system design, alongside human
oversight for maintaining standards of accuracy and accountability.

</details>


### [2] [TRUE: A Reproducible Framework for LLM-Driven Relevance Judgment in Information Retrieval](https://arxiv.org/abs/2509.25602)
*Mouly Dewan,Jiqun Liu,Chirag Shah*

Main category: cs.IR

TL;DR: 本文提出了TRUE方法以改进LLM相关性判断标准化流程，结果显示在多个数据集上该方法表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的相关性判断方法过于依赖敏感的提示策略，缺乏生成可靠标签的标准化流程。然而，LLM的相关性判断生成已成为信息检索中推进评估方法的关键，并且与人工判断呈现高相关性。为了填补这一空缺，本文重新引入TRUE方法，用于相关性判断生成。

Method: 本文介绍了一种名为Task-aware Rubric-based Evaluation (TRUE)的方法，用于生成相关性判断。该方法通过迭代数据采样和推理，评估多个因素下的相关性判断，包括意图、覆盖率、具体性、准确性和有用性。

Result: 本文在TREC DL 2019, 2020和LLMJudge数据集上评估了TRUE，结果显示TRUE在系统排名LLM排行榜上表现强劲。

Conclusion: TRUE框架不仅提供了一个可复制的LLM相关性判断生成框架，还在多个维度上对其有效性进行了分析。

Abstract: LLM-based relevance judgment generation has become a crucial approach in
advancing evaluation methodologies in Information Retrieval (IR). It has
progressed significantly, often showing high correlation with human judgments
as reflected in LLMJudge leaderboards \cite{rahmani2025judging}. However,
existing methods for relevance judgments, rely heavily on sensitive prompting
strategies, lacking standardized workflows for generating reliable labels. To
fill this gap, we reintroduce our method, \textit{Task-aware Rubric-based
Evaluation} (TRUE), for relevance judgment generation. Originally developed for
usefulness evaluation in search sessions, we extend TRUE to mitigate the gap in
relevance judgment due to its demonstrated effectiveness and reproducible
workflow. This framework leverages iterative data sampling and reasoning to
evaluate relevance judgments across multiple factors including intent,
coverage, specificity, accuracy and usefulness. In this paper, we evaluate TRUE
on the TREC DL 2019, 2020 and LLMJudge datasets and our results show that TRUE
achieves strong performance on the system-ranking LLM leaderboards. The primary
focus of this work is to provide a reproducible framework for LLM-based
relevance judgments, and we further analyze the effectiveness of TRUE across
multiple dimensions.

</details>


### [3] [HiFIRec: Towards High-Frequency yet Low-Intention Behaviors for Multi-Behavior Recommendation](https://arxiv.org/abs/2509.25755)
*Ruiqi Luo,Ran Jin,Zhenglong Li,Kaixi Hu,Xiaohui Tao,Lin Li*

Main category: cs.IR

TL;DR: HiFIRec采用差异化行为建模纠正推荐系统中高频低意图行为的干扰，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 在多行为推荐中，用户-项目交互多样，导致数据稀疏和冷启动问题，很多现有方法使用图神经网络来统一建模用户意图，但忽视了行为间的异质性。

Method: 提出了一种新的多行为推荐方法HiFIRec，通过差异化行为建模来校正高频次但低意图行为的影响，并通过层级抑制和自适应跨层特征融合来改正噪声信号和动态调整负样本权重。

Result: HiFIRec在两个基准上进行的广泛实验中，HR@10指标相较多个最先进方法提高了4.21%-6.81%。

Conclusion: HiFIRec通过纠正多行为推荐中的噪声信号和负样本权重，实现了比多个现有方法更好的推荐效果。

Abstract: Multi-behavior recommendation leverages multiple types of user-item
interactions to address data sparsity and cold-start issues, providing
personalized services in domains such as healthcare and e-commerce. Most
existing methods utilize graph neural networks to model user intention in a
unified manner, which inadequately considers the heterogeneity across different
behaviors. Especially, high-frequency yet low-intention behaviors may
implicitly contain noisy signals, and frequent patterns that are plausible
while misleading, thereby hindering the learning of user intentions. To this
end, this paper proposes a novel multi-behavior recommendation method, HiFIRec,
that corrects the effect of high-frequency yet low-intention behaviors by
differential behavior modeling. To revise the noisy signals, we hierarchically
suppress it across layers by extracting neighborhood information through
layer-wise neighborhood aggregation and further capturing user intentions
through adaptive cross-layer feature fusion. To correct plausible frequent
patterns, we propose an intensity-aware non-sampling strategy that dynamically
adjusts the weights of negative samples. Extensive experiments on two
benchmarks show that HiFIRec relatively improves HR@10 by 4.21%-6.81% over
several state-of-the-art methods.

</details>


### [4] [Better with Less: Small Proprietary Models Surpass Large Language Models in Financial Transaction Understanding](https://arxiv.org/abs/2509.25803)
*Wanying Ding,Savinay Narendra,Xiran Shi,Adwait Ratnaparkhi,Chengrui Yang,Nikoo Sabzevar,Ziyan Yin*

Main category: cs.IR

TL;DR: 该论文研究Transformer模型在金融交易分析中的潜力，发现专有小模型在实时应用中更具优势。


<details>
  <summary>Details</summary>
Motivation: 金融交易分析对于确保合规、检测欺诈和支持决策至关重要，但交易数据的复杂性需要先进技术来提取有意义的见解。

Method: 进行了广泛实验比较了三种Transformer模型：编码器、解码器、和编码器-解码器。并在每种类型中探索预训练、微调和从零开发的小型专有模型。最终选择了专有解码器模型来提升交易覆盖率并减少成本。

Result: 在金融交易理解方面，专有小型模型的表现不逊于大型语言模型，速度更快且成本更低，适合实时应用。

Conclusion: 强调根据领域需求选择模型的重要性，专有模型在特殊应用中优于通用大型语言模型。

Abstract: Analyzing financial transactions is crucial for ensuring regulatory
compliance, detecting fraud, and supporting decisions. The complexity of
financial transaction data necessitates advanced techniques to extract
meaningful insights and ensure accurate analysis. Since Transformer-based
models have shown outstanding performance across multiple domains, this paper
seeks to explore their potential in understanding financial transactions. This
paper conducts extensive experiments to evaluate three types of Transformer
models: Encoder-Only, Decoder-Only, and Encoder-Decoder models. For each type,
we explore three options: pretrained LLMs, fine-tuned LLMs, and small
proprietary models developed from scratch. Our analysis reveals that while
LLMs, such as LLaMA3-8b, Flan-T5, and SBERT, demonstrate impressive
capabilities in various natural language processing tasks, they do not
significantly outperform small proprietary models in the specific context of
financial transaction understanding. This phenomenon is particularly evident in
terms of speed and cost efficiency. Proprietary models, tailored to the unique
requirements of transaction data, exhibit faster processing times and lower
operational costs, making them more suitable for real-time applications in the
financial sector. Our findings highlight the importance of model selection
based on domain-specific needs and underscore the potential advantages of
customized proprietary models over general-purpose LLMs in specialized
applications. Ultimately, we chose to implement a proprietary decoder-only
model to handle the complex transactions that we previously couldn't manage.
This model can help us to improve 14% transaction coverage, and save more than
\$13 million annual cost.

</details>


### [5] [RAE: A Neural Network Dimensionality Reduction Method for Nearest Neighbors Preservation in Vector Search](https://arxiv.org/abs/2509.25839)
*Han Zhang,Dongfang Zhao*

Main category: cs.IR

TL;DR: 提出了一种正则化自编码器（RAE），通过限制网络参数变化和调整奇异值来保留k-NN关系，提升检索效率，且具有高k-NN召回率。


<details>
  <summary>Details</summary>
Motivation: 高维嵌入向量在检索增强生成和推荐系统等任务中应用越来越多，而常用的降维方法如PCA和UMAP无法保留向量之间的最近邻关系，导致检索过程加速的效果不佳。为了解决这一问题，本文提出一种保留k-NN关系的降维方法，帮助提升检索效率。

Method: 提出了一种正则化自编码器（RAE），该模型通过神经网络的优化能力和Rayleigh商的约束作用来加强k-NN关系的保留。RAE通过正则化项限制网络参数变化，并调整奇异值以控制降维过程中嵌入向量的幅度变化，从而保留k-NN关系。进行了严谨的数学分析以证明正则化能够为变换后的向量的范数扭曲率建立上界，从而提供k-NN保留的可证明保证。

Result: RAE在保留k-NN关系的同时提供了快速检索效率，相较于现有降维方法，具有更高的k-NN召回率。

Conclusion: RAE在兼顾训练开销的情况下，实现了更优的k-NN召回和快速检索效率，证明了其在k-NN关系保留方面的有效性。

Abstract: While high-dimensional embedding vectors are being increasingly employed in
various tasks like Retrieval-Augmented Generation and Recommendation Systems,
popular dimensionality reduction (DR) methods such as PCA and UMAP have rarely
been adopted for accelerating the retrieval process due to their inability of
preserving the nearest neighbor (NN) relationship among vectors. Empowered by
neural networks' optimization capability and the bounding effect of Rayleigh
quotient, we propose a Regularized Auto-Encoder (RAE) for k-NN preserving
dimensionality reduction. RAE constrains the network parameter variation
through regularization terms, adjusting singular values to control embedding
magnitude changes during reduction, thus preserving k-NN relationships. We
provide a rigorous mathematical analysis demonstrating that regularization
establishes an upper bound on the norm distortion rate of transformed vectors,
thereby offering provable guarantees for k-NN preservation. With modest
training overhead, RAE achieves superior k-NN recall compared to existing DR
approaches while maintaining fast retrieval efficiency.

</details>


### [6] [Fading to Grow: Growing Preference Ratios via Preference Fading Discrete Diffusion for Recommendation](https://arxiv.org/abs/2509.26063)
*Guoqing Hu,An Zhang. Shuchang Liu,Wenyu Mao,Jiancan Wu,Xun Yang,Xiang Li,Lantao Hu,Han Li,Kun Gai,Xiang Wang*

Main category: cs.IR

TL;DR: 论文提出PreferGrow，一种通过离散扩散模型实现的推荐系统，该系统能够有效解决用户偏好数据稀疏问题，并在多个基准数据集上表现优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统在排序离散项目时面临用户偏好数据极度稀疏的问题。最近的扩散模型进展启发了基于扩散的推荐系统，这些系统通过在前向过程注入噪声来防止扰动偏好分布的崩溃，从而缓解了稀疏性问题。然而，目前的扩散推荐系统主要依赖于连续高斯噪声，与推荐任务中离散用户偏好数据的性质不一致。

Method: 论文提出PreferGrow，一种基于离散扩散的推荐系统，能够通过淡化和增长用户在离散项目库中的偏好来建模偏好比率。PreferGrow主要有三个核心方面：(1) 离散的偏好比率建模，建模项目对之间的相对偏好比率，自然地符合推荐任务的离散和排序导向特征。(2) 通过偏好淡化进行扰动，不注入连续噪声，而是通过替换替代项淡化用户偏好，消除任何优先噪声假设的需要。(3) 通过增长进行偏好重建，迭代增长估计比率中的偏好信号。PreferGrow提供了一种矩阵公式，并在Markov过程和可逆性上具有理论保证。

Result: PreferGrow能够在五个基准数据集上表现优于最先进的扩散推荐系统，证明了其理论上的稳健性和实际应用效果。

Conclusion: PreferGrow不仅在理论上具有稳健性，还在五个基准数据集上展示了优于当前最先进扩散系统的性能，凸显了其在稀疏数据环境下的有效性。

Abstract: Recommenders aim to rank items from a discrete item corpus in line with user
interests, yet suffer from extremely sparse user preference data. Recent
advances in diffusion models have inspired diffusion-based recommenders, which
alleviate sparsity by injecting noise during a forward process to prevent the
collapse of perturbed preference distributions. However, current
diffusion-based recommenders predominantly rely on continuous Gaussian noise,
which is intrinsically mismatched with the discrete nature of user preference
data in recommendation. In this paper, building upon recent advances in
discrete diffusion, we propose PreferGrow, a discrete diffusion-based
recommender system that models preference ratios by fading and growing user
preferences over the discrete item corpus. PreferGrow differs from existing
diffusion-based recommenders in three core aspects: (1) Discrete modeling of
preference ratios: PreferGrow models relative preference ratios between item
pairs, rather than operating in the item representation or raw score simplex.
This formulation aligns naturally with the discrete and ranking-oriented nature
of recommendation tasks. (2) Perturbing via preference fading: Instead of
injecting continuous noise, PreferGrow fades user preferences by replacing the
preferred item with alternatives -- physically akin to negative sampling --
thereby eliminating the need for any prior noise assumption. (3) Preference
reconstruction via growing: PreferGrow reconstructs user preferences by
iteratively growing the preference signals from the estimated ratios.
PreferGrow offers a well-defined matrix-based formulation with theoretical
guarantees on Markovianity and reversibility, and it demonstrates consistent
performance gains over state-of-the-art diffusion-based recommenders across
five benchmark datasets, highlighting both its theoretical soundness and
empirical effectiveness.

</details>


### [7] [Items Proxy Bridging: Enabling Frictionless Critiquing in Knowledge Graph Recommendations](https://arxiv.org/abs/2509.26107)
*Huanyu Zhang,Xiaoxuan Shen,Yu Lei,Baolin Yi,Jianfang Liu,Yinao xie*

Main category: cs.IR

TL;DR: 这篇论文提出IPGC框架，解决推荐系统中的批评方法限制及灾难性遗忘问题，为主流推荐场景提供流畅集成的批评机制。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统越来越注重用户体验，有更多的应用允许用户批评并实时优化推荐内容。然而，现有批评方法往往需要专门设计的模型来在训练阶段建立用户与关键短语之间的直接关联，这限制了适用场景。此外，多次步骤批评过程中参数的累积变化常导致灾难性遗忘问题，影响模型性能。

Method: 提出了一种名为IPGC的框架，可以作为大多数基于协同过滤策略的知识图谱推荐模型的通用插件。该框架通过项目代理机制，将用户关键短语对的批评优化目标转化为用户项目对，以使其适应一般的协同过滤推荐模型，同时引入了一个抗遗忘正则化器以缓解模型的灾难性遗忘问题。

Result: IPGC提供了一种新范式，实现了批评机制与主流推荐场景的无缝集成，并有效地减轻了模型的灾难性遗忘问题。

Conclusion: IPGC框架能够作为绝大多数协同过滤策略推荐模型的通用解决方案，解决现有批评方法的局限性并缓解灾难性遗忘现象，从而提升推荐系统的性能。

Abstract: Modern recommender systems place great inclination towards facilitating user
experience, as more applications enabling users to critique and then refine
recommendations immediately. Considering the real-time requirements,
critique-able recommender systems typically straight modify the model
parameters and update the recommend list through analyzing the user critiquing
keyphrases in the inference phase. Current critiquing methods require first
constructing a specially designated model which establish direct correlations
between users and keyphrases during the training phase allowing for innovative
recommendations upon the critiquing,restricting the applicable scenarios.
Additionally, all these approaches ignore the catastrophic forgetting problem,
where the cumulative changes in parameters during continuous multi-step
critiquing may lead to a collapse in model performance. Thus, We conceptualize
a proxy bridging users and keyphrases, proposing a streamlined yet potent Items
Proxy Generic Critiquing Framework (IPGC) framework, which can serve as a
universal plugin for most knowledge graph recommender models based on
collaborative filtering (CF) strategies. IPGC provides a new paradigm for
frictionless integration of critique mechanisms to enable iterative
recommendation refinement in mainstream recommendation scenarios. IPGC
describes the items proxy mechanism for transforming the critiquing
optimization objective of user-keyphrase pairs into user-item pairs, adapting
it for general CF recommender models without the necessity of specifically
designed user-keyphrase correlation module. Furthermore, an anti-forgetting
regularizer is introduced in order to efficiently mitigate the catastrophic
forgetting problem of the model as a prior for critiquing optimization.

</details>


### [8] [Leveraging Scene Context with Dual Networks for Sequential User Behavior Modeling](https://arxiv.org/abs/2509.26172)
*Xu Chen,Yunmeng Shu,Yuangang Pan,Jinsong Lan,Xiaoyong Zhu,Shuai Xiao,Haojin Zhu,Ivor W. Tsang,Bo Zheng*

Main category: cs.IR

TL;DR: 提出DSPnet模型，通过考虑场景特征来提高未来行为的预测能力，并在真实数据集上取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 提升用户的信息检索体验需要有效预测用户的未来行为。

Method: 提出双序列预测网络（DSPnet），利用两条平行网络学习用户在项目和场景上的动态兴趣，并引入条件对比正则化损失来捕捉相似历史序列的不变性。

Result: 应用到线上系统中，CTR提升了0.04，交易量增长了0.78%，GMV增加了0.64%。

Conclusion: DSPnet模型能够有效捕捉用户动态兴趣和场景之间的相互关系，显著提高未来行为预测性能。

Abstract: Modeling sequential user behaviors for future behavior prediction is crucial
in improving user's information retrieval experience. Recent studies highlight
the importance of incorporating contextual information to enhance prediction
performance. One crucial but usually neglected contextual information is the
scene feature which we define as sub-interfaces within an app, created by
developers to provide specific functionalities, such as ``text2product search"
and ``live" modules in e-commence apps. Different scenes exhibit distinct
functionalities and usage habits, leading to significant distribution gap in
user engagement across them. Popular sequential behavior models either ignore
the scene feature or merely use it as attribute embeddings, which cannot
effectively capture the dynamic interests and interplay between scenes and
items when modeling user sequences. In this work, we propose a novel Dual
Sequence Prediction networks (DSPnet) to effectively capture the dynamic
interests and interplay between scenes and items for future behavior
prediction. DSPnet consists of two parallel networks dedicated to learn users'
dynamic interests over items and scenes, and a sequence feature enhancement
module to capture the interplay for enhanced future behavior prediction.
Further, we introduce a Conditional Contrastive Regularization (CCR) loss to
capture the invariance of similar historical sequences. Theoretical analysis
suggests that DSPnet is a principled way to learn the joint relationships
between scene and item sequences. Extensive experiments are conducted on one
public benchmark and two collected industrial datasets. The method has been
deployed online in our system, bringing a 0.04 point increase in CTR, 0.78\%
growth in deals, and 0.64\% rise in GMV. The codes are available at this
anonymous github:
\textcolor{blue}{https://anonymous.4open.science/r/DSPNet-ForPublish-2506/}.

</details>


### [9] [Auto-ARGUE: LLM-Based Report Generation Evaluation](https://arxiv.org/abs/2509.26184)
*William Walden,Marc Mason,Orion Weller,Laura Dietz,Hannah Recknor,Bryan Li,Gabrielle Kaili-May Liu,Yu Hou,James Mayfield,Eugene Yang*

Main category: cs.IR

TL;DR: 本文介绍了Auto-ARGUE，一种用于评估报告生成的工具，表现出与人类判断的良好相关性。


<details>
  <summary>Details</summary>
Motivation: 现有的报告生成评价工具不足以满足检索增强生成系统的需求，尤其是在生成长篇引文支持的报告方面。

Method: 使用了ARGUE框架，并进行基于大语言模型(LLM)的实现来进行报告生成评价。

Result: 引入了Auto-ARGUE，这是一个基于LLM的实现，用于报告生成评价，展现出与人类判断良好的系统级相关性。并发布了用于可视化输出的网页应用。

Conclusion: Auto-ARGUE提供了一种强大的工具来评估报告生成，填补了现有评价工具的空缺，并具有良好的系统级相关性。

Abstract: Generation of long-form, citation-backed reports is a primary use case for
retrieval augmented generation (RAG) systems. While open-source evaluation
tools exist for various RAG tasks, ones tailored to report generation are
lacking. Accordingly, we introduce Auto-ARGUE, a robust LLM-based
implementation of the recent ARGUE framework for report generation evaluation.
We present analysis of Auto-ARGUE on the report generation pilot task from the
TREC 2024 NeuCLIR track, showing good system-level correlations with human
judgments. We further release a web app for visualization of Auto-ARGUE
outputs.

</details>


### [10] [Self-supervised learning for phase retrieval](https://arxiv.org/abs/2509.26203)
*Victor Sechaud,Patrice Abry,Laurent Jacques,Julián Tachella*

Main category: cs.IR

TL;DR: 文章介绍了一种自监督方法，解决相位恢复中的非线性问题。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络在医学和科学成像中面临的监督学习数据不足问题，尤其是处理相位恢复中的非线性问题。

Method: 使用自监督学习方法，利用图像对平移的不变性进行相位恢复的图像重建。

Result: 文章提出了一种自监督的方法，通过利用图像对平移的自然不变性来解决相位恢复中的非线性问题。

Conclusion: 提出的方法能够克服传统方法无法处理相位恢复等非线性问题的限制，为该领域的图像重建提供了一种新思路。

Abstract: In recent years, deep neural networks have emerged as a solution for inverse
imaging problems. These networks are generally trained using pairs of images:
one degraded and the other of high quality, the latter being called 'ground
truth'. However, in medical and scientific imaging, the lack of fully sampled
data limits supervised learning. Recent advances have made it possible to
reconstruct images from measurement data alone, eliminating the need for
references. However, these methods remain limited to linear problems, excluding
non-linear problems such as phase retrieval. We propose a self-supervised
method that overcomes this limitation in the case of phase retrieval by using
the natural invariance of images to translations.

</details>


### [11] [Analyzing BEV Suitability and Charging Strategies Using Italian Driving Data](https://arxiv.org/abs/2509.26262)
*Homa Jamalof,Luca Vassio,Danilo Giordano,Marco Mellia,Claudio De Tommasi*

Main category: cs.IR

TL;DR: 遥测数据分析表明，只要能夜间充电，小容量纯电动汽车可以满足至少35%的用户需求。


<details>
  <summary>Details</summary>
Motivation: 由于纯电动汽车替代内燃机车辆存在障碍，如续航里程焦虑、公共充电站的不便和较高的成本，本研究评估用户转向纯电动汽车可能性及解决方案。

Method: 通过模拟行程和停车事件，并监控电池的充电状态，对比不同充电场景下电动汽车的续航能力与用户需求的匹配程度。

Result: 研究分析了10,441名使用内燃机车辆的用户在意大利某省的遥测数据，评估在不改变现有旅行行为的情况下转向纯电动汽车（BEVs）的可能性。结果表明，在不同的充电场景下，只要能夜间充电，至少35%的用户可以选择采用低容量的纯电动汽车。

Conclusion: 研究表明，在夜间充电的条件下，纯电动汽车可以成为相当一部分用户的可行选择，尽管在充电行为和有限的续航能力之间存在权衡。

Abstract: Battery Electric Vehicles (BEVs) are rapidly evolving from a niche
alternative to an established option for private transportation, often
replacing Internal Combustion Engine (ICE) vehicles. Despite growing interest,
significant barriers remain, including range anxiety, the inconvenience
associated with public charging stations, and higher costs. This study analyses
extensive telemetry data collected from 10,441 users using ICE vehicles in an
Italian province to assess the potential for switching to BEVs without changing
current travel behaviour. We evaluate to what extent the BEV models can fulfil
their mobility needs under different charging scenarios. To do so, we replicate
trips and parking events, simulating and monitoring the battery state of
charge. The analysis reveals the compromises between charging behaviours and
limited BEV autonomy. Assuming access to overnight charging, at least 35% of
the users could already adopt even low-capacity BEVs.

</details>


### [12] [MR$^2$-Bench: Going Beyond Matching to Reasoning in Multimodal Retrieval](https://arxiv.org/abs/2509.26378)
*Junjie Zhou,Ze Liu,Lei Xiong,Jin-Ge Yao,Yueze Wang,Shitao Xiao,Fenfen Lin,Miguel Hu Chen,Zhicheng Dou,Siqi Bao,Defu Lian,Yongping Xiong,Zheng Liu*

Main category: cs.IR

TL;DR: 提出了一个名为MR$^2$-Bench的基准，用于多模态检索中的推理评估。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态检索评估缺乏对深层推理能力的测试，需要一个更加复杂和现实的基准来评估模型在不同内容类型中的推理能力。

Method: 引入MR$^2$-Bench基准，包含1,309个精心设计的查询，用于测试模型的逻辑、空间和因果推理能力。

Result: 当前最先进的模型在现有基准上表现强劲，但在MR$^2$-Bench上的表现仍然较差，展示了两个基准间的巨大性能差距。

Conclusion: MR$^2$-Bench对当前模型在多模态检索中的推理能力提出了更高挑战，突出了这领域需进一步发展的迫切性。

Abstract: Multimodal retrieval is becoming a crucial component of modern AI
applications, yet its evaluation lags behind the demands of more realistic and
challenging scenarios. Existing benchmarks primarily probe surface-level
semantic correspondence (e.g., object-text matching) while failing to assess
the deeper reasoning required to capture complex relationships between visual
and textual information. To address this gap, we introduce MR$^2$-Bench, a
reasoning-intensive benchmark for multimodal retrieval. MR$^2$-Bench presents
the following critical values: 1) all tasks are reasoning-driven, going beyond
shallow matching to effectively assess models' capacity for logical, spatial,
and causal inference; 2) it features diverse multimodal data, such as natural
images, diagrams, and visual puzzles, enabling comprehensive evaluation across
content types; 3) it supports complex queries and documents containing multiple
images and covers diverse retrieval scenarios, more accurately reflecting
real-world applications. Our benchmark contains 1,309 curated queries, derived
either from manual collection and annotation or from selective consolidation of
public datasets. Despite achieving strong results on existing benchmarks,
current state-of-the-art models still struggle on MR$^2$-Bench: for example,
the leading Seed1.6-Embedding model attains a Recall@1 of 77.78 on MMEB, but
only 9.91 on MR$^2$-Bench. This substantial performance gap highlights both the
increased challenge posed by our benchmark and the pressing need for further
advances in reasoning-intensive multimodal retrieval. The dataset and
evaluation code will be made publicly available at
https://github.com/VectorSpaceLab/MR2-Bench.

</details>


### [13] [Informed Dataset Selection](https://arxiv.org/abs/2509.26448)
*Abdullah Abbas,Michael Heep,Theodor Sperle*

Main category: cs.IR

TL;DR: 推荐系统研究中的数据集选择缺乏系统性方法。APS Explorer提高了数据集选择的科学性，通过分析96个数据集和28种算法，增强研究的可靠性。


<details>
  <summary>Details</summary>
Motivation: 推动推荐系统领域的数据集选择从流行性转向经验和证据的适用性，以提高研究的科学性和准确性。

Method: 提出了一个基于APS框架的网络应用程序，用以系统评估数据集的适用性，包括将数据集划分为五个难度级别的统计分类系统。

Result: 开发了APS Explorer工具，能够提供算法性能的可视化、算法直接比较以及数据集元数据分析的交互式模块，并公开提供使用。

Conclusion: APS Explorer成功改变推荐系统研究的数据集选择方法，使之从基于直觉转向基于证据，并提供了与算法性能相关的可视化分析工具。

Abstract: The selection of datasets in recommender systems research lacks a systematic
methodology. Researchers often select datasets based on popularity rather than
empirical suitability. We developed the APS Explorer, a web application that
implements the Algorithm Performance Space (APS) framework for informed dataset
selection. The system analyzes 96 datasets using 28 algorithms across three
metrics (nDCG, Hit Ratio, Recall) at five K-values. We extend the APS framework
with a statistical based classification system that categorizes datasets into
five difficulty levels based on quintiles. We also introduce a
variance-normalized distance metric based on Mahalanobis distance to measure
similarity. The APS Explorer was successfully developed with three interactive
modules for visualizing algorithm performance, direct comparing algorithms, and
analyzing dataset metadata. This tool shifts the process of selecting datasets
from intuition-based to evidence-based practices, and it is publicly available
at datasets.recommender-systems.com.

</details>
