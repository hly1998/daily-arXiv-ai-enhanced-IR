<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 17]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [FinAgentBench: A Benchmark Dataset for Agentic Retrieval in Financial Question Answering](https://arxiv.org/abs/2508.14052)
*Chanyeol Choi,Jihoon Kwon,Alejandro Lopez-Lira,Chaewoon Kim,Minjae Kim,Juneha Hwang,Jaeseon Ha,Hojun Choi,Suyeol Yun,Yongjin Kim,Yongjae Lee*

Main category: cs.IR

TL;DR: The paper introduces FinAgentBench, a benchmark for evaluating multi-step reasoning retrieval in finance, achieves improvements with fine-tuned LLMs, and plans further expansions post-acceptance.


<details>
  <summary>Details</summary>
Motivation: To address the lack of benchmarks for evaluating multi-step reasoning retrieval capabilities of LLMs in the financial domain.

Method: The paper introduces a large-scale benchmark named FinAgentBench to evaluate the multi-step reasoning retrieval capabilities of large language models in the financial domain.

Result: The benchmark contains 3,429 expert-annotated examples focusing on S&P-100 firms, demonstrating that state-of-the-art models can improve retrieval performance through fine-tuning. The framework achieves separation of reasoning steps to handle context limitations.

Conclusion: The paper concludes that with the introduction of FinAgentBench, substantial improvements in agentic retrieval can be achieved through targeted fine-tuning of LLMs in the financial domain.

Abstract: Accurate information retrieval (IR) is critical in the financial domain,
where investors must identify relevant information from large collections of
documents. Traditional IR methods-whether sparse or dense-often fall short in
retrieval accuracy, as it requires not only capturing semantic similarity but
also performing fine-grained reasoning over document structure and
domain-specific knowledge. Recent advances in large language models (LLMs) have
opened up new opportunities for retrieval with multi-step reasoning, where the
model ranks passages through iterative reasoning about which information is
most relevant to a given query. However, there exists no benchmark to evaluate
such capabilities in the financial domain. To address this gap, we introduce
FinAgentBench, the first large-scale benchmark for evaluating retrieval with
multi-step reasoning in finance -- a setting we term agentic retrieval. The
benchmark consists of 3,429 expert-annotated examples on S&P-100 listed firms
and assesses whether LLM agents can (1) identify the most relevant document
type among candidates, and (2) pinpoint the key passage within the selected
document. Our evaluation framework explicitly separates these two reasoning
steps to address context limitations. This design enables to provide a
quantitative basis for understanding retrieval-centric LLM behavior in finance.
We evaluate a suite of state-of-the-art models and further demonstrated how
targeted fine-tuning can significantly improve agentic retrieval performance.
Our benchmark provides a foundation for studying retrieval-centric LLM behavior
in complex, domain-specific tasks for finance. We will release the dataset
publicly upon acceptance of the paper and plan to expand and share dataset for
the full S&P 500 and beyond.

</details>


### [2] [Dual-Phase Playtime-guided Recommendation: Interest Intensity Exploration and Multimodal Random Walks](https://arxiv.org/abs/2508.14058)
*Jingmao Zhang,Zhiting Zhao,Yunqi Lin,Jianghong Ma,Tianjun Wei,Haijun Zhang,Xiaofeng Zhang*

Main category: cs.IR

TL;DR: DP2Rec是一种新的推荐模型，通过利用游戏时间和多模态信息，提升了推荐准确性和多样性，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 视频游戏行业的快速增长需要推荐系统能适应不断扩大的目录并保持用户参与。目前的模型未充分利用独特的行为信号——游戏时间，也忽视了多模态信息提高多样性的潜力。

Method: 该模型引入了两个模块：一个是基于游戏时间指导的兴趣强度探索模块，通过双β建模来分离强弱偏好；另一个是基于游戏时间指导的多模态随机游走模块，结合游戏时间和多模态语义相似性来模拟玩家的探索行为。

Result: 实验结果表明，DP2Rec在实际游戏数据集上的推荐准确性和多样性均优于现有方法。

Conclusion: 该论文提出了DP2Rec模型，在游戏推荐系统中同时优化准确性和多样性，通过实验验证其优于现有方法。

Abstract: The explosive growth of the video game industry has created an urgent need
for recommendation systems that can scale with expanding catalogs and maintain
user engagement. While prior work has explored accuracy and diversity in
recommendations, existing models underutilize playtime, a rich behavioral
signal unique to gaming platforms, and overlook the potential of multimodal
information to enhance diversity. In this paper, we propose DP2Rec, a novel
Dual-Phase Playtime-guided Recommendation model designed to jointly optimize
accuracy and diversity. First, we introduce a playtime-guided interest
intensity exploration module that separates strong and weak preferences via
dual-beta modeling, enabling fine-grained user profiling and more accurate
recommendations. Second, we present a playtime-guided multimodal random walks
module that simulates player exploration using transitions guided by both
playtime-derived interest similarity and multimodal semantic similarity. This
mechanism preserves core preferences while promoting cross-category discovery
through latent semantic associations and adaptive category balancing. Extensive
experiments on a real-world game dataset show that DP2Rec outperforms existing
methods in both recommendation accuracy and diversity.

</details>


### [3] [Graph Neural Network for Product Recommendation on the Amazon Co-purchase Graph](https://arxiv.org/abs/2508.14059)
*Mengyang Cao,Frank F. Yang,Yi Jin,Yijun Yan*

Main category: cs.IR

TL;DR: 研究评估了四种GNN架构在推荐系统中链接预测设置下的表现。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统需要在海量数据中识别相关信息，GNN通过图学习利用结构和语义关系表现出巨大潜力。

Method: 使用四种GNN架构进行链接预测实验，评估它们在Amazon产品共购网络上的能力。

Result: 评估了不同架构之间的实用性权衡，包括模型性能、可扩展性、训练复杂性和泛化能力。

Conclusion: 每种GNN模型在实际推荐场景中的性能特征各异，适用于不同的应用需求。

Abstract: Identifying relevant information among massive volumes of data is a challenge
for modern recommendation systems. Graph Neural Networks (GNNs) have
demonstrated significant potential by utilizing structural and semantic
relationships through graph-based learning. This study assessed the abilities
of four GNN architectures, LightGCN, GraphSAGE, GAT, and PinSAGE, on the Amazon
Product Co-purchase Network under link prediction settings. We examined
practical trade-offs between architectures, model performance, scalability,
training complexity and generalization. The outcomes demonstrated each model's
performance characteristics for deploying GNN in real-world recommendation
scenarios.

</details>


### [4] [GPT-2 as a Compression Preprocessor: Improving Gzip for Structured Text Domains](https://arxiv.org/abs/2508.14061)
*Anurag Kumar Ojha*

Main category: cs.IR

TL;DR: 本文提出了一种基于GPT的预处理器，用于优化域特定文件的压缩效果。


<details>
  <summary>Details</summary>
Motivation: 针对gzip在压缩域特定格式文件时存在的语义重复而非句法重复的问题。

Method: 使用GPT-2作为预处理器，将域特定文件转换为适合gzip压缩的格式，然后进行后续的压缩处理。

Result: 实验显示国防日志压缩效果提高0.34%，HTML文件压缩效果提高5.8%。

Conclusion: 提出的模型在处理不同类型的真实和合成数据时表现出改善效果。

Abstract: In the modern era, large volumes of data are being produced continuously,
especially in domain-specific fields such as medical records and clinical
files, defence logs and HTML-based web traffic. Data with such volume and
complexity needs to be compressed before storing and transmitting efficiently.
Data compression has gained significant attention from modern researchers,
resulting in the development of fast and efficient compression algorithms such
as Gzip. However, since gzip works on the principle of repetition of binary
patterns, one of the limitations of gzip is that domain-specific formats like
JSON, XML, HTML, and log files, while structured, may have semantic repetition
but not syntactic repetition, which gzip finds difficult to compress. In this
article, we propose a GPT-based preprocessor for such domain-specific files. We
propose a pipeline made up of GPT-2 taking domain-specific files as input,
which pattern-based compressors like gzip find difficult to work on. The
preprocessor results are output in a file that is designed for compressors like
gzip. After preprocessing, the gzip works on the other end of the pipeline and
compresses the data as usual. We used different types of both real-world and
synthetically generated data, such as logs and HTML files, for the experiment
of the proposed model. We found promising results and an improvement of the
Defence logs by 0.34 per cent and HTML files by 5.8 per cent.

</details>


### [5] [A Multi-Agent Approach to Neurological Clinical Reasoning](https://arxiv.org/abs/2508.14063)
*Moran Sorka,Alon Gorenshtein,Dvir Aran,Shahar Shelly*

Main category: cs.IR

TL;DR: 多代理系统通过模拟专门认知过程，显著提升大语言模型在神经领域复杂医疗推理方面的表现。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在处理神经领域专门化推理方面的能力，以便探索提高其在复杂医学推理任务中的性能。

Method: 使用305道以色列神经病学认证考试题目创建基准测试，评估十个大语言模型，并采用基于多代理系统的创新方法。

Result: 改进后的多代理系统在中等复杂度问题上的表现显著提高，LLaMA 3.3-70B基础系统的准确率从69.5%提升至89.2%。

Conclusion: 多代理系统在复杂医学推理方面显著优于单一模型或基于检索增强的生成方式。

Abstract: Large language models (LLMs) have shown promise in medical domains, but their
ability to handle specialized neurological reasoning requires systematic
evaluation. We developed a comprehensive benchmark using 305 questions from
Israeli Board Certification Exams in Neurology, classified along three
complexity dimensions: factual knowledge depth, clinical concept integration,
and reasoning complexity. We evaluated ten LLMs using base models,
retrieval-augmented generation (RAG), and a novel multi-agent system. Results
showed significant performance variation. OpenAI-o1 achieved the highest base
performance (90.9% accuracy), while specialized medical models performed poorly
(52.9% for Meditron-70B). RAG provided modest benefits but limited
effectiveness on complex reasoning questions. In contrast, our multi-agent
framework, decomposing neurological reasoning into specialized cognitive
functions including question analysis, knowledge retrieval, answer synthesis,
and validation, achieved dramatic improvements, especially for mid-range
models. The LLaMA 3.3-70B-based agentic system reached 89.2% accuracy versus
69.5% for its base model, with substantial gains on level 3 complexity
questions. The multi-agent approach transformed inconsistent subspecialty
performance into uniform excellence, addressing neurological reasoning
challenges that persisted with RAG enhancement. We validated our approach using
an independent dataset of 155 neurological cases from MedQA. Results confirm
that structured multi-agent approaches designed to emulate specialized
cognitive processes significantly enhance complex medical reasoning, offering
promising directions for AI assistance in challenging clinical contexts.

</details>


### [6] [An automatic patent literature retrieval system based on LLM-RAG](https://arxiv.org/abs/2508.14064)
*Yao Ding,Yuqing Wu,Ziyang Ding*

Main category: cs.IR

TL;DR: 整合大型语言模型与检索增强生成技术，提高专利检索的准确性和召回率。


<details>
  <summary>Details</summary>
Motivation: 随着技术创新加速，专利文献的高效检索和分类成为知识产权管理和企业研发的重要需求。传统的关键词和基于规则的检索方法难以解决复杂的查询意图或跨技术领域的语义关联，导致结果不完整且相关性低。

Method: 本研究的方法包括三个组件：专利数据标准化的预处理模块；利用LLM生成嵌入进行高效向量检索的引擎；结合外部文档检索与上下文响应生成的RAG增强查询模块。

Result: 在谷歌专利数据集（2006-2024）上的评估显示，所提出的gpt-3.5-turbo-0.125-RAG配置达到了80.5%的语义匹配准确率和92.1%的召回率，超过了基线LLM方法28个百分点。

Conclusion: 本研究提出的自动化专利检索框架通过整合大型语言模型（LLM）与检索增强生成（RAG）技术，显著提高了语义匹配的准确性和检索召回率，为下一代AI驱动的知识产权分析平台奠定了基础。

Abstract: With the acceleration of technological innovation efficient retrieval and
classification of patent literature have become essential for intellectual
property management and enterprise RD Traditional keyword and rulebased
retrieval methods often fail to address complex query intents or capture
semantic associations across technical domains resulting in incomplete and
lowrelevance results This study presents an automated patent retrieval
framework integrating Large Language Models LLMs with RetrievalAugmented
Generation RAG technology The system comprises three components: 1) a
preprocessing module for patent data standardization, 2) a highefficiency
vector retrieval engine leveraging LLMgenerated embeddings, and 3) a
RAGenhanced query module that combines external document retrieval with
contextaware response generation Evaluations were conducted on the Google
Patents dataset 20062024 containing millions of global patent records with
metadata such as filing date domain and status The proposed gpt35turbo0125RAG
configuration achieved 805 semantic matching accuracy and 92.1% recall
surpassing baseline LLM methods by 28 percentage points The framework also
demonstrated strong generalization in crossdomain classification and semantic
clustering tasks These results validate the effectiveness of LLMRAG integration
for intelligent patent retrieval providing a foundation for nextgeneration
AIdriven intellectual property analysis platforms

</details>


### [7] [Personalized Contest Recommendation in Fantasy Sports](https://arxiv.org/abs/2508.14065)
*Madiraju Srilakshmi,Kartavya Kothari,Kamlesh Marathe,Vedavyas Chigurupati,Hitesh Kapoor*

Main category: cs.IR

TL;DR: 该论文介绍了一个用于幻想体育平台的比赛推荐系统，基于WiDIR模型，已在大型平台上成功实现，并证明在召回率和业务指标上优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 由于玩家偏好存在异质性，比赛个性化是将玩家与合适比赛匹配的重要工具。

Method: 该系统的核心是一个称为WiDIR（Wide and Deep Interaction Ranker）的模型。

Result: 在线实验表明，该系统在召回率和其他关键业务指标上的表现优于其他候选模型。

Conclusion: 该论文提出了一种可扩展的比赛推荐系统，并在大型幻想体育平台上进行了测试，显示出在召回率和其他关键业务指标上的显著改善。

Abstract: In daily fantasy sports, players enter into "contests" where they compete
against each other by building teams of athletes that score fantasy points
based on what actually occurs in a real-life sports match. For any given sports
match, there are a multitude of contests available to players, with substantial
variation across 3 main dimensions: entry fee, number of spots, and the prize
pool distribution. As player preferences are also quite heterogeneous, contest
personalization is an important tool to match players with contests. This paper
presents a scalable contest recommendation system, powered by a Wide and Deep
Interaction Ranker (WiDIR) at its core. We productionized this system at our
company, one of the large fantasy sports platforms with millions of daily
contests and millions of players, where online experiments show a marked
improvement over other candidate models in terms of recall and other critical
business metrics.

</details>


### [8] [Retrieval-Augmented Generation in Industry: An Interview Study on Use Cases, Requirements, Challenges, and Evaluation](https://arxiv.org/abs/2508.14066)
*Lorenz Brehme,Benedikt Dornauer,Thomas Ströhle,Maximilian Ehrhart,Ruth Breu*

Main category: cs.IR

TL;DR: 研究探讨了RAG在工业中的应用现状，发现应用仍处于早期阶段，主要关注数据保护和质量，评估多由人工进行。


<details>
  <summary>Details</summary>
Motivation: 弥补RAG在工业应用研究上的缺乏，提供行业应用现状的洞察。

Method: 通过半结构化访谈研究对13位行业实践者进行调查。

Result: 发现行业需求主要集中在数据保护、安全和质量方面；数据预处理是主要挑战；系统评估多由人工进行。

Conclusion: 目前，RAG在工业应用中的主要任务是特定领域的问答，系统多处于原型阶段。

Abstract: Retrieval-Augmented Generation (RAG) is a well-established and rapidly
evolving field within AI that enhances the outputs of large language models by
integrating relevant information retrieved from external knowledge sources.
While industry adoption of RAG is now beginning, there is a significant lack of
research on its practical application in industrial contexts. To address this
gap, we conducted a semistructured interview study with 13 industry
practitioners to explore the current state of RAG adoption in real-world
settings. Our study investigates how companies apply RAG in practice, providing
(1) an overview of industry use cases, (2) a consolidated list of system
requirements, (3) key challenges and lessons learned from practical
experiences, and (4) an analysis of current industry evaluation methods. Our
main findings show that current RAG applications are mostly limited to
domain-specific QA tasks, with systems still in prototype stages; industry
requirements focus primarily on data protection, security, and quality, while
issues such as ethics, bias, and scalability receive less attention; data
preprocessing remains a key challenge, and system evaluation is predominantly
conducted by humans rather than automated methods.

</details>


### [9] [RewardRank: Optimizing True Learning-to-Rank Utility](https://arxiv.org/abs/2508.14180)
*Gaurav Bhatt,Kiran Koshy Thekumparampil,Tanmay Gangwani,Tesi Xiao,Leonid Sigal*

Main category: cs.IR

TL;DR: 提出了一种数据驱动的用户行为建模框架，通过RewardRank方法实现效用优化排名，超过传统基线。


<details>
  <summary>Details</summary>
Motivation: 传统排名系统采用的代理损失函数未能有效捕捉用户复杂行为偏差，导致模型与实际用户效用不一致。因此，研究用户行为建模以优化排名效用成为必要。

Method: 首先训练一个深度效用模型，通过登录数据评估用户与整个项目排序的互动，然后使用可微排序操作优化排序策略，以最大化预测效用，并实现过事实和反事实排名的端到端训练。同时引入自动评估协议如KD-Eval和LLM-Eval。

Result: 实验显示，RewardRank在包括Baidu-ULTR和Amazon KDD Cup数据集的大规模基准测试中，始终优于强基线方法，证明其在用户行为动态建模方面的有效性。

Conclusion: RewardRank实现了对用户行为动态的有效建模，并在大型基准测试中优于强基线方法，凸显了该项研究的优势。

Abstract: Traditional ranking systems rely on proxy loss functions that assume
simplistic user behavior, such as users preferring a rank list where items are
sorted by hand-crafted relevance. However, real-world user interactions are
influenced by complex behavioral biases, including position bias, brand
affinity, decoy effects, and similarity aversion, which these objectives fail
to capture. As a result, models trained on such losses often misalign with
actual user utility, such as the probability of any click or purchase across
the ranked list. In this work, we propose a data-driven framework for modeling
user behavior through counterfactual reward learning. Our method, RewardRank,
first trains a deep utility model to estimate user engagement for entire item
permutations using logged data. Then, a ranking policy is optimized to maximize
predicted utility via differentiable soft permutation operators, enabling
end-to-end training over the space of factual and counterfactual rankings. To
address the challenge of evaluation without ground-truth for unseen
permutations, we introduce two automated protocols: (i) $\textit{KD-Eval}$,
using a position-aware oracle for counterfactual reward estimation, and (ii)
$\textit{LLM-Eval}$, which simulates user preferences via large language
models. Experiments on large-scale benchmarks, including Baidu-ULTR and the
Amazon KDD Cup datasets, demonstrate that our approach consistently outperforms
strong baselines, highlighting the effectiveness of modeling user behavior
dynamics for utility-optimized ranking. Our code is available at:
https://github.com/GauravBh1010tt/RewardRank

</details>


### [10] [You Only Evaluate Once: A Tree-based Rerank Method at Meituan](https://arxiv.org/abs/2508.14420)
*Shuli Wang,Yinqiu Huang,Changhao Li,Yuan Zhou,Yonggang Liu,Yongqiang Zhang,Yinhua Zhu,Haitao Wang,Xingxing Wang*

Main category: cs.IR

TL;DR: YOLOR是一种用于推荐系统的一阶段重排方法，解决了以前方法的效率与效果的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 重排在现代推荐系统中至关重要，但传统的两阶段方法存在严重的不一致性问题。

Method: 提出一种名为YOLOR的一阶段重排方法，采用树状上下文提取模块和上下文缓存模块。

Result: 在公共和行业数据集上的广泛实验验证了YOLOR的性能，并成功应用于美团外卖平台。

Conclusion: YOLOR通过去除简单搜索单元，仅保留精确搜索单元，提高推荐系统的整体有效性和效率。

Abstract: Reranking plays a crucial role in modern recommender systems by capturing the
mutual influences within the list. Due to the inherent challenges of
combinatorial search spaces, most methods adopt a two-stage search paradigm: a
simple General Search Unit (GSU) efficiently reduces the candidate space, and
an Exact Search Unit (ESU) effectively selects the optimal sequence. These
methods essentially involve making trade-offs between effectiveness and
efficiency, while suffering from a severe \textbf{inconsistency problem}, that
is, the GSU often misses high-value lists from ESU. To address this problem, we
propose YOLOR, a one-stage reranking method that removes the GSU while
retaining only the ESU. Specifically, YOLOR includes: (1) a Tree-based Context
Extraction Module (TCEM) that hierarchically aggregates multi-scale contextual
features to achieve "list-level effectiveness", and (2) a Context Cache Module
(CCM) that enables efficient feature reuse across candidate permutations to
achieve "permutation-level efficiency". Extensive experiments across public and
industry datasets validate YOLOR's performance, and we have successfully
deployed YOLOR on the Meituan food delivery platform.

</details>


### [11] [Diverse Negative Sampling for Implicit Collaborative Filtering](https://arxiv.org/abs/2508.14468)
*Yueqing Xuan,Kacper Sokol,Mark Sanderson,Jeffrey Chan*

Main category: cs.IR

TL;DR: 引入了一种新的负采样方法(DivNS)，通过增加负样本多样性来改善推荐系统的效果，并且实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的负采样策略通常会在密集区域过度采样负样本，导致负样本同质化及模型表现能力受限，需提高负训练数据的多样性。

Method: DivNS首先通过缓存策略找到具有高偏好评分的困难负样本，然后选择多样化的负样本子集，最后利用合成负样本生成器组合这些负样本和困难负样本以形成有效的训练数据。

Result: 在四个公共数据集上的广泛实验表明，DivNS在提高推荐质量的同时保持了计算效率。

Conclusion: 提出的DivNS方法通过生成多样化且信息丰富的合成负样本，提升了推荐系统的泛化能力，并在实验中有效地提高了推荐质量。

Abstract: Implicit collaborative filtering recommenders are usually trained to learn
user positive preferences. Negative sampling, which selects informative
negative items to form negative training data, plays a crucial role in this
process. Since items are often clustered in the latent space, existing negative
sampling strategies normally oversample negative items from the dense regions.
This leads to homogeneous negative data and limited model expressiveness. In
this paper, we propose Diverse Negative Sampling (DivNS), a novel approach that
explicitly accounts for diversity in negative training data during the negative
sampling process. DivNS first finds hard negative items with large preference
scores and constructs user-specific caches that store unused but highly
informative negative samples. Then, its diversity-augmented sampler selects a
diverse subset of negative items from the cache while ensuring dissimilarity
from the user's hard negatives. Finally, a synthetic negatives generator
combines the selected diverse negatives with hard negatives to form more
effective training data. The resulting synthetic negatives are both informative
and diverse, enabling recommenders to learn a broader item space and improve
their generalisability. Extensive experiments on four public datasets
demonstrate the effectiveness of DivNS in improving recommendation quality
while maintaining computational efficiency.

</details>


### [12] [Distribution-Guided Auto-Encoder for User Multimodal Interest Cross Fusion](https://arxiv.org/abs/2508.14485)
*Moyu Zhang,Yongxiang Tang,Yujun Jin,Jinxin Hu,Yu Zhang*

Main category: cs.IR

TL;DR: 本文提出一种名为DMAE的模型，通过用户行为层面的多模态兴趣融合，有效提高推荐精度并解决数据稀疏问题。


<details>
  <summary>Details</summary>
Motivation: 传统推荐方法依赖于项目ID的嵌入向量来捕捉隐式协同过滤信号以建模用户的兴趣，但这些方法常常面临数据稀疏问题。因此，有必要探索新的方法来解决项目ID稀疏性问题并提高推荐精度。

Method: 提出了一种称为DMAE（Distribution-Guided Multimodal-Interest Auto-Encoder）的新模型，该模型通过在行为层面实现用户多模态兴趣的跨融合，以解决现有多模态推荐方法忽略用户行为序列上下文影响的问题。

Result: 广泛的实验表明，DMAE在捕捉用户多模态兴趣方面的优越性。

Conclusion: DMAE通过动态适应用户行为模式，有效提高了模型捕捉用户多模态兴趣的能力，从而改善了推荐效果。

Abstract: Traditional recommendation methods rely on correlating the embedding vectors
of item IDs to capture implicit collaborative filtering signals to model the
user's interest in the target item. Consequently, traditional ID-based methods
often encounter data sparsity problems stemming from the sparse nature of ID
features. To alleviate the problem of item ID sparsity, recommendation models
incorporate multimodal item information to enhance recommendation accuracy.
However, existing multimodal recommendation methods typically employ early
fusion approaches, which focus primarily on combining text and image features,
while neglecting the contextual influence of user behavior sequences. This
oversight prevents dynamic adaptation of multimodal interest representations
based on behavioral patterns, consequently restricting the model's capacity to
effectively capture user multimodal interests. Therefore, this paper proposes
the Distribution-Guided Multimodal-Interest Auto-Encoder (DMAE), which achieves
the cross fusion of user multimodal interest at the behavioral
level.Ultimately, extensive experiments demonstrate the superiority of DMAE.

</details>


### [13] [Global-Distribution Aware Scenario-Specific Variational Representation Learning Framework](https://arxiv.org/abs/2508.14493)
*Moyu Zhang,Yujun Jin,Jinxin Hu,Yu Zhang*

Main category: cs.IR

TL;DR: 本文介绍一种新的优化框架GSVR，通过估计场景特定概率分布解决数据稀疏问题，提升多场景推荐的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着电子商务的兴起，商业平台必须根据用户的购物偏好调整推荐系统以适应不同的场景。现有方法通常使用统一框架提供个性化推荐，但这种方法难以捕捉场景的独特性。

Method: 提出了一种全球分布感知的场景特定变分表示学习框架（GSVR），直接应用于现有多场景方法。利用概率模型生成每个场景中用户和商品的场景特定分布，通过变分推理估计。同时引入全球知识感知的多项式分布作为先验知识来调节后验用户和商品分布的学习。

Result: 实验结果表明，GSVR能够帮助现有的多场景推荐方法学习更为鲁棒的表示。

Conclusion: GSVR框架在捕捉场景特异性方面具有优势，有效解决了数据稀疏的问题，提高了推荐效果。

Abstract: With the emergence of e-commerce, the recommendations provided by commercial
platforms must adapt to diverse scenarios to accommodate users' varying
shopping preferences. Current methods typically use a unified framework to
offer personalized recommendations for different scenarios. However, they often
employ shared bottom representations, which partially hinders the model's
capacity to capture scenario uniqueness. Ideally, users and items should
exhibit specific characteristics in different scenarios, prompting the need to
learn scenario-specific representations to differentiate scenarios. Yet,
variations in user and item interactions across scenarios lead to data sparsity
issues, impeding the acquisition of scenario-specific representations. To learn
robust scenario-specific representations, we introduce a Global-Distribution
Aware Scenario-Specific Variational Representation Learning Framework (GSVR)
that can be directly applied to existing multi-scenario methods. Specifically,
considering the uncertainty stemming from limited samples, our approach employs
a probabilistic model to generate scenario-specific distributions for each user
and item in each scenario, estimated through variational inference (VI).
Additionally, we introduce the global knowledge-aware multinomial distributions
as prior knowledge to regulate the learning of the posterior user and item
distributions, ensuring similarities among distributions for users with akin
interests and items with similar side information. This mitigates the risk of
users or items with fewer records being overwhelmed in sparse scenarios.
Extensive experimental results affirm the efficacy of GSVR in assisting
existing multi-scenario recommendation methods in learning more robust
representations.

</details>


### [14] [DGenCTR: Towards a Universal Generative Paradigm for Click-Through Rate Prediction via Discrete Diffusion](https://arxiv.org/abs/2508.14500)
*Moyu Zhang,Yun Chen,Yujun Jin,Jinxin Hu,Yu Zhang*

Main category: cs.IR

TL;DR: 提出一种新的生成范式DGenCTR以提高CTR预测性能，包含生成预训练和监督微调阶段，并通过实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: 生成模型有能力理解数据分布以减轻传统判别式模型在标签稀缺空间中的限制，与序列生成方法的项目生成范式相悖，探索适合CTR预测的生成方法。

Method: 两个阶段的框架，包括基于扩散的生成预训练阶段和针对CTR的监督微调阶段。

Result: 广泛的离线实验和在线A/B测试验证了该框架的有效性。

Conclusion: 提出了一种新的针对CTR任务的生成范式，即一个两阶段离散扩散生成CTR训练框架（DGenCTR）。

Abstract: Recent advances in generative models have inspired the field of recommender
systems to explore generative approaches, but most existing research focuses on
sequence generation, a paradigm ill-suited for click-through rate (CTR)
prediction. CTR models critically depend on a large number of cross-features
between the target item and the user to estimate the probability of clicking on
the item, and discarding these cross-features will significantly impair model
performance. Therefore, to harness the ability of generative models to
understand data distributions and thereby alleviate the constraints of
traditional discriminative models in label-scarce space, diverging from the
item-generation paradigm of sequence generation methods, we propose a novel
sample-level generation paradigm specifically designed for the CTR task: a
two-stage Discrete Diffusion-Based Generative CTR training framework (DGenCTR).
This two-stage framework comprises a diffusion-based generative pre-training
stage and a CTR-targeted supervised fine-tuning stage for CTR. Finally,
extensive offline experiments and online A/B testing conclusively validate the
effectiveness of our framework.

</details>


### [15] [MISS: Multi-Modal Tree Indexing and Searching with Lifelong Sequential Behavior for Retrieval Recommendation](https://arxiv.org/abs/2508.14515)
*Chengcheng Guo,Junda She,Kuo Cai,Shiyao Wang,Qigen Hu,Qiang Luo,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: 我们提出MISS，通过多模态索引和终身序列建模改进推荐系统召回。


<details>
  <summary>Details</summary>
Motivation: 为了提高推荐系统召回阶段的性能，弥补现有方法在处理庞大候选项库时难以利用用户终身行为和多模态信息的不足。

Method: 引入了多模态索引树和多模态终身序列建模模块，包括协同通用搜索单元（Co-GSU）和多模态通用搜索单元（MM-GSU）。

Result: 通过多模态嵌入构建的多模态索引树和用户终身序列的多视角兴趣搜索进一步提高了召回模型的准确性和性能。

Conclusion: 我们提出了一种先进的解决方案，结合多模态信息和终身序列建模，提升了工业推荐系统的召回阶段性能。

Abstract: Large-scale industrial recommendation systems typically employ a two-stage
paradigm of retrieval and ranking to handle huge amounts of information. Recent
research focuses on improving the performance of retrieval model. A promising
way is to introduce extensive information about users and items. On one hand,
lifelong sequential behavior is valuable. Existing lifelong behavior modeling
methods in ranking stage focus on the interaction of lifelong behavior and
candidate items from retrieval stage. In retrieval stage, it is difficult to
utilize lifelong behavior because of a large corpus of candidate items. On the
other hand, existing retrieval methods mostly relay on interaction information,
potentially disregarding valuable multi-modal information. To solve these
problems, we represent the pioneering exploration of leveraging multi-modal
information and lifelong sequence model within the advanced tree-based
retrieval model. We propose Multi-modal Indexing and Searching with lifelong
Sequence (MISS), which contains a multi-modal index tree and a multi-modal
lifelong sequence modeling module. Specifically, for better index structure, we
propose multi-modal index tree, which is built using the multi-modal embedding
to precisely represent item similarity. To precisely capture diverse user
interests in user lifelong sequence, we propose collaborative general search
unit (Co-GSU) and multi-modal general search unit (MM-GSU) for
multi-perspective interests searching.

</details>


### [16] [OneLoc: Geo-Aware Generative Recommender Systems for Local Life Service](https://arxiv.org/abs/2508.14646)
*Zhipeng Wei,Kuo Cai,Junda She,Jie Chen,Minghao Chen,Yang Zeng,Qiang Luo,Wencong Zeng,Ruiming Tang,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: OneLoc通过利用地理信息和强化学习，在快手App中实现了显著的推荐效果提升。


<details>
  <summary>Details</summary>
Motivation: 解决结合用户兴趣与实时地理位置进行推荐的挑战，同时处理多个目标。

Method: 使用地理信息的各种方法，包括geo-aware语义ID、geo-aware自注意力编码器和neighbor-aware提示，并通过强化学习平衡用户兴趣和地理奖励。

Result: OneLoc模型在离线和在线上均表现出色，实现了GMV提升21.016%和订单数量提升17.891%的效果。

Conclusion: OneLoc模型在快手App的本地生活服务中得到应用，显著提升了GMV和订单数量。

Abstract: Local life service is a vital scenario in Kuaishou App, where video
recommendation is intrinsically linked with store's location information. Thus,
recommendation in our scenario is challenging because we should take into
account user's interest and real-time location at the same time. In the face of
such complex scenarios, end-to-end generative recommendation has emerged as a
new paradigm, such as OneRec in the short video scenario, OneSug in the search
scenario, and EGA in the advertising scenario. However, in local life service,
an end-to-end generative recommendation model has not yet been developed as
there are some key challenges to be solved. The first challenge is how to make
full use of geographic information. The second challenge is how to balance
multiple objectives, including user interests, the distance between user and
stores, and some other business objectives. To address the challenges, we
propose OneLoc. Specifically, we leverage geographic information from different
perspectives: (1) geo-aware semantic ID incorporates both video and geographic
information for tokenization, (2) geo-aware self-attention in the encoder
leverages both video location similarity and user's real-time location, and (3)
neighbor-aware prompt captures rich context information surrounding users for
generation. To balance multiple objectives, we use reinforcement learning and
propose two reward functions, i.e., geographic reward and GMV reward. With the
above design, OneLoc achieves outstanding offline and online performance. In
fact, OneLoc has been deployed in local life service of Kuaishou App. It serves
400 million active users daily, achieving 21.016% and 17.891% improvements in
terms of gross merchandise value (GMV) and orders numbers.

</details>


### [17] [Benefiting from Negative yet Informative Feedback by Contrasting Opposing Sequential Patterns](https://arxiv.org/abs/2508.14786)
*Veronika Ivanova,Evgeny Frolov,Alexey Vasilev*

Main category: cs.IR

TL;DR: 本文提出一种新方法，用于在序列推荐场景中同时从正负反馈中学习，通过训练两个分别处理正负交互的Transformer编码器，提高了准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 传统的序列推荐模型通常只关注正反馈，而忽略了负反馈的潜在价值。负反馈可以为更准确地识别用户真实兴趣提供有用信号，并且减少负反馈项可以提高用户满意度。因此，需要同时考虑正负反馈的信息来提高推荐系统的性能。

Method: 该方法提出使用两个Transformer编码器分别处理正负交互序列，并引入由正负交叉熵和对比项组成的综合损失函数作为序列推荐器的训练目标，以此更好地建模正负交互模式。

Result: 相比于当前最先进的序列推荐方法，该方法在提高正例指标的同时减少了错误地推送负反馈项的数量。

Conclusion: 本文的创新方法有效结合正负反馈，通过综合损失函数和对比项训练序列推荐系统，能够更准确地识别用户兴趣，并提高推荐性能。

Abstract: We consider the task of learning from both positive and negative feedback in
a sequential recommendation scenario, as both types of feedback are often
present in user interactions. Meanwhile, conventional sequential learning
models usually focus on considering and predicting positive interactions,
ignoring that reducing items with negative feedback in recommendations improves
user satisfaction with the service. Moreover, the negative feedback can
potentially provide a useful signal for more accurate identification of true
user interests. In this work, we propose to train two transformer encoders on
separate positive and negative interaction sequences. We incorporate both types
of feedback into the training objective of the sequential recommender using a
composite loss function that includes positive and negative cross-entropy as
well as a cleverly crafted contrastive term, that helps better modeling
opposing patterns. We demonstrate the effectiveness of this approach in terms
of increasing true-positive metrics compared to state-of-the-art sequential
recommendation methods while reducing the number of wrongly promoted negative
items.

</details>
