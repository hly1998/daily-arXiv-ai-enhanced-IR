<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 21]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Bias Mitigation for AI-Feedback Loops in Recommender Systems: A Systematic Literature Review and Taxonomy](https://arxiv.org/abs/2509.00109)
*Theodor Stoecker,Samed Bayer,Ingo Weber*

Main category: cs.IR

TL;DR: 本文系统复查偏见缓解方法在AI反馈回路中的应用，提出分类体系用于识别研究空白和评估稳健方法选择。


<details>
  <summary>Details</summary>
Motivation: 推荐系统在不断重训过程中会强化偏见，降低公平性，虽然这一风险众所周知，但是多数偏见缓解技术仅在静态数据集上进行测试，缺乏对多次重训的长期公平性验证。

Method: 对AI反馈回路中的偏见缓解方法进行系统性文献综述，筛选了347篇论文，并对其中24项研究进行了分析，编码出六个维度：缓解技术、偏见种类、动态测试设置、评估重点、应用领域和机器学习任务。

Result: 提出了一个分类体系来组织偏见缓解方法，识别研究领域中的空白，例如缺乏共享模拟器、评估指标的差异，以及多数研究仅报告公平性或性能，只有六个同时使用两者。

Conclusion: 本文对2019-2025年间发表的24项主要研究进行了系统性文献综述，提出了一个可重复使用的分类体系，有助于行业实践者选择稳健的方法，并且为研究人员提供识别该领域最紧迫研究空白点的路线图。

Abstract: Recommender systems continually retrain on user reactions to their own
predictions, creating AI feedback loops that amplify biases and diminish
fairness over time. Despite this well-known risk, most bias mitigation
techniques are tested only on static splits, so their long-term fairness across
multiple retraining rounds remains unclear. We therefore present a systematic
literature review of bias mitigation methods that explicitly consider AI
feedback loops and are validated in multi-round simulations or live A/B tests.
Screening 347 papers yields 24 primary studies published between 2019-2025.
Each study is coded on six dimensions: mitigation technique, biases addressed,
dynamic testing set-up, evaluation focus, application domain, and ML task,
organising them into a reusable taxonomy. The taxonomy offers industry
practitioners a quick checklist for selecting robust methods and gives
researchers a clear roadmap to the field's most urgent gaps. Examples include
the shortage of shared simulators, varying evaluation metrics, and the fact
that most studies report either fairness or performance; only six use both.

</details>


### [2] [Algorithm Adaptation Bias in Recommendation System Online Experiments](https://arxiv.org/abs/2509.00199)
*Chen Zheng,Zhenyu Zhao*

Main category: cs.IR

TL;DR: 本文讨论了推荐系统在线实验中的算法适应偏差，并提出了改进实验设计和评估方法以弥补此偏差的方法。


<details>
  <summary>Details</summary>
Motivation: 通过提高对算法适应偏差的认识，并在推荐系统评估的更广泛背景下将其定位，促使实验设计、测量和调整方面的讨论，以期更科学地评估模型的真正影响。

Method: 研究详细阐述了算法适应效应的机制，通过对真实世界实验的实证分析，展示了其对评价结果的影响，并讨论了增强在线评估稳健性的潜在方法。

Result: 研究表明，由于算法适应效应，新产品变化的测量效果可能与全面部署时的真实影响存在显著偏差。实验结果往往倾向于对当前流量较大的生产版本有利，而低估了实验版本的性能。

Conclusion: 本研究提出了一种新的实验偏差算法适应效应，并为其提供了实证证据，强调需要在实验设计和评估方法上进行改进，以提高实验的公正性和准确性。

Abstract: Online experiments (A/B tests) are widely regarded as the gold standard for
evaluating recommender system variants and guiding launch decisions. However, a
variety of biases can distort the results of the experiment and mislead
decision-making. An underexplored but critical bias is algorithm adaptation
effect. This bias arises from the flywheel dynamics among production models,
user data, and training pipelines: new models are evaluated on user data whose
distributions are shaped by the incumbent system or tested only in a small
treatment group. As a result, the measured effect of a new product change in
modeling and user experience in this constrained experimental setting can
diverge substantially from its true impact in full deployment. In practice, the
experiment results often favor the production variant with large traffic while
underestimating the performance of the test variant with small traffic, which
leads to missing opportunities to launch a true winning arm or underestimating
the impact. This paper aims to raise awareness of algorithm adaptation bias,
situate it within the broader landscape of RecSys evaluation biases, and
motivate discussion of solutions that span experiment design, measurement, and
adjustment. We detail the mechanisms of this bias, present empirical evidence
from real-world experiments, and discuss potential methods for a more robust
online evaluation.

</details>


### [3] [Beyond Negative Transfer: Disentangled Preference-Guided Diffusion for Cross-Domain Sequential Recommendation](https://arxiv.org/abs/2509.00389)
*Xiaoxin Ye,Chengkai Huang,Hongtao Huang,Lina Yao*

Main category: cs.IR

TL;DR: 提出了一种基于扩散模型的新方法DPG-Diff，用于跨领域序列推荐，成功解决消除噪音和偏好信号解缠的问题。


<details>
  <summary>Details</summary>
Motivation: 跨领域序列推荐（CDSR）通过利用用户在不同领域的行为来提升推荐质量。然而，简单地聚合序列信号可能会引入领域特定偏好的冲突，导致负迁移。

Method: 提出了一种名为DPG-Diff的解缠偏好引导扩散模型，通过解构用户偏好，指导逆扩散过程，以增强推荐系统的鲁棒性。

Result: DPG-Diff在多个指标上始终优于最先进的基线方法。

Conclusion: DPG-Diff通过将用户偏好解构为领域不变和领域特定的组件，并联合指导逆扩散过程，实现稳健的跨领域知识转移，减少负迁移并过滤噪音。

Abstract: Cross-Domain Sequential Recommendation (CDSR) leverages user behaviors across
domains to enhance recommendation quality. However, naive aggregation of
sequential signals can introduce conflicting domain-specific preferences,
leading to negative transfer. While Sequential Recommendation (SR) already
suffers from noisy behaviors such as misclicks and impulsive actions, CDSR
further amplifies this issue due to domain heterogeneity arising from diverse
item types and user intents. The core challenge is disentangling three
intertwined signals: domain-invariant preferences, domain-specific preferences,
and noise. Diffusion Models (DMs) offer a generative denoising framework
well-suited for disentangling complex user preferences and enhancing robustness
to noise. Their iterative refinement process enables gradual denoising, making
them effective at capturing subtle preference signals. However, existing
applications in recommendation face notable limitations: sequential DMs often
conflate shared and domain-specific preferences, while cross-domain
collaborative filtering DMs neglect temporal dynamics, limiting their ability
to model evolving user preferences. To bridge these gaps, we propose
\textbf{DPG-Diff}, a novel Disentangled Preference-Guided Diffusion Model, the
first diffusion-based approach tailored for CDSR, to or best knowledge.
DPG-Diff decomposes user preferences into domain-invariant and domain-specific
components, which jointly guide the reverse diffusion process. This
disentangled guidance enables robust cross-domain knowledge transfer, mitigates
negative transfer, and filters sequential noise. Extensive experiments on
real-world datasets demonstrate that DPG-Diff consistently outperforms
state-of-the-art baselines across multiple metrics.

</details>


### [4] [ERank: Fusing Supervised Fine-Tuning and Reinforcement Learning for Effective and Efficient Text Reranking](https://arxiv.org/abs/2509.00520)
*Yuzheng Cai,Yanzhao Zhang,Dingkun Long,Mingxin Li,Pengjun Xie,Weiguo Zheng*

Main category: cs.IR

TL;DR: 提出了一种名为ERank的高效点式重排序模型，通过两阶段训练提高相关性区分能力，在多个基准测试中展现出色的性能。


<details>
  <summary>Details</summary>
Motivation: 通过当前大型语言模型（LLMs）驱动的重排序器存在的两难困境进行研究，旨在选择最相关的文档用于生成。

Method: 方法包括两阶段训练：首先使用监督微调，生成细粒度整数评分以增强相关性区分。然后应用强化学习来进一步优化模型，引入从列表式推导的奖励，以提高全球排名意识。

Result: ERank在BRIGHT、FollowIR、TREC DL和BEIR基准上表现出卓越的效果，尤其是在BRIGHT基准上，ERank-4B实现了38.7的nDCG@10，而更大的32B版本达到了40.2的nDCG@10的最新水平。

Conclusion: ERank提供了一种解决现有LLMs重排序器面临的效率与效果矛盾的方法，并展示了出色的性能。

Abstract: Text reranking models are a crucial component in modern systems like
Retrieval-Augmented Generation, tasked with selecting the most relevant
documents prior to generation. However, current Large Language Models (LLMs)
powered rerankers often face a fundamental trade-off. On one hand, Supervised
Fine-Tuning based pointwise methods that frame relevance as a binary
classification task lack the necessary scoring discrimination, particularly for
those built on reasoning LLMs. On the other hand, approaches designed for
complex reasoning often employ powerful yet inefficient listwise formulations,
rendering them impractical for low latency applications. To resolve this
dilemma, we introduce ERank, a highly effective and efficient pointwise
reranker built from a reasoning LLM that excels across diverse relevance
scenarios. We propose a novel two-stage training pipeline that begins with
Supervised Fine-Tuning (SFT). In this stage, we move beyond binary labels and
train the model generatively to output fine grained integer scores, which
significantly enhances relevance discrimination. The model is then further
refined using Reinforcement Learning (RL) with a novel, listwise derived
reward. This technique instills global ranking awareness into the efficient
pointwise architecture. We evaluate the ERank reranker on the BRIGHT, FollowIR,
TREC DL, and BEIR benchmarks, demonstrating superior effectiveness and
robustness compared to existing approaches. On the reasoning-intensive BRIGHT
benchmark, our ERank-4B achieves an nDCG@10 of 38.7, while a larger 32B variant
reaches a state of the art nDCG@10 of 40.2.

</details>


### [5] [A Survey on Open Dataset Search in the LLM Era: Retrospectives and Perspectives](https://arxiv.org/abs/2509.00728)
*Pengyue Li,Sheng Wang,Hua Dai,Zhiyu Chen,Zhifeng Bao,Brian D. Davison*

Main category: cs.IR

TL;DR: 本文综述开放数据集搜索领域的最新进展，强调先进的数据集搜索技术和大型语言模型对该领域挑战的解决潜力，并讨论二者的互惠关系以提高任务性能。


<details>
  <summary>Details</summary>
Motivation: 高质量数据集是完成数据驱动任务的关键，包括医学诊断模型训练、预测实时交通状况和验证研究假设的实验等。开放数据集搜索旨在高效准确地满足用户的数据集需求，是一个重要的研究挑战，吸引了广泛的关注。

Method: 综述了开放数据集搜索领域的最新进展，特别关注基于示例的数据集搜索、基于内容的高级相似性测量技术以及高效的搜索加速技术。此外，重点讨论了大型语言模型（LLMs）与开放数据集搜索之间的互惠关系。

Result: 总结了开放数据集搜索中的开放研究问题，并提出了未来研究的方向。

Conclusion: 开放数据集搜索的研究有助于提高下游任务的性能，同时大型语言模型在查询理解、语义建模和互动指导中发挥重要作用。

Abstract: High-quality datasets are typically required for accomplishing data-driven
tasks, such as training medical diagnosis models, predicting real-time traffic
conditions, or conducting experiments to validate research hypotheses.
Consequently, open dataset search, which aims to ensure the efficient and
accurate fulfillment of users' dataset requirements, has emerged as a critical
research challenge and has attracted widespread interest. Recent studies have
made notable progress in enhancing the flexibility and intelligence of open
dataset search, and large language models (LLMs) have demonstrated strong
potential in addressing long-standing challenges in this area. Therefore, a
systematic and comprehensive review of the open dataset search problem is
essential, detailing the current state of research and exploring future
directions. In this survey, we focus on recent advances in open dataset search
beyond traditional approaches that rely on metadata and keywords. From the
perspective of dataset modalities, we place particular emphasis on
example-based dataset search, advanced similarity measurement techniques based
on dataset content, and efficient search acceleration techniques. In addition,
we emphasize the mutually beneficial relationship between LLMs and open dataset
search. On the one hand, LLMs help address complex challenges in query
understanding, semantic modeling, and interactive guidance within open dataset
search. In turn, advances in dataset search can support LLMs by enabling more
effective integration into retrieval-augmented generation (RAG) frameworks and
data selection processes, thereby enhancing downstream task performance.
Finally, we summarize open research problems and outline promising directions
for future work. This work aims to offer a structured reference for researchers
and practitioners in the field of open dataset search.

</details>


### [6] [HiPS: Hierarchical PDF Segmentation of Textbooks](https://arxiv.org/abs/2509.00909)
*Sabine Wehnert,Harikrishnan Changaramkulath,Ernesto William De Luca*

Main category: cs.IR

TL;DR: 提出了一种针对复杂结构化文件（尤其是法律教材）的分层分割方法，结合TOC和预处理策略，显著提高了解析效果。


<details>
  <summary>Details</summary>
Motivation: 当前的文本解析工具在解析复杂结构化文件（如法律教材）方面存在局限性，亟需开发有效的方法来解决这个问题。

Method: 采用目录表 (TOC) 技术及开放源码结构解析工具或在无明确TOC输入的情况下运行的大型语言模型 (LLMs)，并结合OCR标题检测、XML特征和上下文文本特征的预处理策略。

Result: 结合LLMs和结构感知预处理可以显著减少误报，提高提取质量。

Conclusion: 结合TOC的技术在PDF中的标题元数据质量较高时表现出色，并通过比较评估不同方法的优劣来总结。

Abstract: The growing demand for effective tools to parse PDF-formatted texts,
particularly structured documents such as textbooks, reveals the limitations of
current methods developed mainly for research paper segmentation. This work
addresses the challenge of hierarchical segmentation in complex structured
documents, with a focus on legal textbooks that contain layered knowledge
essential for interpreting and applying legal norms. We examine a Table of
Contents (TOC)-based technique and approaches that rely on open-source
structural parsing tools or Large Language Models (LLMs) operating without
explicit TOC input. To enhance parsing accuracy, we incorporate preprocessing
strategies such as OCR-based title detection, XML-derived features, and
contextual text features. These strategies are evaluated based on their ability
to identify section titles, allocate hierarchy levels, and determine section
boundaries. Our findings show that combining LLMs with structure-aware
preprocessing substantially reduces false positives and improves extraction
quality. We also find that when the metadata quality of headings in the PDF is
high, TOC-based techniques perform particularly well. All code and data are
publicly available to support replication. We conclude with a comparative
evaluation of the methods, outlining their respective strengths and
limitations.

</details>


### [7] [Food Data in the Semantic Web: A Review of Nutritional Resources, Knowledge Graphs, and Emerging Applications](https://arxiv.org/abs/2509.00986)
*Darko Sasanski,Riste Stojanov*

Main category: cs.IR

TL;DR: 这篇综述探讨了语义网中的食品数据，强调了食品知识图谱及新兴应用，并分析了数据资源在营养数据表示中的贡献。


<details>
  <summary>Details</summary>
Motivation: 探索语义网络中的食品数据、营养资源与知识图谱，以推动在食品领域的新兴应用。

Method: 综合分析重要食品数据资源及其在营养数据表示中的贡献，探讨食物实体链接与识别技术以及食品知识图谱的应用。

Result: 强调如USDA、FoodOn、FooDB、Recipe1M+等食品资源在营养数据表示中的贡献，并分析食物知识图谱在语义互操作性、数据丰富化及知识提取中的角色。

Conclusion: 通过分析当前进展和确定挑战，为未来利用语义技术推动食品领域的发展提供指导。

Abstract: This comprehensive review explores food data in the Semantic Web,
highlighting key nutritional resources, knowledge graphs, and emerging
applications in the food domain. It examines prominent food data resources such
as USDA, FoodOn, FooDB, and Recipe1M+, emphasizing their contributions to
nutritional data representation. Special focus is given to food entity linking
and recognition techniques, which enable integration of heterogeneous food data
sources into cohesive semantic resources. The review further discusses food
knowledge graphs, their role in semantic interoperability, data enrichment, and
knowledge extraction, and their applications in personalized nutrition,
ingredient substitution, food-drug and food-disease interactions, and
interdisciplinary research. By synthesizing current advancements and
identifying challenges, this work provides insights to guide future
developments in leveraging semantic technologies for the food domain.

</details>


### [8] [Identifying Origins of Place Names via Retrieval Augmented Generation](https://arxiv.org/abs/2509.01030)
*Alexis Horde Vo,Matt Duckham,Estrid He,Rafe Benli*

Main category: cs.IR

TL;DR: 本研究设计了一个检索增强生成管道，用于在广泛的知识库上搜索地名起源，结果显示语言模型对空间信息的利用不足。


<details>
  <summary>Details</summary>
Motivation: 想了解墨尔本“蝙蝠侠街”背后的“蝙蝠侠”是谁，通过理解地名背后的历史、文化和社会叙事，可以揭示塑造社区的丰富背景。地名在地名词典中虽然是基本的空间参考，但其起源信息常常缺乏。

Method: 提出了一种检索增强生成管道，使用经过微调的基于语言模型的模型ColBERTv2和Llama2，从DBpedia中检索和排名相关的子图来产生查询的最终答案。

Result: 我们的结果强调了自动检索地名起源所面临的关键挑战，特别是语言模型往往低估文本中包含的空间信息作为区分因素的倾向。

Conclusion: 我们的方法指出了检索增强生成在地理信息检索方面的更广泛影响。

Abstract: Who is the "Batman" behind "Batman Street" in Melbourne? Understanding the
historical, cultural, and societal narratives behind place names can reveal the
rich context that has shaped a community. Although place names serve as
essential spatial references in gazetteers, they often lack information about
place name origins. Enriching these place names in today's gazetteers is a
time-consuming, manual process that requires extensive exploration of a vast
archive of documents and text sources. Recent advances in natural language
processing and language models (LMs) hold the promise of significant automation
of identifying place name origins due to their powerful capability to exploit
the semantics of the stored documents. This chapter presents a retrieval
augmented generation pipeline designed to search for place name origins over a
broad knowledge base, DBpedia. Given a spatial query, our approach first
extracts sub-graphs that may contain knowledge relevant to the query; then
ranks the extracted sub-graphs to generate the final answer to the query using
fine-tuned LM-based models (i.e., ColBERTv2 and Llama2). Our results highlight
the key challenges facing automated retrieval of place name origins, especially
the tendency of language models to under-use the spatial information contained
in texts as a discriminating factor. Our approach also frames the wider
implications for geographic information retrieval using retrieval augmented
generation.

</details>


### [9] [Beyond the Surface: A Solution-Aware Retrieval Model for Competition-level Code Generation](https://arxiv.org/abs/2509.01129)
*Shiwen Zhang,Lingxiang Wang,Hainan Zhang,Ziwei Wang,Sijia Wen,Zhiming Zheng*

Main category: cs.IR

TL;DR: 提出了一种解决方案感知的排名模型SolveRank，用于在竞赛编程任务中提高问题和代码检索的准确性，并提升代码生成性能。


<details>
  <summary>Details</summary>
Motivation: 当前的代码生成模型在处理嵌入于复杂叙述背景中的问题陈述时，面临众多无关叙述干扰，难以识别解决方案的逻辑深度。因此，有必要设计一种能够准确识别并检索问题及相应代码的排名模型，以提高难题中的生成性能。

Method: 该论文提出了SolveRank模型，采用DeepSeek-R1生成逻辑等价但措辞不同的新问题，并通过GPT-4o验证解决方案一致性。然后使用这些数据作为正样本，BM25或随机检索问题作为负样本来训练SolveRank。SolveRank在推理时从语料库中检索相关问题和代码，以辅助下游代码生成器。

Result: SolveRank在xCodeEval数据集的实验中表现出色，超越了最新的排名方法，在精度和召回率方面均有提升，并提高了难题的代码生成性能。

Conclusion: SolveRank能够有效检索相关问题和代码，增强代码生成器在解决复杂问题时的性能。这种解决方案感知的排名方法基于合成数据，证明了其在实际应用中的潜力。

Abstract: In competitive programming task, problem statements are often embedded within
elaborate narrative backgrounds, requiring deep understanding of the underlying
solutions to successfully complete the tasks. Current code generation models
primarily focus on token-level semantic modeling, highly susceptible to
distractions from irrelevant narrative statements. Inspired by RAG, retrieving
reference code with similar solutions may help enhance model performance on
difficult problems. However, existing retrieval models also emphasize
surface-level semantic similarity, neglecting the deeper solution-level logical
similarities that are critical in competitive programming. Therefore, designing
ranking models capable of accurately identifying and retrieving problems and
corresponding codes remains an urgent research problem in competitive code
generation. In this paper, we propose SolveRank, a solution-aware ranking model
empowered by synthetic data for competitive programming tasks. Specifically, we
leverage the DeepSeek-R1 model to generate logically equivalent but differently
phrased new problems, verified by GPT-4o for solution consistency. Then, we
train SolveRank with these as positive samples and BM25/random-retrieved
problems as negatives. During inference, SolveRank retrieves relevant problems
and corresponding code from the corpus to assist a downstream code generator.
Experiments on the xCodeEval dataset demonstrate that SolveRank outperforms
SOTA ranking methods in precision and recall metrics, and boosts code
generation performance for difficult problems.

</details>


### [10] [MARS: Modality-Aligned Retrieval for Sequence Augmented CTR Prediction](https://arxiv.org/abs/2509.01184)
*Yutian Xiao,Shukuan Wang,Binhao Wang,Zhao Zhang,Yanze Zhang,Shanqi Liu,Chao Feng,Xiang Li,Fuzhen Zhuang*

Main category: cs.IR

TL;DR: MARS框架通过多模态特征对齐和行为序列增强，提升低活跃用户的CTR预测效果。


<details>
  <summary>Details</summary>
Motivation: 现有CTR模型在低活跃用户场景下表现受限于交互稀疏性，需通过数据增强来改善用户行为建模。

Method: 利用Stein核对齐文本和图像特征到统一语义空间，构建多模态用户嵌入，随后增强用户行为序列。

Result: 提出了一种新框架MARS，利用Stein核方法将文本和图像特征对齐至统一的语义空间，构建多模态用户嵌入。通过检索、过滤和集中低活跃用户及高活跃用户的行为序列，进行数据增强，提高低活跃用户CTR预测的准确性。

Conclusion: MARS框架成功部署，显著提升业务指标，为数亿用户服务，且代码已开放访问。

Abstract: Click-through rate (CTR) prediction serves as a cornerstone of recommender
systems. Despite the strong performance of current CTR models based on user
behavior modeling, they are still severely limited by interaction sparsity,
especially in low-active user scenarios. To address this issue, data
augmentation of user behavior is a promising research direction. However,
existing data augmentation methods heavily rely on collaborative signals while
overlooking the rich multimodal features of items, leading to insufficient
modeling of low-active users.
  To alleviate this problem, we propose a novel framework \textbf{MARS}
(\textbf{M}odality-\textbf{A}ligned \textbf{R}etrieval for \textbf{S}equence
Augmented CTR Prediction). MARS utilizes a Stein kernel-based approach to align
text and image features into a unified and unbiased semantic space to construct
multimodal user embeddings. Subsequently, each low-active user's behavior
sequence is augmented by retrieving, filtering, and concentrating the most
similar behavior sequence of high-active users via multimodal user embeddings.
Validated by extensive offline experiments and online A/B tests, our framework
MARS consistently outperforms state-of-the-art baselines and achieves
substantial growth on core business metrics within
Kuaishou~\footnote{https://www.kuaishou.com/}. Consequently, MARS has been
successfully deployed, serving the main traffic for hundreds of millions of
users. To ensure reproducibility, we provide anonymous access to the
implementation code~\footnote{https://github.com/wangshukuan/MARS}.

</details>


### [11] [Re3: Learning to Balance Relevance & Recency for Temporal Information Retrieval](https://arxiv.org/abs/2509.01306)
*Jiawei Cao,Jie Ouyang,Zhaomeng Zhou,Mingyue Cheng,Yupeng Li,Jiaxian Yan,Qi Liu*

Main category: cs.IR

TL;DR: 介绍了一种新的TIR方法Re3，通过新基准Re2Bench评估其在时间相关性和新鲜性上的性能，达到最新成果，并在线开放获取。


<details>
  <summary>Details</summary>
Motivation: 现代搜索系统中的时间信息检索（TIR）任务需要不仅满足查询的信息需求，还需符合其时间限制。然而，目前的方法通常将相关性和新鲜性两个挑战孤立处理，并依赖脆弱的启发式方法。这些方法在时间要求与抵抗陈旧性紧密交织的情况下常常失败。因此，研究旨在开发一种能够在语义和时间信息之间取得平衡的检索系统。

Method: 提出Re3框架，通过查询感知门控机制动态平衡语义和时间信息，同时引入Re2Bench基准来评估相关性和新鲜性及其混合效果。使用该基准，Re3在R@1方面达到了所有三组的最新结果。通过骨干灵敏度测试进行消融研究，验证其在多种编码器和实际环境中的强鲁棒性和泛化能力。

Result: Re3在Re2Bench基准测试上实现了最先进的结果，特别是在所有三个子集中的R@1指标上领先。

Conclusion: 此研究提供了一种普遍可用的解决方案和一个系统化的评估套件，促进了具备时间敏感度的检索系统的发展。通过在线提供Re3和Re2Bench工具，研究为未来的搜索系统发展打下了基础。

Abstract: Temporal Information Retrieval (TIR) is a critical yet unresolved task for
modern search systems, retrieving documents that not only satisfy a query's
information need but also adhere to its temporal constraints. This task is
shaped by two challenges: Relevance, ensuring alignment with the query's
explicit temporal requirements, and Recency, selecting the freshest document
among multiple versions. Existing methods often address the two challenges in
isolation, relying on brittle heuristics that fail in scenarios where temporal
requirements and staleness resistance are intertwined. To address this gap, we
introduce Re2Bench, a benchmark specifically designed to disentangle and
evaluate Relevance, Recency, and their hybrid combination. Building on this
foundation, we propose Re3, a unified and lightweight framework that
dynamically balances semantic and temporal information through a query-aware
gating mechanism. On Re2Bench, Re3 achieves state-of-the-art results, leading
in R@1 across all three subsets. Ablation studies with backbone sensitivity
tests confirm robustness, showing strong generalization across diverse encoders
and real-world settings. This work provides both a generalizable solution and a
principled evaluation suite, advancing the development of temporally aware
retrieval systems. Re3 and Re2Bench are available online:
https://anonymous.4open.science/r/Re3-0C5A

</details>


### [12] [AI4DiTraRe: Building the BFO-Compliant Chemotion Knowledge Graph](https://arxiv.org/abs/2509.01536)
*Ebrahim Norouzi,Nicole Jung,Anna M. Jacyszyn,Jörg Waitelonis,Harald Sack*

Main category: cs.IR

TL;DR: 本文介绍了一个用于化学研究数据的语义知识图谱，旨在优化数据的共享和利用。


<details>
  <summary>Details</summary>
Motivation: 化学领域的技术进步促使实验室中出现多层次且复杂的工作流程，需要以结构化数据来帮助理解这些过程。

Method: 引入一个语义管道，构建符合BFO标准的Chemotion知识图谱，利用SPARQL CONSTRUCT查询将JSON-LD格式数据转换为RDF，然后转化为与基本形式本体对齐的图。

Result: 开发了Chemotion-KG知识图谱，支持符合FAIR原则，同时促进AI驱动的化学发现和推理。源代码和数据集在GitHub上公开可获取，知识图谱由FIZ Karlsruhe 信息服务工程团队托管。

Conclusion: 完成了符合FAIR原则的Chemotion知识图谱的开发，为化学中的AI驱动研究提供了结构化的数据支持。

Abstract: Chemistry is an example of a discipline where the advancements of technology
have led to multi-level and often tangled and tricky processes ongoing in the
lab. The repeatedly complex workflows are combined with information from
chemical structures, which are essential to understand the scientific process.
An important tool for many chemists is Chemotion, which consists of an
electronic lab notebook and a repository. This paper introduces a semantic
pipeline for constructing the BFO-compliant Chemotion Knowledge Graph,
providing an integrated, ontology-driven representation of chemical research
data. The Chemotion-KG has been developed to adhere to the FAIR (Findable,
Accessible, Interoperable, Reusable) principles and to support AI-driven
discovery and reasoning in chemistry. Experimental metadata were harvested from
the Chemotion API in JSON-LD format, converted into RDF, and subsequently
transformed into a Basic Formal Ontology-aligned graph through SPARQL CONSTRUCT
queries. The source code and datasets are publicly available via GitHub. The
Chemotion Knowledge Graph is hosted by FIZ Karlsruhe Information Service
Engineering. Outcomes presented in this work were achieved within the Leibniz
Science Campus ``Digital Transformation of Research'' (DiTraRe) and are part of
an ongoing interdisciplinary collaboration.

</details>


### [13] [Ultra Fast Warm Start Solution for Graph Recommendations](https://arxiv.org/abs/2509.01549)
*Viacheslav Yusupov,Maxim Rakhuba,Evgeny Frolov*

Main category: cs.IR

TL;DR: 本文介绍了一种低秩逼近方法，用于UltraGCN系统的高速推荐更新，提升了推荐质量和时间效率，并具有高可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在面对大量新数据和用户偏好变化的情况下，保持推荐的相关性是极为重要的。

Method: 采用了一种简单但有效的低秩逼近方法适应于图形模型。

Result: 提出的方法提供即时推荐，其速度比传统方法快30倍，并在推荐质量上有所提升。在大型目录数据集上也表现出高度的可扩展性。

Conclusion: 本文提出了一种快速有效的线性方法，用于更新可扩展的图形推荐系统UltraGCN中的推荐。该方法在大量新数据和用户偏好变化的情况下，保持推荐的相关性至关重要。

Abstract: In this work, we present a fast and effective Linear approach for updating
recommendations in a scalable graph-based recommender system UltraGCN. Solving
this task is extremely important to maintain the relevance of the
recommendations under the conditions of a large amount of new data and changing
user preferences. To address this issue, we adapt the simple yet effective
low-rank approximation approach to the graph-based model. Our method delivers
instantaneous recommendations that are up to 30 times faster than conventional
methods, with gains in recommendation quality, and demonstrates high
scalability even on the large catalogue datasets.

</details>


### [14] [Cloud-Device Collaborative Agents for Sequential Recommendation](https://arxiv.org/abs/2509.01551)
*Jing Long,Sirui Huang,Huan Huo,Tong Chen,Hongzhi Yin,Guandong Xu*

Main category: cs.IR

TL;DR: CDA4Rec是一个云设备协作推荐框架，通过云端和设备端代理伙伴来分配推荐任务，以实现高效和个性化推荐。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的推荐系统存在隐私问题、实时信号访问受限和可扩展性瓶颈，而设备端代理虽然保证了隐私和响应性，却缺乏全局建模和大规模检索的计算能力。

Method: 提出一种云设备协同框架CDA4Rec，包括云端大型语言模型和设备端小型语言模型，通过分解推荐任务为语义建模、候选检索、用户模型构建和最终排序等模块任务，根据计算需求和隐私敏感性在云或设备上进行分配。

Result: 大规模实验证明，在准确性和效率上，CDA4Rec在异构和资源受限环境中均优于竞争基线。

Conclusion: CDA4Rec有效地解决了云设备协同推荐中的核心挑战，实现了实时响应、提高了效率，并支持细粒度的个性化。

Abstract: Recent advances in large language models (LLMs) have enabled agent-based
recommendation systems with strong semantic understanding and flexible
reasoning capabilities. While LLM-based agents deployed in the cloud offer
powerful personalization, they often suffer from privacy concerns, limited
access to real-time signals, and scalability bottlenecks. Conversely, on-device
agents ensure privacy and responsiveness but lack the computational power for
global modeling and large-scale retrieval. To bridge these complementary
limitations, we propose CDA4Rec, a novel Cloud-Device collaborative framework
for sequential Recommendation, powered by dual agents: a cloud-side LLM and a
device-side small language model (SLM). CDA4Rec tackles the core challenge of
cloud-device coordination by decomposing the recommendation task into modular
sub-tasks including semantic modeling, candidate retrieval, structured user
modeling, and final ranking, which are allocated to cloud or device based on
computational demands and privacy sensitivity. A strategy planning mechanism
leverages the cloud agent's reasoning ability to generate personalized
execution plans, enabling context-aware task assignment and partial parallel
execution across agents. This design ensures real-time responsiveness, improved
efficiency, and fine-grained personalization, even under diverse user states
and behavioral sparsity. Extensive experiments across multiple real-world
datasets demonstrate that CDA4Rec consistently outperforms competitive
baselines in both accuracy and efficiency, validating its effectiveness in
heterogeneous and resource-constrained environments.

</details>


### [15] [CSRM-LLM: Embracing Multilingual LLMs for Cold-Start Relevance Matching in Emerging E-commerce Markets](https://arxiv.org/abs/2509.01566)
*Yujing Wang,Yiren Chen,Huoran Li,Chunxu Xu,Yuchong Luo,Xianghui Mao,Cong Li,Lun Du,Chunyang Ma,Qiqi Jiang,Yin Wang,Fan Gao,Wenting Mo,Pei Wen,Shantanu Kumar,Taejin Park,Yiwei Song,Vijay Rajaram,Tao Cheng,Sonu Durgia,Pranam Kolari*

Main category: cs.IR

TL;DR: 本文提出使用多语言大模型框架解决电子商务平台冷启动问题，通过机器翻译、查询增强和多轮自蒸馏策略实现显著线上效果。


<details>
  <summary>Details</summary>
Motivation: 随着全球电子商务平台的扩展，公司进入新市场面临冷启动挑战，因为缺乏人类标签和用户行为数据。

Method: 提出一个冷启动相关性匹配框架（CSRMLLM），使用多语言大模型解决三个主要挑战：跨语言迁移学习、检索式查询增强、以及多轮自蒸馏训练策略。

Result: 在实际应用中，成功部署以CSRM框架为基础的技术，在线取得了显著效果，缺陷率降低了45.8%，会话购买率提升了0.866%。

Conclusion: CSRMLLM框架及所提技术方法有效解决了冷启动挑战，并在实际应用中取得显著业绩提升。

Abstract: As global e-commerce platforms continue to expand, companies are entering new
markets where they encounter cold-start challenges due to limited human labels
and user behaviors. In this paper, we share our experiences in Coupang to
provide a competitive cold-start performance of relevance matching for emerging
e-commerce markets. Specifically, we present a Cold-Start Relevance Matching
(CSRM) framework, utilizing a multilingual Large Language Model (LLM) to
address three challenges: (1) activating cross-lingual transfer learning
abilities of LLMs through machine translation tasks; (2) enhancing query
understanding and incorporating e-commerce knowledge by retrieval-based query
augmentation; (3) mitigating the impact of training label errors through a
multi-round self-distillation training strategy. Our experiments demonstrate
the effectiveness of CSRM-LLM and the proposed techniques, resulting in
successful real-world deployment and significant online gains, with a 45.8%
reduction in defect ratio and a 0.866% uplift in session purchase rate.

</details>


### [16] [Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs](https://arxiv.org/abs/2509.02017)
*Yuhao Wang,Junwei Pan,Xinhang Li,Maolin Wang,Yuan Wang,Yue Liu,Dapeng Liu,Jie Jiang,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 论文提出MME-SID框架，有效解决嵌入塌缩和灾难性遗忘问题，提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM基础的SR方法面临嵌入塌缩和灾难性遗忘的问题，导致模型扩展性降低和推荐性能不足。

Method: 提出MME-SID框架，集成多模态嵌入和量化嵌入，并使用MM-RQ-VAE自动编码器结合最大均值差异和对比学习，以保持模态内距离信息和捕捉模态间关系。另外，通过初始化训练的多模态代码嵌入并采用LoRA用于模型微调。

Result: 引入MME-SID框架通过多模态和量化嵌入有效缓解了嵌入塌缩和灾难性遗忘问题，显著提高了推荐性能。

Conclusion: MME-SID框架在处理嵌入塌缩和灾难性遗忘问题上表现出色，并在多数据集实验中展示了其卓越的推荐性能。

Abstract: Sequential recommendation (SR) aims to capture users' dynamic interests and
sequential patterns based on their historical interactions. Recently, the
powerful capabilities of large language models (LLMs) have driven their
adoption in SR. However, we identify two critical challenges in existing
LLM-based SR methods: 1) embedding collapse when incorporating pre-trained
collaborative embeddings and 2) catastrophic forgetting of quantized embeddings
when utilizing semantic IDs. These issues dampen the model scalability and lead
to suboptimal recommendation performance. Therefore, based on LLMs like
Llama3-8B-instruct, we introduce a novel SR framework named MME-SID, which
integrates multimodal embeddings and quantized embeddings to mitigate embedding
collapse. Additionally, we propose a Multimodal Residual Quantized Variational
Autoencoder (MM-RQ-VAE) with maximum mean discrepancy as the reconstruction
loss and contrastive learning for alignment, which effectively preserve
intra-modal distance information and capture inter-modal correlations,
respectively. To further alleviate catastrophic forgetting, we initialize the
model with the trained multimodal code embeddings. Finally, we fine-tune the
LLM efficiently using LoRA in a multimodal frequency-aware fusion manner.
Extensive experiments on three public datasets validate the superior
performance of MME-SID thanks to its capability to mitigate embedding collapse
and catastrophic forgetting. The implementation code and datasets are publicly
available for reproduction:
https://github.com/Applied-Machine-Learning-Lab/MME-SID.

</details>


### [17] [Towards Multi-Aspect Diversification of News Recommendations Using Neuro-Symbolic AI for Individual and Societal Benefit](https://arxiv.org/abs/2509.02220)
*Markus Reiter-Haas,Elisabeth Lex*

Main category: cs.IR

TL;DR: 此研究引入多方面新闻推荐多样性，结合知识图谱与人工智能，并计划通过用户研究评估模型带来的用户体验及社会影响。


<details>
  <summary>Details</summary>
Motivation: 现有文献主要关注新闻推荐中特定方面的多样性，如观点多样性。论文旨在通过多方面多样性提升新闻推荐的复杂性，并通过人工智能结合知识图谱与规则学习实现这一目标。

Method: 结合使用知识图谱与规则学习的符号和子符号人工智能模型，探索多方面新闻推荐。计划通过用户研究评估模型效果。

Result: 尚未有具体的实验结果，计划通过用户研究评估模型效果。预期会在增强用户新闻消费体验和减少信息极化等方面带来积极影响。

Conclusion: 我们提出了利用符号和子符号人工智能进行多方面新闻推荐的方向，并计划通过用户研究进行评估，以期实现用户体验和社会影响的平衡。

Abstract: News recommendations are complex, with diversity playing a vital role. So
far, existing literature predominantly focuses on specific aspects of news
diversity, such as viewpoints. In this paper, we introduce multi-aspect
diversification in four distinct recommendation modes and outline the nuanced
challenges in diversifying lists, sequences, summaries, and interactions. Our
proposed research direction combines symbolic and subsymbolic artificial
intelligence, leveraging both knowledge graphs and rule learning. We plan to
evaluate our models using user studies to not only capture behavior but also
their perceived experience. Our vision to balance news consumption points to
other positive effects for users (e.g., increased serendipity) and society
(e.g., decreased polarization).

</details>


### [18] [Application Of Large Language Models For The Extraction Of Information From Particle Accelerator Technical Documentation](https://arxiv.org/abs/2509.02227)
*Qing Dai,Rasmus Ischebeck,Maruisz Sapinski,Adam Grycner*

Main category: cs.IR

TL;DR: 研究使用LLM提高对粒子加速器技术文档的知识提取和保存能力，取得初步成果。


<details>
  <summary>Details</summary>
Motivation: 技术文档的数量庞大以及经验丰富人员的退休使得需要高效的方法来保存和传递专业知识。

Method: 应用大语言模型（LLM）来自动化和增强从粒子加速器技术文档中提取信息。

Result: 评估表明LLM在提取、总结和组织知识方面有效，能够显著降低人员退休导致宝贵见解流失的风险。

Conclusion: LLM有潜力在保存机构知识和确保专业领域连续性方面发挥关键作用，但需解决可解释性和处理罕见专业术语的局限性。

Abstract: The large set of technical documentation of legacy accelerator systems,
coupled with the retirement of experienced personnel, underscores the urgent
need for efficient methods to preserve and transfer specialized knowledge. This
paper explores the application of large language models (LLMs), to automate and
enhance the extraction of information from particle accelerator technical
documents. By exploiting LLMs, we aim to address the challenges of knowledge
retention, enabling the retrieval of domain expertise embedded in legacy
documentation. We present initial results of adapting LLMs to this specialized
domain. Our evaluation demonstrates the effectiveness of LLMs in extracting,
summarizing, and organizing knowledge, significantly reducing the risk of
losing valuable insights as personnel retire. Furthermore, we discuss the
limitations of current LLMs, such as interpretability and handling of rare
domain-specific terms, and propose strategies for improvement. This work
highlights the potential of LLMs to play a pivotal role in preserving
institutional knowledge and ensuring continuity in highly specialized fields.

</details>


### [19] [Leveraging Media Frames to Improve Normative Diversity in News Recommendations](https://arxiv.org/abs/2509.02266)
*Sourabh Dattawad,Agnese Daffara,Tanise Ceron*

Main category: cs.IR

TL;DR: 本文提出了一种通过选择不同媒体框架来增加新闻推荐系统多样性的方法，并证明这种方法可以提升用户对未点击过的新闻框架的曝光率达50%。


<details>
  <summary>Details</summary>
Motivation: 现有的新闻推荐系统倾向于根据用户历史记录推荐内容，缺乏多样性，可能导致观点单一。本文旨在通过引入媒体框架多样化改善这一问题。

Method: 本文通过在推荐系统中引入媒体框架多样化，将不同叙事角度视为一种可控制的推荐因素，从而扩大用户的理解视野。

Result: 实验表明，媒体框架的多样化推荐方法能够提升用户对未点击框架的曝光率上升50%，并在类别和情感层面增强多样性。

Conclusion: 通过媒体框架多样化提高新闻推荐系统的多样性，不仅帮助用户接触更多不同视角，还能减少已有偏见的强化。

Abstract: Click-based news recommender systems suggest users content that aligns with
their existing history, limiting the diversity of articles they encounter.
Recent advances in aspect-based diversification -- adding features such as
sentiments or news categories (e.g. world, politics) -- have made progress
toward diversifying recommendations in terms of perspectives. However, these
approaches often overlook the role of news framing, which shapes how stories
are told by emphasizing specific angles or interpretations. In this paper, we
treat media frames as a controllable aspect within the recommendation pipeline.
By selecting articles based on a diversity of frames, our approach emphasizes
varied narrative angles and broadens the interpretive space recommended to
users. In addition to introducing frame-based diversification method, our work
is the first to assess the impact of a news recommender system that integrates
frame diversity using normative diversity metrics: representation, calibration,
and activation. Our experiments based on media frame diversification show an
improvement in exposure to previously unclicked frames up to 50%. This is
important because repeated exposure to the same frames can reinforce existing
biases or narrow interpretations, whereas introducing novel frames broadens
users' understanding of issues and perspectives. The method also enhances
diversification across categorical and sentiment levels, thereby demonstrating
that framing acts as a strong control lever for enhancing normative diversity.

</details>


### [20] [Upcycling Candidate Tokens of Large Language Models for Query Expansion](https://arxiv.org/abs/2509.02377)
*Jinseok Kim,Sukmin Cho,Soyeong Jeong,Sangyeop Kim,Sungzoon Cho*

Main category: cs.IR

TL;DR: CTQE通过利用未选择的候选词汇进行查询扩展，提高检索性能，同时降低成本。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM用于查询扩展面临生成多样化词汇提高性能但增加计算成本的权衡，因此提出CTQE以在降低成本的同时实现多样性和相关性。

Method: 采用单次LLM解码，通过聚合未选择的候选词汇来进行查询扩展，从而在不增加推理的情况下实现查询词汇的相关性与多样性。

Result: CTQE通过从单次LLM解码中提取未被选择的候选词汇，生成多样化和相关性的扩展词，从而提高检索性能，降低计算成本。

Conclusion: 实验结果表明，CTQE能够在显著降低成本的情况下，提供强大的检索性能，且效果优于或相当于更昂贵的方法。

Abstract: Query Expansion (QE) improves retrieval performance by enriching queries with
related terms. Recently, Large Language Models (LLMs) have been used for QE,
but existing methods face a trade-off: generating diverse terms boosts
performance but increases computational cost. To address this challenge, we
propose Candidate Token Query Expansion (CTQE), which extracts diverse and
relevant terms from a single LLM decoding pass by leveraging unselected
candidate tokens. These tokens, though not part of the final output, are
conditioned on the full query and capture useful information. By aggregating
them, CTQE achieves both relevance and diversity without extra inference,
reducing overhead and latency. Experiments show that CTQE delivers strong
retrieval performance with significantly lower cost, outperforming or
comparable to more expensive methods. Code is available at:
https://github.com/bluejeans8/CTQE

</details>


### [21] [Lighting the Way for BRIGHT: Reproducible Baselines with Anserini, Pyserini, and RankLLM](https://arxiv.org/abs/2509.02558)
*Yijun Ge,Sahel Sharifymoghaddam,Jimmy Lin*

Main category: cs.IR

TL;DR: 分析BRIGHT数据集的检索结果，发现BM25实现方法上的差异，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 探讨在涉及推理的查询上的检索效果，并建立可再现的基线，以便更好地适应长查询在检索增强生成中的应用。

Method: 使用了一系列检索技术，包括稀疏、密集和融合方法，并应用了列表重排技术与大型语言模型进行比较。

Result: 基线方法已经整合到流行的检索和重排工具包中，使其易于构建和进一步开发。发现BRIGHT的BM25实现与标准方法不同，并对此进行适应性集成。

Conclusion: 研究提出了一些可再现的基线，并发现原始BRIGHT论文中报告的BM25分数与使用Anserini和Pyserini获得的结果明显不同，应该重新考虑BM25方法以适应新兴应用。

Abstract: The BRIGHT benchmark is a dataset consisting of reasoning-intensive queries
over diverse domains. We explore retrieval results on BRIGHT using a range of
retrieval techniques, including sparse, dense, and fusion methods, and
establish reproducible baselines. We then apply listwise reranking with large
language models (LLMs) to further investigate the impact of reranking on
reasoning-intensive queries. These baselines are integrated into popular
retrieval and reranking toolkits Anserini, Pyserini, and RankLLM, with
two-click reproducibility that makes them easy to build upon and convenient for
further development. While attempting to reproduce the results reported in the
original BRIGHT paper, we find that the provided BM25 scores differ notably
from those that we obtain using Anserini and Pyserini. We discover that this
difference is due to BRIGHT's implementation of BM25, which applies BM25 on the
query rather than using the standard bag-of-words approach, as in Anserini, to
construct query vectors. This difference has become increasingly relevant due
to the rise of longer queries, with BRIGHT's lengthy reasoning-intensive
queries being a prime example, and further accentuated by the increasing usage
of retrieval-augmented generation, where LLM prompts can grow to be much longer
than ''traditional'' search engine queries. Our observation signifies that it
may be time to reconsider BM25 approaches going forward in order to better
accommodate emerging applications. To facilitate this, we integrate query-side
BM25 into both Anserini and Pyserini.

</details>
