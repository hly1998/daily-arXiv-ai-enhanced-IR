<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Efficient and Versatile Model for Multilingual Information Retrieval of Islamic Text: Development and Deployment in Real-World Scenarios](https://arxiv.org/abs/2509.15380)
*Vera Pavlova,Mohammed Makhlouf*

Main category: cs.IR

TL;DR: 本文开发了一个结合跨语与单语技术的多语种信息检索系统，尤其适用于伊斯兰信息需求，评价结果表明其有效性，并对不同训练配置对嵌入空间的影响进行分析，同时探讨了部署成本效益。


<details>
  <summary>Details</summary>
Motivation: 近年来多语种信息检索取得了进展，但研究与实际应用之间仍存在显著差距。许多研究在孤立环境中评估多语种信息检索性能，限制了它们在实际场景中的适用性。本文旨在利用古兰经多语言语料库的独特特性，开发一个专为满足多个语言的信息需求的伊斯兰领域的临时信息检索系统。

Method: 研究中准备了十一个检索模型，采用四种训练方法：单语、跨语、翻译-训练-整体以及新的混合方法（结合跨语和单语技术）。

Result: 论文在一个领域内数据集上的评估表明混合方法在多种检索情景下取得了良好的结果。

Conclusion: 详细分析了不同训练配置如何影响嵌入空间，并探讨了多语种检索的有效性。讨论了部署考量，强调了单一多功能轻量化模型在真实世界中的应用成本效益。

Abstract: Despite recent advancements in Multilingual Information Retrieval (MLIR), a
significant gap remains between research and practical deployment. Many studies
assess MLIR performance in isolated settings, limiting their applicability to
real-world scenarios. In this work, we leverage the unique characteristics of
the Quranic multilingual corpus to examine the optimal strategies to develop an
ad-hoc IR system for the Islamic domain that is designed to satisfy users'
information needs in multiple languages. We prepared eleven retrieval models
employing four training approaches: monolingual, cross-lingual,
translate-train-all, and a novel mixed method combining cross-lingual and
monolingual techniques. Evaluation on an in-domain dataset demonstrates that
the mixed approach achieves promising results across diverse retrieval
scenarios. Furthermore, we provide a detailed analysis of how different
training configurations affect the embedding space and their implications for
multilingual retrieval effectiveness. Finally, we discuss deployment
considerations, emphasizing the cost-efficiency of deploying a single
versatile, lightweight model for real-world MLIR applications.

</details>


### [2] [SERVAL: Surprisingly Effective Zero-Shot Visual Document Retrieval Powered by Large Vision and Language Models](https://arxiv.org/abs/2509.15432)
*Thong Nguyen,Yibin Lei,Jia-Huei Ju,Andrew Yates*

Main category: cs.IR

TL;DR: 这项研究探讨了一种零样本生成和编码的新方法，通过视觉语言模型对文档图像进行文本描述，然后使用标准文本编码器进行嵌入，取得了优于现有多向量视觉文档编码器的性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在改善Visual Document Retrieval的性能，特别是通过视觉语言模型捕获复杂的文本和视觉信息以提升检索效果。

Method: 采用零样本生成和编码管道：使用视觉语言模型生成文档图像的详细文本描述，然后通过标准文本编码器进行嵌入。

Result: 在ViDoRe-v2基准测试中，该方法取得了63.4%的nDCG@5，超越了最强的多向量视觉文档编码器，在大规模文档集和多语言方面表现出色。

Conclusion: 这一方法通过卸载模态对齐任务，消除了对计算密集的文本图像对比训练的需求，并为未来的视觉文档检索系统建立了强大的零样本基线。

Abstract: Visual Document Retrieval (VDR) typically operates as text-to-image retrieval
using specialized bi-encoders trained to directly embed document images. We
revisit a zero-shot generate-and-encode pipeline: a vision-language model first
produces a detailed textual description of each document image, which is then
embedded by a standard text encoder. On the ViDoRe-v2 benchmark, the method
reaches 63.4% nDCG@5, surpassing the strongest specialised multi-vector visual
document encoder. It also scales better to large collections and offers broader
multilingual coverage. Analysis shows that modern vision-language models
capture complex textual and visual cues with sufficient granularity to act as a
reusable semantic proxy. By offloading modality alignment to pretrained
vision-language models, our approach removes the need for computationally
intensive text-image contrastive training and establishes a strong zero-shot
baseline for future VDR systems.

</details>


### [3] [Dual-Mode Visual System for Brain-Computer Interfaces: Integrating SSVEP and P300 Responses](https://arxiv.org/abs/2509.15439)
*Ekgari Kasawala,Surej Mouli*

Main category: cs.IR

TL;DR: 开发了一种结合SSVEP和P300的新型LED刺激设备，提高了脑机接口系统的分类准确性和信息传输率。


<details>
  <summary>Details</summary>
Motivation: 传统的液晶显示（LCD）视觉刺激模式在实际应用中存在局限性，因此开发一种新型LED视觉刺激设备以提高系统实用性。

Method: 采用LED为基础的双刺激设备，通过结合SSVEP和P300模式来提高SSVEP分类准确性。

Result: 系统实现了平均分类准确率为86.25%，平均信息传输率为42.08 bpm。

Conclusion: 新型LED视觉刺激设备在提高BCI系统的应用性及精度方面展现出巨大的潜力。

Abstract: In brain-computer interface (BCI) systems, steady-state visual evoked
potentials (SSVEP) and P300 responses have achieved widespread implementation
owing to their superior information transfer rates (ITR) and minimal training
requirements. These neurophysiological signals have exhibited robust efficacy
and versatility in external device control, demonstrating enhanced precision
and scalability. However, conventional implementations predominantly utilise
liquid crystal display (LCD)-based visual stimulation paradigms, which present
limitations in practical deployment scenarios. This investigation presents the
development and evaluation of a novel light-emitting diode (LED)-based dual
stimulation apparatus designed to enhance SSVEP classification accuracy through
the integration of both SSVEP and P300 paradigms. The system employs four
distinct frequencies, 7 Hz, 8 Hz, 9 Hz, and 10 Hz, corresponding to forward,
backward, right, and left directional controls, respectively. Oscilloscopic
verification confirmed the precision of these stimulation frequencies.
Real-time feature extraction was accomplished through the concurrent analysis
of maximum Fast Fourier Transform (FFT) amplitude and P300 peak detection to
ascertain user intent. Directional control was determined by the frequency
exhibiting maximal amplitude characteristics. The visual stimulation hardware
demonstrated minimal frequency deviation, with error differentials ranging from
0.15%to 0.20%across all frequencies. The implemented signal processing
algorithm successfully discriminated all four stimulus frequencies whilst
correlating them with their respective P300 event markers. Classification
accuracy was evaluated based on correct task intention recognition. The
proposed hybrid system achieved a mean classification accuracy of 86.25%,
coupled with an average ITR of 42.08 bits per minute (bpm).

</details>


### [4] [CFDA & CLIP at TREC iKAT 2025: Enhancing Personalized Conversational Search via Query Reformulation and Rank Fusion](https://arxiv.org/abs/2509.15588)
*Yu-Cheng Chang,Guan-Wei Yeo,Quah Eugene,Fan-Jie Shih,Yuan-Ching Kuo,Tsung-En Yu,Hung-Chun Hsu,Ming-Feng Tsai,Chuan-Ju Wang*

Main category: cs.IR

TL;DR: 研究探索了查询重写和检索融合策略，提高了系统鲁棒性并揭示了效率和效果的权衡。


<details>
  <summary>Details</summary>
Motivation: TREC Interactive Knowledge Assistance Track (iKAT)需要系统在实时约束下运行，强调鲁棒性和效率，与准确性同样重要。同时，还需要在预定义数据集上进行受控评估，以提高段落排名和响应生成准确度。

Method: 采用了Best-of-$N$选择和互惠排名融合（RRF）策略来构建流水线，以处理交互式和离线提交任务。

Result: 通过使用查询重写和检索融合策略，在不同提交任务中进行的实验表明，重排序和融合方法提高了系统的鲁棒性，并揭示了在任务之间效果和效率的权衡。

Conclusion: 重排序和检索融合策略不仅提高了系统的鲁棒性，还揭示了在效果和效率之间的权衡，这是在处理交互和离线提交任务中必要的重要策略。

Abstract: The 2025 TREC Interactive Knowledge Assistance Track (iKAT) featured both
interactive and offline submission tasks. The former requires systems to
operate under real-time constraints, making robustness and efficiency as
important as accuracy, while the latter enables controlled evaluation of
passage ranking and response generation with pre-defined datasets. To address
this, we explored query rewriting and retrieval fusion as core strategies. We
built our pipelines around Best-of-$N$ selection and Reciprocal Rank Fusion
(RRF) strategies to handle different submission tasks. Results show that
reranking and fusion improve robustness while revealing trade-offs between
effectiveness and efficiency across both tasks.

</details>


### [5] [Chunk Knowledge Generation Model for Enhanced Information Retrieval: A Multi-task Learning Approach](https://arxiv.org/abs/2509.15658)
*Jisu Kim,Jinhee Park,Changhyun Jeon,Jungwoo Choi,Keonwoo Kim,Minji Hong,Sehyun Kim*

Main category: cs.IR

TL;DR: 该研究提出了一种基于T5的多任务学习模型，通过文档分块并生成标题和问题来提高信息检索的效率和准确性，验证了在大规模检索系统中的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的查询扩展技术存在上下文敏感性的问题，可能导致性能下降。为了解决这些问题并寻找更结构化和高效的替代方案，该研究提出一种新的方法。

Method: 该研究提出了一种“Chunk Knowledge Generation Model”，采用T5为基础的多任务学习结构，对文档进行分块处理，并为每个块生成文本数据。同时生成标题和候选问题，并从用户查询中提取关键词。这样通过单一编码和两个解码过程并行生成和提取三种语义信息，最大化计算效率。

Result: 通过对305个查询文档对的GPT模型评估，使用所提出模型的检索在Top@10时达到了95.41%的准确率，显示出优于文档块级别检索的性能。

Conclusion: 研究提出的方法通过生成标题和候选问题来改善检索管道，并通过定性评估提供了适用于大规模信息检索系统的经验证据，显示出提高了检索准确性。

Abstract: Traditional query expansion techniques for addressing vocabulary mismatch
problems in information retrieval are context-sensitive and may lead to
performance degradation. As an alternative, document expansion research has
gained attention, but existing methods such as Doc2Query have limitations
including excessive preprocessing costs, increased index size, and reliability
issues with generated content. To mitigate these problems and seek more
structured and efficient alternatives, this study proposes a method that
divides documents into chunk units and generates textual data for each chunk to
simultaneously improve retrieval efficiency and accuracy. The proposed "Chunk
Knowledge Generation Model" adopts a T5-based multi-task learning structure
that simultaneously generates titles and candidate questions from each document
chunk while extracting keywords from user queries. This approach maximizes
computational efficiency by generating and extracting three types of semantic
information in parallel through a single encoding and two decoding processes.
The generated data is utilized as additional information in the retrieval
system. GPT-based evaluation on 305 query-document pairs showed that retrieval
using the proposed model achieved 95.41% accuracy at Top@10, demonstrating
superior performance compared to document chunk-level retrieval. This study
contributes by proposing an approach that simultaneously generates titles and
candidate questions from document chunks for application in retrieval
pipelines, and provides empirical evidence applicable to large-scale
information retrieval systems by demonstrating improved retrieval accuracy
through qualitative evaluation.

</details>


### [6] [Understanding Embedding Scaling in Collaborative Filtering](https://arxiv.org/abs/2509.15709)
*Zhuangzhuang He,Zhou Kaiyu,Haoyue Bai,Fengbin Zhu,Yonghui Yang*

Main category: cs.IR

TL;DR: 研究推荐模型的扩展，尤其是嵌入维度对性能的影响，发现双峰和对数现象，并分析其潜在原因和噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探索推荐模型的扩展及嵌入维度如何影响性能，解决嵌入尺寸无法扩展的根本原因。

Method: 进行大规模实验，总结10个不同稀疏程度和规模的数据集，使用4个经典架构。

Result: 观测到双峰和对数现象，并理解双峰现象的根本原因，理论上分析模型的噪声鲁棒性与实验相符。

Conclusion: 发现双峰和对数现象，解析其原因并进行噪声鲁棒性分析。

Abstract: Scaling recommendation models into large recommendation models has become one
of the most widely discussed topics. Recent efforts focus on components beyond
the scaling embedding dimension, as it is believed that scaling embedding may
lead to performance degradation. Although there have been some initial
observations on embedding, the root cause of their non-scalability remains
unclear. Moreover, whether performance degradation occurs across different
types of models and datasets is still an unexplored area. Regarding the effect
of embedding dimensions on performance, we conduct large-scale experiments
across 10 datasets with varying sparsity levels and scales, using 4
representative classical architectures. We surprisingly observe two novel
phenomenon: double-peak and logarithmic. For the former, as the embedding
dimension increases, performance first improves, then declines, rises again,
and eventually drops. For the latter, it exhibits a perfect logarithmic curve.
Our contributions are threefold. First, we discover two novel phenomena when
scaling collaborative filtering models. Second, we gain an understanding of the
underlying causes of the double-peak phenomenon. Lastly, we theoretically
analyze the noise robustness of collaborative filtering models, with results
matching empirical observations.

</details>


### [7] [Optimizing Product Deduplication in E-Commerce with Multimodal Embeddings](https://arxiv.org/abs/2509.15858)
*Aysenur Kulunk,Berk Taskin,M. Furkan Eseoglu,H. Bahadir Sahin*

Main category: cs.IR

TL;DR: 该论文介绍了一种专为电子商务设计的产品去重系统，利用BERT构架的文本模型和AutoEncoders用于图像表示，实现高效的相似性搜索，F1得分达到0.90。


<details>
  <summary>Details</summary>
Motivation: 解决电子商务市场中因重复产品列表对消费者造成的混淆和运营效率低下的问题。

Method: 使用BERT架构的文本模型与MaskedAutoEncoders生成128维紧凑嵌入，结合Milvus数据库进行高效相似性搜索，开发利用文本和图像向量的决策模型。

Result: 系统在200亿产品列表下消耗仅100GB内存，宏平均F1得分为0.90，优于第三方解决方案的0.83。

Conclusion: 结合域特异性调整和先进的机器学习技术可以有效减少大规模电子商务平台的重复产品列表。

Abstract: In large scale e-commerce marketplaces, duplicate product listings frequently
cause consumer confusion and operational inefficiencies, degrading trust on the
platform and increasing costs. Traditional keyword-based search methodologies
falter in accurately identifying duplicates due to their reliance on exact
textual matches, neglecting semantic similarities inherent in product titles.
To address these challenges, we introduce a scalable, multimodal product
deduplication designed specifically for the e-commerce domain. Our approach
employs a domain-specific text model grounded in BERT architecture in
conjunction with MaskedAutoEncoders for image representations. Both of these
architectures are augmented with dimensionality reduction techniques to produce
compact 128-dimensional embeddings without significant information loss.
Complementing this, we also developed a novel decider model that leverages both
text and image vectors. By integrating these feature extraction mechanisms with
Milvus, an optimized vector database, our system can facilitate efficient and
high-precision similarity searches across extensive product catalogs exceeding
200 million items with just 100GB of system RAM consumption. Empirical
evaluations demonstrate that our matching system achieves a macro-average F1
score of 0.90, outperforming third-party solutions which attain an F1 score of
0.83. Our findings show the potential of combining domain-specific adaptations
with state-of-the-art machine learning techniques to mitigate duplicate
listings in large-scale e-commerce environments.

</details>
