<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 12]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [ACT: Automated Constraint Targeting for Multi-Objective Recommender Systems](https://arxiv.org/abs/2509.03661)
*Daryl Chang,Yi Wu,Jennifer She,Li Wei,Lukasz Heldt*

Main category: cs.IR

TL;DR: 引入一种自动化约束目标（ACT）框架，能够自动调整推荐系统的超参数，以满足次要目标的最低要求。


<details>
  <summary>Details</summary>
Motivation: 推荐系统需要在最大化主要目标的同时，确保次要目标满足最低阈值。手动调整超参数来实现这一目标具有挑战性。

Method: 使用离线的成对评估在无偏数据上找到解决方案，并不断重新训练以适应系统和用户行为的变化。

Result: 实验证明了ACT的有效性，并描述了它在大型生产环境中的部署。

Conclusion: ACT框架可以自动调整推荐系统的超参数，从而保证次要目标的约束条件在变化的系统环境中得到满足。

Abstract: Recommender systems often must maximize a primary objective while ensuring
secondary ones satisfy minimum thresholds, or "guardrails." This is critical
for maintaining a consistent user experience and platform ecosystem, but
enforcing these guardrails despite orthogonal system changes is challenging and
often requires manual hyperparameter tuning. We introduce the Automated
Constraint Targeting (ACT) framework, which automatically finds the minimal set
of hyperparameter changes needed to satisfy these guardrails. ACT uses an
offline pairwise evaluation on unbiased data to find solutions and continuously
retrains to adapt to system and user behavior changes. We empirically
demonstrate its efficacy and describe its deployment in a large-scale
production environment.

</details>


### [2] [lifeXplore at the Lifelog Search Challenge 2021](https://arxiv.org/abs/2509.03692)
*Andreas Leibetseder,Klaus Schoeffmann*

Main category: cs.IR

TL;DR: LSC比赛中，改进版lifeXplore提升了lifelog数据检索系统的功能。


<details>
  <summary>Details</summary>
Motivation: 提高LSC比赛中lifelog数据检索的效率。

Method: 使用时间查询和互动可组合概念过滤技术改进lifelog数据检索工具。

Result: 开发了改进版的lifeXplore检索系统，增加了时序查询、先进的每日摘要功能以及可用性改进。

Conclusion: 新版本的lifeXplore在LSC比赛中的表现可能更为优异。

Abstract: Since its first iteration in 2018, the Lifelog Search Challenge (LSC)
continues to rise in popularity as an interactive lifelog data retrieval
competition, co-located at the ACM International Conference on Multimedia
Retrieval (ICMR). The goal of this annual live event is to search a large
corpus of lifelogging data for specifically announced memories using a
purposefully developed tool within a limited amount of time. As long-standing
participants, we present our improved lifeXplore - a retrieval system combining
chronologic day summary browsing with interactive combinable concept filtering.
Compared to previous versions, the tool is improved by incorporating temporal
queries, advanced day summary features as well as usability improvements.

</details>


### [3] [LLMs for estimating positional bias in logged interaction data](https://arxiv.org/abs/2509.03696)
*Aleksandr V. Petrov,Michael Murtagh,Karthik Nagesh*

Main category: cs.IR

TL;DR: 本文提出利用大型语言模型估计推荐系统中的位置偏差，改善排序质量。


<details>
  <summary>Details</summary>
Motivation: 传统因位置偏差导致推荐系统模型继承前模型的偏见，未能真正提高相关性，该文提出新的估计方法解决这一问题。

Method: 提出了一种使用大型语言模型来估计位置偏差的方法，替代复杂的线上实验，通过对用户交互数据的模型评估来进行权重调整。

Result: 所提出的使用大型语言模型进行位置偏差估计的方法，相比于简单启发式能够更稳定地估计位置概率，并揭示复杂界面布局的影响，在加权NDCG@10提升约2%。

Conclusion: 使用大型语言模型对记录的用户交互数据进行位置偏差估计，可以有效改善推荐排序质量，并能在离线实验中实现与生产模型相当的表现，同时在加权NDCG@10上提升大约2%。

Abstract: Recommender and search systems commonly rely on Learning To Rank models
trained on logged user interactions to order items by predicted relevance.
However, such interaction data is often subject to position bias, as users are
more likely to click on items that appear higher in the ranking, regardless of
their actual relevance. As a result, newly trained models may inherit and
reinforce the biases of prior ranking models rather than genuinely improving
relevance. A standard approach to mitigate position bias is Inverse Propensity
Scoring (IPS), where the model's loss is weighted by the inverse of a
propensity function, an estimate of the probability that an item at a given
position is examined. However, accurate propensity estimation is challenging,
especially in interfaces with complex non-linear layouts. In this paper, we
propose a novel method for estimating position bias using Large Language Models
(LLMs) applied to logged user interaction data. This approach offers a
cost-effective alternative to online experimentation. Our experiments show that
propensities estimated with our LLM-as-a-judge approach are stable across score
buckets and reveal the row-column effects of Viator's grid layout that simpler
heuristics overlook. An IPS-weighted reranker trained with these propensities
matches the production model on standard NDCG@10 while improving weighted
NDCG@10 by roughly 2%. We will verify these offline gains in forthcoming
live-traffic experiments.

</details>


### [4] [Efficient Item ID Generation for Large-Scale LLM-based Recommendation](https://arxiv.org/abs/2509.03746)
*Anushya Subbiah,Vikram Aggarwal,James Pine,Steffen Rendle,Krishna Sayana,Kun Su*

Main category: cs.IR

TL;DR: 本论文提出将项目ID直接集成到LLM中的方法，提高推荐系统效率及性能。


<details>
  <summary>Details</summary>
Motivation: 在项目推荐中，现有技术将项目ID分解成多个标记的方法面临效率瓶颈。

Method: 提出简单且高效的新型训练和推理修正，支持项目单标记表示及单步解码。

Result: 在亚马逊购物数据集上，该方法在推荐质量上优于现有技术，在推理效率上提高了5至14倍。

Conclusion: 本论文展示了一种将项目ID作为LLM中的一等公民进行处理的方法，提高了推荐质量和推理效率。

Abstract: Integrating product catalogs and user behavior into LLMs can enhance
recommendations with broad world knowledge, but the scale of real-world item
catalogs, often containing millions of discrete item identifiers (Item IDs),
poses a significant challenge. This contrasts with the smaller, tokenized text
vocabularies typically used in LLMs. The predominant view within the LLM-based
recommendation literature is that it is infeasible to treat item ids as a first
class citizen in the LLM and instead some sort of tokenization of an item into
multiple tokens is required. However, this creates a key practical bottleneck
in serving these models for real-time low-latency applications.
  Our paper challenges this predominant practice and integrates item ids as
first class citizens into the LLM. We provide simple, yet highly effective,
novel training and inference modifications that enable single-token
representations of items and single-step decoding. Our method shows
improvements in recommendation quality (Recall and NDCG) over existing
techniques on the Amazon shopping datasets while significantly improving
inference efficiency by 5x-14x. Our work offers an efficiency perspective
distinct from that of other popular approaches within LLM-based recommendation,
potentially inspiring further research and opening up a new direction for
integrating IDs into LLMs. Our code is available here
https://drive.google.com/file/d/1cUMj37rV0Z1bCWMdhQ6i4q4eTRQLURtC

</details>


### [5] [LLM-based Relevance Assessment for Web-Scale Search Evaluation at Pinterest](https://arxiv.org/abs/2509.03764)
*Han Wang,Alex Whitworth,Pak Ming Cheung,Zhenjie Zhang,Krishna Kamath*

Main category: cs.IR

TL;DR: 该研究利用微调的LLM自动进行搜索相关性评估，可与人类评估结果媲美，提高了效率并降低了实验评估中的MDE。


<details>
  <summary>Details</summary>
Motivation: 传统的人类注释相关性评估成本高，耗时长，难以扩展。

Method: 使用经过微调的LLM自动进行相关性评估，并与传统的人类注释进行严谨的验证比较。

Result: 实现了更高质量的相关性度量，并显著降低了在线实验测量中的最低可检测效应(MDE)。

Conclusion: 使用经过微调的LLM可以自动进行相关性评估，与人类注释结果具有良好的一致性，并显著提高评估效率。

Abstract: Relevance evaluation plays a crucial role in personalized search systems to
ensure that search results align with a user's queries and intent. While human
annotation is the traditional method for relevance evaluation, its high cost
and long turnaround time limit its scalability. In this work, we present our
approach at Pinterest Search to automate relevance evaluation for online
experiments using fine-tuned LLMs. We rigorously validate the alignment between
LLM-generated judgments and human annotations, demonstrating that LLMs can
provide reliable relevance measurement for experiments while greatly improving
the evaluation efficiency. Leveraging LLM-based labeling further unlocks the
opportunities to expand the query set, optimize sampling design, and
efficiently assess a wider range of search experiences at scale. This approach
leads to higher-quality relevance metrics and significantly reduces the Minimum
Detectable Effect (MDE) in online experiment measurements.

</details>


### [6] [Evaluating the Robustness of Retrieval-Augmented Generation to Adversarial Evidence in the Health Domain](https://arxiv.org/abs/2509.03787)
*Shakiba Amirshahi,Amin Bigdeli,Charles L. A. Clarke,Amira Ghenai*

Main category: cs.IR

TL;DR: 研究RAG系统在健康领域的健壮性，检测模型输出对真实答案的对齐度，发现有益证据可缓解对抗性文档的负面影响。


<details>
  <summary>Details</summary>
Motivation: 探讨RAG系统在健康领域的健壮性，研究模型输出与真实答案的对齐性。考虑到错误回答可能造成的伤害以及许多健康相关问题有真实依据。

Method: 进行控制实验，使用常见健康问题，变更检索文档的类型和构成（有益、有害和对抗性），以及用户提问的框架（一致、中立和不一致）

Result: 对抗性文档显著降低对齐性，但在检索池中也存在有益证据时可以保留稳健性。这些发现提供了设计更安全RAG系统的可行建议。

Conclusion: 提出需要检索保障，以设计在高风险领域中更安全的RAG系统。所有实验结果均公开以促进未来研究。

Abstract: Retrieval augmented generation (RAG) systems provide a method for factually
grounding the responses of a Large Language Model (LLM) by providing retrieved
evidence, or context, as support. Guided by this context, RAG systems can
reduce hallucinations and expand the ability of LLMs to accurately answer
questions outside the scope of their training data. Unfortunately, this design
introduces a critical vulnerability: LLMs may absorb and reproduce
misinformation present in retrieved evidence. This problem is magnified if
retrieved evidence contains adversarial material explicitly intended to
promulgate misinformation. This paper presents a systematic evaluation of RAG
robustness in the health domain and examines alignment between model outputs
and ground-truth answers. We focus on the health domain due to the potential
for harm caused by incorrect responses, as well as the availability of
evidence-based ground truth for many common health-related questions. We
conduct controlled experiments using common health questions, varying both the
type and composition of the retrieved documents (helpful, harmful, and
adversarial) as well as the framing of the question by the user (consistent,
neutral, and inconsistent). Our findings reveal that adversarial documents
substantially degrade alignment, but robustness can be preserved when helpful
evidence is also present in the retrieval pool. These findings offer actionable
insights for designing safer RAG systems in high-stakes domains by highlighting
the need for retrieval safeguards. To enable reproducibility and facilitate
future research, all experimental results are publicly available in our github
repository.
  https://github.com/shakibaam/RAG_ROBUSTNESS_EVAL

</details>


### [7] [NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings](https://arxiv.org/abs/2509.04011)
*Or Shachar,Uri Katz,Yoav Goldberg,Oren Glickman*

Main category: cs.IR

TL;DR: NER Retriever是一个零样本命名实体检索框架，在无需预先定义类型的情况下，通过大语言模型实现实体重检索，性能显著优于现有基准。代码已公开。


<details>
  <summary>Details</summary>
Motivation: 命名实体识别（NER）的某些场景中，感兴趣的实体类型在事前不能预知，因此需要一种零样本检索框架来处理此类问题。

Method: 利用大语言模型（LLMs）的内部表示，将实体提及和用户定义的开放式类型描述嵌入到共享的语义空间中，并训练轻量对比投影网络来细化这些表示。

Result: 在三个基准上进行评估，NER Retriever在性能上显著超过现有基准方法，验证了选择LLMs内部表示的有效性。

Conclusion: NER Retriever大幅优于词汇和稠密句子级重检索基准，为大规模、无模式实体重检索提供了实用的解决方案。

Abstract: We present NER Retriever, a zero-shot retrieval framework for ad-hoc Named
Entity Retrieval, a variant of Named Entity Recognition (NER), where the types
of interest are not provided in advance, and a user-defined type description is
used to retrieve documents mentioning entities of that type. Instead of relying
on fixed schemas or fine-tuned models, our method builds on internal
representations of large language models (LLMs) to embed both entity mentions
and user-provided open-ended type descriptions into a shared semantic space. We
show that internal representations, specifically the value vectors from
mid-layer transformer blocks, encode fine-grained type information more
effectively than commonly used top-layer embeddings. To refine these
representations, we train a lightweight contrastive projection network that
aligns type-compatible entities while separating unrelated types. The resulting
entity embeddings are compact, type-aware, and well-suited for nearest-neighbor
search. Evaluated on three benchmarks, NER Retriever significantly outperforms
both lexical and dense sentence-level retrieval baselines. Our findings provide
empirical support for representation selection within LLMs and demonstrate a
practical solution for scalable, schema-free entity retrieval. The NER
Retriever Codebase is publicly available at
https://github.com/ShacharOr100/ner_retriever

</details>


### [8] [Safeguarding Patient Trust in the Age of AI: Tackling Health Misinformation with Explainable AI](https://arxiv.org/abs/2509.04052)
*Sueun Hong,Shuojie Fu,Ovidiu Serban,Brianna Bao,James Kinross,Francesa Toni,Guy Martin,Uddhav Vaghela*

Main category: cs.IR

TL;DR: 提出了一种可解释的AI框架，以应对医疗错误信息，并提升循证医疗服务。


<details>
  <summary>Details</summary>
Motivation: AI生成的健康误导信息对患者安全和全球医疗系统的信任构成前所未有的威胁。

Method: 通过EPSRC INDICATE项目开发的可解释AI框架，进行了17项研究的系统综述以评估透明AI系统的必要性，并实现了实时自动化的证据综合。

Result: 所提出的解决方案在临床证据检索方面显示出95%的召回率，并且在检测生物医学误导信息方面集成了新的可信度分类器，达到了76%的F1分数。

Conclusion: 这种方法提供了一个关键的干预措施，以在AI时代维护医疗保健的完整性。

Abstract: AI-generated health misinformation poses unprecedented threats to patient
safety and healthcare system trust globally. This white paper presents an
explainable AI framework developed through the EPSRC INDICATE project to combat
medical misinformation while enhancing evidence-based healthcare delivery. Our
systematic review of 17 studies reveals the urgent need for transparent AI
systems in healthcare. The proposed solution demonstrates 95% recall in
clinical evidence retrieval and integrates novel trustworthiness classifiers
achieving 76% F1 score in detecting biomedical misinformation. Results show
that explainable AI can transform traditional 6-month expert review processes
into real-time, automated evidence synthesis while maintaining clinical rigor.
This approach offers a critical intervention to preserve healthcare integrity
in the AI era.

</details>


### [9] [Enhancing Technical Documents Retrieval for RAG](https://arxiv.org/abs/2509.04139)
*Songjiang Lai,Tsun-Hin Cheung,Ka-Chun Fung,Kaiwen Xue,Kwan-Ho Lin,Yan-Ming Choi,Vincent Ng,Kin-Man Lam*

Main category: cs.IR

TL;DR: Technical-Embeddings通过扩展查询和上下文总结提升技术文档检索效果，特别在工程和产品开发中应用广泛。


<details>
  <summary>Details</summary>
Motivation: 解决技术文档中复杂内容的语义检索挑战，借助LLMs提升理解并优化信息检索流程。

Method: 使用大型语言模型(LLMs)和增强双编码BERT模型，结合软提示技术实现查询和文档上下文的细粒度语义提取。

Result: Technical-Embeddings在RAG-EDA和Rust-Docs-QA两组数据集上的实验显示出显著优于基线模型的精确度和召回率。

Conclusion: 通过有效融合查询扩展和文档上下文总结，Technical-Embeddings能够在技术领域中显著提高信息访问和理解精准度。

Abstract: In this paper, we introduce Technical-Embeddings, a novel framework designed
to optimize semantic retrieval in technical documentation, with applications in
both hardware and software development. Our approach addresses the challenges
of understanding and retrieving complex technical content by leveraging the
capabilities of Large Language Models (LLMs). First, we enhance user queries by
generating expanded representations that better capture user intent and improve
dataset diversity, thereby enriching the fine-tuning process for embedding
models. Second, we apply summary extraction techniques to encode essential
contextual information, refining the representation of technical documents. To
further enhance retrieval performance, we fine-tune a bi-encoder BERT model
using soft prompting, incorporating separate learning parameters for queries
and document context to capture fine-grained semantic nuances. We evaluate our
approach on two public datasets, RAG-EDA and Rust-Docs-QA, demonstrating that
Technical-Embeddings significantly outperforms baseline models in both
precision and recall. Our findings highlight the effectiveness of integrating
query expansion and contextual summarization to enhance information access and
comprehension in technical domains. This work advances the state of
Retrieval-Augmented Generation (RAG) systems, offering new avenues for
efficient and accurate technical document retrieval in engineering and product
development workflows.

</details>


### [10] [Temporal Interest-Driven Multimodal Personalized Content Generation](https://arxiv.org/abs/2509.04330)
*Tian Miao*

Main category: cs.IR

TL;DR: TIMGen模型解决了动态兴趣演变和多模态需求的挑战，通过统一的兴趣表示生成个性化内容，可应用于多种实际场景。


<details>
  <summary>Details</summary>
Motivation: 随着用户兴趣的动态演变和互联网应用中多模态需求的增加，基于静态兴趣偏好的个性化内容生成策略难以满足实际应用要求。

Method: TIMGen模型通过建模用户兴趣的长期时间演变和捕获具有强时间依赖性的动态兴趣表示来解决这一挑战，该模型支持多模态特征的融合，并基于多模态偏好提供定制内容。

Result: TIMGen克服了基于静态偏好的个性化内容推荐方法的缺点，能够灵活和动态地建模用户的多模态兴趣，提供了更好的理解和捕获用户兴趣和偏好的能力。

Conclusion: TIMGen模型能够扩展到包括电子商务、广告、在线教育和精准医疗等多种实际应用场景，为未来研究提供了见解。

Abstract: With the dynamic evolution of user interests and the increasing multimodal
demands in internet applications, personalized content generation strategies
based on static interest preferences struggle to meet practical application
requirements. The proposed TIMGen (Temporal Interest-driven Multimodal
Generation) model addresses this challenge by modeling the long-term temporal
evolution of users' interests and capturing dynamic interest representations
with strong temporal dependencies. This model also supports the fusion of
multimodal features, such as text, images, video, and audio, and delivers
customized content based on multimodal preferences. TIMGen jointly learns
temporal dependencies and modal preferences to obtain a unified interest
representation, which it then generates to meet users' personalized content
needs. TIMGen overcomes the shortcomings of personalized content recommendation
methods based on static preferences, enabling flexible and dynamic modeling of
users' multimodal interests, better understanding and capturing their interests
and preferences. It can be extended to a variety of practical application
scenarios, including e-commerce, advertising, online education, and precision
medicine, providing insights for future research.

</details>


### [11] [Decoupled Entity Representation Learning for Pinterest Ads Ranking](https://arxiv.org/abs/2509.04337)
*Jie Liu,Yinrui Li,Jiankai Sun,Kungang Li,Han Sun,Sihan Wang,Huasen Wu,Siyuan Gao,Paulo Soares,Nan Li,Zhifang Liu,Haoyang Li,Siping Ji,Ling Leng,Prathibha Deshikachar*

Main category: cs.IR

TL;DR: 提出了一种新的上下游范式框架构建用户和Pins嵌入，提升Pinterest广告排名系统性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高Pinterest个性化Pins和广告的效果，构建用户和项目（Pin）嵌入以处理不同数据来源。

Method: 采用上下游范式构建用户和Pin嵌入模型，上游模型基于从不同数据来源获得的广泛信号进行训练，通过复杂架构捕捉用户和Pin之间的关系，并通过实体嵌入的异步刷新机制确保模型的可扩展性；下游任务集成这些嵌入用于多种任务。

Result: 该框架在多种下游任务中实现了显著的性能提升，已在Pinterest的广告排名系统中部署，在线指标取得了显著增益。

Conclusion: 提出了一个新的框架，使用户和项目嵌入能够有效处理不同数据源的数据，从而提升广告和个性化推荐的效果。

Abstract: In this paper, we introduce a novel framework following an
upstream-downstream paradigm to construct user and item (Pin) embeddings from
diverse data sources, which are essential for Pinterest to deliver personalized
Pins and ads effectively. Our upstream models are trained on extensive data
sources featuring varied signals, utilizing complex architectures to capture
intricate relationships between users and Pins on Pinterest. To ensure
scalability of the upstream models, entity embeddings are learned, and
regularly refreshed, rather than real-time computation, allowing for
asynchronous interaction between the upstream and downstream models. These
embeddings are then integrated as input features in numerous downstream tasks,
including ad retrieval and ranking models for CTR and CVR predictions. We
demonstrate that our framework achieves notable performance improvements in
both offline and online settings across various downstream tasks. This
framework has been deployed in Pinterest's production ad ranking systems,
resulting in significant gains in online metrics.

</details>


### [12] [Global-to-Local or Local-to-Global? Enhancing Image Retrieval with Efficient Local Search and Effective Global Re-ranking](https://arxiv.org/abs/2509.04351)
*Dror Aiger,Bingyi Cao,Kaifeng Chen,Andre Araujo*

Main category: cs.IR

TL;DR: 提出一种局部到全局检索范式，结合了有效的局部特征搜索和高效的全局特征重排，实现了在大规模图像检索中的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现行的图像检索系统主要利用全局特征进行搜索，并用局部特征匹配技术对初始结果进行重排。然而，局部匹配由于计算成本高，只能应用于少量检索图像。有效的局部特征搜索方法的发展提供了新的可能性，特别是在大尺度上进行详细检索，发现全局特征搜索常常错过的部分匹配。而全局特征基础的重排则显示出高效的计算结果。本研究利用这些基础组件引入了一种新范式——局部到全局检索。

Method: 重新排名时利用多维尺度技术创建尊重局部特征检索相似性的全局特征嵌入，通过高效局部特征搜索和基于局部相似性计算的全局特征重排结合，实现了性能的显著提升。

Result: 实验结果显示，提出的方法在Revisited Oxford和Paris数据集上实现了新的最佳效果。

Conclusion: 通过结合多维尺度技术，提出的方法能在搜索中尊重局部相似性，显著提升重排效果，标志着图像检索系统性能的新高。

Abstract: The dominant paradigm in image retrieval systems today is to search large
databases using global image features, and re-rank those initial results with
local image feature matching techniques. This design, dubbed global-to-local,
stems from the computational cost of local matching approaches, which can only
be afforded for a small number of retrieved images. However, emerging efficient
local feature search approaches have opened up new possibilities, in particular
enabling detailed retrieval at large scale, to find partial matches which are
often missed by global feature search. In parallel, global feature-based
re-ranking has shown promising results with high computational efficiency. In
this work, we leverage these building blocks to introduce a local-to-global
retrieval paradigm, where efficient local feature search meets effective global
feature re-ranking. Critically, we propose a re-ranking method where global
features are computed on-the-fly, based on the local feature retrieval
similarities. Such re-ranking-only global features leverage multidimensional
scaling techniques to create embeddings which respect the local similarities
obtained during search, enabling a significant re-ranking boost.
Experimentally, we demonstrate solid retrieval performance, setting new
state-of-the-art results on the Revisited Oxford and Paris datasets.

</details>
