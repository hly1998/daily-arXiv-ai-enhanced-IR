{"id": "2508.16793", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.16793", "abs": "https://arxiv.org/abs/2508.16793", "authors": ["Hongtao Lin", "Haoyu Chen", "Jaewon Jang", "Jiajing Xu"], "title": "Bootstrapping Conditional Retrieval for User-to-Item Recommendations", "comment": null, "summary": "User-to-item retrieval has been an active research area in recommendation\nsystem, and two tower models are widely adopted due to model simplicity and\nserving efficiency. In this work, we focus on a variant called\n\\textit{conditional retrieval}, where we expect retrieved items to be relevant\nto a condition (e.g. topic). We propose a method that uses the same training\ndata as standard two tower models but incorporates item-side information as\nconditions in query. This allows us to bootstrap new conditional retrieval use\ncases and encourages feature interactions between user and condition.\nExperiments show that our method can retrieve highly relevant items and\noutperforms standard two tower models with filters on engagement metrics. The\nproposed model is deployed to power a topic-based notification feed at\nPinterest and led to +0.26\\% weekly active users.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6761\u4ef6\u4fe1\u606f\u7684\u68c0\u7d22\u6a21\u578b\uff0c\u589e\u5f3a\u4e86\u7528\u6237\u4e0e\u6761\u4ef6\u7684\u7279\u5f81\u4e92\u52a8\uff0c\u63d0\u5347\u4e86\u68c0\u7d22\u6548\u679c\uff0c\u5e76\u5728Pinterest\u4e0a\u5b9e\u73b0\u4e86\u6d3b\u8dc3\u7528\u6237\u7684\u589e\u957f\u3002", "motivation": "\u63d0\u9ad8\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u68c0\u7d22\u5230\u7684\u9879\u76ee\u7684\u76f8\u5173\u6027\u3002", "method": "\u4e0e\u6807\u51c6\u53cc\u5854\u6a21\u578b\u4f7f\u7528\u76f8\u540c\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u4f46\u5728\u67e5\u8be2\u4e2d\u52a0\u5165\u6761\u4ef6\u4fe1\u606f\uff08\u5982\u8bdd\u9898\uff09\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u68c0\u7d22\u5230\u9ad8\u5ea6\u76f8\u5173\u7684\u9879\u76ee\uff0c\u5e76\u5728Pinterest\u4e0a\u7ebf\uff0c\u8d21\u732e\u4e86+0.26%\u7684\u6d3b\u8dc3\u7528\u6237\u589e\u957f\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6761\u4ef6\u4fe1\u606f\u7684\u68c0\u7d22\u65b9\u6cd5\uff0c\u76f8\u8f83\u4e8e\u6807\u51c6\u53cc\u5854\u6a21\u578b\uff0c\u5728\u7528\u6237\u53c2\u4e0e\u5ea6\u6307\u6807\u4e0a\u8868\u73b0\u66f4\u4f73\u3002"}}
{"id": "2508.17076", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.17076", "abs": "https://arxiv.org/abs/2508.17076", "authors": ["Pierre Lubitzsch", "Olga Ovcharenko", "Hao Chen", "Maarten de Rijke", "Sebastian Schelter"], "title": "Towards a Real-World Aligned Benchmark for Unlearning in Recommender Systems", "comment": null, "summary": "Modern recommender systems heavily leverage user interaction data to deliver\npersonalized experiences. However, relying on personal data presents challenges\nin adhering to privacy regulations, such as the GDPR's \"right to be forgotten\".\nMachine unlearning (MU) aims to address these challenges by enabling the\nefficient removal of specific training data from models post-training, without\ncompromising model utility or leaving residual information. However, current\nbenchmarks for unlearning in recommender systems -- most notably CURE4Rec --\nfail to reflect real-world operational demands. They focus narrowly on\ncollaborative filtering, overlook tasks like session-based and next-basket\nrecommendation, simulate unrealistically large unlearning requests, and ignore\ncritical efficiency constraints. In this paper, we propose a set of design\ndesiderata and research questions to guide the development of a more realistic\nbenchmark for unlearning in recommender systems, with the goal of gathering\nfeedback from the research community. Our benchmark proposal spans multiple\nrecommendation tasks, includes domain-specific unlearning scenarios, and\nseveral unlearning algorithms -- including ones adapted from a recent NeurIPS\nunlearning competition. Furthermore, we argue for an unlearning setup that\nreflects the sequential, time-sensitive nature of real-world deletion requests.\nWe also present a preliminary experiment in a next-basket recommendation\nsetting based on our proposed desiderata and find that unlearning also works\nfor sequential recommendation models, exposed to many small unlearning\nrequests. In this case, we observe that a modification of a custom-designed\nunlearning algorithm for recommender systems outperforms general unlearning\nalgorithms significantly, and that unlearning can be executed with a latency of\nonly several seconds.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u65b0\u7684\u63a8\u8350\u7cfb\u7edf\u5378\u8f7d\u57fa\u51c6\uff0c\u5f3a\u8c03\u591a\u4efb\u52a1\u548c\u65f6\u5e8f\u6027\u9a8c\u8bc1\uff0c\u5b9a\u5236\u7b97\u6cd5\u6027\u80fd\u5353\u8d8a\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u8350\u7cfb\u7edf\u5378\u8f7d\u57fa\u51c6\u4e0d\u591f\u73b0\u5b9e\uff0c\u65e0\u6cd5\u6ee1\u8db3\u771f\u5b9e\u64cd\u4f5c\u9700\u6c42\uff0c\u4f8b\u5982CURE4Rec\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u5e76\u8bbe\u8ba1\u4e86\u591a\u4efb\u52a1\u7684\u5378\u8f7d\u57fa\u51c6\uff0c\u91c7\u7528\u5b9a\u5236\u7684\u5378\u8f7d\u7b97\u6cd5\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9a\u5236\u5378\u8f7d\u7b97\u6cd5\u5728\u987a\u5e8f\u63a8\u8350\u6a21\u578b\u4e2d\u7684\u6027\u80fd\u4f18\u4e8e\u901a\u7528\u7b97\u6cd5\uff0c\u5e76\u80fd\u5728\u51e0\u79d2\u5185\u5b8c\u6210\u64cd\u4f5c\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5177\u6709\u73b0\u5b9e\u4e16\u754c\u64cd\u4f5c\u9700\u6c42\u7684\u63a8\u8350\u7cfb\u7edf\u5378\u8f7d\u7684\u57fa\u51c6\uff0c\u5e76\u901a\u8fc7\u521d\u6b65\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5b9a\u5236\u7b97\u6cd5\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2508.17079", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.17079", "abs": "https://arxiv.org/abs/2508.17079", "authors": ["Yejin Choi", "Jaewoo Park", "Janghan Yoon", "Saejin Kim", "Jaehyun Jeon", "Youngjae Yu"], "title": "Zero-shot Multimodal Document Retrieval via Cross-modal Question Generation", "comment": null, "summary": "Rapid advances in Multimodal Large Language Models (MLLMs) have expanded\ninformation retrieval beyond purely textual inputs, enabling retrieval from\ncomplex real world documents that combine text and visuals. However, most\ndocuments are private either owned by individuals or confined within corporate\nsilos and current retrievers struggle when faced with unseen domains or\nlanguages. To address this gap, we introduce PREMIR, a simple yet effective\nframework that leverages the broad knowledge of an MLLM to generate cross modal\npre questions (preQs) before retrieval. Unlike earlier multimodal retrievers\nthat compare embeddings in a single vector space, PREMIR leverages preQs from\nmultiple complementary modalities to expand the scope of matching to the token\nlevel. Experiments show that PREMIR achieves state of the art performance on\nout of distribution benchmarks, including closed domain and multilingual\nsettings, outperforming strong baselines across all retrieval metrics. We\nconfirm the contribution of each component through in depth ablation studies,\nand qualitative analyses of the generated preQs further highlight the model's\nrobustness in real world settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aPREMIR\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u8de8\u6a21\u6001\u9884\u95ee\u9898\u63d0\u5347\u591a\u6a21\u6001\u68c0\u7d22\u6027\u80fd\uff0c\u5bf9\u672a\u89c1\u9886\u57df\u548c\u8bed\u8a00\u5177\u6709\u5f3a\u9002\u5e94\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u68c0\u7d22\u65b9\u6cd5\u5728\u9762\u5bf9\u672a\u89c1\u9886\u57df\u6216\u8bed\u8a00\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u5927\u591a\u6570\u6587\u6863\u4e3a\u79c1\u4eba\u6240\u6709\u6216\u88ab\u4f01\u4e1a\u5185\u90e8\u9650\u5236\uff0c\u8fd9\u5bfc\u81f4\u4e86\u68c0\u7d22\u96be\u5ea6\u589e\u52a0\u3002", "method": "PREMIR\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u77e5\u8bc6\u5728\u68c0\u7d22\u524d\u751f\u6210\u8de8\u6a21\u6001\u9884\u95ee\u9898\uff08preQs\uff09\uff0c\u901a\u8fc7\u591a\u79cd\u8865\u5145\u6027\u6a21\u6001\u6269\u5c55\u5339\u914d\u8303\u56f4\u5230token\u7ea7\u522b\u3002", "result": "PREMIR\u5728\u5206\u5e03\u5916\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5305\u62ec\u5728\u5c01\u95ed\u57df\u548c\u591a\u8bed\u8a00\u73af\u5883\u4e0b\uff0c\u8d85\u8d8a\u4e86\u6240\u6709\u68c0\u7d22\u6307\u6807\u4e0a\u7684\u5f3a\u57fa\u7ebf\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86PREMIR\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u901a\u8fc7\u5728\u68c0\u7d22\u524d\u751f\u6210\u8de8\u6a21\u6001\u95ee\u9898\u6765\u63d0\u5347\u68c0\u7d22\u7cbe\u5ea6\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.17125", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.17125", "abs": "https://arxiv.org/abs/2508.17125", "authors": ["Kaiyuan Li", "Yongxiang Tang", "Yanhua Cheng", "Yong Bai", "Yanxiang Zeng", "Chao Wang", "Xialong Liu", "Peng Jiang"], "title": "VQL: An End-to-End Context-Aware Vector Quantization Attention for Ultra-Long User Behavior Modeling", "comment": null, "summary": "In large-scale recommender systems, ultra-long user behavior sequences encode\nrich signals of evolving interests. Extending sequence length generally\nimproves accuracy, but directly modeling such sequences in production is\ninfeasible due to latency and memory constraints. Existing solutions fall into\ntwo categories: (1) top-k retrieval, which truncates the sequence and may\ndiscard most attention mass when L >> k; and (2) encoder-based compression,\nwhich preserves coverage but often over-compresses and fails to incorporate key\ncontext such as temporal gaps or target-aware signals. Neither class achieves a\ngood balance of low-loss compression, context awareness, and efficiency.\n  We propose VQL, a context-aware Vector Quantization Attention framework for\nultra-long behavior modeling, with three innovations. (1) Key-only\nquantization: only attention keys are quantized, while values remain intact; we\nprove that softmax normalization yields an error bound independent of sequence\nlength, and a codebook loss directly supervises quantization quality. This also\nenables L-free inference via offline caches. (2) Multi-scale quantization:\nattention heads are partitioned into groups, each with its own small codebook,\nwhich reduces quantization error while keeping cache size fixed. (3) Efficient\ncontext injection: static features (e.g., item category, modality) are directly\nintegrated, and relative position is modeled via a separable temporal kernel.\nAll context is injected without enlarging the codebook, so cached\nrepresentations remain query-independent.\n  Experiments on three large-scale datasets (KuaiRand-1K, KuaiRec, TMALL) show\nthat VQL consistently outperforms strong baselines, achieving higher accuracy\nwhile reducing inference latency, establishing a new state of the art in\nbalancing accuracy and efficiency for ultra-long sequence recommendation.", "AI": {"tldr": "VQL\u6846\u67b6\u901a\u8fc7\u5f3a\u8c03\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u4f4e\u635f\u8017\u538b\u7f29\uff0c\u5728\u8d85\u957f\u884c\u4e3a\u63a8\u8350\u4e2d\u53d6\u5f97\u663e\u8457\u6548\u679c\uff0c\u540c\u65f6\u51cf\u5c11\u63a8\u7406\u5ef6\u8fdf\uff0c\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u5927\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u7528\u6237\u7684\u8d85\u957f\u884c\u4e3a\u5e8f\u5217\u5305\u542b\u4e30\u5bcc\u7684\u5174\u8da3\u53d8\u5316\u4fe1\u53f7\u3002\u7136\u800c\uff0c\u7531\u4e8e\u5ef6\u8fdf\u548c\u5185\u5b58\u9650\u5236\uff0c\u76f4\u63a5\u5efa\u6a21\u8fd9\u4e9b\u5e8f\u5217\u5728\u751f\u4ea7\u4e2d\u662f\u4e0d\u53ef\u884c\u7684\u3002\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u5982top-k\u68c0\u7d22\u548c\u7f16\u7801\u5668\u538b\u7f29\u5747\u672a\u80fd\u5728\u4f4e\u635f\u5931\u538b\u7f29\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u6548\u7387\u4e4b\u95f4\u5b9e\u73b0\u826f\u597d\u7684\u5e73\u8861\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5411\u91cf\u91cf\u5316\u6ce8\u610f\u529b\u6846\u67b6\uff08VQL\uff09\u7528\u4e8e\u8d85\u957f\u884c\u4e3a\u5efa\u6a21\uff0c\u5305\u62ec\u4e09\u9879\u521b\u65b0\uff1a(1)\u4ec5\u5bf9\u6ce8\u610f\u529b\u952e\u8fdb\u884c\u91cf\u5316\uff0c\u800c\u4fdd\u6301\u503c\u4e0d\u53d8\uff0c\u8bc1\u660e\u4e86softmax\u5f52\u4e00\u5316\u5728\u8bef\u5dee\u7ea6\u675f\u5728\u4e0e\u5e8f\u5217\u957f\u5ea6\u65e0\u5173\u7684\u4e00\u70b9\u53ef\u76f4\u63a5\u76d1\u7763\u91cf\u5316\u8d28\u91cf\uff1b(2) \u591a\u7ea7\u91cf\u5316\uff1a\u6ce8\u610f\u529b\u5934\u88ab\u5206\u7ec4\uff0c\u6bcf\u7ec4\u4f7f\u7528\u81ea\u5df1\u7684\u5c0f\u578b\u4ee3\u7801\u7c3f\uff0c\u51cf\u5c11\u4e86\u91cf\u5316\u8bef\u5dee\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7f13\u5b58\u5927\u5c0f\u4e0d\u53d8\uff1b(3)\u9ad8\u6548\u7684\u4e0a\u4e0b\u6587\u6ce8\u5165\uff1a\u76f4\u63a5\u6574\u5408\u9759\u6001\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u53ef\u5206\u79bb\u7684\u65f6\u95f4\u6838\u6765\u5efa\u6a21\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u65e0\u9700\u6269\u5927\u4ee3\u7801\u7c3f\u3002", "result": "\u5728KuaiRand-1K\u3001KuaiRec\u548cTMALL\u8fd9\u4e09\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVQL\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u8fd8\u964d\u4f4e\u4e86\u63a8\u7406\u5ef6\u8fdf\uff0c\u786e\u7acb\u4e86\u8d85\u957f\u5e8f\u5217\u63a8\u8350\u4e2d\u5e73\u8861\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u65b0\u6807\u51c6\u3002", "conclusion": "VQL\u6846\u67b6\u901a\u8fc7\u4e00\u7cfb\u5217\u521b\u65b0\u5b9e\u73b0\u4e86\u5bf9\u8d85\u957f\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u7684\u6709\u6548\u5efa\u6a21\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3a\u5927\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.17297", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.17297", "abs": "https://arxiv.org/abs/2508.17297", "authors": ["Parviz Ahmadov", "Masoud Mansoury"], "title": "Opening the Black Box: Interpretable Remedies for Popularity Bias in Recommender Systems", "comment": null, "summary": "Popularity bias is a well-known challenge in recommender systems, where a\nsmall number of popular items receive disproportionate attention, while the\nmajority of less popular items are largely overlooked. This imbalance often\nresults in reduced recommendation quality and unfair exposure of items.\nAlthough existing mitigation techniques address this bias to some extent, they\ntypically lack transparency in how they operate. In this paper, we propose a\npost-hoc method using a Sparse Autoencoder (SAE) to interpret and mitigate\npopularity bias in deep recommendation models. The SAE is trained to replicate\na pre-trained model's behavior while enabling neuron-level interpretability. By\nintroducing synthetic users with clear preferences for either popular or\nunpopular items, we identify neurons encoding popularity signals based on their\nactivation patterns. We then adjust the activations of the most biased neurons\nto steer recommendations toward fairer exposure. Experiments on two public\ndatasets using a sequential recommendation model show that our method\nsignificantly improves fairness with minimal impact on accuracy. Moreover, it\noffers interpretability and fine-grained control over the fairness-accuracy\ntrade-off.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u6574\u795e\u7ecf\u5143\u6fc0\u6d3b\u6765\u7f13\u89e3\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6d41\u884c\u5ea6\u504f\u5dee\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u63d0\u9ad8\u516c\u5e73\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6d41\u884c\u5ea6\u504f\u5dee\u95ee\u9898\u4f7f\u5f97\u5c11\u6570\u70ed\u95e8\u9879\u76ee\u5360\u636e\u4e86\u8fc7\u5ea6\u7684\u5173\u6ce8\uff0c\u800c\u5927\u591a\u6570\u4e0d\u90a3\u4e48\u53d7\u6b22\u8fce\u7684\u9879\u76ee\u88ab\u5ffd\u89c6\uff0c\u5bfc\u81f4\u63a8\u8350\u8d28\u91cf\u4e0b\u964d\u548c\u9879\u76ee\u66dd\u5149\u4e0d\u516c\u5e73\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u89e3\u51b3\u4e86\u8fd9\u79cd\u504f\u5dee\uff0c\u4f46\u901a\u5e38\u7f3a\u4e4f\u900f\u660e\u5ea6\u3002", "method": "\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u590d\u5236\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u884c\u4e3a\u5e76\u63d0\u4f9b\u795e\u7ecf\u5143\u7ea7\u522b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u901a\u8fc7\u5f15\u5165\u5177\u6709\u660e\u786e\u504f\u597d\u7684\u5408\u6210\u7528\u6237\u8bc6\u522b\u6d41\u884c\u5ea6\u4fe1\u53f7\uff0c\u5e76\u8c03\u6574\u795e\u7ecf\u5143\u7684\u6fc0\u6d3b\u72b6\u6001\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4e24\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u987a\u5e8f\u63a8\u8350\u6a21\u578b\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u516c\u5e73\u6027\uff0c\u540c\u65f6\u5bf9\u51c6\u786e\u7387\u7684\u5f71\u54cd\u5f88\u5c0f\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u7684\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u7528\u6765\u89e3\u91ca\u548c\u51cf\u8f7b\u6df1\u5ea6\u63a8\u8350\u6a21\u578b\u4e2d\u7684\u6d41\u884c\u5ea6\u504f\u5dee\u95ee\u9898\u3002\u901a\u8fc7\u8c03\u6574\u6700\u504f\u5411\u7684\u795e\u7ecf\u5143\u7684\u6fc0\u6d3b\u72b6\u6001\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u8bc1\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u63a8\u8350\u7684\u516c\u5e73\u6027\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u4ee5\u53ca\u5bf9\u516c\u5e73\u6027\u548c\u51c6\u786e\u7387\u4e4b\u95f4\u6743\u8861\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\u3002"}}
{"id": "2508.17571", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.17571", "abs": "https://arxiv.org/abs/2508.17571", "authors": ["Yu Tokutake", "Kazushi Okamoto", "Kei Harada", "Atsushi Shibata", "Koki Karube"], "title": "A Universal Framework for Offline Serendipity Evaluation in Recommender Systems via Large Language Models", "comment": null, "summary": "Serendipity in recommender systems (RSs) has attracted increasing attention\nas a concept that enhances user satisfaction by presenting unexpected and\nuseful items. However, evaluating serendipitous performance remains challenging\nbecause its ground truth is generally unobservable. The existing offline\nmetrics often depend on ambiguous definitions or are tailored to specific\ndatasets and RSs, thereby limiting their generalizability. To address this\nissue, we propose a universally applicable evaluation framework that leverages\nlarge language models (LLMs) known for their extensive knowledge and reasoning\ncapabilities, as evaluators. First, to improve the evaluation performance of\nthe proposed framework, we assessed the serendipity prediction accuracy of LLMs\nusing four different prompt strategies on a dataset containing user-annotated\nserendipitous ground truth and found that the chain-of-thought prompt achieved\nthe highest accuracy. Next, we re-evaluated the serendipitous performance of\nboth serendipity-oriented and general RSs using the proposed framework on three\ncommonly used real-world datasets, without the ground truth. The results\nindicated that there was no serendipity-oriented RS that consistently\noutperformed across all datasets, and even a general RS sometimes achieved\nhigher performance than the serendipity-oriented RS.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u8bc4\u4f30\u6846\u67b6\u6765\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5076\u7136\u6027\u8868\u73b0\uff0c\u53d1\u73b0\u901a\u5e38\u7684\u63a8\u8350\u7cfb\u7edf\u6709\u65f6\u4f18\u4e8e\u5076\u7136\u6027\u5bfc\u5411\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u7684\u79bb\u7ebf\u6307\u6807\u4f9d\u8d56\u4e8e\u6a21\u7cca\u7684\u5b9a\u4e49\u6216\u7279\u5b9a\u6570\u636e\u96c6\u548c\u63a8\u8350\u7cfb\u7edf\uff0c\u9650\u5236\u4e86\u5176\u666e\u9002\u6027\uff0c\u9700\u8981\u4e00\u4e2a\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u7684\u65b0\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u8bc4\u4f30\u5076\u7136\u6027\u8868\u73b0\uff0c\u5e76\u901a\u8fc7\u56db\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\u8bc4\u4f30LLMs\u7684\u5076\u7136\u6027\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u53d1\u73b0\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u7b56\u7565\u8fbe\u5230\u6700\u9ad8\u51c6\u786e\u6027\u3002\u7136\u540e\u5728\u4e09\u4e2a\u5e38\u7528\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u91cd\u65b0\u8bc4\u4f30\u5076\u7136\u6027\u8868\u73b0\u3002", "result": "\u4f7f\u7528\u65b0\u8bc4\u4f30\u6846\u67b6\u53d1\u73b0\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u7b56\u7565\u5bf9\u5076\u7136\u6027\u9884\u6d4b\u7684\u51c6\u786e\u6027\u6700\u9ad8\u3002\u901a\u8fc7\u8bc4\u4f30\u6846\u67b6\u91cd\u8bc4\u5076\u7136\u6027\u8868\u73b0\uff0c\u7ed3\u679c\u8868\u660e\u4e00\u822c\u7684\u63a8\u8350\u7cfb\u7edf\u6709\u65f6\u6bd4\u5076\u7136\u6027\u5bfc\u5411\u7684\u63a8\u8350\u7cfb\u7edf\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u901a\u8fc7\u8bc4\u4f30\u6846\u67b6\u7684\u7ed3\u679c\uff0c\u7814\u7a76\u53d1\u73b0\u6ca1\u6709\u4e00\u79cd\u4e13\u6ce8\u4e8e\u5076\u7136\u6027\u7684\u63a8\u8350\u7cfb\u7edf\u80fd\u591f\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u59cb\u7ec8\u8868\u73b0\u51fa\u8272\uff0c\u751a\u81f3\u6709\u65f6\u4e00\u822c\u7684\u63a8\u8350\u7cfb\u7edf\u6bd4\u5076\u7136\u6027\u5bfc\u5411\u7684\u63a8\u8350\u7cfb\u7edf\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2508.17618", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.17618", "abs": "https://arxiv.org/abs/2508.17618", "authors": ["Li Li", "Mingyue Cheng", "Yuyang Ye", "Zhiding Liu", "Enhong Chen"], "title": "Preference Trajectory Modeling via Flow Matching for Sequential Recommendation", "comment": null, "summary": "Sequential recommendation predicts each user's next item based on their\nhistorical interaction sequence. Recently, diffusion models have attracted\nsignificant attention in this area due to their strong ability to model user\ninterest distributions. They typically generate target items by denoising\nGaussian noise conditioned on historical interactions. However, these models\nface two critical limitations. First, they exhibit high sensitivity to the\ncondition, making it difficult to recover target items from pure Gaussian\nnoise. Second, the inference process is computationally expensive, limiting\npractical deployment. To address these issues, we propose FlowRec, a simple yet\neffective sequential recommendation framework which leverages flow matching to\nexplicitly model user preference trajectories from current states to future\ninterests. Flow matching is an emerging generative paradigm, which offers\ngreater flexibility in initial distributions and enables more efficient\nsampling. Based on this, we construct a personalized behavior-based prior\ndistribution to replace Gaussian noise and learn a vector field to model user\npreference trajectories. To better align flow matching with the recommendation\nobjective, we further design a single-step alignment loss incorporating both\npositive and negative samples, improving sampling efficiency and generation\nquality. Extensive experiments on four benchmark datasets verify the\nsuperiority of FlowRec over the state-of-the-art baselines.", "AI": {"tldr": "\u63d0\u51faFlowRec\uff0c\u901a\u8fc7\u6d41\u5339\u914d\u6280\u672f\u6539\u8fdb\u63a8\u8350\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u5728\u987a\u5e8f\u63a8\u8350\u4e2d\u9762\u4e34\u5bf9\u6761\u4ef6\u9ad8\u5ea6\u654f\u611f\u548c\u63a8\u7406\u8fc7\u7a0b\u8ba1\u7b97\u6602\u8d35\u7684\u95ee\u9898\u3002", "method": "\u6211\u4eec\u63d0\u51faFlowRec\u6846\u67b6\uff0c\u501f\u52a9\u6d41\u5339\u914d\u6280\u672f\uff0c\u663e\u5f0f\u5efa\u6a21\u7528\u6237\u504f\u597d\u7684\u8f68\u8ff9\uff0c\u5e76\u8bbe\u8ba1\u5355\u6b65\u5bf9\u9f50\u635f\u5931\uff0c\u63d0\u9ad8\u91c7\u6837\u6548\u7387\u548c\u751f\u6210\u8d28\u91cf\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86FlowRec\u76f8\u8f83\u4e8e\u76ee\u524d\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "FlowRec\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u987a\u5e8f\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u7528\u6237\u504f\u597d\u9884\u6d4b\u548c\u91c7\u6837\u6548\u7387\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2508.17644", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.17644", "abs": "https://arxiv.org/abs/2508.17644", "authors": ["Marwah Alaofi", "Nicola Ferro", "Paul Thomas", "Falk Scholer", "Mark Sanderson"], "title": "Demographically-Inspired Query Variants Using an LLM", "comment": "Published in the proceedings of ICTIR'25, Padua, Italy", "summary": "This study proposes a method to diversify queries in existing test\ncollections to reflect some of the diversity of search engine users, aligning\nwith an earlier vision of an 'ideal' test collection. A Large Language Model\n(LLM) is used to create query variants: alternative queries that have the same\nmeaning as the original. These variants represent user profiles characterised\nby different properties, such as language and domain proficiency, which are\nknown in the IR literature to influence query formulation.\n  The LLM's ability to generate query variants that align with user profiles is\nempirically validated, and the variants' utility is further explored for IR\nsystem evaluation. Results demonstrate that the variants impact how systems are\nranked and show that user profiles experience significantly different levels of\nsystem effectiveness. This method enables an alternative perspective on system\nevaluation where we can observe both the impact of user profiles on system\nrankings and how system performance varies across users.", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u67e5\u8be2\u53d8\u4f53\u4ee5\u53cd\u6620\u7528\u6237\u591a\u6837\u6027\u5e76\u5f71\u54cd\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u8bc4\u4f30\u3002", "motivation": "\u65e8\u5728\u4f7f\u73b0\u6709\u6d4b\u8bd5\u96c6\u4e2d\u7684\u67e5\u8be2\u591a\u6837\u5316\uff0c\u4ee5\u53cd\u6620\u641c\u7d22\u5f15\u64ce\u7528\u6237\u7684\u591a\u6837\u6027\uff0c\u4e0e\u4e4b\u524d\u5bf9\u201c\u7406\u60f3\u201d\u6d4b\u8bd5\u96c6\u7684\u613f\u666f\u4fdd\u6301\u4e00\u81f4\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u751f\u6210\u67e5\u8be2\u53d8\u4f53\uff0c\u8fd9\u4e9b\u67e5\u8be2\u53d8\u4f53\u4ee3\u8868\u4e0d\u540c\u7279\u6027\u7684\u7528\u6237\u914d\u7f6e\u6587\u4ef6\u3002", "result": "\u8bc1\u660e\u4e86\u67e5\u8be2\u53d8\u4f53\u5bf9\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u8bc4\u4f30\u7684\u6709\u7528\u6027\uff0c\u5e76\u4e14\u89c2\u5bdf\u5230\u4e86\u7528\u6237\u914d\u7f6e\u6587\u4ef6\u5bf9\u7cfb\u7edf\u6392\u540d\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u7cfb\u7edf\u6027\u80fd\u5728\u4e0d\u540c\u7528\u6237\u95f4\u7684\u53d8\u5316\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u67e5\u8be2\u53d8\u4f53\u80fd\u591f\u5f71\u54cd\u7cfb\u7edf\u7684\u6392\u540d\uff0c\u5e76\u663e\u793a\u7528\u6237\u914d\u7f6e\u6587\u4ef6\u5728\u7cfb\u7edf\u6709\u6548\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002"}}
{"id": "2508.17694", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.17694", "abs": "https://arxiv.org/abs/2508.17694", "authors": ["Kayla Farivar"], "title": "Semantic Search for Information Retrieval", "comment": null, "summary": "Information retrieval systems have progressed notably from lexical techniques\nsuch as BM25 and TF-IDF to modern semantic retrievers. This survey provides a\nbrief overview of the BM25 baseline, then discusses the architecture of modern\nstate-of-the-art semantic retrievers. Advancing from BERT, we introduce dense\nbi-encoders (DPR), late-interaction models (ColBERT), and neural sparse\nretrieval (SPLADE). Finally, we examine MonoT5, a cross-encoder model. We\nconclude with common evaluation tactics, pressing challenges, and propositions\nfor future directions.", "AI": {"tldr": "\u672c\u6587\u8c03\u67e5\u4e86\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u4ece\u4f20\u7edf\u7684\u8bcd\u6c47\u6280\u672f\u5230\u73b0\u4ee3\u8bed\u4e49\u68c0\u7d22\u5668\u7684\u53d1\u5c55\uff0c\u5305\u62ecDense Bi-Encoder\u3001ColBERT\u3001SPLADE\u548cMonoT5\u7b49\u6a21\u578b\u3002", "motivation": "\u63a2\u7d22\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u7279\u522b\u662f\u4ece\u8bcd\u6c47\u6280\u672f\u5230\u8bed\u4e49\u68c0\u7d22\u5668\u7684\u6f14\u53d8\uff0c\u4ee5\u63d0\u9ad8\u68c0\u7d22\u6548\u7387\u548c\u6548\u679c\u3002", "method": "\u901a\u8fc7\u4ecb\u7ecdBM25\u3001BERT\u7b49\u57fa\u7ebf\u6a21\u578b\uff0c\u518d\u5230\u73b0\u4ee3\u8bed\u4e49\u68c0\u7d22\u5668\u5982Dense Bi-Encoder (DPR)\u3001ColBERT\u3001SPLADE\u548cMonoT5\u7684\u67b6\u6784\u8fdb\u884c\u6bd4\u8f83\u548c\u5206\u6790\u3002", "result": "\u672c\u6587\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u51e0\u79cd\u73b0\u4ee3\u8bed\u4e49\u68c0\u7d22\u5668\u7684\u67b6\u6784\u548c\u6027\u80fd\uff0c\u5e76\u5bf9\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u7684\u8bc4\u4f30\u7b56\u7565\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u8fdb\u884c\u4e86\u63a2\u8ba8\u3002", "conclusion": "\u672c\u6587\u603b\u7ed3\u4e86\u5f53\u524d\u8bed\u4e49\u68c0\u7d22\u5668\u7684\u53d1\u5c55\u548c\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u7684\u5efa\u8bae\u3002"}}
{"id": "2508.17715", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.17715", "abs": "https://arxiv.org/abs/2508.17715", "authors": ["Wei Huang", "Keping Bi", "Yinqiong Cai", "Wei Chen", "Jiafeng Guo", "Xueqi Cheng"], "title": "How Do LLM-Generated Texts Impact Term-Based Retrieval Models?", "comment": null, "summary": "As more content generated by large language models (LLMs) floods into the\nInternet, information retrieval (IR) systems now face the challenge of\ndistinguishing and handling a blend of human-authored and machine-generated\ntexts. Recent studies suggest that neural retrievers may exhibit a preferential\ninclination toward LLM-generated content, while classic term-based retrievers\nlike BM25 tend to favor human-written documents. This paper investigates the\ninfluence of LLM-generated content on term-based retrieval models, which are\nvalued for their efficiency and robust generalization across domains. Our\nlinguistic analysis reveals that LLM-generated texts exhibit smoother\nhigh-frequency and steeper low-frequency Zipf slopes, higher term specificity,\nand greater document-level diversity. These traits are aligned with LLMs being\ntrained to optimize reader experience through diverse and precise expressions.\nOur study further explores whether term-based retrieval models demonstrate\nsource bias, concluding that these models prioritize documents whose term\ndistributions closely correspond to those of the queries, rather than\ndisplaying an inherent source bias. This work provides a foundation for\nunderstanding and addressing potential biases in term-based IR systems managing\nmixed-source content.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u672f\u8bed\u68c0\u7d22\u6a21\u578b\u66f4\u503e\u5411\u4e8e\u6587\u672c\u4e0e\u67e5\u8be2\u672f\u8bed\u5206\u5e03\u76f8\u4e00\u81f4\u7684\u6587\u6863\uff0c\u800c\u975e\u5448\u73b0\u6765\u6e90\u504f\u5411\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u5185\u5bb9\u5145\u65a5\u4e92\u8054\u7f51\u4e0a\uff0c\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u9700\u5904\u7406\u4eba\u7c7b\u521b\u4f5c\u548c\u673a\u5668\u751f\u6210\u6587\u672c\u7684\u6df7\u5408\u5185\u5bb9\u3002\u7814\u7a76\u76ee\u7684\u5728\u4e8e\u63a2\u8ba8\u6b64\u7c7b\u6df7\u5408\u5185\u5bb9\u5bf9\u4f20\u7edf\u672f\u8bed\u68c0\u7d22\u6a21\u578b\uff08\u4f8b\u5982BM25\uff09\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u8bed\u8a00\u5206\u6790\u63a2\u8ba8LLM\u751f\u6210\u5185\u5bb9\u5bf9\u672f\u8bed\u68c0\u7d22\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u7814\u7a76\u672f\u8bed\u5206\u5e03\u7279\u5f81\u4e0e\u68c0\u7d22\u6a21\u578b\u7684\u8868\u73b0\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u53d1\u73b0LLM\u751f\u6210\u7684\u6587\u672c\u5177\u6709\u66f4\u5e73\u6ed1\u7684\u9ad8\u9891\u548c\u66f4\u9661\u5ced\u7684\u4f4e\u9891Zipf\u659c\u7387\u3001\u8f83\u9ad8\u7684\u672f\u8bed\u7279\u5f02\u6027\u53ca\u66f4\u5927\u7684\u6587\u6863\u5c42\u7ea7\u591a\u6837\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u672f\u8bed\u68c0\u7d22\u6a21\u578b\u4f18\u5148\u8003\u8651\u4e0e\u67e5\u8be2\u672f\u8bed\u5206\u5e03\u76f8\u5bf9\u5e94\u7684\u6587\u6863\uff0c\u800c\u975e\u663e\u793a\u56fa\u6709\u7684\u6765\u6e90\u504f\u5411\u3002"}}
{"id": "2508.17754", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.17754", "abs": "https://arxiv.org/abs/2508.17754", "authors": ["Qinyao Li", "Xiaoyang Zheng", "Qihang Zhao", "Ke Xu", "Zhongbo Sun", "Chao Wang", "Chenyi Lei", "Han Li", "Wenwu Ou"], "title": "DiffusionGS: Generative Search with Query Conditioned Diffusion in Kuaishou", "comment": null, "summary": "Personalized search ranking systems are critical for driving engagement and\nrevenue in modern e-commerce and short-video platforms. While existing methods\nexcel at estimating users' broad interests based on the filtered historical\nbehaviors, they typically under-exploit explicit alignment between a user's\nreal-time intent (represented by the user query) and their past actions. In\nthis paper, we propose DiffusionGS, a novel and scalable approach powered by\ngenerative models. Our key insight is that user queries can serve as explicit\nintent anchors to facilitate the extraction of users' immediate interests from\nlong-term, noisy historical behaviors. Specifically, we formulate interest\nextraction as a conditional denoising task, where the user's query guides a\nconditional diffusion process to produce a robust, user intent-aware\nrepresentation from their behavioral sequence. We propose the User-aware\nDenoising Layer (UDL) to incorporate user-specific profiles into the\noptimization of attention distribution on the user's past actions. By reframing\nqueries as intent priors and leveraging diffusion-based denoising, our method\nprovides a powerful mechanism for capturing dynamic user interest shifts.\nExtensive offline and online experiments demonstrate the superiority of\nDiffusionGS over state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86DiffusionGS\uff0c\u901a\u8fc7\u751f\u6210\u6a21\u578b\u548c\u6269\u6563\u673a\u5236\u63d0\u9ad8\u4e2a\u6027\u5316\u641c\u7d22\u7684\u6548\u7387\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u7528\u6237\u5b9e\u65f6\u610f\u56fe\u4e0e\u5386\u53f2\u884c\u4e3a\u7684\u7ed3\u5408\u3002\u79bb\u7ebf\u548c\u5728\u7ebf\u6d4b\u8bd5\u663e\u793a\u5176\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u7ed3\u5408\u7528\u6237\u5b9e\u65f6\u610f\u56fe\u4e0e\u5386\u53f2\u884c\u4e3a\uff0c\u8fd9\u9650\u5236\u4e86\u4e2a\u6027\u5316\u641c\u7d22\u7684\u7cbe\u5ea6\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u7528\u6237\u5174\u8da3\u6355\u6349\u6548\u7387\u3002", "method": "\u8be5\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u5f15\u5165\u751f\u6210\u6a21\u578b\u4e2d\u7684\u6269\u6563\u673a\u5236\u8fdb\u884c\u6761\u4ef6\u53bb\u566a\u5904\u7406\uff0c\u5229\u7528\u7528\u6237\u67e5\u8be2\u4f5c\u4e3a\u610f\u56fe\u5148\u9a8c\uff0c\u5f15\u5bfc\u6ce8\u610f\u529b\u5206\u5e03\u7684\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDiffusionGS\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u6d4b\u8bd5\u4e2d\u5747\u4f18\u4e8e\u5f53\u524d\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "DiffusionGS\u5728\u4e2a\u4eba\u5316\u641c\u7d22\u6392\u540d\u7cfb\u7edf\u4e2d\u6bd4\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u4f18\u52bf\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u7528\u6237\u5174\u8da3\u7684\u52a8\u6001\u53d8\u5316\u3002"}}
{"id": "2508.17782", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.17782", "abs": "https://arxiv.org/abs/2508.17782", "authors": ["Shu Zhang", "LiSha Zhang", "Kai Duan", "XinKai Sun"], "title": "Research on Evaluation Methods for Patent Novelty Search Systems and Empirical Analysis", "comment": null, "summary": "Patent novelty search systems are critical to IP protection and innovation\nassessment; their retrieval accuracy directly impacts patent quality. We\npropose a comprehensive evaluation methodology that builds high-quality,\nreproducible datasets from examiner citations and X-type citations extracted\nfrom technically consistent family patents, and evaluates systems using\ninvention descriptions as inputs. Using Top-k Detection Rate and Recall as core\nmetrics, we further conduct multi-dimensional analyses by language, technical\nfield (IPC), and filing jurisdiction. Experiments show the method effectively\nexposes performance differences across scenarios and offers actionable evidence\nfor system improvement. The framework is scalable and practical, providing a\nuseful reference for development and optimization of patent novelty search\nsystems", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7efc\u5408\u8bc4\u4ef7\u65b9\u6cd5\uff0c\u5229\u7528\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u548c\u591a\u7ef4\u5206\u6790\u8bc4\u4f30\u4e13\u5229\u68c0\u7d22\u7cfb\u7edf\u6027\u80fd\uff0c\u5e76\u4e3a\u6539\u8fdb\u63d0\u4f9b\u8bc1\u636e\u3002", "motivation": "\u4e13\u5229\u65b0\u9896\u6027\u68c0\u7d22\u7cfb\u7edf\u5bf9\u4e8e\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u548c\u521b\u65b0\u8bc4\u4f30\u81f3\u5173\u91cd\u8981\uff0c\u5176\u68c0\u7d22\u51c6\u786e\u6027\u76f4\u63a5\u5f71\u54cd\u4e13\u5229\u8d28\u91cf\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7efc\u5408\u8bc4\u4ef7\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u4ece\u5ba1\u67e5\u5458\u5f15\u6587\u548c\u6280\u672f\u4e00\u81f4\u7684\u5bb6\u65cf\u4e13\u5229\u4e2d\u63d0\u53d6\u7684X\u578b\u5f15\u6587\u6784\u5efa\u9ad8\u8d28\u91cf\u3001\u53ef\u91cd\u590d\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528\u53d1\u660e\u63cf\u8ff0\u4f5c\u4e3a\u8f93\u5165\u6765\u8bc4\u4f30\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u5730\u63ed\u793a\u4e86\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u4e3a\u7cfb\u7edf\u6539\u8fdb\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u8bc1\u636e\u3002", "conclusion": "\u8be5\u6846\u67b6\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\uff0c\u4e3a\u4e13\u5229\u65b0\u9896\u6027\u68c0\u7d22\u7cfb\u7edf\u7684\u5f00\u53d1\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u53c2\u8003\u3002"}}
{"id": "2508.17858", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.17858", "abs": "https://arxiv.org/abs/2508.17858", "authors": ["Shaoxiong Zhan", "Hai Lin", "Hongming Tan", "Xiaodong Cai", "Hai-Tao Zheng", "Xin Su", "Zifei Shan", "Ruitong Liu", "Hong-Gee Kim"], "title": "LexSemBridge: Fine-Grained Dense Representation Enhancement through Token-Aware Embedding Augmentation", "comment": null, "summary": "As queries in retrieval-augmented generation (RAG) pipelines powered by large\nlanguage models (LLMs) become increasingly complex and diverse, dense retrieval\nmodels have demonstrated strong performance in semantic matching. Nevertheless,\nthey often struggle with fine-grained retrieval tasks, where precise keyword\nalignment and span-level localization are required, even in cases with high\nlexical overlap that would intuitively suggest easier retrieval. To\nsystematically evaluate this limitation, we introduce two targeted tasks,\nkeyword retrieval and part-of-passage retrieval, designed to simulate practical\nfine-grained scenarios. Motivated by these observations, we propose\nLexSemBridge, a unified framework that enhances dense query representations\nthrough fine-grained, input-aware vector modulation. LexSemBridge constructs\nlatent enhancement vectors from input tokens using three paradigms: Statistical\n(SLR), Learned (LLR), and Contextual (CLR), and integrates them with dense\nembeddings via element-wise interaction. Theoretically, we show that this\nmodulation preserves the semantic direction while selectively amplifying\ndiscriminative dimensions. LexSemBridge operates as a plug-in without modifying\nthe backbone encoder and naturally extends to both text and vision modalities.\nExtensive experiments across semantic and fine-grained retrieval tasks validate\nthe effectiveness and generality of our approach. All code and models are\npublicly available at https://github.com/Jasaxion/LexSemBridge/", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86LexSemBridge\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u5bc6\u96c6\u67e5\u8be2\u8868\u8fbe\u6539\u5584\u7cbe\u7ec6\u5316\u68c0\u7d22\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u4e0d\u6539\u53d8\u539f\u6709\u7f16\u7801\u5668\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u79cd\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6d41\u6c34\u7ebf\u4e2d\u7684\u67e5\u8be2\u65e5\u76ca\u590d\u6742\uff0c\u73b0\u6709\u7684\u5bc6\u96c6\u68c0\u7d22\u6a21\u578b\u5728\u8bed\u4e49\u5339\u914d\u4e0a\u6709\u8f83\u597d\u7684\u8868\u73b0\uff0c\u4f46\u5728\u9700\u8981\u7cbe\u51c6\u5173\u952e\u8bcd\u5bf9\u9f50\u548c\u533a\u95f4\u5b9a\u4f4d\u7684\u7cbe\u7ec6\u5316\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u6b20\u4f73\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86LexSemBridge\u6846\u67b6\uff0c\u901a\u8fc7\u7cbe\u7ec6\u5316\u3001\u8f93\u5165\u611f\u77e5\u7684\u5411\u91cf\u8c03\u5236\u6765\u589e\u5f3a\u5bc6\u96c6\u67e5\u8be2\u8868\u8fbe\u3002\u8be5\u6846\u67b6\u6784\u5efa\u4e86\u57fa\u4e8e\u8f93\u5165\u6807\u8bb0\u8bcd\u7684\u6f5c\u5728\u589e\u5f3a\u5411\u91cf\uff0c\u5e76\u901a\u8fc7\u5143\u7d20\u7ea7\u4e92\u52a8\u6574\u5408\u5230\u5bc6\u96c6\u5d4c\u5165\u4e2d\u3002", "result": "LexSemBridge\u5728\u4e0d\u4fee\u6539\u57fa\u7840\u7f16\u7801\u5668\u7684\u60c5\u51b5\u4e0b\u5de5\u4f5c\uff0c\u81ea\u7136\u6269\u5c55\u5230\u6587\u672c\u548c\u89c6\u89c9\u6a21\u6001\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8bed\u4e49\u548c\u7cbe\u7ec6\u5316\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002", "conclusion": "LexSemBridge\u6210\u529f\u589e\u5f3a\u4e86\u5bc6\u96c6\u68c0\u7d22\u6a21\u578b\u5728\u7cbe\u7ec6\u5316\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u7684\u666e\u9002\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2508.17862", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.17862", "abs": "https://arxiv.org/abs/2508.17862", "authors": ["Leqian Li", "Dianxi Shi", "Jialu Zhou", "Xinyu Wei", "Mingyue Yang", "Songchang Jin", "Shaowu Yang"], "title": "Retrieval Feedback Memory Enhancement Large Model Retrieval Generation Method", "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities across\ndiverse tasks, yet they face inherent limitations such as constrained\nparametric knowledge and high retraining costs. Retrieval-Augmented Generation\n(RAG) augments the generation process by retrieving externally stored knowledge\nabsent from the models internal parameters. However, RAG methods face\nchallenges such as information loss and redundant retrievals during multi-round\nqueries, accompanying the difficulties in precisely characterizing knowledge\ngaps for complex tasks. To address these problems, we propose Retrieval\nFeedback and Memory Retrieval Augmented Generation(RFM-RAG), which transforms\nthe stateless retrieval of previous methods into stateful continuous knowledge\nmanagement by constructing a dynamic evidence pool. Specifically, our method\ngenerates refined queries describing the models knowledge gaps using relational\ntriples from questions and evidence from the dynamic evidence pool; Retrieves\ncritical external knowledge to iteratively update this evidence pool; Employs a\nR-Feedback Model to evaluate evidence completeness until convergence. Compared\nto traditional RAG methods, our approach enables persistent storage of\nretrieved passages and effectively distills key information from passages to\nconstruct clearly new queries. Experiments on three public QA benchmarks\ndemonstrate that RFM-RAG outperforms previous methods and improves overall\nsystem accuracy.", "AI": {"tldr": "RFM-RAG\u6539\u8fdb\u4e86RAG\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8bc1\u636e\u6c60\u8fdb\u884c\u8fde\u7eed\u77e5\u8bc6\u7ba1\u7406\uff0c\u63d0\u9ad8\u4e86\u591a\u8f6e\u67e5\u8be2\u4e2d\u7684\u51c6\u786e\u6027\u3002", "motivation": "LLMs\u5728\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u53c2\u6570\u77e5\u8bc6\u53d7\u9650\u548c\u91cd\u8bad\u7ec3\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0cRAG\u867d\u7136\u589e\u52a0\u4e86\u5916\u90e8\u77e5\u8bc6\u68c0\u7d22\uff0c\u4f46\u5728\u591a\u8f6e\u67e5\u8be2\u4e2d\u5bb9\u6613\u53d1\u751f\u4fe1\u606f\u4e22\u5931\u548c\u5197\u4f59\u68c0\u7d22\u3002", "method": "\u63d0\u51fa\u4e86RFM-RAG\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u52a8\u6001\u8bc1\u636e\u6c60\u5b9e\u73b0\u6709\u72b6\u6001\u7684\u8fde\u7eed\u77e5\u8bc6\u7ba1\u7406\uff0c\u751f\u6210\u63cf\u8ff0\u6a21\u578b\u77e5\u8bc6\u7f3a\u53e3\u7684\u7cbe\u7ec6\u67e5\u8be2\uff0c\u68c0\u7d22\u5173\u952e\u5916\u90e8\u77e5\u8bc6\u4ee5\u8fed\u4ee3\u66f4\u65b0\u8bc1\u636e\u6c60\uff0c\u5e76\u4f7f\u7528R-Feedback Model\u8bc4\u4f30\u8bc1\u636e\u5b8c\u6574\u6027\u3002", "result": "RFM-RAG\u5728\u4e09\u4e2a\u516c\u5171QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u6574\u4f53\u7cfb\u7edf\u51c6\u786e\u6027\u3002", "conclusion": "RFM-RAG\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3RAG\u65b9\u6cd5\u5728\u591a\u8f6e\u67e5\u8be2\u4e2d\u4fe1\u606f\u4e22\u5931\u548c\u5197\u4f59\u68c0\u7d22\u7684\u95ee\u9898\uff0c\u5e76\u4e14\u5728\u516c\u5171QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2508.18048", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18048", "abs": "https://arxiv.org/abs/2508.18048", "authors": ["Jiyoon Myung", "Jihyeon Park", "Joohyung Han"], "title": "HyST: LLM-Powered Hybrid Retrieval over Semi-Structured Tabular Data", "comment": "Accepted at the 2nd EARL Workshop on Evaluating and Applying\n  Recommender Systems with Large Language Models (RecSys 2025)", "summary": "User queries in real-world recommendation systems often combine structured\nconstraints (e.g., category, attributes) with unstructured preferences (e.g.,\nproduct descriptions or reviews). We introduce HyST (Hybrid retrieval over\nSemi-structured Tabular data), a hybrid retrieval framework that combines\nLLM-powered structured filtering with semantic embedding search to support\ncomplex information needs over semi-structured tabular data. HyST extracts\nattribute-level constraints from natural language using large language models\n(LLMs) and applies them as metadata filters, while processing the remaining\nunstructured query components via embedding-based retrieval. Experiments on a\nsemi-structured benchmark show that HyST consistently outperforms tradtional\nbaselines, highlighting the importance of structured filtering in improving\nretrieval precision, offering a scalable and accurate solution for real-world\nuser queries.", "AI": {"tldr": "HyST, a hybrid retrieval framework, combines structured filtering with embedding-based retrieval to enhance precision in handling real-world user queries over semi-structured data.", "motivation": "The motivation is to address the need for a system that combines structured and unstructured data in user queries within real-world recommendation systems, providing an accurate and scalable solution.", "method": "The method involves using HyST, which extracts attribute-level constraints through large language models (LLMs) for structured filtering and processes the remaining unstructured components using semantic embedding search.", "result": "The result shows that HyST outperforms traditional baselines in a semi-structured benchmark, emphasizing the value of structured filtering in enhancing retrieval precision.", "conclusion": "The paper concludes that HyST, a hybrid retrieval framework, effectively improves retrieval precision in real-world user queries by combining structured filtering with embedding-based retrieval."}}
{"id": "2508.18118", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.18118", "abs": "https://arxiv.org/abs/2508.18118", "authors": ["Junyi Chen", "Lu Chi", "Siliang Xu", "Shiwei Ran", "Bingyue Peng", "Zehuan Yuan"], "title": "HLLM-Creator: Hierarchical LLM-based Personalized Creative Generation", "comment": null, "summary": "AI-generated content technologies are widely used in content creation.\nHowever, current AIGC systems rely heavily on creators' inspiration, rarely\ngenerating truly user-personalized content. In real-world applications such as\nonline advertising, a single product may have multiple selling points, with\ndifferent users focusing on different features. This underscores the\nsignificant value of personalized, user-centric creative generation. Effective\npersonalized content generation faces two main challenges: (1) accurately\nmodeling user interests and integrating them into the content generation\nprocess while adhering to factual constraints, and (2) ensuring high efficiency\nand scalability to handle the massive user base in industrial scenarios.\nAdditionally, the scarcity of personalized creative data in practice\ncomplicates model training, making data construction another key hurdle. We\npropose HLLM-Creator, a hierarchical LLM framework for efficient user interest\nmodeling and personalized content generation. During inference, a combination\nof user clustering and a user-ad-matching-prediction based pruning strategy is\nemployed to significantly enhance generation efficiency and reduce\ncomputational overhead, making the approach suitable for large-scale\ndeployment. Moreover, we design a data construction pipeline based on\nchain-of-thought reasoning, which generates high-quality, user-specific\ncreative titles and ensures factual consistency despite limited personalized\ndata. This pipeline serves as a critical foundation for the effectiveness of\nour model. Extensive experiments on personalized title generation for Douyin\nSearch Ads show the effectiveness of HLLM-Creator. Online A/B test shows a\n0.476% increase on Adss, paving the way for more effective and efficient\npersonalized generation in industrial scenarios. Codes for academic dataset are\navailable at https://github.com/bytedance/HLLM.", "AI": {"tldr": "\u5f15\u5165HLLM-Creator\uff0c\u901a\u8fc7\u7528\u6237\u5174\u8da3\u5efa\u6a21\u548c\u4e2a\u6027\u5316\u5185\u5bb9\u751f\u6210\u5b9e\u73b0\u5728\u7ebf\u5e7f\u544a\u6807\u9898\u751f\u6210\u7684\u4f18\u5316\uff0c\u63d0\u9ad8\u4e86\u751f\u6210\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u5f53\u524dAIGC\u7cfb\u7edf\u96be\u4ee5\u751f\u6210\u771f\u6b63\u4e2a\u6027\u5316\u7684\u5185\u5bb9\uff0c\u5c24\u5176\u662f\u5728\u4ea7\u54c1\u5177\u6709\u591a\u79cd\u5356\u70b9\u7684\u60c5\u51b5\u4e0b\u3002\u4e3a\u4e86\u6ee1\u8db3\u7528\u6237\u4e0d\u540c\u7684\u9700\u6c42\uff0c\u4e2a\u6027\u5316\u5185\u5bb9\u751f\u6210\u53d8\u5f97\u6781\u5177\u4ef7\u503c\u3002", "method": "\u63d0\u51fa\u4e86HLLM-Creator\uff0c\u4e00\u4e2a\u7528\u4e8e\u9ad8\u6548\u7528\u6237\u5174\u8da3\u5efa\u6a21\u548c\u4e2a\u6027\u5316\u5185\u5bb9\u751f\u6210\u7684\u5c42\u7ea7LLM\u6846\u67b6\u3002\u901a\u8fc7\u7528\u6237\u805a\u7c7b\u548c\u7528\u6237-\u5e7f\u544a\u5339\u914d\u9884\u6d4b\u7684\u4fee\u526a\u7b56\u7565\u663e\u8457\u63d0\u9ad8\u751f\u6210\u6548\u7387\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u7684\u6570\u636e\u6784\u5efa\u7ba1\u9053\u4fdd\u8bc1\u6570\u636e\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u6d4b\u8bd5\u4e2d\uff0cHLLM-Creator\u5b9e\u73b0\u4e86\u5bf9\u6296\u97f3\u641c\u7d22\u5e7f\u544a\u7684\u4e2a\u6027\u5316\u6807\u9898\u751f\u6210\uff0c\u5e76\u5728\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u83b7\u5f97\u4e860.476%\u7684Adss\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5176\u6548\u679c\u548c\u6548\u7387\u3002", "conclusion": "HLLM-Creator\u6210\u529f\u63d0\u5347\u4e2a\u6027\u5316\u6807\u9898\u751f\u6210\u7684\u6548\u7387\u548c\u6548\u679c\uff0c\u7279\u522b\u662f\u5728\u5927\u578b\u5de5\u4e1a\u573a\u666f\u4e2d\u3002\u4ee3\u7801\u548c\u76f8\u5173\u6570\u636e\u96c6\u5df2\u7ecf\u53d1\u5e03\uff0c\u4fbf\u4e8e\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u4ea7\u4e1a\u5e94\u7528\u3002"}}
{"id": "2508.18132", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.18132", "abs": "https://arxiv.org/abs/2508.18132", "authors": ["Hung-Chun Hsu", "Yuan-Ching Kuo", "Chao-Han Huck Yang", "Szu-Wei Fu", "Hanrong Ye", "Hongxu Yin", "Yu-Chiang Frank Wang", "Ming-Feng Tsai", "Chuan-Ju Wang"], "title": "Test-Time Scaling Strategies for Generative Retrieval in Multimodal Conversational Recommendations", "comment": null, "summary": "The rapid evolution of e-commerce has exposed the limitations of traditional\nproduct retrieval systems in managing complex, multi-turn user interactions.\nRecent advances in multimodal generative retrieval -- particularly those\nleveraging multimodal large language models (MLLMs) as retrievers -- have shown\npromise. However, most existing methods are tailored to single-turn scenarios\nand struggle to model the evolving intent and iterative nature of multi-turn\ndialogues when applied naively. Concurrently, test-time scaling has emerged as\na powerful paradigm for improving large language model (LLM) performance\nthrough iterative inference-time refinement. Yet, its effectiveness typically\nrelies on two conditions: (1) a well-defined problem space (e.g., mathematical\nreasoning), and (2) the model's ability to self-correct -- conditions that are\nrarely met in conversational product search. In this setting, user queries are\noften ambiguous and evolving, and MLLMs alone have difficulty grounding\nresponses in a fixed product corpus. Motivated by these challenges, we propose\na novel framework that introduces test-time scaling into conversational\nmultimodal product retrieval. Our approach builds on a generative retriever,\nfurther augmented with a test-time reranking (TTR) mechanism that improves\nretrieval accuracy and better aligns results with evolving user intent\nthroughout the dialogue. Experiments across multiple benchmarks show consistent\nimprovements, with average gains of 14.5 points in MRR and 10.6 points in\nnDCG@1.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u6d4b\u8bd5\u65f6\u7f29\u653e\u548c\u91cd\u65b0\u6392\u540d\u673a\u5236\u6765\u63d0\u9ad8\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u4ea7\u54c1\u68c0\u7d22\u6027\u80fd\uff0c\u5b9e\u9a8c\u663e\u793a\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u4ea7\u54c1\u68c0\u7d22\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u7684\u591a\u8f6e\u7528\u6237\u4ea4\u4e92\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u6709\u6548\u5efa\u6a21\u6f14\u53d8\u7684\u7528\u6237\u610f\u56fe\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u5c06\u6d4b\u8bd5\u65f6\u7f29\u653e\u5f15\u5165\u591a\u6a21\u6001\u4ea7\u54c1\u68c0\u7d22\uff0c\u5e76\u5728\u751f\u6210\u68c0\u7d22\u5668\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e00\u4e2a\u6d4b\u8bd5\u65f6\u91cd\u65b0\u6392\u540d\u673a\u5236\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5e73\u5747\u63d0\u9ad8\u4e8614.5\u70b9\u7684MRR\u548c10.6\u70b9\u7684nDCG@1\u3002", "conclusion": "\u5f15\u5165\u6d4b\u8bd5\u65f6\u7f29\u653e\u548c\u91cd\u65b0\u6392\u540d\u673a\u5236\u7684\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u68c0\u7d22\u51c6\u786e\u6027\uff0c\u5e76\u4e0e\u7528\u6237\u610f\u56fe\u4fdd\u6301\u4e00\u81f4\u3002"}}
{"id": "2508.18166", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.18166", "abs": "https://arxiv.org/abs/2508.18166", "authors": ["Bin Tan", "Wangyao Ge", "Yidi Wang", "Xin Liu", "Jeff Burtoft", "Hao Fan", "Hui Wang"], "title": "PCR-CA: Parallel Codebook Representations with Contrastive Alignment for Multiple-Category App Recommendation", "comment": "9 pages, 4 figures, conference", "summary": "Modern app store recommender systems struggle with multiple-category apps, as\ntraditional taxonomies fail to capture overlapping semantics, leading to\nsuboptimal personalization. We propose PCR-CA (Parallel Codebook\nRepresentations with Contrastive Alignment), an end-to-end framework for\nimproved CTR prediction. PCR-CA first extracts compact multimodal embeddings\nfrom app text, then introduces a Parallel Codebook VQ-AE module that learns\ndiscrete semantic representations across multiple codebooks in parallel --\nunlike hierarchical residual quantization (RQ-VAE). This design enables\nindependent encoding of diverse aspects (e.g., gameplay, art style), better\nmodeling multiple-category semantics. To bridge semantic and collaborative\nsignals, we employ a contrastive alignment loss at both the user and item\nlevels, enhancing representation learning for long-tail items. Additionally, a\ndual-attention fusion mechanism combines ID-based and semantic features to\ncapture user interests, especially for long-tail apps. Experiments on a\nlarge-scale dataset show PCR-CA achieves a +0.76% AUC improvement over strong\nbaselines, with +2.15% AUC gains for long-tail apps. Online A/B testing further\nvalidates our approach, showing a +10.52% lift in CTR and a +16.30% improvement\nin CVR, demonstrating PCR-CA's effectiveness in real-world deployment. The new\nframework has now been fully deployed on the Microsoft Store.", "AI": {"tldr": "PCR-CA\u6846\u67b6\u901a\u8fc7\u5e76\u884c\u7f16\u7801\u548c\u5bf9\u6bd4\u5bf9\u9f50\u673a\u5236\u6539\u5584\u591a\u7c7b\u522b\u5e94\u7528\u63a8\u8350\uff0c\u5b9e\u9a8c\u663e\u793a\u660e\u663e\u63d0\u5347\u63a8\u8350\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5e94\u7528\u5546\u5e97\u63a8\u8350\u7cfb\u7edf\u5728\u5904\u7406\u591a\u7c7b\u522b\u5e94\u7528\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u4f20\u7edf\u5206\u7c7b\u4f53\u7cfb\u96be\u4ee5\u6355\u6349\u91cd\u53e0\u7684\u8bed\u4e49\uff0c\u5bfc\u81f4\u4e2a\u6027\u5316\u63a8\u8350\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86PCR-CA\u6846\u67b6\uff0c\u901a\u8fc7\u5e76\u884c\u4ee3\u7801\u7c3f\u8868\u8fbe\u548c\u5bf9\u6bd4\u5bf9\u9f50\u673a\u5236\u63d0\u9ad8\u70b9\u51fb\u7387\u9884\u6d4b\u3002\u9996\u5148\u4ece\u5e94\u7528\u6587\u672c\u4e2d\u63d0\u53d6\u591a\u6a21\u6001\u5d4c\u5165\uff0c\u7136\u540e\u91c7\u7528\u5e76\u884c\u4ee3\u7801\u7c3fVQ-AE\u6a21\u5757\u5b66\u4e60\u79bb\u6563\u8bed\u4e49\u8868\u8fbe\u3002\u4e0e\u5c42\u6b21\u6b8b\u5dee\u91cf\u5316\u4e0d\u540c\uff0c\u8be5\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u72ec\u7acb\u7f16\u7801\u591a\u6837\u65b9\u9762\uff0c\u5e76\u4f7f\u7528\u5bf9\u6bd4\u5bf9\u9f50\u635f\u5931\u589e\u5f3a\u957f\u5c3e\u9879\u76ee\u7684\u8868\u793a\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cPCR-CA\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u6bd4\u5f3a\u57fa\u7ebf\u63d0\u53470.76% AUC\uff0c\u957f\u5c3e\u5e94\u7528\u4e0a\u63d0\u53472.15% AUC\u3002\u5728\u7ebfA/B\u6d4b\u8bd5\u8fdb\u4e00\u6b65\u8bc1\u660e\uff0c\u5176\u5728CTR\u4e0a\u63d0\u534710.52%\uff0cCVR\u4e0a\u63d0\u534716.30%\u3002", "conclusion": "PCR-CA\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u591a\u7c7b\u522b\u5e94\u7528\u63a8\u8350\u4e2d\u7684\u8bed\u4e49\u91cd\u53e0\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u3002"}}
