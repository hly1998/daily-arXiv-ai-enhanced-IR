<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 12]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [SPELUNKER: Item Similarity Search Using Large Language Models and Custom K-Nearest Neighbors](https://arxiv.org/abs/2509.21323)
*Ana Rodrigues,João Mata,Rui Rego*

Main category: cs.IR

TL;DR: 使用结合LLM和KNN的混合系统进行物品相似性搜索，提高了搜索的透明性和解释能力，并在葡萄酒评论数据集上表现出高效性。


<details>
  <summary>Details</summary>
Motivation: 与黑箱密集向量系统不同，此架构通过提高可解释性，旨在使自然语言查询转化为结构化搜索，从而更好地保留不同数据类型的特性，以便在物品相似性搜索中更精准地满足用户的深层意图。

Method: 本文提出了一种混合系统，通过结合大型语言模型（LLM）和定制的K临近算法（KNN）来实现直观的物品相似性搜索。LLM将自然语言查询转换为结构化的、基于属性的搜索，随后输入到使用BallTree搜索策略的定制KNN算法中。

Result: 在500篇葡萄酒评论数据集上进行的评估显示，LLM在信息抽取上的F1分数为0.9779，并表现出很高的忠实度（Jaro字符串相似度为0.9321）。通过与LLM为基础的重排名结合，KNN算法在召回率上有显著提升（p=0.013）。

Conclusion: 该方法在提供人类语言与机器可理解的物品表示之间的桥梁方面非常有效，为用户提供了透明且细致的搜索能力。

Abstract: This paper presents a hybrid system for intuitive item similarity search that
combines a Large Language Model (LLM) with a custom K-Nearest Neighbors (KNN)
algorithm. Unlike black-box dense vector systems, this architecture provides
superior interpretability by first using an LLM to convert natural language
queries into structured, attribute-based searches. This structured query then
serves as input to a custom KNN algorithm with a BallTree search strategy,
which uses a heterogeneous distance metric to preserve distinct data types. Our
evaluation, conducted on a dataset of 500 wine reviews, demonstrates the
system's effectiveness. The LLM achieved an F1-score of 0.9779 in information
extraction, while also demonstrating high fidelity with a Jaro string
similarity of 0.9321. When we augmented the KNN algorithm with LLM-based
re-ranking, we observed a statistically significant improvement in recall
(p=0.013), indicating the LLM's ability to identify and promote relevant items
that align with nuanced user intent. This approach effectively bridges the gap
between human language and machine-understandable item representations,
offering a transparent and nuanced search capability.

</details>


### [2] [From Search to Reasoning: A Five-Level RAG Capability Framework for Enterprise Data](https://arxiv.org/abs/2509.21324)
*Gurbinder Gill,Ritvik Gupta,Denis Lusson,Anand Chandrashekar,Donald Nguyen*

Main category: cs.IR

TL;DR: 本文提出了一种框架划分企业问答系统的复杂性，并评价了相关平台。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG方法在处理企业数据上的问答问题时主要依赖文本语义搜索和重排序，但在处理总结文本以外的问题以及非文本数据时效果有限。因此，人们尝试通过补充RAG来弥合问题实施范式和企业用户对问答需求之间的差距。

Method: 提出分类框架L1-L5，并通过基准测试和实验证实其效果，评估了现有四个问答平台的能力。

Result: 提出了一种新的分级框架（L1-L5），用于根据数据模态和问答任务复杂性对系统进行分类，并引入与这些等级对齐的基准测试来评价四种最先进的平台：LangChain、Azure AI Search、OpenAI 和 Corvic AI。实验证实了多空间检索和动态编排在发挥L1-L4能力上的价值。

Conclusion: 多空间检索和动态编排对于实现企业数据问答系统的多级能力至关重要。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as the standard paradigm for
answering questions on enterprise data. Traditionally, RAG has centered on
text-based semantic search and re-ranking. However, this approach falls short
when dealing with questions beyond data summarization or non-text data. This
has led to various attempts to supplement RAG to bridge the gap between RAG,
the implementation paradigm, and the question answering problem that enterprise
users expect it to solve. Given that contemporary RAG is a collection of
techniques rather than a defined implementation, discussion of RAG and related
question-answering systems benefits from a problem-oriented understanding.
  We propose a new classification framework (L1-L5) to categorize systems based
on data modalities and task complexity of the underlying question answering
problems: L1 (Surface Knowledge of Unstructured Data) through L4 (Reflective
and Reasoned Knowledge) and the aspirational L5 (General Intelligence). We also
introduce benchmarks aligned with these levels and evaluate four
state-of-the-art platforms: LangChain, Azure AI Search, OpenAI, and Corvic AI.
Our experiments highlight the value of multi-space retrieval and dynamic
orchestration for enabling L1-L4 capabilities. We empirically validate our
findings using diverse datasets indicative of enterprise use cases.

</details>


### [3] [PIR-RAG: A System for Private Information Retrieval in Retrieval-Augmented Generation](https://arxiv.org/abs/2509.21325)
*Baiqiang Wang,Qian Lou,Mengxin Zheng,Dongfang Zhao*

Main category: cs.IR

TL;DR: PIR-RAG通过创新架构和协议优化了隐私保护的检索增强生成（RAG），在性能和可扩展性上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统的检索增强生成（RAG）组件暴露用户查询给服务提供商，带来了隐私风险。

Method: 采用了一种新的架构，通过粗粒度语义聚类来修剪搜索空间，并结合快速的基于晶格的私人信息检索（PIR）协议。

Result: PIR-RAG在与强大的基准架构对比中展示了其可扩展性，并且在“RAG准备延迟”方面表现优异。

Conclusion: PIR-RAG为大规模AI系统中的隐私保护提供了可行且高效的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) has become a foundational component of
modern AI systems, yet it introduces significant privacy risks by exposing user
queries to service providers. To address this, we introduce PIR-RAG, a
practical system for privacy-preserving RAG. PIR-RAG employs a novel
architecture that uses coarse-grained semantic clustering to prune the search
space, combined with a fast, lattice-based Private Information Retrieval (PIR)
protocol. This design allows for the efficient retrieval of entire document
clusters, uniquely optimizing for the end-to-end RAG workflow where full
document content is required. Our comprehensive evaluation against strong
baseline architectures, including graph-based PIR and Tiptoe-style private
scoring, demonstrates PIR-RAG's scalability and its superior performance in
terms of "RAG-Ready Latency"-the true end-to-end time required to securely
fetch content for an LLM. Our work establishes PIR-RAG as a viable and highly
efficient solution for privacy in large-scale AI systems.

</details>


### [4] [HetaRAG: Hybrid Deep Retrieval-Augmented Generation across Heterogeneous Data Stores](https://arxiv.org/abs/2509.21336)
*Guohang Yan,Yue Zhang,Pinlong Cai,Ding Wang,Song Mao,Hongwei Zhang,Yaoze Zhang,Hairong Zhang,Xinyu Cai,Botian Shi*

Main category: cs.IR

TL;DR: 本文介绍了HetaRAG框架，通过融合异构数据存储解决传统RAG系统的设计缺陷，以改善检索召回率、精确性和上下文忠实度。


<details>
  <summary>Details</summary>
Motivation: 为了缓解大型语言模型中的知识幻觉和陈旧性问题，同时保障数据安全，提出了一种新的检索增强生成框架。

Method: 引入HetaRAG框架，将向量索引、知识图谱、全文引擎和结构化数据库结合为一个单一的检索平面，通过动态路由和融合证据来最大化检索的召回率、精确性和上下文忠实度。

Result: 进行了初步探索，构建了初始的RAG管道，并提供了部分代码以供查看。

Conclusion: 不同检索方式有各自的优势，通过融合这些异构检索模式可以相互补充，增强RAG框架的性能。

Abstract: Retrieval-augmented generation (RAG) has become a dominant paradigm for
mitigating knowledge hallucination and staleness in large language models
(LLMs) while preserving data security. By retrieving relevant evidence from
private, domain-specific corpora and injecting it into carefully engineered
prompts, RAG delivers trustworthy responses without the prohibitive cost of
fine-tuning. Traditional retrieval-augmented generation (RAG) systems are
text-only and often rely on a single storage backend, most commonly a vector
database. In practice, this monolithic design suffers from unavoidable
trade-offs: vector search captures semantic similarity yet loses global
context; knowledge graphs excel at relational precision but struggle with
recall; full-text indexes are fast and exact yet semantically blind; and
relational engines such as MySQL provide strong transactional guarantees but no
semantic understanding. We argue that these heterogeneous retrieval paradigms
are complementary, and propose a principled fusion scheme to orchestrate them
synergistically, mitigating the weaknesses of any single modality. In this work
we introduce HetaRAG, a hybrid, deep-retrieval augmented generation framework
that orchestrates cross-modal evidence from heterogeneous data stores. We plan
to design a system that unifies vector indices, knowledge graphs, full-text
engines, and structured databases into a single retrieval plane, dynamically
routing and fusing evidence to maximize recall, precision, and contextual
fidelity. To achieve this design goal, we carried out preliminary explorations
and constructed an initial RAG pipeline; this technical report provides a brief
overview. The partial code is available at
https://github.com/KnowledgeXLab/HetaRAG.

</details>


### [5] [Cross-Modal Retrieval with Cauchy-Schwarz Divergence](https://arxiv.org/abs/2509.21339)
*Jiahao Zhang,Wenzhe Yin,Shujian Yu*

Main category: cs.IR

TL;DR: Introduce Cauchy-Schwarz divergence for stable and effective cross-modal retrieval, and extend it to Generalized CS divergence for multi-modality alignment, improving efficiency and performance.


<details>
  <summary>Details</summary>
Motivation: 现有的方法在异质数据类型之间进行双模态检索时常受限于分布对齐技术，如Kullback-Leibler发散、最大均值差异和相关性对齐。然而，这些方法存在数值不稳定性、对超参数敏感以及无法捕捉潜在分布的完整结构的问题。

Method: 利用Cauchy-Schwarz (CS) 发散和广义CS (GCS) 发散，通过双向循环比较方案实现跨多个模态的直接对齐。

Result: 提出了Cauchy-Schwarz (CS) 发散，一种无需超参数的度量，能够改善训练稳定性和检索性能。此外，进一步提出了基于Hölder不等式的广义CS (GCS) 发散，能够在统一的数学框架内直接对齐三个或多个模态，而无需进行详尽的成对比较。

Conclusion: 我们的方法在六个基准数据集上表现出色，证明了其在双模态和三模态检索任务中的有效性。

Abstract: Effective cross-modal retrieval requires robust alignment of heterogeneous
data types. Most existing methods focus on bi-modal retrieval tasks and rely on
distributional alignment techniques such as Kullback-Leibler divergence,
Maximum Mean Discrepancy, and correlation alignment. However, these methods
often suffer from critical limitations, including numerical instability,
sensitivity to hyperparameters, and their inability to capture the full
structure of the underlying distributions. In this paper, we introduce the
Cauchy-Schwarz (CS) divergence, a hyperparameter-free measure that improves
both training stability and retrieval performance. We further propose a novel
Generalized CS (GCS) divergence inspired by H\"older's inequality. This
extension enables direct alignment of three or more modalities within a unified
mathematical framework through a bidirectional circular comparison scheme,
eliminating the need for exhaustive pairwise comparisons. Extensive experiments
on six benchmark datasets demonstrate the effectiveness of our method in both
bi-modal and tri-modal retrieval tasks. The code of our CS/GCS divergence is
publicly available at https://github.com/JiahaoZhang666/CSD.

</details>


### [6] [ReGeS: Reciprocal Retrieval-Generation Synergy for Conversational Recommender Systems](https://arxiv.org/abs/2509.21371)
*Dayu Yang,Hui Fang*

Main category: cs.IR

TL;DR: 提出了一种框架ReGeS，通过增强检索和生成实现对话推荐系统的性能提升。


<details>
  <summary>Details</summary>
Motivation: 利用外部领域知识来准确理解用户偏好对于对话推荐系统至关重要。然而，目前的方法要么需要特定领域的工程，限制了灵活性，要么过于依赖大型语言模型，导致幻觉的风险增加。

Method: 提出了一种相互的检索-生成协同框架ReGeS，通过生成增强检索来提炼来自对话的用户意图信息，并通过检索增强生成来区分细微的项目特征。

Result: ReGeS在多个CRS基准上实现了推荐精度的最新水平。

Conclusion: 相互协作的生成和检索技术对于知识密集型对话推荐系统任务的有效性得到证明。

Abstract: Connecting conversation with external domain knowledge is vital for
conversational recommender systems (CRS) to correctly understand user
preferences. However, existing solutions either require domain-specific
engineering, which limits flexibility, or rely solely on large language models,
which increases the risk of hallucination. While Retrieval-Augmented Generation
(RAG) holds promise, its naive use in CRS is hindered by noisy dialogues that
weaken retrieval and by overlooked nuances among similar items. We propose
ReGeS, a reciprocal Retrieval-Generation Synergy framework that unifies
generation-augmented retrieval to distill informative user intent from
conversations and retrieval-augmented generation to differentiate subtle item
features. This synergy obviates the need for extra annotations, reduces
hallucinations, and simplifies continuous updates. Experiments on multiple CRS
benchmarks show that ReGeS achieves state-of-the-art performance in
recommendation accuracy, demonstrating the effectiveness of reciprocal synergy
for knowledge-intensive CRS tasks.

</details>


### [7] [MIXRAG : Mixture-of-Experts Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering](https://arxiv.org/abs/2509.21391)
*Lihui Liu,Carl J. Yang*

Main category: cs.IR

TL;DR: MIXRAG框架通过引入多个图检索器和动态路由控制器增强LLMs性能，在基于图的任务中表现出色，并减少噪声影响。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在知识密集域存在幻觉现象，其原因在于依赖静态预训练语料。

Method: 提出MIXRAG框架，引入多个专业图检索器和动态路由控制器，每个检索器专注于图语义的特定方面，如实体、关系或子图拓扑。混合专家模块根据输入查询自适应选择和融合相关检索器。

Result: 实验结果表明，该方法实现了最先进的性能，并且在不同领域的基于图的任务中表现出色。

Conclusion: MIXRAG有效地处理查询意图多样性，并通过查询感知的GraphEncoder减少检索信息中的噪声。

Abstract: Large Language Models (LLMs) have achieved impressive performance across a
wide range of applications. However, they often suffer from hallucinations in
knowledge-intensive domains due to their reliance on static pretraining
corpora. To address this limitation, Retrieval-Augmented Generation (RAG)
enhances LLMs by incorporating external knowledge sources during inference.
Among these sources, textual graphs provide structured and semantically rich
information that supports more precise and interpretable reasoning. This has
led to growing interest in graph-based RAG systems. Despite their potential,
most existing approaches rely on a single retriever to identify relevant
subgraphs, which limits their ability to capture the diverse aspects of complex
queries. Moreover, these systems often struggle to accurately judge the
relevance of retrieved content, making them prone to distraction by irrelevant
noise. To address these challenges, in this paper, we propose MIXRAG, a
Mixture-of-Experts Graph-RAG framework that introduces multiple specialized
graph retrievers and a dynamic routing controller to better handle diverse
query intents. Each retriever is trained to focus on a specific aspect of graph
semantics, such as entities, relations, or subgraph topology. A
Mixture-of-Experts module adaptively selects and fuses relevant retrievers
based on the input query. To reduce noise in the retrieved information, we
introduce a query-aware GraphEncoder that carefully analyzes relationships
within the retrieved subgraphs, highlighting the most relevant parts while
down-weighting unnecessary noise. Empirical results demonstrate that our method
achieves state-of-the-art performance and consistently outperforms various
baselines. MIXRAG is effective across a wide range of graph-based tasks in
different domains. The code will be released upon paper acceptance.

</details>


### [8] [Effect of Model Merging in Domain-Specific Ad-hoc Retrieval](https://arxiv.org/abs/2509.21966)
*Taiga Sasaki,Takehiro Yamamoto,Hiroaki Ohshima,Sumio Fujita*

Main category: cs.IR

TL;DR: 模型合并可以提高特定领域的临时检索任务效果，无需额外微调，特别适合有限数据情况，是LoRA微调的可行替代方案。


<details>
  <summary>Details</summary>
Motivation: 我们假设将模型合并应用于特定领域的临时检索任务可以提高检索效果。

Method: 我们使用线性插值方法合并了源检索模型和特定领域（非检索）模型的权重，两者的合并无需额外的模型微调。我们在医疗和日本领域进行了实验比较。

Result: 实验结果表明，模型合并有可能比源检索模型产生更有效的特定领域检索模型，并且可能在数据有限的情况下成为LoRA微调的实际替代方案。

Conclusion: 在进行实验的领域中，模型合并技术能提高检索的有效性，特别是在数据有限时表现良好。

Abstract: In this study, we evaluate the effect of model merging in ad-hoc retrieval
tasks. Model merging is a technique that combines the diverse characteristics
of multiple models. We hypothesized that applying model merging to
domain-specific ad-hoc retrieval tasks could improve retrieval effectiveness.
To verify this hypothesis, we merged the weights of a source retrieval model
and a domain-specific (non-retrieval) model using a linear interpolation
approach. A key advantage of our approach is that it requires no additional
fine-tuning of the models. We conducted two experiments each in the medical and
Japanese domains. The first compared the merged model with the source retrieval
model, and the second compared it with a LoRA fine-tuned model under both full
and limited data settings for model construction. The experimental results
indicate that model merging has the potential to produce more effective
domain-specific retrieval models than the source retrieval model, and may serve
as a practical alternative to LoRA fine-tuning, particularly when only a
limited amount of data is available.

</details>


### [9] [GoalRank: Group-Relative Optimization for a Large Ranking Model](https://arxiv.org/abs/2509.22046)
*Kaike Zhang,Xiaobei Wang,Shuchang Liu,Hailan Yang,Xiang Li,Lantao Hu,Han Li,Qi Cao,Fei Sun,Kun Gai*

Main category: cs.IR

TL;DR: 被证明生成器单阶段模型比两阶段模型更有效，提出 GoalRank 框架在多项实验中超过现有排序方法。


<details>
  <summary>Details</summary>
Motivation: 现有的主流排序方法通常采用生成器-评估器两阶段范式，但性能提升有限。随着大推荐模型的进展，一阶段模型显示出潜力，激发了从生成器单阶段视角重新审视排序问题的动机。

Method: 提出了一种只有生成器的排序模型，可以更小的逼近误差，并且随着模型规模增大而享有伸缩性。基于此结果，提出了一种一阶段优化目标的上证据界，利用真实用户反馈训练的奖励模型构建了参考策略。

Result: GoalRank框架在公共基准测试和大规模在线A/B测试中均表现出色，超过了最新的排序方法。

Conclusion: 理论证明生成器单阶段模型能够实现更小的逼近误差。实行生成器单阶段排名框架 GoalRank ，可以显著提高排序性能。

Abstract: Mainstream ranking approaches typically follow a Generator-Evaluator
two-stage paradigm, where a generator produces candidate lists and an evaluator
selects the best one. Recent work has attempted to enhance performance by
expanding the number of candidate lists, for example, through multi-generator
settings. However, ranking involves selecting a recommendation list from a
combinatorially large space. Simply enlarging the candidate set remains
ineffective, and performance gains quickly saturate. At the same time, recent
advances in large recommendation models have shown that end-to-end one-stage
models can achieve promising performance with the expectation of scaling laws.
Motivated by this, we revisit ranking from a generator-only one-stage
perspective. We theoretically prove that, for any (finite
Multi-)Generator-Evaluator model, there always exists a generator-only model
that achieves strictly smaller approximation error to the optimal ranking
policy, while also enjoying scaling laws as its size increases. Building on
this result, we derive an evidence upper bound of the one-stage optimization
objective, from which we find that one can leverage a reward model trained on
real user feedback to construct a reference policy in a group-relative manner.
This reference policy serves as a practical surrogate of the optimal policy,
enabling effective training of a large generator-only ranker. Based on these
insights, we propose GoalRank, a generator-only ranking framework. Extensive
offline experiments on public benchmarks and large-scale online A/B tests
demonstrate that GoalRank consistently outperforms state-of-the-art methods.

</details>


### [10] [Does Generative Retrieval Overcome the Limitations of Dense Retrieval?](https://arxiv.org/abs/2509.22116)
*Yingchen Zhang,Ruqing Zhang,Jiafeng Guo,Maarten de Rijke,Yixing Fan,Xueqi Cheng*

Main category: cs.IR

TL;DR: 这篇论文研究了生成检索（GR）与密集检索（DR）的理论和实践差异。GR通过生成相关文档的标识符进行检索，具有全球归一化最大似然优化的特点；而DR使用局部归一化目标并通过外部嵌入表示文档然后进行相似性计算。实验表明，GR可以在大规模下克服DR的局限性，但在实际中并不总是优于DR。


<details>
  <summary>Details</summary>
Motivation: 探究生成检索（GR）如何在理论和实践上与密集检索（DR）不同，并寻找理论支持来优化信息检索性能。

Method: 理论和实证分析，通过对不同数据集和实验条件（如负采样策略、嵌入维度和模型规模）的控制实验来验证结论。

Result: 研究表明，在大规模语料和模型条件下，GR能克服DR的优化漂移问题和表示能力受限的问题，但实际应用效果未能全面超越DR。

Conclusion: 尽管GR在理论上具有优势，但在实际应用中并未普遍优于DR。研究建议探索更好的方法来缩短理论与实践之间的差距。

Abstract: Generative retrieval (GR) has emerged as a new paradigm in neural information
retrieval, offering an alternative to dense retrieval (DR) by directly
generating identifiers of relevant documents. In this paper, we theoretically
and empirically investigate how GR fundamentally diverges from DR in both
learning objectives and representational capacity. GR performs globally
normalized maximum-likelihood optimization and encodes corpus and relevance
information directly in the model parameters, whereas DR adopts locally
normalized objectives and represents the corpus with external embeddings before
computing similarity via a bilinear interaction. Our analysis suggests that,
under scaling, GR can overcome the inherent limitations of DR, yielding two
major benefits. First, with larger corpora, GR avoids the sharp performance
degradation caused by the optimization drift induced by DR's local
normalization. Second, with larger models, GR's representational capacity
scales with parameter size, unconstrained by the global low-rank structure that
limits DR. We validate these theoretical insights through controlled
experiments on the Natural Questions and MS MARCO datasets, across varying
negative sampling strategies, embedding dimensions, and model scales. But
despite its theoretical advantages, GR does not universally outperform DR in
practice. We outline directions to bridge the gap between GR's theoretical
potential and practical performance, providing guidance for future research in
scalable and robust generative retrieval.

</details>


### [11] [Can Synthetic Query Rewrites Capture User Intent Better than Humans in Retrieval-Augmented Generation?](https://arxiv.org/abs/2509.22325)
*JiaYing Zheng,HaiNan Zhang,Liang Pang,YongXin Tong,ZhiMing Zheng*

Main category: cs.IR

TL;DR: SynRewrite通过生成合成查询重写提高RAG系统的检索和生成性能，优于人工重写。


<details>
  <summary>Details</summary>
Motivation: 传统的查询重写依赖于人工注释来澄清查询，但由于人类注释者在表达能力和理解深度上的局限性，这些人工重写的查询往往与真实世界RAG系统中所需的查询存在差异，从而导致用户意图和系统响应之间的差距。多轮RAG系统常因口语省略和模糊参照面临重大的检索与生成挑战。

Method: 本文提出了一种基于合成数据的查询重写模型SynRewrite，以生成更高质量、更符合用户意图的合成重写。数据构建上，首先利用GPT-4o根据对话历史、当前查询、正面文档以及答案生成高质量重写，然后在此数据集上微调Flan-T5模型以将对话历史和查询映射到合成重写。最后，使用DPO算法通过生成器的反馈进一步提升重写器的末端任务性能。

Result: 实验结果表明SynRewrite在TopiOCQA和QRECC数据集的检索和生成任务中始终优于人工重写。

Conclusion: 合成重写可以成为人工注释的可扩展且有效的替代方案。

Abstract: Multi-turn RAG systems often face queries with colloquial omissions and
ambiguous references, posing significant challenges for effective retrieval and
generation. Traditional query rewriting relies on human annotators to clarify
queries, but due to limitations in annotators' expressive ability and depth of
understanding, manually rewritten queries often diverge from those needed in
real-world RAG systems, resulting in a gap between user intent and system
response. We observe that high-quality synthetic queries can better bridge this
gap, achieving superior performance in both retrieval and generation compared
to human rewrites. This raises an interesting question: Can rewriting models
trained on synthetic queries better capture user intent than human annotators?
In this paper, we propose SynRewrite, a synthetic data-driven query rewriting
model to generate high-quality synthetic rewrites more aligned with user
intent. To construct training data, we prompt GPT-4o with dialogue history,
current queries, positive documents, and answers to synthesize high-quality
rewrites. A Flan-T5 model is then finetuned on this dataset to map dialogue
history and queries to synthetic rewrites. Finally, we further enhance the
rewriter using the generator's feedback through the DPO algorithm to boost
end-task performance. Experiments on TopiOCQA and QRECC datasets show that
SynRewrite consistently outperforms human rewrites in both retrieval and
generation tasks. Our results demonstrate that synthetic rewrites can serve as
a scalable and effective alternative to human annotations.

</details>


### [12] [Your RAG is Unfair: Exposing Fairness Vulnerabilities in Retrieval-Augmented Generation via Backdoor Attacks](https://arxiv.org/abs/2509.22486)
*Gaurav Bagwe,Saket S. Chaturvedi,Xiaolong Ma,Xiaoyong Yuan,Kuang-Ching Wang,Lan Zhang*

Main category: cs.IR

TL;DR: BiasRAG框架系统性揭露信息检索增强生成中的公平性漏洞，通过两阶段后门攻击实现高效且隐蔽的攻击，同时保持上下文相关性和实用性。


<details>
  <summary>Details</summary>
Motivation: 在信息检索增强生成（RAG）系统中，传统的后门攻击依赖于直接的触发到目标的映射，而公平性驱动的攻击通过操控目标群体与社会偏见的语义关系，建立一个隐蔽且持久的内容生成影响，研究尚未深入。

Method: 该研究提出了一个名为BiasRAG的两阶段后门攻击框架。在预训练阶段，利用查询编码器使目标群体与预设的社会偏见对齐。在部署后阶段，向知识库中注入对抗性文档，以加强后门攻击。

Result: BiasRAG框架在RAG系统中高效实施后门攻击，成功在内容生成中隐蔽地加入社会偏见，同时保持文本的上下文相关性。

Conclusion: BiasRAG框架能够系统性地揭露RAG中的公平性漏洞，攻击成功率高，并能够在保持上下文相关性和效用的同时，持续影响内容生成。

Abstract: Retrieval-augmented generation (RAG) enhances factual grounding by
integrating retrieval mechanisms with generative models but introduces new
attack surfaces, particularly through backdoor attacks. While prior research
has largely focused on disinformation threats, fairness vulnerabilities remain
underexplored. Unlike conventional backdoors that rely on direct
trigger-to-target mappings, fairness-driven attacks exploit the interaction
between retrieval and generation models, manipulating semantic relationships
between target groups and social biases to establish a persistent and covert
influence on content generation.
  This paper introduces BiasRAG, a systematic framework that exposes fairness
vulnerabilities in RAG through a two-phase backdoor attack. During the
pre-training phase, the query encoder is compromised to align the target group
with the intended social bias, ensuring long-term persistence. In the
post-deployment phase, adversarial documents are injected into knowledge bases
to reinforce the backdoor, subtly influencing retrieved content while remaining
undetectable under standard fairness evaluations. Together, BiasRAG ensures
precise target alignment over sensitive attributes, stealthy execution, and
resilience. Empirical evaluations demonstrate that BiasRAG achieves high attack
success rates while preserving contextual relevance and utility, establishing a
persistent and evolving threat to fairness in RAG.

</details>
