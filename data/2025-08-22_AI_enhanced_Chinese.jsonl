{"id": "2508.14905", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14905", "abs": "https://arxiv.org/abs/2508.14905", "authors": ["Michael Sun", "Tai Vu", "Andrew Wang"], "title": "Privacy Preserving Inference of Personalized Content for Out of Matrix Users", "comment": null, "summary": "Recommender systems for niche and dynamic communities face persistent\nchallenges from data sparsity, cold start users and items, and privacy\nconstraints. Traditional collaborative filtering and content-based approaches\nunderperform in these settings, either requiring invasive user data or failing\nwhen preference histories are absent. We present DeepNaniNet, a deep neural\nrecommendation framework that addresses these challenges through an inductive\ngraph-based architecture combining user-item interactions, item-item relations,\nand rich textual review embeddings derived from BERT. Our design enables cold\nstart recommendations without profile mining, using a novel \"content basket\"\nuser representation and an autoencoder-based generalization strategy for unseen\nusers. We introduce AnimeULike, a new dataset of 10,000 anime titles and 13,000\nusers, to evaluate performance in realistic scenarios with high proportions of\nguest or low-activity users. DeepNaniNet achieves state-of-the-art cold start\nresults on the CiteULike benchmark, matches DropoutNet in user recall without\nperformance degradation for out-of-matrix users, and outperforms Weighted\nMatrix Factorization (WMF) and DropoutNet on AnimeULike warm start by up to 7x\nand 1.5x in Recall@100, respectively. Our findings demonstrate that DeepNaniNet\ndelivers high-quality, privacy-preserving recommendations in data-sparse, cold\nstart-heavy environments while effectively integrating heterogeneous content\nsources.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a DeepNaniNet \u7684\u6df1\u5ea6\u795e\u7ecf\u63a8\u8350\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u758f\u3001\u51b7\u542f\u52a8\u53ca\u9690\u79c1\u95ee\u9898\uff0c\u5e76\u5229\u7528 AnimeULike \u6570\u636e\u96c6\u8fdb\u884c\u9a8c\u8bc1\uff0c\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u7ed3\u679c\u3002", "motivation": "\u586b\u8865\u4f20\u7edf\u534f\u540c\u8fc7\u6ee4\u548c\u57fa\u4e8e\u5185\u5bb9\u7684\u65b9\u6cd5\u5728\u6570\u636e\u7a00\u758f\u548c\u51b7\u542f\u52a8\u573a\u666f\u4e2d\u7684\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u4fb5\u5165\u6027\u7528\u6237\u6570\u636e\u6216\u8005\u504f\u597d\u5386\u53f2\u7f3a\u5931\u65f6\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u96c6\u6210\u7528\u6237-\u9879\u76ee\u4ea4\u4e92\u3001\u9879\u76ee-\u9879\u76ee\u5173\u7cfb\u4e0e\u4ece BERT \u6d3e\u751f\u7684\u4e30\u5bcc\u6587\u672c\u8bc4\u8bba\u5d4c\u5165\u7684\u5f52\u7eb3\u56fe\u67b6\u6784\uff0c\u5e76\u91c7\u7528\u4e86\u65b0\u9896\u7684\u201c\u5185\u5bb9\u7bee\u5b50\u201d\u7528\u6237\u8868\u793a\u548c\u57fa\u4e8e\u81ea\u7f16\u7801\u5668\u7684\u7b56\u7565\u6765\u5904\u7406\u672a\u89c1\u7528\u6237\u95ee\u9898\u3002", "result": "DeepNaniNet \u5728 CiteULike \u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u51b7\u542f\u52a8\u7ed3\u679c\uff0c\u4e0e DropoutNet \u5728\u7528\u6237\u53ec\u56de\u65b9\u9762\u5339\u654c\uff0c\u5e76\u4e14\u5728\u4e0d\u5f71\u54cd\u51fa\u77e9\u9635\u7528\u6237\u7684\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\uff0c\u5728 AnimeULike \u6570\u636e\u96c6\u4e0a\u5728 Recall@100 \u65b9\u9762\u8d85\u8fc7\u4e86 Weighted Matrix Factorization (WMF) \u548c DropoutNet \u7684\u6700\u591a7\u500d\u548c1.5\u500d\u3002", "conclusion": "DeepNaniNet \u80fd\u5728\u6570\u636e\u7a00\u758f\u548c\u51b7\u542f\u52a8\u96c6\u4e2d\u7684\u73af\u5883\u4e2d\u63d0\u4f9b\u9ad8\u8d28\u91cf\u548c\u4fdd\u62a4\u9690\u79c1\u7684\u63a8\u8350\uff0c\u540c\u65f6\u9ad8\u6548\u6574\u5408\u5f02\u6784\u5185\u5bb9\u6765\u6e90\u3002"}}
{"id": "2508.14906", "categories": ["cs.IR", "cs.AI", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14906", "abs": "https://arxiv.org/abs/2508.14906", "authors": ["Amir Kermanshahani", "Ebrahim Ardeshir-Larijani", "Rakesh Saini", "Saif Al-Kuwari"], "title": "Collaborative Filtering using Variational Quantum Hopfield Associative Memory", "comment": null, "summary": "Quantum computing, with its ability to do exponentially faster computation\ncompared to classical systems, has found novel applications in various fields\nsuch as machine learning and recommendation systems. Quantum Machine Learning\n(QML), which integrates quantum computing with machine learning techniques,\npresents powerful new tools for data processing and pattern recognition. This\npaper proposes a hybrid recommendation system that combines Quantum Hopfield\nAssociative Memory (QHAM) with deep neural networks to improve the extraction\nand classification on the MovieLens 1M dataset. User archetypes are clustered\ninto multiple unique groups using the K-Means algorithm and converted into\npolar patterns through the encoder's activation function. These polar patterns\nare then integrated into the variational QHAM-based hybrid recommendation\nmodel. The system was trained using the MSE loss over 35 epochs in an ideal\nenvironment, achieving an ROC value of 0.9795, an accuracy of 0.8841, and an\nF-1 Score of 0.8786. Trained with the same number of epochs in a noisy\nenvironment using a custom Qiskit AER noise model incorporating bit-flip and\nreadout errors with the same probabilities as in real quantum hardware, it\nachieves an ROC of 0.9177, an accuracy of 0.8013, and an F-1 Score equal to\n0.7866, demonstrating consistent performance.\n  Additionally, we were able to optimize the qubit overhead present in previous\nQHAM architectures by efficiently updating only one random targeted qubit. This\nresearch presents a novel framework that combines variational quantum computing\nwith deep learning, capable of dealing with real-world datasets with comparable\nperformance compared to purely classical counterparts. Additionally, the model\ncan perform similarly well in noisy configurations, showcasing a steady\nperformance and proposing a promising direction for future usage in\nrecommendation systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\uff0c\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u548c\u6df1\u5ea6\u5b66\u4e60\uff0c\u5728MovieLens 1M\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u9ad8\u6548\u6027\u80fd\uff0c\u5e76\u80fd\u5728\u566a\u58f0\u73af\u5883\u4e2d\u7ef4\u6301\u7a33\u5b9a\u8868\u73b0\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u80fd\u6bd4\u7ecf\u5178\u7cfb\u7edf\u8fdb\u884c\u6307\u6570\u7ea7\u66f4\u5feb\u7684\u8ba1\u7b97\uff0c\u5df2\u5728\u8bf8\u5982\u673a\u5668\u5b66\u4e60\u548c\u63a8\u8350\u7cfb\u7edf\u7b49\u9886\u57df\u627e\u5230\u4e86\u65b0\u7684\u5e94\u7528\u3002\u91cf\u5b50\u673a\u5668\u5b66\u4e60\uff08QML\uff09\u7ed3\u5408\u4e86\u91cf\u5b50\u8ba1\u7b97\u4e0e\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u53ef\u4ee5\u63d0\u4f9b\u5f3a\u5927\u7684\u6570\u636e\u5904\u7406\u548c\u6a21\u5f0f\u8bc6\u522b\u5de5\u5177\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7ec4\u5408\u91cf\u5b50\u8ba1\u7b97\u548c\u6df1\u5ea6\u5b66\u4e60\u6765\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\uff0c\u5c06\u91cf\u5b50Hopfield\u5173\u8054\u8bb0\u5fc6\uff08QHAM\uff09\u4e0e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\uff0c\u4ee5\u6539\u5584MovieLens 1M\u6570\u636e\u96c6\u7684\u63d0\u53d6\u548c\u5206\u7c7b\u3002\u7528\u6237\u539f\u578b\u901a\u8fc7K-Means\u7b97\u6cd5\u805a\u7c7b\uff0c\u5e76\u901a\u8fc7\u7f16\u7801\u5668\u7684\u6fc0\u6d3b\u51fd\u6570\u8f6c\u6362\u4e3a\u6781\u6027\u6a21\u5f0f\uff0c\u8fd9\u4e9b\u6781\u6027\u6a21\u5f0f\u88ab\u6574\u5408\u5230\u57fa\u4e8e\u53d8\u5206QHAM\u7684\u6df7\u5408\u63a8\u8350\u6a21\u578b\u4e2d\u3002\u5728\u7406\u60f3\u548c\u566a\u58f0\u73af\u5883\u4e2d\u5206\u522b\u8bad\u7ec3\u8be5\u7cfb\u7edf\u5e76\u8bb0\u5f55\u5176\u6027\u80fd\u3002", "result": "\u5728\u7406\u60f3\u73af\u5883\u4e2d\uff0c\u7cfb\u7edf\u4f7f\u7528MSE\u635f\u5931\u51fd\u6570\u8bad\u7ec335\u8f6e\uff0c\u53d6\u5f97\u4e86ROC\u503c0.9795\uff0c\u51c6\u786e\u73870.8841\uff0cF-1 Score\u4e3a0.8786\u3002\u5728\u566a\u58f0\u73af\u5883\u4e2d\uff0c\u4f7f\u7528\u5b9a\u5236\u7684Qiskit AER\u566a\u58f0\u6a21\u578b\u8bad\u7ec3\uff0cROC\u4e3a0.9177\uff0c\u51c6\u786e\u73870.8013\uff0cF-1 Score\u4e3a0.7866\uff0c\u5c55\u793a\u4e86\u7a33\u5b9a\u7684\u8868\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u91cf\u5b50\u53d8\u5206\u8ba1\u7b97\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u65b0\u6846\u67b6\uff0c\u80fd\u591f\u5904\u7406\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff0c\u5176\u6027\u80fd\u4e0e\u7eaf\u7ecf\u5178\u65b9\u6cd5\u76f8\u5f53\u3002\u540c\u65f6\uff0c\u8be5\u6a21\u578b\u5728\u566a\u58f0\u73af\u5883\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5c55\u793a\u4e86\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.14910", "categories": ["cs.IR", "cs.LG", "68T07, 68P20", "I.2.6; H.3.3"], "pdf": "https://arxiv.org/pdf/2508.14910", "abs": "https://arxiv.org/abs/2508.14910", "authors": ["Simon Lepage", "Jeremie Mary", "David Picard"], "title": "Closing the Performance Gap in Generative Recommenders with Collaborative Tokenization and Efficient Modeling", "comment": "Code coming soon", "summary": "Recent work has explored generative recommender systems as an alternative to\ntraditional ID-based models, reframing item recommendation as a sequence\ngeneration task over discrete item tokens. While promising, such methods often\nunderperform in practice compared to well-tuned ID-based baselines like SASRec.\nIn this paper, we identify two key limitations holding back generative\napproaches: the lack of collaborative signal in item tokenization, and\ninefficiencies in the commonly used encoder-decoder architecture. To address\nthese issues, we introduce COSETTE, a contrastive tokenization method that\nintegrates collaborative information directly into the learned item\nrepresentations, jointly optimizing for both content reconstruction and\nrecommendation relevance. Additionally, we propose MARIUS, a lightweight,\naudio-inspired generative model that decouples timeline modeling from item\ndecoding. MARIUS reduces inference cost while improving recommendation\naccuracy. Experiments on standard sequential recommendation benchmarks show\nthat our approach narrows, or even eliminates, the performance gap between\ngenerative and modern ID-based models, while retaining the benefits of the\ngenerative paradigm.", "AI": {"tldr": "COSETTE and MARIUS enhance generative recommender systems, improving accuracy and efficiency, and reducing the performance gap with traditional models.", "motivation": "Improve generative recommender systems by addressing the lack of collaborative signal and inefficiencies in current generative methods.", "method": "Introduced COSETTE, a contrastive tokenization method, and MARIUS, a generative model that separates timeline modeling from item decoding.", "result": "Our proposed approach improves recommendation accuracy and reduces inference cost, making generative recommender systems more competitive with ID-based models.", "conclusion": "COSETTE and MARIUS effectively address the limitations of generative recommender systems, closing the performance gap with ID-based models while maintaining generative benefits."}}
{"id": "2508.14911", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14911", "abs": "https://arxiv.org/abs/2508.14911", "authors": ["Bahar Boroomand", "James R. Wright"], "title": "Personalized Recommendations via Active Utility-based Pairwise Sampling", "comment": null, "summary": "Recommender systems play a critical role in enhancing user experience by\nproviding personalized suggestions based on user preferences. Traditional\napproaches often rely on explicit numerical ratings or assume access to fully\nranked lists of items. However, ratings frequently fail to capture true\npreferences due to users' behavioral biases and subjective interpretations of\nrating scales, while eliciting full rankings is demanding and impractical. To\novercome these limitations, we propose a generalized utility-based framework\nthat learns preferences from simple and intuitive pairwise comparisons. Our\napproach is model-agnostic and designed to optimize for arbitrary,\ntask-specific utility functions, allowing the system's objective to be\nexplicitly aligned with the definition of a high-quality outcome in any given\napplication. A central contribution of our work is a novel utility-based active\nsampling strategy for preference elicitation. This method selects queries that\nare expected to provide the greatest improvement to the utility of the final\nrecommended outcome. We ground our preference model in the probabilistic\nPlackett-Luce framework for pairwise data. To demonstrate the versatility of\nour approach, we present two distinct experiments: first, an implementation\nusing matrix factorization for a classic movie recommendation task, and second,\nan implementation using a neural network for a complex candidate selection\nscenario in university admissions. Experimental results demonstrate that our\nframework provides a more accurate, data-efficient, and user-centric paradigm\nfor personalized ranking.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6548\u7528\u7684\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u6210\u5bf9\u6bd4\u8f83\u6765\u6539\u8fdb\u4e2a\u6027\u5316\u63a8\u8350\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u63d0\u4f9b\u4e86\u66f4\u7528\u6237\u53cb\u597d\u7684\u4f53\u9a8c\u3002", "motivation": "\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u4f9d\u8d56\u4e8e\u660e\u786e\u7684\u8bc4\u5206\u6216\u5b8c\u5168\u6392\u5e8f\u7684\u7269\u54c1\u5217\u8868\uff0c\u8fd9\u79cd\u65b9\u6cd5\u7531\u4e8e\u7528\u6237\u884c\u4e3a\u504f\u89c1\u548c\u8bc4\u5206\u5c3a\u5ea6\u7684\u4e3b\u89c2\u89e3\u91ca\uff0c\u5f80\u5f80\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u7528\u6237\u771f\u5b9e\u7684\u504f\u597d\u3002\u540c\u65f6\uff0c\u83b7\u53d6\u5b8c\u6574\u7684\u6392\u540d\u4e5f\u975e\u5e38\u7e41\u7410\u4e14\u4e0d\u73b0\u5b9e\u3002\u56e0\u6b64\uff0c\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b80\u5355\u800c\u76f4\u89c2\u7684\u6210\u5bf9\u6bd4\u8f83\u7684\u6cdb\u5316\u6548\u7528\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6548\u7528\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u7b80\u5355\u7684\u6210\u5bf9\u6bd4\u8f83\u6765\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4e8e\u5177\u4f53\u6a21\u578b\uff0c\u5e76\u4e14\u8bbe\u8ba1\u7528\u4e8e\u4f18\u5316\u4efb\u610f\u3001\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u6548\u7528\u51fd\u6570\u3002\u5176\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6548\u7528\u4e3b\u52a8\u91c7\u6837\u7b56\u7565\u6765\u83b7\u53d6\u504f\u597d\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u6570\u636e\u6548\u7387\uff0c\u540c\u65f6\u589e\u5f3a\u7528\u6237\u4f53\u9a8c\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u9a8c\uff0c\u8be5\u6cdb\u5316\u6548\u7528\u6846\u67b6\u5728\u7535\u5f71\u63a8\u8350\u548c\u5927\u5b66\u7533\u8bf7\u573a\u666f\u4e2d\u90fd\u8868\u73b0\u51fa\u8272\u3002\u8fd9\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u4e00\u79cd\u66f4\u51c6\u786e\u3001\u6570\u636e\u9ad8\u6548\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u4e2a\u6027\u5316\u6392\u540d\u6a21\u5f0f\u3002"}}
{"id": "2508.14912", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.14912", "abs": "https://arxiv.org/abs/2508.14912", "authors": ["Yalong Guan", "Xiang Chen", "Mingyang Wang", "Xiangyu Wu", "Lihao Liu", "Chao Qi", "Shuang Yang", "Tingting Gao", "Guorui Zhou", "Changjian Chen"], "title": "Multimodal Recommendation via Self-Corrective Preference Alignmen", "comment": null, "summary": "With the rapid growth of live streaming platforms, personalized\nrecommendation systems have become pivotal in improving user experience and\ndriving platform revenue. The dynamic and multimodal nature of live streaming\ncontent (e.g., visual, audio, textual data) requires joint modeling of user\nbehavior and multimodal features to capture evolving author characteristics.\nHowever, traditional methods relying on single-modal features or treating\nmultimodal ones as supplementary struggle to align users' dynamic preferences\nwith authors' multimodal attributes, limiting accuracy and interpretability. To\naddress this, we propose MSPA (Multimodal Self-Corrective Preference\nAlignment), a personalized author recommendation framework with two components:\n(1) a Multimodal Preference Composer that uses MLLMs to generate structured\npreference text and embeddings from users' tipping history; and (2) a\nSelf-Corrective Preference Alignment Recommender that aligns these preferences\nwith authors' multimodal features to improve accuracy and interpretability.\nExtensive experiments and visualizations show that MSPA significantly improves\naccuracy, recall, and text quality, outperforming baselines in dynamic live\nstreaming scenarios.", "AI": {"tldr": "MSPA\u6846\u67b6\u901a\u8fc7\u81ea\u6211\u6821\u6b63\u65b9\u6cd5\u548c\u591a\u6a21\u6001\u6570\u636e\u7ec4\u5408\uff0c\u63d0\u5347\u4e86\u76f4\u64ad\u5e73\u53f0\u4e2a\u6027\u5316\u63a8\u8350\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u968f\u7740\u76f4\u64ad\u5e73\u53f0\u7684\u5feb\u901f\u589e\u957f\uff0c\u4e2a\u6027\u5316\u63a8\u8350\u7cfb\u7edf\u5728\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u548c\u63a8\u52a8\u5e73\u53f0\u6536\u5165\u65b9\u9762\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u5bf9\u9f50\u7528\u6237\u7684\u52a8\u6001\u504f\u597d\uff0c\u540c\u65f6\u8003\u8651\u5230\u76f4\u64ad\u5185\u5bb9\u7684\u591a\u6a21\u6001\u7279\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u63a8\u8350\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u540d\u4e3aMSPA\u7684\u4e2a\u6027\u5316\u63a8\u8350\u6846\u67b6\uff0c\u5305\u62ec\u4e24\u4e2a\u7ec4\u4ef6\uff1a\uff081\uff09\u5229\u7528MLLMs\u751f\u6210\u7ed3\u6784\u5316\u504f\u597d\u6587\u672c\u548c\u5d4c\u5165\u7684\u591a\u6a21\u6001\u504f\u597d\u7ec4\u5408\u5668\uff1b\uff082\uff09\u80fd\u591f\u6821\u6b63\u504f\u597d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u51c6\u786e\u6027\u7684\u81ea\u6211\u6821\u6b63\u63a8\u8350\u5668\u3002", "result": "MSPA\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3001\u53ec\u56de\u7387\u548c\u6587\u672c\u8d28\u91cf\uff0c\u5728\u52a8\u6001\u76f4\u64ad\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "\u901a\u8fc7MSPA\uff0c\u4e2a\u6027\u5316\u63a8\u8350\u53d8\u5f97\u66f4\u52a0\u51c6\u786e\u548c\u53ef\u89e3\u91ca\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u4e0d\u8db3\u3002"}}
{"id": "2508.15262", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15262", "abs": "https://arxiv.org/abs/2508.15262", "authors": ["Lining Chen", "Qingwen Zeng", "Huaming Chen"], "title": "M-$LLM^3$REC: A Motivation-Aware User-Item Interaction Framework for Enhancing Recommendation Accuracy with LLMs", "comment": "10pages", "summary": "Recommendation systems have been essential for both user experience and\nplatform efficiency by alleviating information overload and supporting\ndecision-making. Traditional methods, i.e., content-based filtering,\ncollaborative filtering, and deep learning, have achieved impressive results in\nrecommendation systems. However, the cold-start and sparse-data scenarios are\nstill challenging to deal with. Existing solutions either generate\npseudo-interaction sequence, which often introduces redundant or noisy signals,\nor rely heavily on semantic similarity, overlooking dynamic shifts in user\nmotivation. To address these limitations, this paper proposes a novel\nrecommendation framework, termed M-$LLM^3$REC, which leverages large language\nmodels for deep motivational signal extraction from limited user interactions.\nM-$LLM^3$REC comprises three integrated modules: the Motivation-Oriented\nProfile Extractor (MOPE), Motivation-Oriented Trait Encoder (MOTE), and\nMotivational Alignment Recommender (MAR). By emphasizing motivation-driven\nsemantic modeling, M-$LLM^3$REC demonstrates robust, personalized, and\ngeneralizable recommendations, particularly boosting performance in cold-start\nsituations in comparison with the state-of-the-art frameworks.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86M-$LLM^3$REC\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u673a\u9a71\u52a8\u7684\u8bed\u4e49\u5efa\u6a21\uff0c\u4ece\u6709\u9650\u7528\u6237\u4e92\u52a8\u4e2d\u63d0\u53d6\u6df1\u5c42\u52a8\u673a\u4fe1\u53f7\uff0c\u663e\u8457\u6539\u5584\u51b7\u542f\u52a8\u60c5\u51b5\u4e0b\u7684\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u5728\u51b7\u542f\u52a8\u548c\u6570\u636e\u7a00\u758f\u60c5\u51b5\u4e0b\u8868\u73b0\u6709\u9650\uff0c\u901a\u5e38\u751f\u6210\u4f2a\u4ea4\u4e92\u5e8f\u5217\u6216\u8fc7\u5ea6\u4f9d\u8d56\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u5ffd\u89c6\u7528\u6237\u52a8\u673a\u7684\u52a8\u6001\u53d8\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aM-$LLM^3$REC\u7684\u65b0\u63a8\u8350\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u6709\u9650\u7684\u7528\u6237\u4e92\u52a8\u4e2d\u63d0\u53d6\u6df1\u5c42\u52a8\u673a\u4fe1\u53f7\uff0c\u5305\u62ec\u4e09\u4e2a\u6a21\u5757\uff1a\u52a8\u673a\u5bfc\u5411\u7684\u6863\u6848\u63d0\u53d6\u5668\uff08MOPE\uff09\u3001\u52a8\u673a\u5bfc\u5411\u7684\u7279\u8d28\u7f16\u7801\u5668\uff08MOTE\uff09\u548c\u52a8\u673a\u5bf9\u9f50\u63a8\u8350\u5668\uff08MAR\uff09\u3002", "result": "M-$LLM^3$REC\u5728\u51b7\u542f\u52a8\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u4f9b\u5f3a\u5927\u3001\u4e2a\u6027\u5316\u548c\u53ef\u63a8\u5e7f\u7684\u63a8\u8350\u6027\u80fd\uff0c\u6bd4\u73b0\u6709\u7684\u6700\u5148\u8fdb\u6846\u67b6\u6548\u679c\u66f4\u597d\u3002", "conclusion": "M-$LLM^3$REC\u901a\u8fc7\u52a8\u673a\u9a71\u52a8\u7684\u8bed\u4e49\u5efa\u6a21\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u51b7\u542f\u52a8\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2508.15263", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.15263", "abs": "https://arxiv.org/abs/2508.15263", "authors": ["Liu Yang", "Zhaochun Ren", "Ziqi Zhao", "Pengjie Ren", "Zhumin Chen", "Xinyi Li", "Shuaiqiang Wang", "Dawei Yin", "Xin Xin"], "title": "Curriculum Approximate Unlearning for Session-based Recommendation", "comment": null, "summary": "Approximate unlearning for session-based recommendation refers to eliminating\nthe influence of specific training samples from the recommender without\nretraining of (sub-)models. Gradient ascent (GA) is a representative method to\nconduct approximate unlearning. However, there still exist dual challenges to\napply GA for session-based recommendation. On the one hand, naive applying of\nGA could lead to degradation of recommendation performance. On the other hand,\nexisting studies fail to consider the ordering of unlearning samples when\nsimultaneously processing multiple unlearning requests, leading to sub-optimal\nrecommendation performance and unlearning effect. To address the above\nchallenges, we introduce CAU, a curriculum approximate unlearning framework\ntailored to session-based recommendation. CAU handles the unlearning task with\na GA term on unlearning samples. Specifically, to address the first challenge,\nCAU formulates the overall optimization task as a multi-objective optimization\nproblem, where the GA term for unlearning samples is combined with retaining\nterms for preserving performance. The multi-objective optimization problem is\nsolved through seeking the Pareto-Optimal solution, which achieves effective\nunlearning with trivial sacrifice on recommendation performance. To tackle the\nsecond challenge, CAU adopts a curriculum-based sequence to conduct unlearning\non batches of unlearning samples. The key motivation is to perform unlearning\nfrom easy samples to harder ones. To this end, CAU first introduces two metrics\nto measure the unlearning difficulty, including gradient unlearning difficulty\nand embedding unlearning difficulty. Then, two strategies, hard-sampling and\nsoft-sampling, are proposed to select unlearning samples according to\ndifficulty scores.", "AI": {"tldr": "CAU\u6846\u67b6\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u548c\u9010\u6b65\u53d6\u6d88\u5b66\u4e60\u5904\u7406\u4f1a\u8bdd\u63a8\u8350\u4e2d\u7684\u8bad\u7ec3\u6837\u672c\u95ee\u9898\uff0c\u63d0\u5347\u53d6\u6d88\u5b66\u4e60\u6548\u679c\u540c\u65f6\u4fdd\u6301\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u5728\u5904\u7406\u591a\u4e2a\u53d6\u6d88\u5b66\u4e60\u8bf7\u6c42\u65f6\u6ca1\u6709\u8003\u8651\u6837\u672c\u6392\u5e8f\uff0c\u5bfc\u81f4\u63a8\u8350\u6027\u80fd\u548c\u53d6\u6d88\u5b66\u4e60\u6548\u679c\u4e0d\u4f73\u3002\u6b64\u5916\uff0c\u7b80\u5355\u5e94\u7528GA\u53ef\u80fd\u4f1a\u5bfc\u81f4\u63a8\u8350\u6027\u80fd\u4e0b\u964d\u3002", "method": "CAU\u6846\u67b6\u63d0\u51fa\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u5c06GA\u672f\u8bed\u5728\u4e0d\u5f71\u54cd\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u4e0e\u4fdd\u7559\u672f\u8bed\u7ed3\u5408\uff0c\u5e76\u901a\u8fc7\u83b7\u5f97Pareto-Optimal\u89e3\u6765\u89e3\u51b3\u95ee\u9898\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u8bfe\u7a0b\u7684\u5e8f\u5217\u6765\u8fdb\u884c\u6279\u91cf\u5b66\u4e60\uff0c\u91c7\u7528\u4e24\u4e2a\u6307\u6807\u6765\u8861\u91cf\u53d6\u6d88\u5b66\u4e60\u7684\u96be\u5ea6\uff0c\u63d0\u51fa\u4e86hard-sampling\u548csoft-sampling\u7b56\u7565\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6709\u6548\u8fdb\u884c\u53d6\u6d88\u5b66\u4e60\u7684\u540c\u65f6\uff0c\u4ec5\u5bf9\u63a8\u8350\u6027\u80fd\u9020\u6210\u4e86\u5fae\u5c0f\u7684\u5f71\u54cd\u3002", "conclusion": "CAU\u6846\u67b6\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u548c\u57fa\u4e8e\u8bfe\u7a0b\u5b66\u4e60\u7684\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u4e86GA\u5728\u4f1a\u8bdd\u63a8\u8350\u4e2d\u7684\u6027\u80fd\u4e0b\u964d\u548c\u6837\u672c\u6392\u5e8f\u95ee\u9898\u3002"}}
{"id": "2508.15281", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15281", "abs": "https://arxiv.org/abs/2508.15281", "authors": ["Yi Xu", "Moyu Zhang", "Chenxuan Li", "Zhihao Liao", "Haibo Xing", "Hao Deng", "Jinxin Hu", "Yu Zhang", "Xiaoyi Zeng", "Jing Zhang"], "title": "MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation", "comment": null, "summary": "Recommender systems traditionally represent items using unique identifiers\n(ItemIDs), but this approach struggles with large, dynamic item corpora and\nsparse long-tail data, limiting scalability and generalization. Semantic IDs,\nderived from multimodal content such as text and images, offer a promising\nalternative by mapping items into a shared semantic space, enabling knowledge\ntransfer and improving recommendations for new or rare items. However, existing\nmethods face two key challenges: (1) balancing cross-modal synergy with\nmodality-specific uniqueness, and (2) bridging the semantic-behavioral gap,\nwhere semantic representations may misalign with actual user preferences. To\naddress these challenges, we propose Multimodal Mixture-of-Quantization (MMQ),\na two-stage framework that trains a novel multimodal tokenizer. First, a\nshared-specific tokenizer leverages a multi-expert architecture with\nmodality-specific and modality-shared experts, using orthogonal regularization\nto capture comprehensive multimodal information. Second, behavior-aware\nfine-tuning dynamically adapts semantic IDs to downstream recommendation\nobjectives while preserving modality information through a multimodal\nreconstruction loss. Extensive offline experiments and online A/B tests\ndemonstrate that MMQ effectively unifies multimodal synergy, specificity, and\nbehavioral adaptation, providing a scalable and versatile solution for both\ngenerative retrieval and discriminative ranking tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u591a\u6a21\u6001\u91cf\u5316\u6df7\u5408\uff08MMQ\uff09\u6846\u67b6\u6765\u6539\u8fdb\u63a8\u8350\u7cfb\u7edf\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u8bed\u4e49\u8868\u793a\u4e0e\u7528\u6237\u504f\u597d\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u4f7f\u7528\u552f\u4e00\u6807\u8bc6\u7b26(ItemIDs)\u6765\u8868\u793a\u9879\u76ee\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5728\u5904\u7406\u5927\u578b\u52a8\u6001\u9879\u76ee\u5e93\u548c\u7a00\u758f\u957f\u5c3e\u6570\u636e\u65f6\u663e\u5f97\u4e4f\u529b\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u6587\u4e2d\u7684\u52a8\u673a\u662f\u901a\u8fc7\u8bed\u4e49ID\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u6846\u67b6\u6765\u5e94\u5bf9\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u4e24\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u6a21\u6001\u91cf\u5316\u6df7\u5408\uff08MMQ\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u8bad\u7ec3\u65b0\u578b\u591a\u6a21\u6001\u5206\u8bcd\u5668\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\u3002", "result": "MMQ\u901a\u8fc7\u5e7f\u6cdb\u7684\u79bb\u7ebf\u5b9e\u9a8c\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "MMQ\u5728\u7edf\u4e00\u591a\u6a21\u6001\u534f\u540c\u3001\u7279\u5f02\u6027\u548c\u884c\u4e3a\u9002\u5e94\u65b9\u9762\u5177\u6709\u6548\u529b\uff0c\u63d0\u4f9b\u4e86\u7528\u4e8e\u751f\u6210\u68c0\u7d22\u548c\u5224\u522b\u6392\u540d\u4efb\u52a1\u7684\u53ef\u6269\u5c55\u4e14\u591a\u529f\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15283", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15283", "abs": "https://arxiv.org/abs/2508.15283", "authors": ["Amin Bigdeli", "Negar Arabzadeh", "Ebrahim Bagheri", "Charles L. A. Clarke"], "title": "Adversarial Attacks against Neural Ranking Models via In-Context Learning", "comment": null, "summary": "While neural ranking models (NRMs) have shown high effectiveness, they remain\nsusceptible to adversarial manipulation. In this work, we introduce Few-Shot\nAdversarial Prompting (FSAP), a novel black-box attack framework that leverages\nthe in-context learning capabilities of Large Language Models (LLMs) to\ngenerate high-ranking adversarial documents. Unlike previous approaches that\nrely on token-level perturbations or manual rewriting of existing documents,\nFSAP formulates adversarial attacks entirely through few-shot prompting,\nrequiring no gradient access or internal model instrumentation. By conditioning\nthe LLM on a small support set of previously observed harmful examples, FSAP\nsynthesizes grammatically fluent and topically coherent documents that subtly\nembed false or misleading information and rank competitively against authentic\ncontent. We instantiate FSAP in two modes: FSAP-IntraQ, which leverages harmful\nexamples from the same query to enhance topic fidelity, and FSAP-InterQ, which\nenables broader generalization by transferring adversarial patterns across\nunrelated queries. Our experiments on the TREC 2020 and 2021 Health\nMisinformation Tracks, using four diverse neural ranking models, reveal that\nFSAP-generated documents consistently outrank credible, factually accurate\ndocuments. Furthermore, our analysis demonstrates that these adversarial\noutputs exhibit strong stance alignment and low detectability, posing a\nrealistic and scalable threat to neural retrieval systems. FSAP also\neffectively generalizes across both proprietary and open-source LLMs.", "AI": {"tldr": "\u5f15\u5165\u4e86\u5c11\u6837\u672c\u5bf9\u6297\u6027\u63d0\u793a(FSAP)\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u6392\u540d\u7684\u5bf9\u6297\u6027\u6587\u6863\uff0c\u6210\u529f\u8d85\u8fc7\u51c6\u786e\u6587\u6863\u7684\u6392\u540d\uff0c\u5177\u5907\u73b0\u5b9e\u53ef\u64cd\u4f5c\u6027\u3002", "motivation": "\u795e\u7ecf\u6392\u5e8f\u6a21\u578b\u867d\u7136\u6709\u6548\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u653b\u51fb\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9ed1\u76d2\u653b\u51fb\u6846\u67b6\uff0c\u5373\u5c11\u6837\u672c\u5bf9\u6297\u6027\u63d0\u793a\uff08FSAP\uff09\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u751f\u6210\u9ad8\u6392\u540d\u7684\u5bf9\u6297\u6027\u6587\u6863\u3002", "method": "FSAP\u901a\u8fc7\u5c11\u6837\u672c\u63d0\u793a\u8fdb\u884c\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u65e0\u9700\u68af\u5ea6\u8bbf\u95ee\u6216\u5185\u90e8\u6a21\u578b\u4eea\u5668\u3002\u901a\u8fc7\u5728\u4e00\u4e2a\u5c0f\u652f\u6301\u96c6\u4e0a\u6761\u4ef6\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u7efc\u5408\u751f\u6210\u6587\u6cd5\u6d41\u7545\u548c\u4e3b\u9898\u8fde\u8d2f\u7684\u6587\u6863\u3002\u5206\u4e3aFSAP-IntraQ\u548cFSAP-InterQ\u4e24\u79cd\u6a21\u5f0f\u3002", "result": "FSAP\u751f\u6210\u7684\u6587\u6863\u5728TREC 2020\u548c2021\u5065\u5eb7\u9519\u8bef\u4fe1\u606f\u8f68\u9053\u4e0a\u4f7f\u7528\u56db\u79cd\u4e0d\u540c\u7684\u795e\u7ecf\u6392\u5e8f\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u8868\u73b0\u51fa\u6301\u7eed\u8d85\u8fc7\u53ef\u4fe1\u7684\u51c6\u786e\u6587\u6863\u7684\u6392\u540d\uff0c\u5e76\u5177\u6709\u5f3a\u7684\u7acb\u573a\u4e00\u81f4\u6027\u548c\u4f4e\u53ef\u68c0\u6d4b\u6027\u3002", "conclusion": "FSAP\u63d0\u51fa\u4e00\u79cd\u73b0\u5b9e\u4e14\u53ef\u6269\u5c55\u7684\u5a01\u80c1\uff0c\u8fd9\u79cd\u65b9\u6cd5\u6709\u6548\u5730\u5728\u4e13\u6709\u548c\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e4b\u95f4\u8fdb\u884c\u6cdb\u5316\u3002"}}
{"id": "2508.15304", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.15304", "abs": "https://arxiv.org/abs/2508.15304", "authors": ["Yuzhuo Dang", "Xin Zhang", "Zhiqiang Pan", "Yuxiao Duan", "Wanyu Chen", "Fei Cai", "Honghui Chen"], "title": "MLLMRec: Exploring the Potential of Multimodal Large Language Models in Recommender Systems", "comment": null, "summary": "Multimodal recommendation typically combines the user behavioral data with\nthe modal features of items to reveal user's preference, presenting superior\nperformance compared to the conventional recommendations. However, existing\nmethods still suffer from two key problems: (1) the initialization methods of\nuser multimodal representations are either behavior-unperceived or\nnoise-contaminated, and (2) the KNN-based item-item graph contains noisy edges\nwith low similarities and lacks audience co-occurrence relationships. To\naddress such issues, we propose MLLMRec, a novel MLLM-driven multimodal\nrecommendation framework with two item-item graph refinement strategies. On the\none hand, the item images are first converted into high-quality semantic\ndescriptions using an MLLM, which are then fused with the textual metadata of\nitems. Then, we construct a behavioral description list for each user and feed\nit into the MLLM to reason about the purified user preference containing\ninteraction motivations. On the other hand, we design the threshold-controlled\ndenoising and topology-aware enhancement strategies to refine the suboptimal\nitem-item graph, thereby enhancing the item representation learning. Extensive\nexperiments on three publicly available datasets demonstrate that MLLMRec\nachieves the state-of-the-art performance with an average improvement of 38.53%\nover the best baselines.", "AI": {"tldr": "MLLMRec\u901a\u8fc7\u6539\u8fdb\u7528\u6237\u8868\u793a\u548c\u53bb\u566a\u7269\u54c1\u56fe\u7684\u65b9\u6cd5\uff0c\u5728\u591a\u6a21\u6001\u63a8\u8350\u4e2d\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4f18\u4e8e\u65e2\u6709\u65b9\u6cd5\u3002", "motivation": "\u591a\u6a21\u6001\u63a8\u8350\u7ed3\u5408\u7528\u6237\u884c\u4e3a\u6570\u636e\u548c\u7269\u54c1\u7684\u591a\u6a21\u6001\u7279\u5f81\uff0c\u8f83\u4f20\u7edf\u63a8\u8350\u5177\u6709\u66f4\u4f18\u8d8a\u7684\u8868\u73b0\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u7528\u6237\u591a\u6a21\u6001\u8868\u793a\u521d\u59cb\u5316\u4e0d\u51c6\u786e\u548c\u7269\u54c1-\u7269\u54c1\u56fe\u542b\u566a\u58f0\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faMLLMRec\u6846\u67b6\uff0c\u901a\u8fc7MLLM\u5c06\u7269\u54c1\u56fe\u50cf\u8f6c\u6362\u4e3a\u9ad8\u8d28\u91cf\u8bed\u4e49\u63cf\u8ff0\uff0c\u5e76\u4e0e\u7269\u54c1\u7684\u6587\u672c\u4fe1\u606f\u878d\u5408\uff1b\u6784\u5efa\u7528\u6237\u7684\u884c\u4e3a\u63cf\u8ff0\u5217\u8868\uff0c\u8f93\u5165MLLM\u63a8\u7406\u7528\u6237\u504f\u597d\uff1b\u8bbe\u8ba1\u63a7\u5236\u9608\u503c\u53bb\u566a\u548c\u62d3\u6251\u589e\u5f3a\u7b56\u7565\u4f18\u5316\u7269\u54c1-\u7269\u54c1\u56fe\u3002", "result": "MLLMRec\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u591a\u4e2a\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u8fc7\u53bb\u7684\u63a8\u8350\u65b9\u6cd5\uff0c\u53d6\u5f97\u4e86\u5e73\u574738.53%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "MLLMRec\u6846\u67b6\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u591a\u6a21\u6001\u63a8\u8350\u7684\u6027\u80fd\uff0c\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5176\u8868\u73b0\u4f18\u4e8e\u76ee\u524d\u6700\u597d\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e73\u5747\u63d0\u5347\u5e45\u5ea6\u8fbe\u523038.53%\u3002"}}
{"id": "2508.15308", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.15308", "abs": "https://arxiv.org/abs/2508.15308", "authors": ["Haibo Xing", "Hao Deng", "Yucheng Mao", "Jinxin Hu", "Yi Xu", "Hao Zhang", "Jiahao Wang", "Shizhun Wang", "Yu Zhang", "Xiaoyi Zeng", "Jing Zhang"], "title": "REG4Rec: Reasoning-Enhanced Generative Model for Large-Scale Recommendation Systems", "comment": null, "summary": "Sequential recommendation aims to predict a user's next action in large-scale\nrecommender systems. While traditional methods often suffer from insufficient\ninformation interaction, recent generative recommendation models partially\naddress this issue by directly generating item predictions. To better capture\nuser intents, recent studies have introduced a reasoning process into\ngenerative recommendation, significantly improving recommendation performance.\nHowever, these approaches are constrained by the singularity of item semantic\nrepresentations, facing challenges such as limited diversity in reasoning\npathways and insufficient reliability in the reasoning process. To tackle these\nissues, we introduce REG4Rec, a reasoning-enhanced generative model that\nconstructs multiple dynamic semantic reasoning paths alongside a\nself-reflection process, ensuring high-confidence recommendations.\nSpecifically, REG4Rec utilizes an MoE-based parallel quantization codebook\n(MPQ) to generate multiple unordered semantic tokens for each item, thereby\nconstructing a larger-scale diverse reasoning space. Furthermore, to enhance\nthe reliability of reasoning, we propose a training reasoning enhancement\nstage, which includes Preference Alignment for Reasoning (PARS) and a\nMulti-Step Reward Augmentation (MSRA) strategy. PARS uses reward functions\ntailored for recommendation to enhance reasoning and reflection, while MSRA\nintroduces future multi-step actions to improve overall generalization. During\ninference, Consistency-Oriented Self-Reflection for Pruning (CORP) is proposed\nto discard inconsistent reasoning paths, preventing the propagation of\nerroneous reasoning. Lastly, we develop an efficient offline training strategy\nfor large-scale recommendation. Experiments on real-world datasets and online\nevaluations show that REG4Rec delivers outstanding performance and substantial\npractical value.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86REG4Rec\uff0c\u4e00\u4e2a\u589e\u5f3a\u63a8\u7406\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u52a8\u6001\u8bed\u4e49\u63a8\u7406\u8def\u5f84\u548c\u81ea\u6211\u53cd\u601d\u8fc7\u7a0b\u5b9e\u73b0\u9ad8\u7f6e\u4fe1\u5ea6\u63a8\u8350\u5e76\u63d0\u9ad8\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u63a8\u8350\u65b9\u6cd5\u901a\u5e38\u5728\u4fe1\u606f\u4ea4\u4e92\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\uff0c\u800c\u751f\u6210\u63a8\u8350\u6a21\u578b\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u4ecd\u9762\u4e34\u63a8\u7406\u8def\u5f84\u591a\u6837\u6027\u6709\u9650\u548c\u63a8\u7406\u8fc7\u7a0b\u4e0d\u591f\u53ef\u9760\u7684\u6311\u6218\u3002", "method": "REG4Rec\u6a21\u578b\u5229\u7528\u57fa\u4e8eMoE\u7684\u5e76\u884c\u91cf\u5316\u7801\u4e66\u751f\u6210\u6bcf\u4e2a\u9879\u76ee\u7684\u591a\u4e2a\u65e0\u5e8f\u8bed\u4e49\u6807\u8bb0\uff0c\u4ece\u800c\u6784\u5efa\u66f4\u5927\u89c4\u6a21\u7684\u591a\u6837\u5316\u63a8\u7406\u7a7a\u95f4\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u589e\u5f3a\u63a8\u7406\u7684\u53ef\u9760\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u62ecPARS\uff08Reasoning\u504f\u597d\u5bf9\u9f50\uff09\u548cMSRA\uff08\u591a\u6b65\u5956\u52b1\u589e\u5f3a\uff09\u7b56\u7565\u7684\u8bad\u7ec3\u63a8\u7406\u589e\u5f3a\u9636\u6bb5\u3002PARS\u4f7f\u7528\u9488\u5bf9\u63a8\u8350\u7684\u5956\u52b1\u51fd\u6570\u6765\u589e\u5f3a\u63a8\u7406\u548c\u53cd\u601d\uff0c\u800cMSRA\u5f15\u5165\u672a\u6765\u591a\u6b65\u52a8\u4f5c\u4ee5\u63d0\u9ad8\u603b\u4f53\u6cdb\u5316\u3002\u63a8\u7406\u65f6\uff0c\u63d0\u51fa\u4e86CORP\uff08\u4e00\u81f4\u6027\u5bfc\u5411\u81ea\u6211\u53cd\u601d\u4fee\u526a\uff09\u6765\u4e22\u5f03\u4e0d\u4e00\u81f4\u7684\u63a8\u7406\u8def\u5f84\uff0c\u9632\u6b62\u9519\u8bef\u63a8\u7406\u7684\u4f20\u64ad\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cREG4Rec\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u548c\u5728\u7ebf\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u5907\u663e\u8457\u7684\u5b9e\u9645\u4ef7\u503c\u3002", "conclusion": "REG4Rec delivers outstanding performance and substantial practical value."}}
{"id": "2508.15311", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.15311", "abs": "https://arxiv.org/abs/2508.15311", "authors": ["Weijiang Lai", "Beihong Jin", "Yapeng Zhang", "Yiyuan Zheng", "Rui Zhao", "Jian Dong", "Jun Lei", "Xingxing Wang"], "title": "Modeling Long-term User Behaviors with Diffusion-driven Multi-interest Network for CTR Prediction", "comment": null, "summary": "CTR (Click-Through Rate) prediction, crucial for recommender systems and\nonline advertising, etc., has been confirmed to benefit from modeling long-term\nuser behaviors. Nonetheless, the vast number of behaviors and complexity of\nnoise interference pose challenges to prediction efficiency and effectiveness.\nRecent solutions have evolved from single-stage models to two-stage models.\nHowever, current two-stage models often filter out significant information,\nresulting in an inability to capture diverse user interests and build the\ncomplete latent space of user interests. Inspired by multi-interest and\ngenerative modeling, we propose DiffuMIN (Diffusion-driven Multi-Interest\nNetwork) to model long-term user behaviors and thoroughly explore the user\ninterest space. Specifically, we propose a target-oriented multi-interest\nextraction method that begins by orthogonally decomposing the target to obtain\ninterest channels. This is followed by modeling the relationships between\ninterest channels and user behaviors to disentangle and extract multiple user\ninterests. We then adopt a diffusion module guided by contextual interests and\ninterest channels, which anchor users' personalized and target-oriented\ninterest types, enabling the generation of augmented interests that align with\nthe latent spaces of user interests, thereby further exploring restricted\ninterest space. Finally, we leverage contrastive learning to ensure that the\ngenerated augmented interests align with users' genuine preferences. Extensive\noffline experiments are conducted on two public datasets and one industrial\ndataset, yielding results that demonstrate the superiority of DiffuMIN.\nMoreover, DiffuMIN increased CTR by 1.52% and CPM by 1.10% in online A/B\ntesting. Our source code is available at\nhttps://github.com/laiweijiang/DiffuMIN.", "AI": {"tldr": "\u63d0\u51fa\u4e86DiffuMIN\uff0c\u7ed3\u5408\u591a\u5174\u8da3\u63d0\u53d6\u4e0e\u6269\u6563\u6a21\u5757\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u6349\u957f\u671f\u7528\u6237\u884c\u4e3a\u5e76\u63d0\u5347CTR\u9884\u6d4b\u6027\u80fd\uff0c\u83b7\u5f97\u4e86\u663e\u8457\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u4e24\u9636\u6bb5\u6a21\u578b\u901a\u5e38\u4f1a\u8fc7\u6ee4\u6389\u91cd\u8981\u7684\u4fe1\u606f\uff0c\u65e0\u6cd5\u6355\u6349\u5230\u591a\u6837\u7684\u7528\u6237\u5174\u8da3\u3002\u56e0\u6b64\uff0c\u63d0\u51faDiffuMIN\u4ee5\u6539\u8fdb\u957f\u671f\u7528\u6237\u884c\u4e3a\u5efa\u6a21\u5e76\u66f4\u5168\u9762\u63a2\u7d22\u7528\u6237\u5174\u8da3\u7a7a\u95f4\u3002", "method": "\u63d0\u51fa\u76ee\u6807\u5bfc\u5411\u7684\u591a\u5174\u8da3\u63d0\u53d6\u65b9\u6cd5\uff0c\u901a\u8fc7\u6b63\u4ea4\u5206\u89e3\u76ee\u6807\u83b7\u5f97\u5174\u8da3\u9891\u9053\uff0c\u968f\u540e\u5efa\u6a21\u5174\u8da3\u9891\u9053\u4e0e\u7528\u6237\u884c\u4e3a\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u91c7\u7528\u6269\u6563\u6a21\u5757\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u5174\u8da3\u548c\u5174\u8da3\u9891\u9053\uff0c\u751f\u6210\u7b26\u5408\u7528\u6237\u6f5c\u5728\u7a7a\u95f4\u7684\u6269\u5c55\u5174\u8da3\uff0c\u540c\u65f6\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u786e\u4fdd\u751f\u6210\u7684\u5174\u8da3\u4e0e\u7528\u6237\u771f\u5b9e\u504f\u597d\u4e00\u81f4\u3002", "result": "DiffuMIN\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u5de5\u4e1a\u6570\u636e\u96c6\u7684\u79bb\u7ebf\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6548\u679c\uff0c\u5e76\u5728\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u63d0\u9ad8\u4e86CTR 1.52%\u548cCPM 1.10%\u3002", "conclusion": "DiffuMIN\u901a\u8fc7\u5f15\u5165\u591a\u5174\u8da3\u63d0\u53d6\u65b9\u6cd5\u548c\u6269\u6563\u6a21\u5757\uff0c\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u5176\u5728CTR\u9884\u6d4b\u4e2d\u7684\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002"}}
{"id": "2508.15326", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.15326", "abs": "https://arxiv.org/abs/2508.15326", "authors": ["Weijiang Lai", "Beihong Jin", "Jiongyan Zhang", "Yiyuan Zheng", "Jian Dong", "Jia Cheng", "Jun Lei", "Xingxing Wang"], "title": "Exploring Scaling Laws of CTR Model for Online Performance Improvement", "comment": null, "summary": "CTR models play a vital role in improving user experience and boosting\nbusiness revenue in many online personalized services. However, current CTR\nmodels generally encounter bottlenecks in performance improvement. Inspired by\nthe scaling law phenomenon of LLMs, we propose a new paradigm for improving CTR\npredictions: first, constructing a CTR model with accuracy scalable to the\nmodel grade and data size, and then distilling the knowledge implied in this\nmodel into its lightweight model that can serve online users. To put it into\npractice, we construct a CTR model named SUAN (Stacked Unified Attention\nNetwork). In SUAN, we propose the UAB as a behavior sequence encoder. A single\nUAB unifies the modeling of the sequential and non-sequential features and also\nmeasures the importance of each user behavior feature from multiple\nperspectives. Stacked UABs elevate the configuration to a high grade, paving\nthe way for performance improvement. In order to benefit from the high\nperformance of the high-grade SUAN and avoid the disadvantage of its long\ninference time, we modify the SUAN with sparse self-attention and parallel\ninference strategies to form LightSUAN, and then adopt online distillation to\ntrain the low-grade LightSUAN, taking a high-grade SUAN as a teacher. The\ndistilled LightSUAN has superior performance but the same inference time as the\nLightSUAN, making it well-suited for online deployment. Experimental results\nshow that SUAN performs exceptionally well and holds the scaling laws spanning\nthree orders of magnitude in model grade and data size, and the distilled\nLightSUAN outperforms the SUAN configured with one grade higher. More\nimportantly, the distilled LightSUAN has been integrated into an online\nservice, increasing the CTR by 2.81% and CPM by 1.69% while keeping the average\ninference time acceptable. Our source code is available at\nhttps://github.com/laiweijiang/SUAN.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684CTR\u9884\u6d4b\u65b9\u6cd5\uff0c\u5229\u7528SUAN\u6a21\u578b\u53ca\u5176\u84b8\u998f\u7248LightSUAN\u63d0\u9ad8\u5728\u7ebf\u670d\u52a1\u6027\u80fd\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u3002", "motivation": "\u5f53\u524dCTR\u6a21\u578b\u5728\u6027\u80fd\u63d0\u5347\u65b9\u9762\u9047\u5230\u74f6\u9888\uff0c\u53d7LLMs\u7684\u6269\u5c55\u6cd5\u5219\u73b0\u8c61\u542f\u53d1\uff0c\u63d0\u51fa\u65b0\u7684CTR\u9884\u6d4b\u589e\u5f3a\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u901a\u8fc7\u6784\u5efaSUAN\uff08Stacked Unified Attention Network\uff09\u6a21\u578b\uff0c\u5176\u4e2d\u4f7f\u7528UAB\u4f5c\u4e3a\u884c\u4e3a\u5e8f\u5217\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u7a00\u758f\u81ea\u6ce8\u610f\u529b\u4e0e\u5e76\u884c\u63a8\u7406\u7b56\u7565\u5f62\u6210LightSUAN\uff0c\u5e76\u91c7\u7528\u5728\u7ebf\u84b8\u998f\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aSUAN\u6027\u80fd\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5c55\u73b0\u8de8\u8d8a\u4e09\u4e2a\u6570\u91cf\u7ea7\u7684\u6269\u5c55\u6cd5\u5219\u80fd\u529b\uff0cLightSUAN\u5728\u76f8\u540c\u63a8\u7406\u65f6\u95f4\u4e0b\u6027\u80fd\u4f18\u4e8e\u9ad8\u4e00\u7b49\u7ea7\u7684SUAN\uff0c\u5e76\u6709\u6548\u63d0\u9ad8\u5728\u7ebf\u670d\u52a1CTR2.81%\u548cCPM1.69%\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684CTR\u9884\u6d4b\u8303\u5f0f\uff0c\u901a\u8fc7\u6784\u5efa\u51c6\u786e\u7387\u4e0e\u6a21\u578b\u7b49\u7ea7\u548c\u6570\u636e\u89c4\u6a21\u53ef\u6269\u5c55\u7684CTR\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u77e5\u8bc6\u84b8\u998f\u5230\u8f7b\u91cf\u7ea7\u6a21\u578b\u63d0\u9ad8\u5728\u7ebf\u670d\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2508.15388", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.15388", "abs": "https://arxiv.org/abs/2508.15388", "authors": ["Yu Xia", "Rui Zhong", "Zeyu Song", "Wei Yang", "Junchen Wan", "Qingpeng Cai", "Chi Lu", "Peng Jiang"], "title": "TrackRec: Iterative Alternating Feedback with Chain-of-Thought via Preference Alignment for Recommendation", "comment": null, "summary": "The extensive world knowledge and powerful reasoning capabilities of large\nlanguage models (LLMs) have attracted significant attention in recommendation\nsystems (RS). Specifically, The chain of thought (CoT) has been shown to\nimprove the performance of LLMs on complex reasoning tasks for RS. However, due\nto the fact that LLMs often suffer from hallucination issues, there is no\nguarantee that their reasoning CoT is effective. A key challenge is to further\nenhance the recommendation capabilities of LLMs through effective CoT\nreasonings. Therefore, we propose \\textbf{TrackRec}, a framework designed to\nenhance reasoning capabilities of LLMs for RS. TrackRec specifically focuses on\naccurately inferring recommendation CoT \\textbf{(RecCoT)} for user preference\nusing the knowledge from LLMs. This RecCoT can serve both as an explanation for\nthe LLM's completion of recommendation tasks and as auxiliary features to\nassist recommendation models in accomplishing recommendation tasks. TrackRec\nconsists of a RecCoT generator $(G)$ and a RecCoT validator $(V)$. Furthermore,\nwe design alternating feedback learning mechanism that $G$ undergoes direct\npreference optimization via feedback from $V$ to produce increasingly accurate\nRecCoT aligned with $V$'s standards. Meanwhile, $V$ is fine-tuned using the\ninference feedback from $G$ to enhance its validation capabilities in alignment\nwith recommendation tasks. Through iterative alternating feedback learning\nbetween $G$ and $V$, TrackRec continuously improves the user preference\nanalysis capability of $G$ and the validation capacity of $V$. Extensive\nexperiments demonstrate the effectiveness of our approach, showing that it\nsurpasses state-of-the-art methods. Moreover, TrackRec has been deployed on a\nlagre advertising platform with hundreds of millions of users, achieving\nsubstantial gains.", "AI": {"tldr": "\u63d0\u51faTrackRec\u6846\u67b6\uff0c\u6539\u5584\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u53d6\u5f97\u663e\u8457\u6548\u679c\u5e76\u6210\u529f\u90e8\u7f72\u5728\u5927\u578b\u5e7f\u544a\u5e73\u53f0\u4e0a\u3002", "motivation": "\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u514b\u670d\u5176\u5bb9\u6613\u51fa\u73b0\u5e7b\u89c9\u7684\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8\u63a8\u8350\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aTrackRec\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bbe\u8ba1RecCoT\u751f\u6210\u5668(G)\u548c\u9a8c\u8bc1\u5668(V)\uff0c\u5e76\u91c7\u7528\u4ea4\u66ff\u53cd\u9988\u5b66\u4e60\u673a\u5236\u6765\u589e\u5f3a\u63a8\u8350\u63a8\u7406\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\uff0cTrackRec\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u5df2\u5728\u4e00\u4e2a\u62e5\u6709\u6570\u4ebf\u7528\u6237\u7684\u5927\u578b\u5e7f\u544a\u5e73\u53f0\u4e0a\u90e8\u7f72\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6536\u76ca\u3002", "conclusion": "TrackRec\u80fd\u591f\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u8350\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e14\u80fd\u591f\u4e3a\u7528\u6237\u504f\u597d\u63a8\u7406\u63d0\u4f9b\u51c6\u786e\u7684\u94fe\u8def\u601d\u7ef4\uff0c\u540c\u65f6\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u5f88\u597d\u7684\u6548\u679c\u3002"}}
{"id": "2508.15436", "categories": ["cs.IR", "cs.CV", "cs.DB", "cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2508.15436", "abs": "https://arxiv.org/abs/2508.15436", "authors": ["Yutaro Oguri", "Mai Nishimura", "Yusuke Matsui"], "title": "On the Effectiveness of Graph Reordering for Accelerating Approximate Nearest Neighbor Search on GPU", "comment": null, "summary": "We present the first systematic investigation of graph reordering effects for\ngraph-based Approximate Nearest Neighbor Search (ANNS) on a GPU. While\ngraph-based ANNS has become the dominant paradigm for modern AI applications,\nrecent approaches focus on algorithmic innovations while neglecting memory\nlayout considerations that significantly affect execution time. Our unified\nevaluation framework enables comprehensive evaluation of diverse reordering\nstrategies across different graph indices through a graph adapter that converts\narbitrary graph topologies into a common representation and a GPU-optimized\ngraph traversal engine. We conduct a comprehensive analysis across diverse\ndatasets and state-of-the-art graph indices, introducing analysis metrics that\nquantify the relationship between structural properties and memory layout\neffectiveness. Our GPU-targeted reordering achieves up to 15$\\%$ QPS\nimprovements while preserving search accuracy, demonstrating that memory layout\noptimization operates orthogonally to existing algorithmic innovations. We will\nrelease all code upon publication to facilitate reproducibility and foster\nfurther research.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u63a2\u7d22\u56fe\u91cd\u6392\u5e8f\u5bf9\u57fa\u4e8e\u56fe\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7684\u5f71\u54cd\uff0c\u901a\u8fc7GPU\u4f18\u5316\u8fbe\u6210\u4e86\u6700\u9ad815% \u7684QPS\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u641c\u7d22\u51c6\u786e\u6027\u3002", "motivation": "\u5c3d\u7ba1\u56fe\u5f62ANNS\u5df2\u6210\u4e3a\u73b0\u4ee3AI\u5e94\u7528\u7684\u4e3b\u8981\u8303\u5f0f\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u8fc7\u4e8e\u5173\u6ce8\u7b97\u6cd5\u521b\u65b0\uff0c\u5ffd\u89c6\u4e86\u663e\u8457\u5f71\u54cd\u6267\u884c\u65f6\u95f4\u7684\u5185\u5b58\u5e03\u5c40\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4e3a\u4e0d\u540c\u56fe\u7d22\u5f15\u4e2d\u7684\u591a\u79cd\u91cd\u6392\u5e8f\u7b56\u7565\u63d0\u4f9b\u5168\u9762\u8bc4\u4f30\u3002\u4f7f\u7528\u4e86\u4e00\u4e2a\u56fe\u9002\u914d\u5668\u6765\u5c06\u4efb\u610f\u56fe\u62d3\u6251\u8f6c\u6362\u4e3a\u516c\u5171\u8868\u793a\uff0c\u5e76\u7ed3\u5408\u4e00\u4e2aGPU\u4f18\u5316\u7684\u56fe\u904d\u5386\u5f15\u64ce\u3002", "result": "\u901a\u8fc7GPU\u9488\u5bf9\u6027\u7684\u91cd\u6392\u5e8f\uff0c\u5728\u4fdd\u6301\u641c\u7d22\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u6700\u9ad815%\u7684QPS\u63d0\u5347\u3002", "conclusion": "\u5728\u786e\u4fdd\u641c\u7d22\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u4f18\u5316\u5185\u5b58\u5e03\u5c40\u53ef\u4ee5\u72ec\u7acb\u4e8e\u73b0\u6709\u7b97\u6cd5\u521b\u65b0\u8fd0\u4f5c\uff0c\u6709\u6548\u63d0\u5347\u4e86\u56fe\u6392\u5e8f\u6548\u679c\uff0c\u88ab\u8bc1\u660e\u80fd\u63d0\u9ad8\u9ad8\u8fbe15% \u7684QPS\u6027\u80fd\u3002"}}
{"id": "2508.15437", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15437", "abs": "https://arxiv.org/abs/2508.15437", "authors": ["Mandeep Rathee", "Venktesh V", "Sean MacAvaney", "Avishek Anand"], "title": "Test-time Corpus Feedback: From Retrieval to RAG", "comment": "18 pages, 1 figure", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a standard framework for\nknowledge-intensive NLP tasks, combining large language models (LLMs) with\ndocument retrieval from external corpora. Despite its widespread use, most RAG\npipelines continue to treat retrieval and reasoning as isolated components,\nretrieving documents once and then generating answers without further\ninteraction. This static design often limits performance on complex tasks that\nrequire iterative evidence gathering or high-precision retrieval. Recent work\nin both the information retrieval (IR) and NLP communities has begun to close\nthis gap by introducing adaptive retrieval and ranking methods that incorporate\nfeedback. In this survey, we present a structured overview of advanced\nretrieval and ranking mechanisms that integrate such feedback. We categorize\nfeedback signals based on their source and role in improving the query,\nretrieved context, or document pool. By consolidating these developments, we\naim to bridge IR and NLP perspectives and highlight retrieval as a dynamic,\nlearnable component of end-to-end RAG systems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86RAG\u6846\u67b6\u4e2d\u7684\u9ad8\u7ea7\u68c0\u7d22\u548c\u6392\u540d\u673a\u5236\uff0c\u63a2\u8ba8\u4e86\u96c6\u6210\u53cd\u9988\u7684\u65b9\u6cd5\u4ee5\u6539\u5584\u590d\u6742\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1RAG\u6846\u67b6\u5728\u77e5\u8bc6\u5bc6\u96c6\u578bNLP\u4efb\u52a1\u4e2d\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5176\u9759\u6001\u8bbe\u8ba1\u9650\u5236\u4e86\u590d\u6742\u4efb\u52a1\u7684\u6027\u80fd\u8868\u73b0\uff0c\u4fc3\u4f7f\u7814\u7a76\u8005\u63a2\u7d22\u96c6\u6210\u53cd\u9988\u7684\u68c0\u7d22\u4e0e\u6392\u540d\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u7cfb\u7edf\u7684\u7cbe\u786e\u6027\u548c\u8fed\u4ee3\u6027\u80fd\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86\u7ed3\u6784\u5316\u7efc\u8ff0\u7684\u65b9\u6cd5\uff0c\u5bf9\u9ad8\u7ea7\u68c0\u7d22\u548c\u6392\u540d\u673a\u5236\u8fdb\u884c\u5206\u7c7b\uff0c\u5c24\u5176\u5173\u6ce8\u96c6\u6210\u53cd\u9988\u589e\u5f3a\u68c0\u7d22\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "result": "\u672c\u6587\u5c06\u53cd\u9988\u4fe1\u53f7\u7684\u6765\u6e90\u548c\u5728\u6539\u5584\u67e5\u8be2\u3001\u68c0\u7d22\u4e0a\u4e0b\u6587\u53ca\u6587\u6863\u6c60\u4e2d\u7684\u4f5c\u7528\u8fdb\u884c\u5206\u7c7b\uff0c\u6574\u5408\u4e86\u4fe1\u606f\u68c0\u7d22\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u793e\u533a\u7684\u6700\u65b0\u8fdb\u5c55\u3002", "conclusion": "\u672c\u6587\u7efc\u8ff0\u4e86\u96c6\u6210\u53cd\u9988\u7684\u9ad8\u7ea7\u68c0\u7d22\u548c\u6392\u540d\u673a\u5236\uff0c\u65e8\u5728\u6865\u63a5\u4fe1\u606f\u68c0\u7d22\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u89c6\u89d2\uff0c\u5f3a\u8c03\u68c0\u7d22\u4f5c\u4e3a\u7aef\u5230\u7aefRAG\u7cfb\u7edf\u4e2d\u52a8\u6001\u3001\u53ef\u5b66\u4e60\u7684\u7ec4\u6210\u90e8\u5206\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.15481", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.15481", "abs": "https://arxiv.org/abs/2508.15481", "authors": ["Fang Wang", "Yongjie Wang", "Zonghao Yang", "Minghao Hu", "Xiaoying Bai"], "title": "On Evaluating the Adversarial Robustness of Foundation Models for Multimodal Entity Linking", "comment": null, "summary": "The explosive growth of multimodal data has driven the rapid development of\nmultimodal entity linking (MEL) models. However, existing studies have not\nsystematically investigated the impact of visual adversarial attacks on MEL\nmodels. We conduct the first comprehensive evaluation of the robustness of\nmainstream MEL models under different adversarial attack scenarios, covering\ntwo core tasks: Image-to-Text (I2T) and Image+Text-to-Text (IT2T). Experimental\nresults show that current MEL models generally lack sufficient robustness\nagainst visual perturbations. Interestingly, contextual semantic information in\ninput can partially mitigate the impact of adversarial perturbations. Based on\nthis insight, we propose an LLM and Retrieval-Augmented Entity Linking\n(LLM-RetLink), which significantly improves the model's anti-interference\nability through a two-stage process: first, extracting initial entity\ndescriptions using large vision models (LVMs), and then dynamically generating\ncandidate descriptive sentences via web-based retrieval. Experiments on five\ndatasets demonstrate that LLM-RetLink improves the accuracy of MEL by\n0.4%-35.7%, especially showing significant advantages under adversarial\nconditions. This research highlights a previously unexplored facet of MEL\nrobustness, constructs and releases the first MEL adversarial example dataset,\nand sets the stage for future work aimed at strengthening the resilience of\nmultimodal systems in adversarial environments.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u591a\u6a21\u6001\u5b9e\u4f53\u94fe\u63a5\u6a21\u578b\u5728\u89c6\u89c9\u5bf9\u6297\u653b\u51fb\u4e0b\u9c81\u68d2\u6027\u4e0d\u8db3\uff0c\u63d0\u51faLLM-RetLink\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6a21\u578b\u6297\u5e72\u6270\u80fd\u529b\u3002", "motivation": "\u7531\u4e8e\u591a\u6a21\u6001\u6570\u636e\u7684\u7206\u70b8\u6027\u589e\u957f\uff0c\u73b0\u6709\u7814\u7a76\u5c1a\u672a\u7cfb\u7edf\u6027\u5730\u63a2\u8ba8\u89c6\u89c9\u5bf9\u6297\u653b\u51fb\u5bf9\u591a\u6a21\u6001\u5b9e\u4f53\u94fe\u63a5\uff08MEL\uff09\u6a21\u578b\u7684\u5f71\u54cd\u3002", "method": "\u9996\u5148\u4f7f\u7528\u5927\u578b\u89c6\u89c9\u6a21\u578b\uff08LVMs\uff09\u63d0\u53d6\u521d\u59cb\u5b9e\u4f53\u63cf\u8ff0\uff0c\u7136\u540e\u901a\u8fc7\u7f51\u7edc\u68c0\u7d22\u52a8\u6001\u751f\u6210\u5019\u9009\u63cf\u8ff0\u6027\u53e5\u5b50\u3002", "result": "LLM-RetLink\u6a21\u578b\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cMEL\u7684\u51c6\u786e\u6027\u63d0\u9ad8\u4e860.4%-35.7%\uff0c\u5c24\u5176\u5728\u5bf9\u6297\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524d\u591a\u6a21\u6001\u5b9e\u4f53\u94fe\u63a5\u6a21\u578b\u5728\u89c6\u89c9\u5bf9\u6297\u653b\u51fb\u4e0b\u666e\u904d\u7f3a\u4e4f\u8db3\u591f\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u548c\u68c0\u7d22\u589e\u5f3a\u7684\u5b9e\u4f53\u94fe\u63a5\u65b9\u6cd5\uff08LLM-RetLink\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6297\u5e72\u6270\u80fd\u529b\u3002"}}
{"id": "2508.15486", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.15486", "abs": "https://arxiv.org/abs/2508.15486", "authors": ["Ren Qin", "Chai Zheng", "Xiao Xijun", "Zheng Yuchao", "Wu Di"], "title": "LongRetriever: Towards Ultra-Long Sequence based Candidate Retrieval for Recommendation", "comment": null, "summary": "Precisely modeling user ultra-long sequences is critical for industrial\nrecommender systems. Current approaches predominantly focus on leveraging\nultra-long sequences in the ranking stage, whereas research for the candidate\nretrieval stage remains under-explored. This paper presents LongRetriever, a\npractical framework for incorporating ultra-long sequences into the retrieval\nstage of recommenders. Specifically, we propose in-context training and\nmulti-context retrieval, which enable candidate-specific interaction between\nuser sequence and candidate item, and ensure training-serving consistency under\nthe search-based paradigm. Extensive online A/B testing conducted on a\nlarge-scale e-commerce platform demonstrates statistically significant\nimprovements, confirming the framework's effectiveness. Currently,\nLongRetriever has been fully deployed in the platform, impacting billions of\nusers.", "AI": {"tldr": "\u7814\u7a76LongRetriever\u6846\u67b6\uff0c\u901a\u8fc7\u7528\u6237\u8d85\u957f\u5e8f\u5217\u4f18\u5316\u63a8\u8350\u7cfb\u7edf\u7684\u68c0\u7d22\u9636\u6bb5\uff0c\u6d4b\u8bd5\u8868\u660e\u6709\u6548\u5e76\u5df2\u5e7f\u6cdb\u5e94\u7528\u3002", "motivation": "\u589e\u5f3a\u63a8\u8350\u7cfb\u7edf\u5019\u9009\u68c0\u7d22\u9636\u6bb5\u7684\u80fd\u529b\uff0c\u5904\u7406\u7528\u6237\u8d85\u957f\u5e8f\u5217\u95ee\u9898\u3002", "method": "\u63d0\u51faLongRetriever\u6846\u67b6\uff0c\u7ed3\u5408\u8d85\u957f\u5e8f\u5217\u8fdb\u884c\u5019\u9009\u68c0\u7d22\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u8bad\u7ec3\u548c\u591a\u4e0a\u4e0b\u6587\u68c0\u7d22\u65b9\u6cd5\u3002", "result": "\u5728\u7ebfA/B\u6d4b\u8bd5\u8bc1\u5b9e\u4e86\u8be5\u6846\u67b6\u5728\u5927\u89c4\u6a21\u7535\u5546\u5e73\u53f0\u4e0a\u7684\u6709\u6548\u6027\uff0c\u76ee\u524d\u5df2\u5168\u9762\u90e8\u7f72\u5f71\u54cd\u6570\u5341\u4ebf\u7528\u6237\u3002", "conclusion": "\u957f\u5e8f\u5217\u5728\u63a8\u8350\u7cfb\u7edf\u5019\u9009\u68c0\u7d22\u9636\u6bb5\u7684\u5e94\u7528\u80fd\u591f\u5e26\u6765\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\u3002"}}
{"id": "2508.15643", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.15643", "abs": "https://arxiv.org/abs/2508.15643", "authors": ["Nityaa Kalra", "Savvina Daniil"], "title": "Reading Between the Lines: A Study of Thematic Bias in Book Recommender Systems", "comment": "7 pages, 5 figures, Accepted at FAccTRec at RecSys 2025", "summary": "Recommender systems help users discover new content, but can also reinforce\nexisting biases, leading to unfair exposure and reduced diversity. This paper\nintroduces and investigates thematic bias in book recommendations, defined as a\ndisproportionate favouring or neglect of certain book themes. We adopt a\nmulti-stage bias evaluation framework using the Book-Crossing dataset to\nevaluate thematic bias in recommendations and its impact on different user\ngroups.\n  Our findings show that thematic bias originates from content imbalances and\nis amplified by user engagement patterns. By segmenting users based on their\nthematic preferences, we find that users with niche and long-tail interests\nreceive less personalised recommendations, whereas users with diverse interests\nreceive more consistent recommendations. These findings suggest that\nrecommender systems should be carefully designed to accommodate a broader range\nof user interests. By contributing to the broader goal of responsible AI, this\nwork also lays the groundwork for extending thematic bias analysis to other\ndomains.", "AI": {"tldr": "\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e66\u7c4d\u63a8\u8350\u4e2d\u7684\u4e3b\u9898\u504f\u89c1\uff0c\u5e76\u53d1\u73b0\u63a8\u8350\u7cfb\u7edf\u53ef\u80fd\u52a0\u5267\u504f\u89c1\uff0c\u5efa\u8bae\u4e3a\u4e86\u8d1f\u8d23\u4efb\u7684AI\u53d1\u5c55\uff0c\u5e94\u8bbe\u8ba1\u80fd\u591f\u5bb9\u7eb3\u5e7f\u6cdb\u7528\u6237\u5174\u8da3\u7684\u7cfb\u7edf\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u5728\u5e2e\u52a9\u7528\u6237\u53d1\u73b0\u65b0\u5185\u5bb9\u7684\u540c\u65f6\uff0c\u4e5f\u53ef\u80fd\u52a0\u5267\u73b0\u6709\u504f\u89c1\uff0c\u5bfc\u81f4\u4e0d\u516c\u5e73\u7684\u66dd\u5149\u548c\u591a\u6837\u6027\u51cf\u5c11\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u504f\u89c1\u8bc4\u4f30\u6846\u67b6\uff0c\u5229\u7528Book-Crossing\u6570\u636e\u96c6\u8bc4\u4f30\u63a8\u8350\u4e2d\u7684\u4e3b\u9898\u504f\u89c1\u53ca\u5176\u5bf9\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u4e3b\u9898\u504f\u89c1\u6e90\u4e8e\u5185\u5bb9\u4e0d\u5e73\u8861\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u53c2\u4e0e\u6a21\u5f0f\u653e\u5927\u3002\u540c\u65f6\uff0c\u4e0d\u540c\u5174\u8da3\u7fa4\u4f53\u7684\u7528\u6237\u5f97\u5230\u7684\u63a8\u8350\u4e2a\u6027\u5316\u7a0b\u5ea6\u4e0d\u540c\uff1a\u62e5\u6709\u5c0f\u4f17\u53ca\u957f\u5c3e\u5174\u8da3\u7684\u7528\u6237\u5f97\u5230\u7684\u63a8\u8350\u4e2a\u6027\u5316\u7a0b\u5ea6\u8f83\u4f4e\uff0c\u800c\u5174\u8da3\u591a\u6837\u7684\u7528\u6237\u5219\u83b7\u5f97\u8f83\u4e00\u81f4\u7684\u63a8\u8350\u3002", "conclusion": "\u63a8\u8350\u7cfb\u7edf\u5e94\u7cbe\u5fc3\u8bbe\u8ba1\uff0c\u4ee5\u6ee1\u8db3\u66f4\u5e7f\u6cdb\u7684\u7528\u6237\u5174\u8da3\uff0c\u4ee5\u51cf\u5c11\u504f\u89c1\u5e76\u63d0\u9ad8\u591a\u6837\u6027\u3002"}}
