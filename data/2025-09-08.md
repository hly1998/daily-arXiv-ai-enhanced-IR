<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Unified Representation Learning for Multi-Intent Diversity and Behavioral Uncertainty in Recommender Systems](https://arxiv.org/abs/2509.04694)
*Wei Xu,Jiasen Zheng,Junjiang Lin,Mingxuan Han,Junliang Du*

Main category: cs.IR

TL;DR: 该框架通过多意图表示模块和不确定性建模提高了推荐准确度和稳健性。


<details>
  <summary>Details</summary>
Motivation: 应对推荐系统中用户意图多样性和行为不确定性的挑战。

Method: 提出了一个多意图表示模块和不确定性建模机制的统一表示学习框架。

Result: 该方法在标准公共数据集上进行评估，实验证明其在多个指标上优于现有代表模型，且在冷启动和行为干扰情况下表现出更大的稳定性和适应性。

Conclusion: 研究结果证实了统一建模策略在现实推荐任务中的有效性和实用价值。

Abstract: This paper addresses the challenge of jointly modeling user intent diversity
and behavioral uncertainty in recommender systems. A unified representation
learning framework is proposed. The framework builds a multi-intent
representation module and an uncertainty modeling mechanism. It extracts
multi-granularity interest structures from user behavior sequences. Behavioral
ambiguity and preference fluctuation are captured using Bayesian distribution
modeling. In the multi-intent modeling part, the model introduces multiple
latent intent vectors. These vectors are weighted and fused using an attention
mechanism to generate semantically rich representations of long-term user
preferences. In the uncertainty modeling part, the model learns the mean and
covariance of behavior representations through Gaussian distributions. This
reflects the user's confidence in different behavioral contexts. Next, a
learnable fusion strategy is used to combine long-term intent and short-term
behavior signals. This produces the final user representation, improving both
recommendation accuracy and robustness. The method is evaluated on standard
public datasets. Experimental results show that it outperforms existing
representative models across multiple metrics. It also demonstrates greater
stability and adaptability under cold-start and behavioral disturbance
scenarios. The approach alleviates modeling bottlenecks faced by traditional
methods when dealing with complex user behavior. These findings confirm the
effectiveness and practical value of the unified modeling strategy in
real-world recommendation tasks.

</details>


### [2] [Multimodal Foundation Model-Driven User Interest Modeling and Behavior Analysis on Short Video Platforms](https://arxiv.org/abs/2509.04751)
*Yushang Zhao,Yike Peng,Li Zhang,Qianyi Sun,Zhihui Zhang,Yingying Zhuang*

Main category: cs.IR

TL;DR: 该论文提出了基于多模态基础模型的用户兴趣建模和行为分析框架，以提高短视频平台推荐系统的准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 传统兴趣建模方法局限于单模态数据，无法在复杂的多模态内容环境中充分捕捉用户偏好。

Method: 该方法通过跨模态对齐策略整合视频帧、文本描述和背景音乐，构建细粒度用户兴趣向量，并引入行为驱动特征嵌入机制以建模动态兴趣演变。

Result: 结果显示，该框架在行为预测准确性、冷启动用户兴趣建模和推荐点击率方面有显著提高，并通过可解释性机制提升推荐系统的透明度和可控性。

Conclusion: 实验结果显示，该方法在行为预测准确性、冷启动用户兴趣建模和推荐点击率方面都有显著改进。

Abstract: With the rapid expansion of user bases on short video platforms, personalized
recommendation systems are playing an increasingly critical role in enhancing
user experience and optimizing content distribution. Traditional interest
modeling methods often rely on unimodal data, such as click logs or text
labels, which limits their ability to fully capture user preferences in a
complex multimodal content environment. To address this challenge, this paper
proposes a multimodal foundation model-based framework for user interest
modeling and behavior analysis. By integrating video frames, textual
descriptions, and background music into a unified semantic space using
cross-modal alignment strategies, the framework constructs fine-grained user
interest vectors. Additionally, we introduce a behavior-driven feature
embedding mechanism that incorporates viewing, liking, and commenting sequences
to model dynamic interest evolution, thereby improving both the timeliness and
accuracy of recommendations. In the experimental phase, we conduct extensive
evaluations using both public and proprietary short video datasets, comparing
our approach against multiple mainstream recommendation algorithms and modeling
techniques. Results demonstrate significant improvements in behavior prediction
accuracy, interest modeling for cold-start users, and recommendation
click-through rates. Moreover, we incorporate interpretability mechanisms using
attention weights and feature visualization to reveal the model's decision
basis under multimodal inputs and trace interest shifts, thereby enhancing the
transparency and controllability of the recommendation system.

</details>


### [3] [Fishing for Answers: Exploring One-shot vs. Iterative Retrieval Strategies for Retrieval Augmented Generation](https://arxiv.org/abs/2509.04820)
*Huifeng Lin,Gang Su,Jintao Liang,You Wu,Rui Zhao,Ziyue Li*

Main category: cs.IR

TL;DR: 本文探讨了如何通过改进检索增强生成（RAG）策略来提升法律和监管领域的问答性能。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG方法在处理复杂的法律和监管领域问答时常表现不佳，特别是在面对大量政府文件时。

Method: 研究提出了一次性检索方法和迭代检索策略，以增强RAG在复杂QA任务中的表现。一次性检索方法通过根据令牌预算选择相关内容，而迭代检索策略通过推理代理式框架动态优化检索过程。

Result: 实验表明，改进后的检索策略能有效解决查询漂移和检索惰性问题，提高实际应用中的问答质量。

Conclusion: 通过设计新的检索策略，我们能够显著提高证据覆盖率和答案质量。

Abstract: Retrieval-Augmented Generation (RAG) based on Large Language Models (LLMs) is
a powerful solution to understand and query the industry's closed-source
documents. However, basic RAG often struggles with complex QA tasks in legal
and regulatory domains, particularly when dealing with numerous government
documents. The top-$k$ strategy frequently misses golden chunks, leading to
incomplete or inaccurate answers. To address these retrieval bottlenecks, we
explore two strategies to improve evidence coverage and answer quality. The
first is a One-SHOT retrieval method that adaptively selects chunks based on a
token budget, allowing as much relevant content as possible to be included
within the model's context window. Additionally, we design modules to further
filter and refine the chunks. The second is an iterative retrieval strategy
built on a Reasoning Agentic RAG framework, where a reasoning LLM dynamically
issues search queries, evaluates retrieved results, and progressively refines
the context over multiple turns. We identify query drift and retrieval laziness
issues and further design two modules to tackle them. Through extensive
experiments on a dataset of government documents, we aim to offer practical
insights and guidance for real-world applications in legal and regulatory
domains.

</details>


### [4] [Hybrid Matrix Factorization Based Graph Contrastive Learning for Recommendation System](https://arxiv.org/abs/2509.05115)
*Hao Chen,Wenming Ma,Zihao Chu,Mingqi Li*

Main category: cs.IR

TL;DR: HMFGCL 用 MF 和 SVD 改进图对比学习，在推荐系统中表现优秀，特别是在数据稀疏的小规模数据集上。


<details>
  <summary>Details</summary>
Motivation: 现有图对比学习方法的增强策略未能充分捕获用户-项目交互信息，有必要探索新方法。

Method: 提出了一种新方法 HMFGCL，结合低秩矩阵分解（MF）和奇异值分解（SVD），补充获取全局协作信息，以构建增强视图。

Result: 在多个公共数据集上的实验结果表明，HMFGCL 模型优于现有基线，尤其是在小规模数据集上表现突出。

Conclusion: HMFGCL 模型通过结合两种矩阵分解技术和图对比学习，在小规模数据集上表现优异，超越现有基线。

Abstract: In recent years, methods that combine contrastive learning with graph neural
networks have emerged to address the challenges of recommendation systems,
demonstrating powerful performance and playing a significant role in this
domain. Contrastive learning primarily tackles the issue of data sparsity by
employing data augmentation strategies, effectively alleviating this problem
and showing promising results. Although existing research has achieved
favorable outcomes, most current graph contrastive learning methods are based
on two types of data augmentation strategies: the first involves perturbing the
graph structure, such as by randomly adding or removing edges; and the second
applies clustering techniques. We believe that the interactive information
obtained through these two strategies does not fully capture the user-item
interactions. In this paper, we propose a novel method called HMFGCL (Hybrid
Matrix Factorization Based Graph Contrastive Learning), which integrates two
distinct matrix factorization techniques-low-rank matrix factorization (MF) and
singular value decomposition (SVD)-to complementarily acquire global
collaborative information, thereby constructing enhanced views. Experimental
results on multiple public datasets demonstrate that our model outperforms
existing baselines, particularly on small-scale datasets.

</details>
