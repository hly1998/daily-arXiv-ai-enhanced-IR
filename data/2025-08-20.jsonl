{"id": "2508.13209", "categories": ["cs.IR", "cs.AI", "cs.SI", "J.4; I.2; K.4"], "pdf": "https://arxiv.org/pdf/2508.13209", "abs": "https://arxiv.org/abs/2508.13209", "authors": ["Yaying Luo", "Hui Fang", "Zhu Sun"], "title": "Research on Conversational Recommender System Considering Consumer Types", "comment": "10 pages", "summary": "Conversational Recommender Systems (CRS) provide personalized services\nthrough multi-turn interactions, yet most existing methods overlook users'\nheterogeneous decision-making styles and knowledge levels, which constrains\nboth accuracy and efficiency. To address this gap, we propose CT-CRS (Consumer\nType-Enhanced Conversational Recommender System), a framework that integrates\nconsumer type modeling into dialogue recommendation. Based on consumer type\ntheory, we define four user categories--dependent, efficient, cautious, and\nexpert--derived from two dimensions: decision-making style (maximizers vs.\nsatisficers) and knowledge level (high vs. low). CT-CRS employs interaction\nhistories and fine-tunes the large language model to automatically infer user\ntypes in real time, avoiding reliance on static questionnaires. We incorporate\nuser types into state representation and design a type-adaptive policy that\ndynamically adjusts recommendation granularity, diversity, and attribute query\ncomplexity. To further optimize the dialogue policy, we adopt Inverse\nReinforcement Learning (IRL), enabling the agent to approximate expert-like\nstrategies conditioned on consumer type. Experiments on LastFM, Amazon-Book,\nand Yelp show that CTCRS improves recommendation success rate and reduces\ninteraction turns compared to strong baselines. Ablation studies confirm that\nboth consumer type modeling and IRL contribute significantly to performance\ngains. These results demonstrate that CT-CRS offers a scalable and\ninterpretable solution for enhancing CRS personalization through the\nintegration of psychological modeling and advanced policy optimization."}
{"id": "2508.13390", "categories": ["cs.IR", "H.3"], "pdf": "https://arxiv.org/pdf/2508.13390", "abs": "https://arxiv.org/abs/2508.13390", "authors": ["William Zhang", "Yiwen Zhu", "Yunlei Lu", "Mathieu Demarne", "Wenjing Wang", "Kai Deng", "Nutan Sahoo", "Katherine Lin", "Miso Cilimdzic", "Subru Krishnan"], "title": "FLAIR: Feedback Learning for Adaptive Information Retrieval", "comment": "Accepted to CIKM2025", "summary": "Recent advances in Large Language Models (LLMs) have driven the adoption of\ncopilots in complex technical scenarios, underscoring the growing need for\nspecialized information retrieval solutions. In this paper, we introduce FLAIR,\na lightweight, feedback learning framework that adapts copilot systems'\nretrieval strategies by integrating domain-specific expert feedback. FLAIR\noperates in two stages: an offline phase obtains indicators from (1) user\nfeedback and (2) questions synthesized from documentation, storing these\nindicators in a decentralized manner. An online phase then employs a two-track\nranking mechanism to combine raw similarity scores with the collected\nindicators. This iterative setup refines retrieval performance for any query.\nExtensive real-world evaluations of FLAIR demonstrate significant performance\ngains on both previously seen and unseen queries, surpassing state-of-the-art\napproaches. The system has been successfully integrated into Copilot DECO,\nserving thousands of users at Microsoft, demonstrating its scalability and\neffectiveness in operational environments."}
{"id": "2508.13394", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.13394", "abs": "https://arxiv.org/abs/2508.13394", "authors": ["Lam Thanh Do", "Linh Van Nguyen", "David Fu", "Kevin Chen-Chuan Chang"], "title": "CASPER: Concept-integrated Sparse Representation for Scientific Retrieval", "comment": "11 Pages. Code: https://github.com/louisdo/CASPER", "summary": "The exponential growth of scientific literature has made it increasingly\ndifficult for researchers to keep up with the literature. In an attempt to\nalleviate this problem, we propose CASPER, a sparse retrieval model for\nscientific search that utilizes tokens and keyphrases as representation units\n(i.e. dimensions in the sparse embedding space), enabling it to represent\nqueries and documents with research concepts and match them at both granular\nand conceptual levels. To overcome the lack of suitable training data, we\npropose mining training data by leveraging scholarly references (i.e. signals\nthat capture how research concepts of papers are expressed in different\nsettings), including titles, citation contexts, author-assigned keyphrases, and\nco-citations. CASPER outperforms strong dense and sparse retrieval baselines on\neight scientific retrieval benchmarks. Moreover, we demonstrate that through\nsimple post-processing, CASPER can be effectively used for the keyphrase\ngeneration tasks, achieving competitive performance with the established\nCopyRNN while producing more diverse keyphrases and being nearly four times\nfaster."}
{"id": "2508.13423", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13423", "abs": "https://arxiv.org/abs/2508.13423", "authors": ["Qixin Wang", "Dawei Wang", "Kun Chen", "Yaowei Hu", "Puneet Girdhar", "Ruoteng Wang", "Aadesh Gupta", "Chaitanya Devella", "Wenlai Guo", "Shangwen Huang", "Bachir Aoun", "Greg Hayworth", "Han Li", "Xintao Wu"], "title": "AdaptJobRec: Enhancing Conversational Career Recommendation through an LLM-Powered Agentic System", "comment": null, "summary": "In recent years, recommendation systems have evolved from providing a single\nlist of recommendations to offering a comprehensive suite of topic focused\nservices. To better accomplish this task, conversational recommendation systems\n(CRS) have progressed from basic retrieval augmented LLM generation to agentic\nsystems with advanced reasoning and self correction capabilities. However,\nagentic systems come with notable response latency, a longstanding challenge\nfor conversational recommendation systems. To balance the trade off between\nhandling complex queries and minimizing latency, we propose AdaptJobRec, the\nfirst conversational job recommendation system that leverages autonomous agent\nto integrate personalized recommendation algorithm tools. The system employs a\nuser query complexity identification mechanism to minimize response latency.\nFor straightforward queries, the agent directly selects the appropriate tool\nfor rapid responses. For complex queries, the agent uses the memory processing\nmodule to filter chat history for relevant content, then passes the results to\nthe intelligent task decomposition planner, and finally executes the tasks\nusing personalized recommendation tools. Evaluation on Walmart's real world\ncareer recommendation scenarios demonstrates that AdaptJobRec reduces average\nresponse latency by up to 53.3% compared to competitive baselines, while\nsignificantly improving recommendation accuracy."}
{"id": "2508.13500", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13500", "abs": "https://arxiv.org/abs/2508.13500", "authors": ["Jaewan Moon", "Seongmin Park", "Jongwuk Lee"], "title": "LLM-Enhanced Linear Autoencoders for Recommendation", "comment": "Accepted by CIKM 2025", "summary": "Large language models (LLMs) have been widely adopted to enrich the semantic\nrepresentation of textual item information in recommender systems. However,\nexisting linear autoencoders (LAEs) that incorporate textual information rely\non sparse word co-occurrence patterns, limiting their ability to capture rich\ntextual semantics. To address this, we propose L3AE, the first integration of\nLLMs into the LAE framework. L3AE effectively integrates the heterogeneous\nknowledge of textual semantics and user-item interactions through a two-phase\noptimization strategy. (i) L3AE first constructs a semantic item-to-item\ncorrelation matrix from LLM-derived item representations. (ii) It then learns\nan item-to-item weight matrix from collaborative signals while distilling\nsemantic item correlations as regularization. Notably, each phase of L3AE is\noptimized through closed-form solutions, ensuring global optimality and\ncomputational efficiency. Extensive experiments demonstrate that L3AE\nconsistently outperforms state-of-the-art LLM-enhanced models on three\nbenchmark datasets, achieving gains of 27.6% in Recall@20 and 39.3% in NDCG@20.\nThe source code is available at https://github.com/jaewan7599/L3AE_CIKM2025."}
{"id": "2508.13517", "categories": ["cs.IR", "cs.AI", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2508.13517", "abs": "https://arxiv.org/abs/2508.13517", "authors": ["Hongru Hou", "Jiachen Sun", "Wenqing Lin", "Wendong Bi", "Xiangrong Wang", "Deqing Yang"], "title": "Heterogeneous Influence Maximization in User Recommendation", "comment": "Accepted in CIKM 2025", "summary": "User recommendation systems enhance user engagement by encouraging users to\nact as inviters to interact with other users (invitees), potentially fostering\ninformation propagation. Conventional recommendation methods typically focus on\nmodeling interaction willingness. Influence-Maximization (IM) methods focus on\nidentifying a set of users to maximize the information propagation. However,\nexisting methods face two significant challenges. First, recommendation methods\nfail to unleash the candidates' spread capability. Second, IM methods fail to\naccount for the willingness to interact. To solve these issues, we propose two\nmodels named HeteroIR and HeteroIM. HeteroIR provides an intuitive solution to\nunleash the dissemination potential of user recommendation systems. HeteroIM\nfills the gap between the IM method and the recommendation task, improving\ninteraction willingness and maximizing spread coverage. The HeteroIR introduces\na two-stage framework to estimate the spread profits. The HeteroIM\nincrementally selects the most influential invitee to recommend and rerank\nbased on the number of reverse reachable (RR) sets containing inviters and\ninvitees. RR set denotes a set of nodes that can reach a target via\npropagation. Extensive experiments show that HeteroIR and HeteroIM\nsignificantly outperform the state-of-the-art baselines with the p-value <\n0.05. Furthermore, we have deployed HeteroIR and HeteroIM in Tencent's online\ngaming platforms and gained an 8.5\\% and 10\\% improvement in the online A/B\ntest, respectively. Implementation codes are available at\nhttps://github.com/socialalgo/HIM."}
{"id": "2508.13567", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.13567", "abs": "https://arxiv.org/abs/2508.13567", "authors": ["Wenji Zhou", "Yuhang Zheng", "Yinfu Feng", "Yunan Ye", "Rong Xiao", "Long Chen", "Xiaosong Yang", "Jun Xiao"], "title": "ENCODE: Breaking the Trade-Off Between Performance and Efficiency in Long-Term User Behavior Modeling", "comment": "Accepted to TKDE", "summary": "Long-term user behavior sequences are a goldmine for businesses to explore\nusers' interests to improve Click-Through Rate. However, it is very challenging\nto accurately capture users' long-term interests from their long-term behavior\nsequences and give quick responses from the online serving systems. To meet\nsuch requirements, existing methods \"inadvertently\" destroy two basic\nrequirements in long-term sequence modeling: R1) make full use of the entire\nsequence to keep the information as much as possible; R2) extract information\nfrom the most relevant behaviors to keep high relevance between learned\ninterests and current target items. The performance of online serving systems\nis significantly affected by incomplete and inaccurate user interest\ninformation obtained by existing methods. To this end, we propose an efficient\ntwo-stage long-term sequence modeling approach, named as EfficieNt Clustering\nbased twO-stage interest moDEling (ENCODE), consisting of offline extraction\nstage and online inference stage. It not only meets the aforementioned two\nbasic requirements but also achieves a desirable balance between online service\nefficiency and precision. Specifically, in the offline extraction stage, ENCODE\nclusters the entire behavior sequence and extracts accurate interests. To\nreduce the overhead of the clustering process, we design a metric\nlearning-based dimension reduction algorithm that preserves the relative\npairwise distances of behaviors in the new feature space. While in the online\ninference stage, ENCODE takes the off-the-shelf user interests to predict the\nassociations with target items. Besides, to further ensure the relevance\nbetween user interests and target items, we adopt the same relevance metric\nthroughout the whole pipeline of ENCODE. The extensive experiment and\ncomparison with SOTA have demonstrated the effectiveness and efficiency of our\nproposed ENCODE."}
{"id": "2508.13568", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13568", "abs": "https://arxiv.org/abs/2508.13568", "authors": ["Diego Correa da Silva", "Denis Robson Dantas Boaventura", "Mayki dos Santos Oliveira", "Eduardo Ferreira da Silva", "Joel Machado Pires", "Frederico Araújo Durão"], "title": "Understanding Distribution Structure on Calibrated Recommendation Systems", "comment": null, "summary": "Traditional recommender systems aim to generate a recommendation list\ncomprising the most relevant or similar items to the user's profile. These\napproaches can create recommendation lists that omit item genres from the less\nprominent areas of a user's profile, thereby undermining the user's experience.\nTo solve this problem, the calibrated recommendation system provides a\nguarantee of including less representative areas in the recommended list. The\ncalibrated context works with three distributions. The first is from the user's\nprofile, the second is from the candidate items, and the last is from the\nrecommendation list. These distributions are G-dimensional, where G is the\ntotal number of genres in the system. This high dimensionality requires a\ndifferent evaluation method, considering that traditional recommenders operate\nin a one-dimensional data space. In this sense, we implement fifteen models\nthat help to understand how these distributions are structured. We evaluate the\nusers' patterns in three datasets from the movie domain. The results indicate\nthat the models of outlier detection provide a better understanding of the\nstructures. The calibrated system creates recommendation lists that act\nsimilarly to traditional recommendation lists, allowing users to change their\ngroups of preferences to the same degree."}
{"id": "2508.13670", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.13670", "abs": "https://arxiv.org/abs/2508.13670", "authors": ["Ilwoong Baek", "Mincheol Yoon", "Seongmin Park", "Jongwuk Lee"], "title": "MUFFIN: Mixture of User-Adaptive Frequency Filtering for Sequential Recommendation", "comment": "Accepted by CIKM 2025", "summary": "Sequential recommendation (SR) aims to predict users' subsequent interactions\nby modeling their sequential behaviors. Recent studies have explored frequency\ndomain analysis, which effectively models periodic patterns in user sequences.\nHowever, existing frequency-domain SR models still face two major drawbacks:\n(i) limited frequency band coverage, often missing critical behavioral patterns\nin a specific frequency range, and (ii) lack of personalized frequency\nfiltering, as they apply an identical filter for all users regardless of their\ndistinct frequency characteristics. To address these challenges, we propose a\nnovel frequency-domain model, Mixture of User-adaptive Frequency FIlteriNg\n(MUFFIN), operating through two complementary modules. (i) The global filtering\nmodule (GFM) handles the entire frequency spectrum to capture comprehensive\nbehavioral patterns. (ii) The local filtering module (LFM) selectively\nemphasizes important frequency bands without excluding information from other\nranges. (iii) In both modules, the user-adaptive filter (UAF) is adopted to\ngenerate user-specific frequency filters tailored to individual unique\ncharacteristics. Finally, by aggregating both modules, MUFFIN captures diverse\nuser behavioral patterns across the full frequency spectrum. Extensive\nexperiments show that MUFFIN consistently outperforms state-of-the-art\nfrequency-domain SR models over five benchmark datasets. The source code is\navailable at https://github.com/ilwoong100/MUFFIN."}
{"id": "2508.13745", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.13745", "abs": "https://arxiv.org/abs/2508.13745", "authors": ["Shouxing Ma", "Yawen Zeng", "Shiqing Wu", "Guandong Xu"], "title": "Refining Contrastive Learning and Homography Relations for Multi-Modal Recommendation", "comment": "This paper has been accepted as a full paper at ACM MM 2025", "summary": "Multi-modal recommender system focuses on utilizing rich modal information (\ni.e., images and textual descriptions) of items to improve recommendation\nperformance. The current methods have achieved remarkable success with the\npowerful structure modeling capability of graph neural networks. However, these\nmethods are often hindered by sparse data in real-world scenarios. Although\ncontrastive learning and homography ( i.e., homogeneous graphs) are employed to\naddress the data sparsity challenge, existing methods still suffer two main\nlimitations: 1) Simple multi-modal feature contrasts fail to produce effective\nrepresentations, causing noisy modal-shared features and loss of valuable\ninformation in modal-unique features; 2) The lack of exploration of the\nhomograph relations between user interests and item co-occurrence results in\nincomplete mining of user-item interplay.\n  To address the above limitations, we propose a novel framework for\n\\textbf{R}\\textbf{E}fining multi-mod\\textbf{A}l cont\\textbf{R}astive learning\nand ho\\textbf{M}ography relations (\\textbf{REARM}). Specifically, we complement\nmulti-modal contrastive learning by employing meta-network and orthogonal\nconstraint strategies, which filter out noise in modal-shared features and\nretain recommendation-relevant information in modal-unique features. To mine\nhomogeneous relationships effectively, we integrate a newly constructed user\ninterest graph and an item co-occurrence graph with the existing user\nco-occurrence and item semantic graphs for graph learning. The extensive\nexperiments on three real-world datasets demonstrate the superiority of REARM\nto various state-of-the-art baselines. Our visualization further shows an\nimprovement made by REARM in distinguishing between modal-shared and\nmodal-unique features. Code is available\n\\href{https://github.com/MrShouxingMa/REARM}{here}."}
{"id": "2508.13843", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13843", "abs": "https://arxiv.org/abs/2508.13843", "authors": ["Zihan Liang", "Yufei Ma", "ZhiPeng Qian", "Huangyu Dai", "Zihan Wang", "Ben Chen", "Chenyi Lei", "Yuqing Ding", "Han Li"], "title": "UniECS: Unified Multimodal E-Commerce Search Framework with Gated Cross-modal Fusion", "comment": "Accepted at CIKM2025 as a long paper", "summary": "Current e-commerce multimodal retrieval systems face two key limitations:\nthey optimize for specific tasks with fixed modality pairings, and lack\ncomprehensive benchmarks for evaluating unified retrieval approaches. To\naddress these challenges, we introduce UniECS, a unified multimodal e-commerce\nsearch framework that handles all retrieval scenarios across image, text, and\ntheir combinations. Our work makes three key contributions. First, we propose a\nflexible architecture with a novel gated multimodal encoder that uses adaptive\nfusion mechanisms. This encoder integrates different modality representations\nwhile handling missing modalities. Second, we develop a comprehensive training\nstrategy to optimize learning. It combines cross-modal alignment loss (CMAL),\ncohesive local alignment loss (CLAL), intra-modal contrastive loss (IMCL), and\nadaptive loss weighting. Third, we create M-BEER, a carefully curated\nmultimodal benchmark containing 50K product pairs for e-commerce search\nevaluation. Extensive experiments demonstrate that UniECS consistently\noutperforms existing methods across four e-commerce benchmarks with fine-tuning\nor zero-shot evaluation. On our M-BEER bench, UniECS achieves substantial\nimprovements in cross-modal tasks (up to 28\\% gain in R@10 for text-to-image\nretrieval) while maintaining parameter efficiency (0.2B parameters) compared to\nlarger models like GME-Qwen2VL (2B) and MM-Embed (8B). Furthermore, we deploy\nUniECS in the e-commerce search platform of Kuaishou Inc. across two search\nscenarios, achieving notable improvements in Click-Through Rate (+2.74\\%) and\nRevenue (+8.33\\%). The comprehensive evaluation demonstrates the effectiveness\nof our approach in both experimental and real-world settings. Corresponding\ncodes, models and datasets will be made publicly available at\nhttps://github.com/qzp2018/UniECS."}
{"id": "2508.13870", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.13870", "abs": "https://arxiv.org/abs/2508.13870", "authors": ["Jiazheng Jing", "Yinan Zhang", "Chunyan Miao"], "title": "Bites of Tomorrow: Personalized Recommendations for a Healthier and Greener Plate", "comment": null, "summary": "The recent emergence of extreme climate events has significantly raised\nawareness about sustainable living. In addition to developing energy-saving\nmaterials and technologies, existing research mainly relies on traditional\nmethods that encourage behavioral shifts towards sustainability, which can be\noverly demanding or only passively engaging. In this work, we propose to employ\nrecommendation systems to actively nudge users toward more sustainable choices.\nWe introduce Green Recommender Aligned with Personalized Eating (GRAPE), which\nis designed to prioritize and recommend sustainable food options that align\nwith users' evolving preferences. We also design two innovative Green Loss\nfunctions that cater to green indicators with either uniform or differentiated\npriorities, thereby enhancing adaptability across a range of scenarios.\nExtensive experiments on a real-world dataset demonstrate the effectiveness of\nour GRAPE."}
{"id": "2508.13889", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.13889", "abs": "https://arxiv.org/abs/2508.13889", "authors": ["Chuang Li", "Yang Deng", "Hengchang Hu", "See-Kiong Ng", "Min-Yen Kan", "Haizhou Li"], "title": "CARE: Contextual Adaptation of Recommenders for LLM-based Conversational Recommendation", "comment": null, "summary": "We tackle the challenge of integrating large language models (LLMs) with\nexternal recommender systems to enhance domain expertise in conversational\nrecommendation (CRS). Current LLM-based CRS approaches primarily rely on zero-\nor few-shot methods for generating item recommendations based on user queries,\nbut this method faces two significant challenges: (1) without domain-specific\nadaptation, LLMs frequently recommend items not in the target item space,\nresulting in low recommendation accuracy; and (2) LLMs largely rely on dialogue\ncontext for content-based recommendations, neglecting the collaborative\nrelationships among entities or item sequences. To address these limitations,\nwe introduce the CARE (Contextual Adaptation of Recommenders) framework. CARE\ncustomizes LLMs for CRS tasks, and synergizes them with external recommendation\nsystems. CARE (a) integrates external recommender systems as domain experts,\nproducing recommendations through entity-level insights, and (b) enhances those\nrecommendations by leveraging contextual information for more accurate and\nunbiased final recommendations using LLMs. Our results demonstrate that\nincorporating external recommender systems with entity-level information\nsignificantly enhances recommendation accuracy of LLM-based CRS by an average\nof 54% and 25% for ReDial and INSPIRED datasets. The most effective strategy in\nthe CARE framework involves LLMs selecting and reranking candidate items that\nexternal recommenders provide based on contextual insights. Our analysis\nindicates that the CARE framework effectively addresses the identified\nchallenges and mitigates the popularity bias in the external recommender."}
{"id": "2508.13930", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13930", "abs": "https://arxiv.org/abs/2508.13930", "authors": ["Matey Krastev", "Miklos Hamar", "Danilo Toapanta", "Jesse Brouwers", "Yibin Lei"], "title": "InPars+: Supercharging Synthetic Data Generation for Information Retrieval Systems", "comment": null, "summary": "This work revisits and extends synthetic query generation pipelines for\nNeural Information Retrieval (NIR) by leveraging the InPars Toolkit, a\nreproducible, end-to-end framework for generating training data using large\nlanguage models (LLMs). We first assess the reproducibility of the original\nInPars, InPars-V2, and Promptagator pipelines on the SciFact benchmark and\nvalidate their effectiveness using open-source reranker and generator models.\nBuilding on this foundation, we introduce two key extensions to the pipeline:\n(1) fine-tuning a query generator LLM via Contrastive Preference Optimization\n(CPO) to improve the signal quality in generated queries, and (2) replacing\nstatic prompt templates with dynamic, Chain-of-Thought (CoT) optimized prompts\nusing the DSPy framework. Our results show that both extensions reduce the need\nfor aggressive filtering while improving retrieval performance. All code,\nmodels, and synthetic datasets are publicly released to support further\nresearch at: \\href{https://github.com/danilotpnta/IR2-project}{this https URL}."}
{"id": "2508.13978", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.13978", "abs": "https://arxiv.org/abs/2508.13978", "authors": ["Hardy", "Sebastian Padó", "Amelie Wührl", "Tanise Ceron"], "title": "Democratizing News Recommenders: Modeling Multiple Perspectives for News Candidate Generation with VQ-VAE", "comment": null, "summary": "Current News Recommender Systems based on past clicks are designed for\nengagement, but come at the cost of limiting diversity in the suggested\ncontent. While diversity-aware algorithms exist, they suffer from two major\nlimitations. First, they fail to account for normative diversity, which\nrequires fair access to a broad range of perspectives. Second, they typically\napply diversity late in the system's pipeline, after a lot of content has\nalready been filtered out. Both limitations confine their effectiveness and\nprevent them from promoting true normative diversity in news recommendations.\n  We propose Aspect-Aware Candidate Generation (A2CG) to address these\nlimitations. Our framework introduces diversity into the earliest pipeline\nstage and uses a configurable mechanism to align diversity with specific\ndemocratic goals. A2CG represents each news article using multiple aspects of\nperspectives (e.g., sentiment, political leaning, frame) and uses a Vector\nQuantized Variational Autoencoder (VQ-VAE) to create a discrete, multi-faceted\nrepresentation. A decoder-only model then learns user preferences over these\naspect codes. We then inject diversity directly by reversing the sign on some\nof the query vector's aspects during the candidate retrieval process, ensuring\na more diverse set of candidates.\n  Our method, evaluated on the MIND dataset, enables a flexible trade-off\nbetween personalization and diversity early in the recommendation pipeline. It\nalso generates more novel, diverse, and serendipitous candidates while\neffectively taking into account aspects that strengthen democratic values.\nThese empirical results make it a promising approach for downstream\ndemocratized news recommendation systems."}
