<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 19]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Privacy Preserving Inference of Personalized Content for Out of Matrix Users](https://arxiv.org/abs/2508.14905)
*Michael Sun,Tai Vu,Andrew Wang*

Main category: cs.IR

TL;DR: 本文提出了一种名为 DeepNaniNet 的深度神经推荐框架，解决了数据稀疏、冷启动及隐私问题，并利用 AnimeULike 数据集进行验证，取得了优异的结果。


<details>
  <summary>Details</summary>
Motivation: 填补传统协同过滤和基于内容的方法在数据稀疏和冷启动场景中的不足，尤其是在需要侵入性用户数据或者偏好历史缺失时的问题。

Method: 使用集成用户-项目交互、项目-项目关系与从 BERT 派生的丰富文本评论嵌入的归纳图架构，并采用了新颖的“内容篮子”用户表示和基于自编码器的策略来处理未见用户问题。

Result: DeepNaniNet 在 CiteULike 基准测试上实现了最先进的冷启动结果，与 DropoutNet 在用户召回方面匹敌，并且在不影响出矩阵用户的性能的情况下，在 AnimeULike 数据集上在 Recall@100 方面超过了 Weighted Matrix Factorization (WMF) 和 DropoutNet 的最多7倍和1.5倍。

Conclusion: DeepNaniNet 能在数据稀疏和冷启动集中的环境中提供高质量和保护隐私的推荐，同时高效整合异构内容来源。

Abstract: Recommender systems for niche and dynamic communities face persistent
challenges from data sparsity, cold start users and items, and privacy
constraints. Traditional collaborative filtering and content-based approaches
underperform in these settings, either requiring invasive user data or failing
when preference histories are absent. We present DeepNaniNet, a deep neural
recommendation framework that addresses these challenges through an inductive
graph-based architecture combining user-item interactions, item-item relations,
and rich textual review embeddings derived from BERT. Our design enables cold
start recommendations without profile mining, using a novel "content basket"
user representation and an autoencoder-based generalization strategy for unseen
users. We introduce AnimeULike, a new dataset of 10,000 anime titles and 13,000
users, to evaluate performance in realistic scenarios with high proportions of
guest or low-activity users. DeepNaniNet achieves state-of-the-art cold start
results on the CiteULike benchmark, matches DropoutNet in user recall without
performance degradation for out-of-matrix users, and outperforms Weighted
Matrix Factorization (WMF) and DropoutNet on AnimeULike warm start by up to 7x
and 1.5x in Recall@100, respectively. Our findings demonstrate that DeepNaniNet
delivers high-quality, privacy-preserving recommendations in data-sparse, cold
start-heavy environments while effectively integrating heterogeneous content
sources.

</details>


### [2] [Collaborative Filtering using Variational Quantum Hopfield Associative Memory](https://arxiv.org/abs/2508.14906)
*Amir Kermanshahani,Ebrahim Ardeshir-Larijani,Rakesh Saini,Saif Al-Kuwari*

Main category: cs.IR

TL;DR: 提出了一种新的混合推荐系统，结合量子计算和深度学习，在MovieLens 1M数据集上取得了高效性能，并能在噪声环境中维持稳定表现。


<details>
  <summary>Details</summary>
Motivation: 量子计算能比经典系统进行指数级更快的计算，已在诸如机器学习和推荐系统等领域找到了新的应用。量子机器学习（QML）结合了量子计算与机器学习技术，可以提供强大的数据处理和模式识别工具。本文旨在通过组合量子计算和深度学习来提升推荐系统的性能。

Method: 本文提出了一种混合推荐系统，将量子Hopfield关联记忆（QHAM）与深度神经网络结合，以改善MovieLens 1M数据集的提取和分类。用户原型通过K-Means算法聚类，并通过编码器的激活函数转换为极性模式，这些极性模式被整合到基于变分QHAM的混合推荐模型中。在理想和噪声环境中分别训练该系统并记录其性能。

Result: 在理想环境中，系统使用MSE损失函数训练35轮，取得了ROC值0.9795，准确率0.8841，F-1 Score为0.8786。在噪声环境中，使用定制的Qiskit AER噪声模型训练，ROC为0.9177，准确率0.8013，F-1 Score为0.7866，展示了稳定的表现。

Conclusion: 该研究提出了一种结合量子变分计算和深度学习的新框架，能够处理真实世界数据集，其性能与纯经典方法相当。同时，该模型在噪声环境中表现良好，展示了在推荐系统中应用的潜力。

Abstract: Quantum computing, with its ability to do exponentially faster computation
compared to classical systems, has found novel applications in various fields
such as machine learning and recommendation systems. Quantum Machine Learning
(QML), which integrates quantum computing with machine learning techniques,
presents powerful new tools for data processing and pattern recognition. This
paper proposes a hybrid recommendation system that combines Quantum Hopfield
Associative Memory (QHAM) with deep neural networks to improve the extraction
and classification on the MovieLens 1M dataset. User archetypes are clustered
into multiple unique groups using the K-Means algorithm and converted into
polar patterns through the encoder's activation function. These polar patterns
are then integrated into the variational QHAM-based hybrid recommendation
model. The system was trained using the MSE loss over 35 epochs in an ideal
environment, achieving an ROC value of 0.9795, an accuracy of 0.8841, and an
F-1 Score of 0.8786. Trained with the same number of epochs in a noisy
environment using a custom Qiskit AER noise model incorporating bit-flip and
readout errors with the same probabilities as in real quantum hardware, it
achieves an ROC of 0.9177, an accuracy of 0.8013, and an F-1 Score equal to
0.7866, demonstrating consistent performance.
  Additionally, we were able to optimize the qubit overhead present in previous
QHAM architectures by efficiently updating only one random targeted qubit. This
research presents a novel framework that combines variational quantum computing
with deep learning, capable of dealing with real-world datasets with comparable
performance compared to purely classical counterparts. Additionally, the model
can perform similarly well in noisy configurations, showcasing a steady
performance and proposing a promising direction for future usage in
recommendation systems.

</details>


### [3] [Closing the Performance Gap in Generative Recommenders with Collaborative Tokenization and Efficient Modeling](https://arxiv.org/abs/2508.14910)
*Simon Lepage,Jeremie Mary,David Picard*

Main category: cs.IR

TL;DR: COSETTE and MARIUS enhance generative recommender systems, improving accuracy and efficiency, and reducing the performance gap with traditional models.


<details>
  <summary>Details</summary>
Motivation: Improve generative recommender systems by addressing the lack of collaborative signal and inefficiencies in current generative methods.

Method: Introduced COSETTE, a contrastive tokenization method, and MARIUS, a generative model that separates timeline modeling from item decoding.

Result: Our proposed approach improves recommendation accuracy and reduces inference cost, making generative recommender systems more competitive with ID-based models.

Conclusion: COSETTE and MARIUS effectively address the limitations of generative recommender systems, closing the performance gap with ID-based models while maintaining generative benefits.

Abstract: Recent work has explored generative recommender systems as an alternative to
traditional ID-based models, reframing item recommendation as a sequence
generation task over discrete item tokens. While promising, such methods often
underperform in practice compared to well-tuned ID-based baselines like SASRec.
In this paper, we identify two key limitations holding back generative
approaches: the lack of collaborative signal in item tokenization, and
inefficiencies in the commonly used encoder-decoder architecture. To address
these issues, we introduce COSETTE, a contrastive tokenization method that
integrates collaborative information directly into the learned item
representations, jointly optimizing for both content reconstruction and
recommendation relevance. Additionally, we propose MARIUS, a lightweight,
audio-inspired generative model that decouples timeline modeling from item
decoding. MARIUS reduces inference cost while improving recommendation
accuracy. Experiments on standard sequential recommendation benchmarks show
that our approach narrows, or even eliminates, the performance gap between
generative and modern ID-based models, while retaining the benefits of the
generative paradigm.

</details>


### [4] [Personalized Recommendations via Active Utility-based Pairwise Sampling](https://arxiv.org/abs/2508.14911)
*Bahar Boroomand,James R. Wright*

Main category: cs.IR

TL;DR: 该论文提出了一种基于效用的推荐框架，通过成对比较来改进个性化推荐的准确性和效率，提供了更用户友好的体验。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统依赖于明确的评分或完全排序的物品列表，这种方法由于用户行为偏见和评分尺度的主观解释，往往无法准确捕捉用户真实的偏好。同时，获取完整的排名也非常繁琐且不现实。因此，该论文提出了一种基于简单而直观的成对比较的泛化效用框架来解决这些问题。

Method: 论文提出了一种基于效用的框架，通过学习简单的成对比较来提高推荐系统的性能。该方法不依赖于具体模型，并且设计用于优化任意、与任务相关的效用函数。其核心贡献是提出了一种新颖的效用主动采样策略来获取偏好数据。

Result: 实验结果表明，所提出的框架能够显著提高推荐系统的准确性和数据效率，同时增强用户体验。

Conclusion: 通过实验，该泛化效用框架在电影推荐和大学申请场景中都表现出色。这表明该方法能够提供一种更准确、数据高效、以用户为中心的个性化排名模式。

Abstract: Recommender systems play a critical role in enhancing user experience by
providing personalized suggestions based on user preferences. Traditional
approaches often rely on explicit numerical ratings or assume access to fully
ranked lists of items. However, ratings frequently fail to capture true
preferences due to users' behavioral biases and subjective interpretations of
rating scales, while eliciting full rankings is demanding and impractical. To
overcome these limitations, we propose a generalized utility-based framework
that learns preferences from simple and intuitive pairwise comparisons. Our
approach is model-agnostic and designed to optimize for arbitrary,
task-specific utility functions, allowing the system's objective to be
explicitly aligned with the definition of a high-quality outcome in any given
application. A central contribution of our work is a novel utility-based active
sampling strategy for preference elicitation. This method selects queries that
are expected to provide the greatest improvement to the utility of the final
recommended outcome. We ground our preference model in the probabilistic
Plackett-Luce framework for pairwise data. To demonstrate the versatility of
our approach, we present two distinct experiments: first, an implementation
using matrix factorization for a classic movie recommendation task, and second,
an implementation using a neural network for a complex candidate selection
scenario in university admissions. Experimental results demonstrate that our
framework provides a more accurate, data-efficient, and user-centric paradigm
for personalized ranking.

</details>


### [5] [Multimodal Recommendation via Self-Corrective Preference Alignmen](https://arxiv.org/abs/2508.14912)
*Yalong Guan,Xiang Chen,Mingyang Wang,Xiangyu Wu,Lihao Liu,Chao Qi,Shuang Yang,Tingting Gao,Guorui Zhou,Changjian Chen*

Main category: cs.IR

TL;DR: MSPA框架通过自我校正方法和多模态数据组合，提升了直播平台个性化推荐的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着直播平台的快速增长，个性化推荐系统在提升用户体验和推动平台收入方面变得至关重要。然而，传统方法难以准确对齐用户的动态偏好，同时考虑到直播内容的多模态特性，这限制了推荐的准确性和可解释性。

Method: 提出一个名为MSPA的个性化推荐框架，包括两个组件：（1）利用MLLMs生成结构化偏好文本和嵌入的多模态偏好组合器；（2）能够校正偏好的可解释性和准确性的自我校正推荐器。

Result: MSPA显著提高了准确性、召回率和文本质量，在动态直播场景中表现优于基准测试。

Conclusion: 通过MSPA，个性化推荐变得更加准确和可解释，解决了传统方法中的不足。

Abstract: With the rapid growth of live streaming platforms, personalized
recommendation systems have become pivotal in improving user experience and
driving platform revenue. The dynamic and multimodal nature of live streaming
content (e.g., visual, audio, textual data) requires joint modeling of user
behavior and multimodal features to capture evolving author characteristics.
However, traditional methods relying on single-modal features or treating
multimodal ones as supplementary struggle to align users' dynamic preferences
with authors' multimodal attributes, limiting accuracy and interpretability. To
address this, we propose MSPA (Multimodal Self-Corrective Preference
Alignment), a personalized author recommendation framework with two components:
(1) a Multimodal Preference Composer that uses MLLMs to generate structured
preference text and embeddings from users' tipping history; and (2) a
Self-Corrective Preference Alignment Recommender that aligns these preferences
with authors' multimodal features to improve accuracy and interpretability.
Extensive experiments and visualizations show that MSPA significantly improves
accuracy, recall, and text quality, outperforming baselines in dynamic live
streaming scenarios.

</details>


### [6] [M-$LLM^3$REC: A Motivation-Aware User-Item Interaction Framework for Enhancing Recommendation Accuracy with LLMs](https://arxiv.org/abs/2508.15262)
*Lining Chen,Qingwen Zeng,Huaming Chen*

Main category: cs.IR

TL;DR: 本论文提出了M-$LLM^3$REC推荐框架，通过动机驱动的语义建模，从有限用户互动中提取深层动机信号，显著改善冷启动情况下的推荐性能。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统在冷启动和数据稀疏情况下表现有限，通常生成伪交互序列或过度依赖语义相似性，忽视用户动机的动态变化。

Method: 提出了一种名为M-$LLM^3$REC的新推荐框架，利用大型语言模型从有限的用户互动中提取深层动机信号，包括三个模块：动机导向的档案提取器（MOPE）、动机导向的特质编码器（MOTE）和动机对齐推荐器（MAR）。

Result: M-$LLM^3$REC在冷启动情况下表现出色，提供强大、个性化和可推广的推荐性能，比现有的最先进框架效果更好。

Conclusion: M-$LLM^3$REC通过动机驱动的语义建模显著提高了推荐系统的性能，尤其是在冷启动情况下。

Abstract: Recommendation systems have been essential for both user experience and
platform efficiency by alleviating information overload and supporting
decision-making. Traditional methods, i.e., content-based filtering,
collaborative filtering, and deep learning, have achieved impressive results in
recommendation systems. However, the cold-start and sparse-data scenarios are
still challenging to deal with. Existing solutions either generate
pseudo-interaction sequence, which often introduces redundant or noisy signals,
or rely heavily on semantic similarity, overlooking dynamic shifts in user
motivation. To address these limitations, this paper proposes a novel
recommendation framework, termed M-$LLM^3$REC, which leverages large language
models for deep motivational signal extraction from limited user interactions.
M-$LLM^3$REC comprises three integrated modules: the Motivation-Oriented
Profile Extractor (MOPE), Motivation-Oriented Trait Encoder (MOTE), and
Motivational Alignment Recommender (MAR). By emphasizing motivation-driven
semantic modeling, M-$LLM^3$REC demonstrates robust, personalized, and
generalizable recommendations, particularly boosting performance in cold-start
situations in comparison with the state-of-the-art frameworks.

</details>


### [7] [Curriculum Approximate Unlearning for Session-based Recommendation](https://arxiv.org/abs/2508.15263)
*Liu Yang,Zhaochun Ren,Ziqi Zhao,Pengjie Ren,Zhumin Chen,Xinyi Li,Shuaiqiang Wang,Dawei Yin,Xin Xin*

Main category: cs.IR

TL;DR: CAU框架通过多目标优化和逐步取消学习处理会话推荐中的训练样本问题，提升取消学习效果同时保持推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在处理多个取消学习请求时没有考虑样本排序，导致推荐性能和取消学习效果不佳。此外，简单应用GA可能会导致推荐性能下降。

Method: CAU框架提出通过多目标优化将GA术语在不影响性能的情况下与保留术语结合，并通过获得Pareto-Optimal解来解决问题。此外，通过引入基于课程的序列来进行批量学习，采用两个指标来衡量取消学习的难度，提出了hard-sampling和soft-sampling策略。

Result: 该方法在有效进行取消学习的同时，仅对推荐性能造成了微小的影响。

Conclusion: CAU框架通过多目标优化和基于课程学习的方法有效缓解了GA在会话推荐中的性能下降和样本排序问题。

Abstract: Approximate unlearning for session-based recommendation refers to eliminating
the influence of specific training samples from the recommender without
retraining of (sub-)models. Gradient ascent (GA) is a representative method to
conduct approximate unlearning. However, there still exist dual challenges to
apply GA for session-based recommendation. On the one hand, naive applying of
GA could lead to degradation of recommendation performance. On the other hand,
existing studies fail to consider the ordering of unlearning samples when
simultaneously processing multiple unlearning requests, leading to sub-optimal
recommendation performance and unlearning effect. To address the above
challenges, we introduce CAU, a curriculum approximate unlearning framework
tailored to session-based recommendation. CAU handles the unlearning task with
a GA term on unlearning samples. Specifically, to address the first challenge,
CAU formulates the overall optimization task as a multi-objective optimization
problem, where the GA term for unlearning samples is combined with retaining
terms for preserving performance. The multi-objective optimization problem is
solved through seeking the Pareto-Optimal solution, which achieves effective
unlearning with trivial sacrifice on recommendation performance. To tackle the
second challenge, CAU adopts a curriculum-based sequence to conduct unlearning
on batches of unlearning samples. The key motivation is to perform unlearning
from easy samples to harder ones. To this end, CAU first introduces two metrics
to measure the unlearning difficulty, including gradient unlearning difficulty
and embedding unlearning difficulty. Then, two strategies, hard-sampling and
soft-sampling, are proposed to select unlearning samples according to
difficulty scores.

</details>


### [8] [MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation](https://arxiv.org/abs/2508.15281)
*Yi Xu,Moyu Zhang,Chenxuan Li,Zhihao Liao,Haibo Xing,Hao Deng,Jinxin Hu,Yu Zhang,Xiaoyi Zeng,Jing Zhang*

Main category: cs.IR

TL;DR: 提出了一种利用多模态量化混合（MMQ）框架来改进推荐系统的解决方案，能够有效应对语义表示与用户偏好不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统使用唯一标识符(ItemIDs)来表示项目，但这种方法在处理大型动态项目库和稀疏长尾数据时显得乏力，限制了可扩展性和泛化能力。文中的动机是通过语义ID解决这些问题，并提出框架来应对现有方法中的两大挑战。

Method: 提出了多模态量化混合（MMQ）框架，这是一种训练新型多模态分词器的两阶段方法。

Result: MMQ通过广泛的离线实验和在线A/B测试证明了其有效性。

Conclusion: MMQ在统一多模态协同、特异性和行为适应方面具有效力，提供了用于生成检索和判别排名任务的可扩展且多功能的解决方案。

Abstract: Recommender systems traditionally represent items using unique identifiers
(ItemIDs), but this approach struggles with large, dynamic item corpora and
sparse long-tail data, limiting scalability and generalization. Semantic IDs,
derived from multimodal content such as text and images, offer a promising
alternative by mapping items into a shared semantic space, enabling knowledge
transfer and improving recommendations for new or rare items. However, existing
methods face two key challenges: (1) balancing cross-modal synergy with
modality-specific uniqueness, and (2) bridging the semantic-behavioral gap,
where semantic representations may misalign with actual user preferences. To
address these challenges, we propose Multimodal Mixture-of-Quantization (MMQ),
a two-stage framework that trains a novel multimodal tokenizer. First, a
shared-specific tokenizer leverages a multi-expert architecture with
modality-specific and modality-shared experts, using orthogonal regularization
to capture comprehensive multimodal information. Second, behavior-aware
fine-tuning dynamically adapts semantic IDs to downstream recommendation
objectives while preserving modality information through a multimodal
reconstruction loss. Extensive offline experiments and online A/B tests
demonstrate that MMQ effectively unifies multimodal synergy, specificity, and
behavioral adaptation, providing a scalable and versatile solution for both
generative retrieval and discriminative ranking tasks.

</details>


### [9] [Adversarial Attacks against Neural Ranking Models via In-Context Learning](https://arxiv.org/abs/2508.15283)
*Amin Bigdeli,Negar Arabzadeh,Ebrahim Bagheri,Charles L. A. Clarke*

Main category: cs.IR

TL;DR: 引入了少样本对抗性提示(FSAP)，利用大型语言模型生成高排名的对抗性文档，成功超过准确文档的排名，具备现实可操作性。


<details>
  <summary>Details</summary>
Motivation: 神经排序模型虽然有效，但容易受到对抗性攻击。本文提出了一种新的黑盒攻击框架，即少样本对抗性提示（FSAP），利用大型语言模型的上下文学习生成高排名的对抗性文档。

Method: FSAP通过少样本提示进行对抗性攻击，无需梯度访问或内部模型仪器。通过在一个小支持集上条件化大型语言模型来综合生成文法流畅和主题连贯的文档。分为FSAP-IntraQ和FSAP-InterQ两种模式。

Result: FSAP生成的文档在TREC 2020和2021健康错误信息轨道上使用四种不同的神经排序模型进行测试，表现出持续超过可信的准确文档的排名，并具有强的立场一致性和低可检测性。

Conclusion: FSAP提出一种现实且可扩展的威胁，这种方法有效地在专有和开源大型语言模型之间进行泛化。

Abstract: While neural ranking models (NRMs) have shown high effectiveness, they remain
susceptible to adversarial manipulation. In this work, we introduce Few-Shot
Adversarial Prompting (FSAP), a novel black-box attack framework that leverages
the in-context learning capabilities of Large Language Models (LLMs) to
generate high-ranking adversarial documents. Unlike previous approaches that
rely on token-level perturbations or manual rewriting of existing documents,
FSAP formulates adversarial attacks entirely through few-shot prompting,
requiring no gradient access or internal model instrumentation. By conditioning
the LLM on a small support set of previously observed harmful examples, FSAP
synthesizes grammatically fluent and topically coherent documents that subtly
embed false or misleading information and rank competitively against authentic
content. We instantiate FSAP in two modes: FSAP-IntraQ, which leverages harmful
examples from the same query to enhance topic fidelity, and FSAP-InterQ, which
enables broader generalization by transferring adversarial patterns across
unrelated queries. Our experiments on the TREC 2020 and 2021 Health
Misinformation Tracks, using four diverse neural ranking models, reveal that
FSAP-generated documents consistently outrank credible, factually accurate
documents. Furthermore, our analysis demonstrates that these adversarial
outputs exhibit strong stance alignment and low detectability, posing a
realistic and scalable threat to neural retrieval systems. FSAP also
effectively generalizes across both proprietary and open-source LLMs.

</details>


### [10] [MLLMRec: Exploring the Potential of Multimodal Large Language Models in Recommender Systems](https://arxiv.org/abs/2508.15304)
*Yuzhuo Dang,Xin Zhang,Zhiqiang Pan,Yuxiao Duan,Wanyu Chen,Fei Cai,Honghui Chen*

Main category: cs.IR

TL;DR: MLLMRec通过改进用户表示和去噪物品图的方法，在多模态推荐中取得显著性能提升，实验结果优于既有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态推荐结合用户行为数据和物品的多模态特征，较传统推荐具有更优越的表现，但现有方法存在用户多模态表示初始化不准确和物品-物品图含噪声等问题。

Method: 提出MLLMRec框架，通过MLLM将物品图像转换为高质量语义描述，并与物品的文本信息融合；构建用户的行为描述列表，输入MLLM推理用户偏好；设计控制阈值去噪和拓扑增强策略优化物品-物品图。

Result: MLLMRec在三个公开数据集上的多个实验中表现出色，优于过去的推荐方法，取得了平均38.53%的性能提升。

Conclusion: MLLMRec框架能够显著提高多模态推荐的性能，在三个公开数据集上的实验表明，其表现优于目前最好的基线方法，平均提升幅度达到38.53%。

Abstract: Multimodal recommendation typically combines the user behavioral data with
the modal features of items to reveal user's preference, presenting superior
performance compared to the conventional recommendations. However, existing
methods still suffer from two key problems: (1) the initialization methods of
user multimodal representations are either behavior-unperceived or
noise-contaminated, and (2) the KNN-based item-item graph contains noisy edges
with low similarities and lacks audience co-occurrence relationships. To
address such issues, we propose MLLMRec, a novel MLLM-driven multimodal
recommendation framework with two item-item graph refinement strategies. On the
one hand, the item images are first converted into high-quality semantic
descriptions using an MLLM, which are then fused with the textual metadata of
items. Then, we construct a behavioral description list for each user and feed
it into the MLLM to reason about the purified user preference containing
interaction motivations. On the other hand, we design the threshold-controlled
denoising and topology-aware enhancement strategies to refine the suboptimal
item-item graph, thereby enhancing the item representation learning. Extensive
experiments on three publicly available datasets demonstrate that MLLMRec
achieves the state-of-the-art performance with an average improvement of 38.53%
over the best baselines.

</details>


### [11] [REG4Rec: Reasoning-Enhanced Generative Model for Large-Scale Recommendation Systems](https://arxiv.org/abs/2508.15308)
*Haibo Xing,Hao Deng,Yucheng Mao,Jinxin Hu,Yi Xu,Hao Zhang,Jiahao Wang,Shizhun Wang,Yu Zhang,Xiaoyi Zeng,Jing Zhang*

Main category: cs.IR

TL;DR: 我们提出了REG4Rec，一个增强推理生成模型，通过动态语义推理路径和自我反思过程实现高置信度推荐并提高推荐性能。


<details>
  <summary>Details</summary>
Motivation: 传统的推荐方法通常在信息交互方面表现不足，而生成推荐模型在一定程度上解决了这一问题，但仍面临推理路径多样性有限和推理过程不够可靠的挑战。

Method: REG4Rec模型利用基于MoE的并行量化码书生成每个项目的多个无序语义标记，从而构建更大规模的多样化推理空间。此外，为了增强推理的可靠性，提出了一个包括PARS（Reasoning偏好对齐）和MSRA（多步奖励增强）策略的训练推理增强阶段。PARS使用针对推荐的奖励函数来增强推理和反思，而MSRA引入未来多步动作以提高总体泛化。推理时，提出了CORP（一致性导向自我反思修剪）来丢弃不一致的推理路径，防止错误推理的传播。

Result: 实验表明，REG4Rec模型在真实数据集和在线评估中表现出色，具备显著的实际价值。

Conclusion: REG4Rec delivers outstanding performance and substantial practical value.

Abstract: Sequential recommendation aims to predict a user's next action in large-scale
recommender systems. While traditional methods often suffer from insufficient
information interaction, recent generative recommendation models partially
address this issue by directly generating item predictions. To better capture
user intents, recent studies have introduced a reasoning process into
generative recommendation, significantly improving recommendation performance.
However, these approaches are constrained by the singularity of item semantic
representations, facing challenges such as limited diversity in reasoning
pathways and insufficient reliability in the reasoning process. To tackle these
issues, we introduce REG4Rec, a reasoning-enhanced generative model that
constructs multiple dynamic semantic reasoning paths alongside a
self-reflection process, ensuring high-confidence recommendations.
Specifically, REG4Rec utilizes an MoE-based parallel quantization codebook
(MPQ) to generate multiple unordered semantic tokens for each item, thereby
constructing a larger-scale diverse reasoning space. Furthermore, to enhance
the reliability of reasoning, we propose a training reasoning enhancement
stage, which includes Preference Alignment for Reasoning (PARS) and a
Multi-Step Reward Augmentation (MSRA) strategy. PARS uses reward functions
tailored for recommendation to enhance reasoning and reflection, while MSRA
introduces future multi-step actions to improve overall generalization. During
inference, Consistency-Oriented Self-Reflection for Pruning (CORP) is proposed
to discard inconsistent reasoning paths, preventing the propagation of
erroneous reasoning. Lastly, we develop an efficient offline training strategy
for large-scale recommendation. Experiments on real-world datasets and online
evaluations show that REG4Rec delivers outstanding performance and substantial
practical value.

</details>


### [12] [Modeling Long-term User Behaviors with Diffusion-driven Multi-interest Network for CTR Prediction](https://arxiv.org/abs/2508.15311)
*Weijiang Lai,Beihong Jin,Yapeng Zhang,Yiyuan Zheng,Rui Zhao,Jian Dong,Jun Lei,Xingxing Wang*

Main category: cs.IR

TL;DR: 提出了DiffuMIN，结合多兴趣提取与扩散模块，以更好地捕捉长期用户行为并提升CTR预测性能，获得了显著的实验结果。


<details>
  <summary>Details</summary>
Motivation: 现有的两阶段模型通常会过滤掉重要的信息，无法捕捉到多样的用户兴趣。因此，提出DiffuMIN以改进长期用户行为建模并更全面探索用户兴趣空间。

Method: 提出目标导向的多兴趣提取方法，通过正交分解目标获得兴趣频道，随后建模兴趣频道与用户行为之间的关系。采用扩散模块引导的上下文兴趣和兴趣频道，生成符合用户潜在空间的扩展兴趣，同时利用对比学习确保生成的兴趣与用户真实偏好一致。

Result: DiffuMIN在两个公开数据集和一个工业数据集的离线实验中取得了优越的效果，并在在线A/B测试中提高了CTR 1.52%和CPM 1.10%。

Conclusion: DiffuMIN通过引入多兴趣提取方法和扩散模块，在离线和在线实验中证明了其在CTR预测中的有效性和优越性。

Abstract: CTR (Click-Through Rate) prediction, crucial for recommender systems and
online advertising, etc., has been confirmed to benefit from modeling long-term
user behaviors. Nonetheless, the vast number of behaviors and complexity of
noise interference pose challenges to prediction efficiency and effectiveness.
Recent solutions have evolved from single-stage models to two-stage models.
However, current two-stage models often filter out significant information,
resulting in an inability to capture diverse user interests and build the
complete latent space of user interests. Inspired by multi-interest and
generative modeling, we propose DiffuMIN (Diffusion-driven Multi-Interest
Network) to model long-term user behaviors and thoroughly explore the user
interest space. Specifically, we propose a target-oriented multi-interest
extraction method that begins by orthogonally decomposing the target to obtain
interest channels. This is followed by modeling the relationships between
interest channels and user behaviors to disentangle and extract multiple user
interests. We then adopt a diffusion module guided by contextual interests and
interest channels, which anchor users' personalized and target-oriented
interest types, enabling the generation of augmented interests that align with
the latent spaces of user interests, thereby further exploring restricted
interest space. Finally, we leverage contrastive learning to ensure that the
generated augmented interests align with users' genuine preferences. Extensive
offline experiments are conducted on two public datasets and one industrial
dataset, yielding results that demonstrate the superiority of DiffuMIN.
Moreover, DiffuMIN increased CTR by 1.52% and CPM by 1.10% in online A/B
testing. Our source code is available at
https://github.com/laiweijiang/DiffuMIN.

</details>


### [13] [Exploring Scaling Laws of CTR Model for Online Performance Improvement](https://arxiv.org/abs/2508.15326)
*Weijiang Lai,Beihong Jin,Jiongyan Zhang,Yiyuan Zheng,Jian Dong,Jia Cheng,Jun Lei,Xingxing Wang*

Main category: cs.IR

TL;DR: 提出了一种新的CTR预测方法，利用SUAN模型及其蒸馏版LightSUAN提高在线服务性能，实验验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 当前CTR模型在性能提升方面遇到瓶颈，受LLMs的扩展法则现象启发，提出新的CTR预测增强方法。

Method: 本文通过构建SUAN（Stacked Unified Attention Network）模型，其中使用UAB作为行为序列编码器，通过稀疏自注意力与并行推理策略形成LightSUAN，并采用在线蒸馏进行训练。

Result: 实验结果显示SUAN性能表现优异，并展现跨越三个数量级的扩展法则能力，LightSUAN在相同推理时间下性能优于高一等级的SUAN，并有效提高在线服务CTR2.81%和CPM1.69%。

Conclusion: 本文提出了一种新的CTR预测范式，通过构建准确率与模型等级和数据规模可扩展的CTR模型，并将其知识蒸馏到轻量级模型提高在线服务的性能。

Abstract: CTR models play a vital role in improving user experience and boosting
business revenue in many online personalized services. However, current CTR
models generally encounter bottlenecks in performance improvement. Inspired by
the scaling law phenomenon of LLMs, we propose a new paradigm for improving CTR
predictions: first, constructing a CTR model with accuracy scalable to the
model grade and data size, and then distilling the knowledge implied in this
model into its lightweight model that can serve online users. To put it into
practice, we construct a CTR model named SUAN (Stacked Unified Attention
Network). In SUAN, we propose the UAB as a behavior sequence encoder. A single
UAB unifies the modeling of the sequential and non-sequential features and also
measures the importance of each user behavior feature from multiple
perspectives. Stacked UABs elevate the configuration to a high grade, paving
the way for performance improvement. In order to benefit from the high
performance of the high-grade SUAN and avoid the disadvantage of its long
inference time, we modify the SUAN with sparse self-attention and parallel
inference strategies to form LightSUAN, and then adopt online distillation to
train the low-grade LightSUAN, taking a high-grade SUAN as a teacher. The
distilled LightSUAN has superior performance but the same inference time as the
LightSUAN, making it well-suited for online deployment. Experimental results
show that SUAN performs exceptionally well and holds the scaling laws spanning
three orders of magnitude in model grade and data size, and the distilled
LightSUAN outperforms the SUAN configured with one grade higher. More
importantly, the distilled LightSUAN has been integrated into an online
service, increasing the CTR by 2.81% and CPM by 1.69% while keeping the average
inference time acceptable. Our source code is available at
https://github.com/laiweijiang/SUAN.

</details>


### [14] [TrackRec: Iterative Alternating Feedback with Chain-of-Thought via Preference Alignment for Recommendation](https://arxiv.org/abs/2508.15388)
*Yu Xia,Rui Zhong,Zeyu Song,Wei Yang,Junchen Wan,Qingpeng Cai,Chi Lu,Peng Jiang*

Main category: cs.IR

TL;DR: 提出TrackRec框架，改善大语言模型在推荐系统中的推理能力，取得显著效果并成功部署在大型广告平台上。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型在推荐系统中的推理能力，克服其容易出现幻觉的问题，以提高推荐效果。

Method: 提出了一个名为TrackRec的框架，通过设计RecCoT生成器(G)和验证器(V)，并采用交替反馈学习机制来增强推荐推理能力。

Result: 通过大量实验验证，TrackRec超过了现有的先进方法，并已在一个拥有数亿用户的大型广告平台上部署，实现了显著的收益。

Conclusion: TrackRec能够增强大语言模型在推荐任务中的推理能力，并且能够为用户偏好推理提供准确的链路思维，同时在实际应用中取得了很好的效果。

Abstract: The extensive world knowledge and powerful reasoning capabilities of large
language models (LLMs) have attracted significant attention in recommendation
systems (RS). Specifically, The chain of thought (CoT) has been shown to
improve the performance of LLMs on complex reasoning tasks for RS. However, due
to the fact that LLMs often suffer from hallucination issues, there is no
guarantee that their reasoning CoT is effective. A key challenge is to further
enhance the recommendation capabilities of LLMs through effective CoT
reasonings. Therefore, we propose \textbf{TrackRec}, a framework designed to
enhance reasoning capabilities of LLMs for RS. TrackRec specifically focuses on
accurately inferring recommendation CoT \textbf{(RecCoT)} for user preference
using the knowledge from LLMs. This RecCoT can serve both as an explanation for
the LLM's completion of recommendation tasks and as auxiliary features to
assist recommendation models in accomplishing recommendation tasks. TrackRec
consists of a RecCoT generator $(G)$ and a RecCoT validator $(V)$. Furthermore,
we design alternating feedback learning mechanism that $G$ undergoes direct
preference optimization via feedback from $V$ to produce increasingly accurate
RecCoT aligned with $V$'s standards. Meanwhile, $V$ is fine-tuned using the
inference feedback from $G$ to enhance its validation capabilities in alignment
with recommendation tasks. Through iterative alternating feedback learning
between $G$ and $V$, TrackRec continuously improves the user preference
analysis capability of $G$ and the validation capacity of $V$. Extensive
experiments demonstrate the effectiveness of our approach, showing that it
surpasses state-of-the-art methods. Moreover, TrackRec has been deployed on a
lagre advertising platform with hundreds of millions of users, achieving
substantial gains.

</details>


### [15] [On the Effectiveness of Graph Reordering for Accelerating Approximate Nearest Neighbor Search on GPU](https://arxiv.org/abs/2508.15436)
*Yutaro Oguri,Mai Nishimura,Yusuke Matsui*

Main category: cs.IR

TL;DR: 本文首次系统探索图重排序对基于图的近似最近邻搜索的影响，通过GPU优化达成了最高15% 的QPS提升，同时保持了搜索准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管图形ANNS已成为现代AI应用的主要范式，但现有方法过于关注算法创新，忽视了显著影响执行时间的内存布局问题。

Method: 提出了一个统一的评估框架，为不同图索引中的多种重排序策略提供全面评估。使用了一个图适配器来将任意图拓扑转换为公共表示，并结合一个GPU优化的图遍历引擎。

Result: 通过GPU针对性的重排序，在保持搜索准确性的同时，实现了最高15%的QPS提升。

Conclusion: 在确保搜索准确性的同时，优化内存布局可以独立于现有算法创新运作，有效提升了图排序效果，被证明能提高高达15% 的QPS性能。

Abstract: We present the first systematic investigation of graph reordering effects for
graph-based Approximate Nearest Neighbor Search (ANNS) on a GPU. While
graph-based ANNS has become the dominant paradigm for modern AI applications,
recent approaches focus on algorithmic innovations while neglecting memory
layout considerations that significantly affect execution time. Our unified
evaluation framework enables comprehensive evaluation of diverse reordering
strategies across different graph indices through a graph adapter that converts
arbitrary graph topologies into a common representation and a GPU-optimized
graph traversal engine. We conduct a comprehensive analysis across diverse
datasets and state-of-the-art graph indices, introducing analysis metrics that
quantify the relationship between structural properties and memory layout
effectiveness. Our GPU-targeted reordering achieves up to 15$\%$ QPS
improvements while preserving search accuracy, demonstrating that memory layout
optimization operates orthogonally to existing algorithmic innovations. We will
release all code upon publication to facilitate reproducibility and foster
further research.

</details>


### [16] [Test-time Corpus Feedback: From Retrieval to RAG](https://arxiv.org/abs/2508.15437)
*Mandeep Rathee,Venktesh V,Sean MacAvaney,Avishek Anand*

Main category: cs.IR

TL;DR: 本文综述了RAG框架中的高级检索和排名机制，探讨了集成反馈的方法以改善复杂任务的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管RAG框架在知识密集型NLP任务中被广泛使用，其静态设计限制了复杂任务的性能表现，促使研究者探索集成反馈的检索与排名方法，以提高系统的精确性和迭代性能。

Method: 本文采用了结构化综述的方法，对高级检索和排名机制进行分类，尤其关注集成反馈增强检索性能的方法。

Result: 本文将反馈信号的来源和在改善查询、检索上下文及文档池中的作用进行分类，整合了信息检索和自然语言处理社区的最新进展。

Conclusion: 本文综述了集成反馈的高级检索和排名机制，旨在桥接信息检索和自然语言处理的视角，强调检索作为端到端RAG系统中动态、可学习的组成部分的重要性。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a standard framework for
knowledge-intensive NLP tasks, combining large language models (LLMs) with
document retrieval from external corpora. Despite its widespread use, most RAG
pipelines continue to treat retrieval and reasoning as isolated components,
retrieving documents once and then generating answers without further
interaction. This static design often limits performance on complex tasks that
require iterative evidence gathering or high-precision retrieval. Recent work
in both the information retrieval (IR) and NLP communities has begun to close
this gap by introducing adaptive retrieval and ranking methods that incorporate
feedback. In this survey, we present a structured overview of advanced
retrieval and ranking mechanisms that integrate such feedback. We categorize
feedback signals based on their source and role in improving the query,
retrieved context, or document pool. By consolidating these developments, we
aim to bridge IR and NLP perspectives and highlight retrieval as a dynamic,
learnable component of end-to-end RAG systems.

</details>


### [17] [On Evaluating the Adversarial Robustness of Foundation Models for Multimodal Entity Linking](https://arxiv.org/abs/2508.15481)
*Fang Wang,Yongjie Wang,Zonghao Yang,Minghao Hu,Xiaoying Bai*

Main category: cs.IR

TL;DR: 研究发现现有多模态实体链接模型在视觉对抗攻击下鲁棒性不足，提出LLM-RetLink方法显著提升模型抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 由于多模态数据的爆炸性增长，现有研究尚未系统性地探讨视觉对抗攻击对多模态实体链接（MEL）模型的影响。

Method: 首先使用大型视觉模型（LVMs）提取初始实体描述，然后通过网络检索动态生成候选描述性句子。

Result: LLM-RetLink模型在五个数据集上的实验结果显示，MEL的准确性提高了0.4%-35.7%，尤其在对抗条件下表现出显著优势。

Conclusion: 该研究揭示了当前多模态实体链接模型在视觉对抗攻击下普遍缺乏足够的鲁棒性，同时提出了一种基于LLM和检索增强的实体链接方法（LLM-RetLink），显著提升了模型的抗干扰能力。

Abstract: The explosive growth of multimodal data has driven the rapid development of
multimodal entity linking (MEL) models. However, existing studies have not
systematically investigated the impact of visual adversarial attacks on MEL
models. We conduct the first comprehensive evaluation of the robustness of
mainstream MEL models under different adversarial attack scenarios, covering
two core tasks: Image-to-Text (I2T) and Image+Text-to-Text (IT2T). Experimental
results show that current MEL models generally lack sufficient robustness
against visual perturbations. Interestingly, contextual semantic information in
input can partially mitigate the impact of adversarial perturbations. Based on
this insight, we propose an LLM and Retrieval-Augmented Entity Linking
(LLM-RetLink), which significantly improves the model's anti-interference
ability through a two-stage process: first, extracting initial entity
descriptions using large vision models (LVMs), and then dynamically generating
candidate descriptive sentences via web-based retrieval. Experiments on five
datasets demonstrate that LLM-RetLink improves the accuracy of MEL by
0.4%-35.7%, especially showing significant advantages under adversarial
conditions. This research highlights a previously unexplored facet of MEL
robustness, constructs and releases the first MEL adversarial example dataset,
and sets the stage for future work aimed at strengthening the resilience of
multimodal systems in adversarial environments.

</details>


### [18] [LongRetriever: Towards Ultra-Long Sequence based Candidate Retrieval for Recommendation](https://arxiv.org/abs/2508.15486)
*Ren Qin,Chai Zheng,Xiao Xijun,Zheng Yuchao,Wu Di*

Main category: cs.IR

TL;DR: 研究LongRetriever框架，通过用户超长序列优化推荐系统的检索阶段，测试表明有效并已广泛应用。


<details>
  <summary>Details</summary>
Motivation: 增强推荐系统候选检索阶段的能力，处理用户超长序列问题。

Method: 提出LongRetriever框架，结合超长序列进行候选检索，包括上下文训练和多上下文检索方法。

Result: 在线A/B测试证实了该框架在大规模电商平台上的有效性，目前已全面部署影响数十亿用户。

Conclusion: 长序列在推荐系统候选检索阶段的应用能够带来显著的性能改进。

Abstract: Precisely modeling user ultra-long sequences is critical for industrial
recommender systems. Current approaches predominantly focus on leveraging
ultra-long sequences in the ranking stage, whereas research for the candidate
retrieval stage remains under-explored. This paper presents LongRetriever, a
practical framework for incorporating ultra-long sequences into the retrieval
stage of recommenders. Specifically, we propose in-context training and
multi-context retrieval, which enable candidate-specific interaction between
user sequence and candidate item, and ensure training-serving consistency under
the search-based paradigm. Extensive online A/B testing conducted on a
large-scale e-commerce platform demonstrates statistically significant
improvements, confirming the framework's effectiveness. Currently,
LongRetriever has been fully deployed in the platform, impacting billions of
users.

</details>


### [19] [Reading Between the Lines: A Study of Thematic Bias in Book Recommender Systems](https://arxiv.org/abs/2508.15643)
*Nityaa Kalra,Savvina Daniil*

Main category: cs.IR

TL;DR: 研究介绍了书籍推荐中的主题偏见，并发现推荐系统可能加剧偏见，建议为了负责任的AI发展，应设计能够容纳广泛用户兴趣的系统。


<details>
  <summary>Details</summary>
Motivation: 推荐系统在帮助用户发现新内容的同时，也可能加剧现有偏见，导致不公平的曝光和多样性减少。

Method: 采用多阶段偏见评估框架，利用Book-Crossing数据集评估推荐中的主题偏见及其对不同用户群体的影响。

Result: 发现主题偏见源于内容不平衡，并通过用户参与模式放大。同时，不同兴趣群体的用户得到的推荐个性化程度不同：拥有小众及长尾兴趣的用户得到的推荐个性化程度较低，而兴趣多样的用户则获得较一致的推荐。

Conclusion: 推荐系统应精心设计，以满足更广泛的用户兴趣，以减少偏见并提高多样性。

Abstract: Recommender systems help users discover new content, but can also reinforce
existing biases, leading to unfair exposure and reduced diversity. This paper
introduces and investigates thematic bias in book recommendations, defined as a
disproportionate favouring or neglect of certain book themes. We adopt a
multi-stage bias evaluation framework using the Book-Crossing dataset to
evaluate thematic bias in recommendations and its impact on different user
groups.
  Our findings show that thematic bias originates from content imbalances and
is amplified by user engagement patterns. By segmenting users based on their
thematic preferences, we find that users with niche and long-tail interests
receive less personalised recommendations, whereas users with diverse interests
receive more consistent recommendations. These findings suggest that
recommender systems should be carefully designed to accommodate a broader range
of user interests. By contributing to the broader goal of responsible AI, this
work also lays the groundwork for extending thematic bias analysis to other
domains.

</details>
