{"id": "2509.02837", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02837", "abs": "https://arxiv.org/abs/2509.02837", "authors": ["Payel Santra", "Madhusudan Ghosh", "Debasis Ganguly", "Partha Basuchowdhuri", "Sudip Kumar Naskar"], "title": "HF-RAG: Hierarchical Fusion-based RAG with Multiple Sources and Rankers", "comment": null, "summary": "Leveraging both labeled (input-output associations) and unlabeled data (wider\ncontextual grounding) may provide complementary benefits in retrieval augmented\ngeneration (RAG). However, effectively combining evidence from these\nheterogeneous sources is challenging as the respective similarity scores are\nnot inter-comparable. Additionally, aggregating beliefs from the outputs of\nmultiple rankers can improve the effectiveness of RAG. Our proposed method\nfirst aggregates the top-documents from a number of IR models using a standard\nrank fusion technique for each source (labeled and unlabeled). Next, we\nstandardize the retrieval score distributions within each source by applying\nz-score transformation before merging the top-retrieved documents from the two\nsources. We evaluate our approach on the fact verification task, demonstrating\nthat it consistently improves over the best-performing individual ranker or\nsource and also shows better out-of-domain generalization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6807\u7b7e\u548c\u975e\u6807\u7b7e\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u68c0\u7d22\u5f97\u5206\u6539\u5584\u4e8b\u5b9e\u9a8c\u8bc1\u4efb\u52a1\u7684\u6548\u679c\u3002", "motivation": "\u7ed3\u5408\u6807\u7b7e\u548c\u975e\u6807\u7b7e\u6570\u636e\u4ee5\u63d0\u5347\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u6548\u679c\uff0c\u5e76\u89e3\u51b3\u5f02\u6784\u6765\u6e90\u8bc1\u636e\u5408\u5e76\u56f0\u96be\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u6807\u51c6\u6392\u884c\u878d\u5408\u6280\u672f\u6574\u5408\u591a\u4e2a\u4fe1\u606f\u68c0\u7d22\u6a21\u578b\u7684\u9876\u90e8\u6587\u6863\u3002\u7136\u540e\uff0c\u5e94\u7528z-score\u8f6c\u5316\u6807\u51c6\u5316\u6bcf\u4e2a\u6765\u6e90\u7684\u68c0\u7d22\u5f97\u5206\u5206\u5e03\uff0c\u5408\u5e76\u4e24\u4e2a\u6765\u6e90\u7684\u9876\u90e8\u68c0\u7d22\u6587\u6863\u3002", "result": "\u65b9\u6cd5\u5728\u4e8b\u5b9e\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u63d0\u9ad8\u4e86\u6548\u679c\uff0c\u4e14\u8868\u73b0\u51fa\u66f4\u597d\u7684\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u6539\u5584\u4e86\u4e2a\u522b\u6392\u884c\u5668\u7684\u8868\u73b0\uff0c\u663e\u793a\u51fa\u66f4\u597d\u7684\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.02890", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02890", "abs": "https://arxiv.org/abs/2509.02890", "authors": ["Akshay Kekuda", "Murali Mohana Krishna Dandu", "Rimita Lahiri", "Shiqin Cai", "Sinduja Subramaniam", "Evren Korpeoglu", "Kannan Achan"], "title": "Grocery to General Merchandise: A Cross-Pollination Recommender using LLMs and Real-Time Cart Context", "comment": null, "summary": "Modern e-commerce platforms strive to enhance customer experience by\nproviding timely and contextually relevant recommendations. However,\nrecommending general merchandise to customers focused on grocery shopping --\nsuch as pairing milk with a milk frother -- remains a critical yet\nunder-explored challenge. This paper introduces a cross-pollination (XP)\nframework, a novel approach that bridges grocery and general merchandise\ncross-category recommendations by leveraging multi-source product associations\nand real-time cart context. Our solution employs a two-stage framework: (1) A\ncandidate generation mechanism that uses co-purchase market basket analysis and\nLLM-based approach to identify novel item-item associations; and (2) a\ntransformer-based ranker that leverages the real-time sequential cart context\nand optimizes for engagement signals such as add-to-carts. Offline analysis and\nonline A/B tests show an increase of 36\\% add-to-cart rate with LLM-based\nretrieval, and 27\\% NDCG\\@4 lift using cart context-based ranker. Our work\ncontributes practical techniques for cross-category recommendations and broader\ninsights for e-commerce systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u8de8\u6388\u7c89\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u591a\u6e90\u4ea7\u54c1\u5173\u8054\u548c\u5b9e\u65f6\u8d2d\u7269\u8f66\u4e0a\u4e0b\u6587\u6765\u89e3\u51b3\u63a8\u8350\u6742\u8d27\u548c\u4e00\u822c\u5546\u54c1\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u4ee3\u7535\u5b50\u5546\u52a1\u5e73\u53f0\u901a\u8fc7\u63d0\u4f9b\u53ca\u65f6\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u63a8\u8350\u6765\u589e\u5f3a\u5ba2\u6237\u4f53\u9a8c\u3002\u7136\u800c\uff0c\u5c06\u4e00\u822c\u5546\u54c1\u63a8\u8350\u7ed9\u4e13\u6ce8\u4e8e\u6742\u8d27\u8d2d\u7269\u7684\u5ba2\u6237\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u8981\u4f46\u5c1a\u672a\u6df1\u5165\u7814\u7a76\u7684\u6311\u6218\u3002", "method": "\u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u662f\u5019\u9009\u751f\u6210\u673a\u5236\uff0c\u5229\u7528\u5171\u540c\u8d2d\u4e70\u5e02\u573a\u7bee\u5b50\u5206\u6790\u548cLLM\u65b9\u6cd5\u8bc6\u522b\u65b0\u9896\u7684\u9879\u76ee\u4e0e\u9879\u76ee\u5173\u8054\uff1b\u7b2c\u4e8c\u9636\u6bb5\u662f\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u6392\u5e8f\u5668\uff0c\u5229\u7528\u5b9e\u65f6\u5e8f\u5217\u8d2d\u7269\u8f66\u4e0a\u4e0b\u6587\uff0c\u4f18\u5316\u52a0\u5165\u8d2d\u7269\u8f66\u7b49\u53c2\u4e0e\u4fe1\u53f7\u3002", "result": "\u79bb\u7ebf\u5206\u6790\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\uff0c\u901a\u8fc7LLM\u68c0\u7d22\uff0c\u52a0\u5165\u8d2d\u7269\u8f66\u7387\u63d0\u9ad8\u4e8636%\uff0c\u4f7f\u7528\u8d2d\u7269\u8f66\u4e0a\u4e0b\u6587\u6392\u5e8f\u5668\uff0cNDCG@4\u63d0\u5347\u4e8627%\u3002", "conclusion": "\u6211\u4eec\u7684\u5de5\u4f5c\u4e3a\u8de8\u7c7b\u522b\u63a8\u8350\u63d0\u4f9b\u4e86\u5b9e\u7528\u6280\u672f\uff0c\u5e76\u4e3a\u7535\u5b50\u5546\u52a1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.02942", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.02942", "abs": "https://arxiv.org/abs/2509.02942", "authors": ["Renzhi Wu", "Junjie Yang", "Li Chen", "Hong Li", "Li Yu", "Hong Yan"], "title": "RankGraph: Unified Heterogeneous Graph Learning for Cross-Domain Recommendation", "comment": "RecSys 2025", "summary": "Cross-domain recommendation systems face the challenge of integrating\nfine-grained user and item relationships across various product domains. To\naddress this, we introduce RankGraph, a scalable graph learning framework\ndesigned to serve as a core component in recommendation foundation models\n(FMs). By constructing and leveraging graphs composed of heterogeneous nodes\nand edges across multiple products, RankGraph enables the integration of\ncomplex relationships between users, posts, ads, and other entities. Our\nframework employs a GPU-accelerated Graph Neural Network and contrastive\nlearning, allowing for dynamic extraction of subgraphs such as item-item and\nuser-user graphs to support similarity-based retrieval and real-time\nclustering. Furthermore, RankGraph integrates graph-based pretrained\nrepresentations as contextual tokens into FM sequence models, enriching them\nwith structured relational knowledge. RankGraph has demonstrated improvements\nin click (+0.92%) and conversion rates (+2.82%) in online A/B tests, showcasing\nits effectiveness in cross-domain recommendation scenarios.", "AI": {"tldr": "RankGraph\u6846\u67b6\u5229\u7528\u56fe\u7ed3\u6784\u5b66\u4e60\u63d0\u5347\u8de8\u9886\u57df\u63a8\u8350\u7cfb\u7edf\u7684\u70b9\u51fb\u7387\u548c\u8f6c\u5316\u7387\u3002", "motivation": "\u8de8\u9886\u57df\u63a8\u8350\u7cfb\u7edf\u9762\u4e34\u5728\u4e0d\u540c\u4ea7\u54c1\u9886\u57df\u4e2d\u6574\u5408\u7528\u6237\u548c\u9879\u76ee\u4e4b\u95f4\u7684\u7ec6\u7c92\u5ea6\u5173\u7cfb\u7684\u6311\u6218\u3002", "method": "RankGraph\u4f7f\u7528GPU\u52a0\u901f\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5728\u591a\u4e2a\u4ea7\u54c1\u95f4\u6784\u5efa\u7531\u5f02\u6784\u8282\u70b9\u548c\u8fb9\u7ec4\u6210\u7684\u56fe\uff0c\u4ee5\u652f\u6301\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7684\u68c0\u7d22\u548c\u5b9e\u65f6\u805a\u7c7b\uff0c\u5e76\u5c06\u56fe\u7ed3\u6784\u7684\u9884\u8bad\u7ec3\u8868\u793a\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u6807\u8bb0\u6574\u5408\u5230\u63a8\u8350\u57fa\u7840\u6a21\u578b\u4e2d\u3002", "result": "\u901a\u8fc7\u5728\u7ebfA/B\u6d4b\u8bd5\uff0cRankGraph\u5728\u70b9\u51fb\u7387\u548c\u8f6c\u5316\u7387\u4e0a\u5206\u522b\u63d0\u9ad8\u4e860.92%\u548c2.82%\u3002", "conclusion": "RankGraph\u5728\u8de8\u9886\u57df\u63a8\u8350\u573a\u666f\u4e2d\u5c55\u73b0\u4e86\u5176\u6709\u6548\u6027\uff0c\u63d0\u9ad8\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u8868\u73b0\u3002"}}
{"id": "2509.02943", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.02943", "abs": "https://arxiv.org/abs/2509.02943", "authors": ["Yu Fang"], "title": "Knowledge graph-based personalized multimodal recommendation fusion framework", "comment": null, "summary": "In the contemporary age characterized by information abundance, rapid\nadvancements in artificial intelligence have rendered recommendation systems\nindispensable. Conventional recommendation methodologies based on collaborative\nfiltering or individual attributes encounter deficiencies in capturing nuanced\nuser interests. Knowledge graphs and multimodal data integration offer enhanced\nrepresentations of users and items with greater richness and precision. This\npaper reviews existing multimodal knowledge graph recommendation frameworks,\nidentifying shortcomings in modal interaction and higher-order dependency\nmodeling. We propose the Cross-Graph Cross-Modal Mutual Information-Driven\nUnified Knowledge Graph Learning and Recommendation Framework\n(CrossGMMI-DUKGLR), which employs pre-trained visual-text alignment models for\nfeature extraction, achieves fine-grained modality fusion through multi-head\ncross-attention, and propagates higher-order adjacency information via graph\nattention networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63a8\u8350\u6846\u67b6CrossGMMI-DUKGLR\uff0c\u6539\u5584\u4e86\u6a21\u6001\u4ea4\u4e92\u548c\u9ad8\u9636\u4f9d\u8d56\u5efa\u6a21\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u5728\u5f53\u4ee3\u4fe1\u606f\u4e30\u5bcc\u7684\u65f6\u4ee3\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u7684\u63a8\u8350\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u7ec6\u5fae\u7684\u7528\u6237\u5174\u8da3\u3002\u77e5\u8bc6\u56fe\u8c31\u548c\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u63d0\u4f9b\u4e86\u66f4\u4e3a\u4e30\u5bcc\u548c\u7cbe\u786e\u7684\u7528\u6237\u548c\u9879\u76ee\u8868\u793a\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86CrossGMMI-DUKGLR\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u9884\u8bad\u7ec3\u7684\u89c6\u89c9-\u6587\u672c\u5bf9\u9f50\u6a21\u578b\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u901a\u8fc7\u591a\u5934\u4ea4\u53c9\u6ce8\u610f\u529b\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u6a21\u6001\u878d\u5408\uff0c\u5e76\u901a\u8fc7\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u4f20\u64ad\u9ad8\u9636\u90bb\u63a5\u4fe1\u606f\u3002", "result": "CrossGMMI-DUKGLR\u6846\u67b6\u53ef\u4ee5\u66f4\u597d\u5730\u89e3\u51b3\u73b0\u6709\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u63a8\u8350\u6846\u67b6\u5728\u6a21\u6001\u4ea4\u4e92\u548c\u9ad8\u9636\u4f9d\u8d56\u5efa\u6a21\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "conclusion": "\u901a\u8fc7CrossGMMI-DUKGLR\u6846\u67b6\uff0c\u53ef\u4ee5\u5b9e\u73b0\u5bf9\u7528\u6237\u548c\u9879\u76ee\u66f4\u7cbe\u786e\u7684\u8868\u793a\uff0c\u4ece\u800c\u6539\u5584\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2509.03130", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.03130", "abs": "https://arxiv.org/abs/2509.03130", "authors": ["Yunqi Mi", "Boyang Yan", "Guoshuai Zhao", "Jialie Shen", "Xueming Qian"], "title": "A Plug-and-play Model-agnostic Embedding Enhancement Approach for Explainable Recommendation", "comment": null, "summary": "Existing multimedia recommender systems provide users with suggestions of\nmedia by evaluating the similarities, such as games and movies. To enhance the\nsemantics and explainability of embeddings, it is a consensus to apply\nadditional information (e.g., interactions, contexts, popularity). However,\nwithout systematic consideration of representativeness and value, the utility\nand explainability of embedding drops drastically. Hence, we introduce RVRec, a\nplug-and-play model-agnostic embedding enhancement approach that can improve\nboth personality and explainability of existing systems. Specifically, we\npropose a probability-based embedding optimization method that uses a\ncontrastive loss based on negative 2-Wasserstein distance to learn to enhance\nthe representativeness of the embeddings. In addtion, we introduce a reweighing\nmethod based on multivariate Shapley values strategy to evaluate and explore\nthe value of interactions and embeddings. Extensive experiments on multiple\nbackbone recommenders and real-world datasets show that RVRec can improve the\npersonalization and explainability of existing recommenders, outperforming\nstate-of-the-art baselines.", "AI": {"tldr": "RVRec\u901a\u8fc7\u589e\u5f3a\u5d4c\u5165\u7684\u4ee3\u8868\u6027\u548c\u4ef7\u503c\u8bc4\u4f30\uff0c\u6539\u5584\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u4e2a\u6027\u5316\u548c\u89e3\u91ca\u6027\uff0c\u8868\u73b0\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u6700\u65b0\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u5a92\u4f53\u63a8\u8350\u7cfb\u7edf\u901a\u8fc7\u8bc4\u4f30\u76f8\u4f3c\u6027\u63d0\u4f9b\u5a92\u4f53\u5efa\u8bae\uff0c\u5982\u6e38\u620f\u548c\u7535\u5f71\uff0c\u4e3a\u4e86\u589e\u5f3a\u5d4c\u5165\u7684\u8bed\u4e49\u548c\u89e3\u91ca\u6027\uff0c\u901a\u5e38\u4f1a\u5e94\u7528\u9644\u52a0\u4fe1\u606f\u3002\u7136\u800c\uff0c\u5982\u679c\u6ca1\u6709\u7cfb\u7edf\u5730\u8003\u8651\u4ee3\u8868\u6027\u548c\u4ef7\u503c\uff0c\u5d4c\u5165\u7684\u6548\u7528\u548c\u89e3\u91ca\u6027\u4f1a\u6025\u5267\u4e0b\u964d\u3002", "method": "\u5f15\u5165RVRec\uff0c\u4e00\u79cd\u8be5\u7cfb\u7edf\u4e2d\u667a\u80fd\u5316\u7684\u5d4c\u5165\u589e\u5f3a\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u662f\u4e0e\u6a21\u578b\u65e0\u5173\u7684\uff0c\u53ef\u6539\u5584\u73b0\u6709\u7cfb\u7edf\u7684\u4e2a\u6027\u5316\u548c\u89e3\u91ca\u6027\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6982\u7387\u7684\u5d4c\u5165\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d1f2-\u74e6\u745f\u65af\u5766\u8ddd\u79bb\u7684\u5bf9\u6bd4\u635f\u5931\u6765\u5b66\u4e60\uff0c\u4ee5\u589e\u5f3a\u5d4c\u5165\u7684\u4ee3\u8868\u6027\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u53d8\u91cfShapley\u503c\u7b56\u7565\u7684\u91cd\u65b0\u52a0\u6743\u65b9\u6cd5\uff0c\u4ee5\u8bc4\u4f30\u548c\u63a2\u7d22\u4ea4\u4e92\u548c\u5d4c\u5165\u7684\u4ef7\u503c\u3002", "result": "\u5728\u591a\u4e2a\u63a8\u8350\u7cfb\u7edf\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cRVRec\u53ef\u4ee5\u63d0\u9ad8\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u7684\u4e2a\u6027\u5316\u548c\u89e3\u91ca\u6027\uff0c\u6027\u80fd\u4f18\u4e8e\u6700\u65b0\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "RVRec\u4f5c\u4e3a\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u6a21\u578b\u65e0\u5173\u5d4c\u5165\u589e\u5f3a\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u5347\u591a\u5a92\u4f53\u63a8\u8350\u7cfb\u7edf\u7684\u4e2a\u6027\u5316\u548c\u89e3\u91ca\u6027\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u8d85\u8fc7\u4e86\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2509.03131", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.03131", "abs": "https://arxiv.org/abs/2509.03131", "authors": ["Sashuai Zhou", "Weinan Gan", "Qijiong Liu", "Ke Lei", "Jieming Zhu", "Hai Huang", "Yan Xia", "Ruiming Tang", "Zhenhua Dong", "Zhou Zhao"], "title": "RecBase: Generative Foundation Model Pretraining for Zero-Shot Recommendation", "comment": null, "summary": "Recent advances in LLM-based recommendation have shown promise, yet their\ncross-domain generalization is hindered by a fundamental mismatch between\nlanguage-centric pretraining and the recommendation task. Existing methods,\nrelying on language-level knowledge, fail to capture dynamic, item-level user\ninterests across domains. To bridge this gap, we propose RecBase, a\ndomain-agnostic foundational model pretrained with a recommendation-oriented\nobjective. RecBase leverages a large-scale, heterogeneous, cross-domain corpus\nwith unified textual representations and feature mappings to enhance\ncross-domain generalization. To further align item semantics across domains, we\nintroduce a unified item tokenizer that encodes items into hierarchical concept\nidentifiers, enabling structured representation and efficient vocabulary\nsharing. The model is trained using an autoregressive objective to capture\ncomplex item-level sequential patterns. On eight real-world datasets, our\n1.5B-parameter model matches or surpasses the performance of LLM baselines up\nto 7B parameters in zero-shot and cross-domain recommendation tasks.", "AI": {"tldr": "RecBase\u6a21\u578b\u6539\u8fdb\u8de8\u9886\u57df\u6cdb\u5316\uff0c\u901a\u8fc7\u63a8\u8350\u5bfc\u5411\u9884\u8bad\u7ec3\uff0c\u8d85\u8d8a\u66f4\u5927\u53c2\u6570\u7684LLM\u57fa\u7ebf\u3002", "motivation": "\u8bed\u8a00\u9884\u8bad\u7ec3\u4e0e\u63a8\u8350\u4efb\u52a1\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\uff0c\u5bfc\u81f4\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u9886\u57df\u95f4\u52a8\u6001\u7684\u3001\u57fa\u4e8e\u9879\u76ee\u7684\u7528\u6237\u5174\u8da3\u3002", "method": "\u63d0\u51fa\u4e86RecBase\uff0c\u4e00\u4e2a\u9886\u57df\u4e0d\u53ef\u77e5\u7684\u57fa\u7840\u6a21\u578b\uff0c\u91c7\u7528\u4ee5\u63a8\u8350\u4e3a\u5bfc\u5411\u7684\u76ee\u6807\u8fdb\u884c\u9884\u8bad\u7ec3\u3002", "result": "\u5728\u516b\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c1.5B\u53c2\u6570\u7684\u6a21\u578b\u5728\u96f6\u6837\u672c\u548c\u8de8\u9886\u57df\u63a8\u8350\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4e0eLLM\u57fa\u7ebf\uff08\u53c2\u6570\u9ad8\u8fbe7B\uff09\u76f8\u5ab2\u7f8e\u751a\u81f3\u8d85\u8d8a\u3002", "conclusion": "RecBase\u901a\u8fc7\u63a8\u8350\u5bfc\u5411\u7684\u9884\u8bad\u7ec3\u4efb\u52a1\u548c\u7edf\u4e00\u7684\u9879\u76ee\u6807\u8bb0\u5668\uff0c\u63d0\u5347\u8de8\u9886\u57df\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2509.03187", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.03187", "abs": "https://arxiv.org/abs/2509.03187", "authors": ["Xiaoxiao Xu", "Hao Wu", "Wenhui Yu", "Lantao Hu", "Peng Jiang", "Kun Gai"], "title": "Enhancing Interpretability and Effectiveness in Recommendation with Numerical Features via Learning to Contrast the Counterfactual samples", "comment": "Accepted by TheWebConf2024", "summary": "We propose a general model-agnostic Contrastive learning framework with\nCounterfactual Samples Synthesizing (CCSS) for modeling the monotonicity\nbetween the neural network output and numerical features which is critical for\ninterpretability and effectiveness of recommender systems. CCSS models the\nmonotonicity via a two-stage process: synthesizing counterfactual samples and\ncontrasting the counterfactual samples. The two techniques are naturally\nintegrated into a model-agnostic framework, forming an end-to-end training\nprocess. Abundant empirical tests are conducted on a publicly available dataset\nand a real industrial dataset, and the results well demonstrate the\neffectiveness of our proposed CCSS. Besides, CCSS has been deployed in our real\nlarge-scale industrial recommender, successfully serving over hundreds of\nmillions users.", "AI": {"tldr": "CCSS\u662f\u4e00\u79cd\u901a\u7528\u7684\u3001\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u53cd\u4e8b\u5b9e\u6837\u672c\u6765\u5efa\u6a21\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6570\u636e\u5355\u8c03\u6027\uff0c\u5df2\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u53cd\u4e8b\u5b9e\u6837\u672c\u5408\u6210\u6765\u5efa\u6a21\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u4e0e\u6570\u503c\u7279\u5f81\u4e4b\u95f4\u7684\u5355\u8c03\u6027\uff0c\u8fd9\u5bf9\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6709\u6548\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "CCSS\u6846\u67b6\u901a\u8fc7\u4e24\u9636\u6bb5\u8fc7\u7a0b\u6765\u5efa\u6a21\u5355\u8c03\u6027\uff1a\u9996\u5148\u5408\u6210\u53cd\u4e8b\u5b9e\u6837\u672c\uff0c\u7136\u540e\u5bf9\u6bd4\u53cd\u4e8b\u5b9e\u6837\u672c\u3002\u8fd9\u4e9b\u6280\u672f\u88ab\u81ea\u7136\u6574\u5408\u5f62\u6210\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u548c\u771f\u5b9e\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u5b9e\u8bc1\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793aCCSS\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0cCCSS\u5df2\u6210\u529f\u90e8\u7f72\u5728\u771f\u5b9e\u7684\u5927\u578b\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u4e3a\u6570\u4ebf\u7528\u6237\u670d\u52a1\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660eCCSS\u6846\u67b6\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e14\u5df2\u7ecf\u6210\u529f\u90e8\u7f72\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\uff0c\u8868\u660e\u5176\u5bf9\u7528\u6237\u670d\u52a1\u7684\u652f\u6301\u80fd\u529b\u3002"}}
{"id": "2509.03236", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.03236", "abs": "https://arxiv.org/abs/2509.03236", "authors": ["Ben Chen", "Xian Guo", "Siyuan Wang", "Zihan Liang", "Yue Lv", "Yufei Ma", "Xinlong Xiao", "Bowen Xue", "Xuxin Zhang", "Ying Yang", "Huangyu Dai", "Xing Xu", "Tong Zhao", "Mingcan Peng", "XiaoYang Zheng", "Cong Zhang", "Qihang Zhao", "Yuqing Ding", "Chenyi Lei", "Wenwu Ou", "Han Li"], "title": "OneSearch: A Preliminary Exploration of the Unified End-to-End Generative Framework for E-commerce Search", "comment": null, "summary": "Traditional e-commerce search systems employ multi-stage cascading\narchitectures (MCA) that progressively filter items through recall,\npre-ranking, and ranking stages. While effective at balancing computational\nefficiency with business conversion, these systems suffer from fragmented\ncomputation and optimization objective collisions across stages, which\nultimately limit their performance ceiling. To address these, we propose\n\\textbf{OneSearch}, the first industrial-deployed end-to-end generative\nframework for e-commerce search. This framework introduces three key\ninnovations: (1) a Keyword-enhanced Hierarchical Quantization Encoding (KHQE)\nmodule, to preserve both hierarchical semantics and distinctive item attributes\nwhile maintaining strong query-item relevance constraints; (2) a multi-view\nuser behavior sequence injection strategy that constructs behavior-driven user\nIDs and incorporates both explicit short-term and implicit long-term sequences\nto model user preferences comprehensively; and (3) a Preference-Aware Reward\nSystem (PARS) featuring multi-stage supervised fine-tuning and adaptive\nreward-weighted ranking to capture fine-grained user preferences. Extensive\noffline evaluations on large-scale industry datasets demonstrate OneSearch's\nsuperior performance for high-quality recall and ranking. The rigorous online\nA/B tests confirm its ability to enhance relevance in the same exposure\nposition, achieving statistically significant improvements: +1.67\\% item CTR,\n+2.40\\% buyer, and +3.22\\% order volume. Furthermore, OneSearch reduces\noperational expenditure by 75.40\\% and improves Model FLOPs Utilization from\n3.26\\% to 27.32\\%. The system has been successfully deployed across multiple\nsearch scenarios in Kuaishou, serving millions of users, generating tens of\nmillions of PVs daily.", "AI": {"tldr": "OneSearch\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u521b\u65b0\u6539\u8fdb\u7535\u5546\u641c\u7d22\u6027\u80fd\uff0c\u5df2\u6210\u529f\u5728Kuaishou\u90e8\u7f72\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u7535\u5546\u641c\u7d22\u7cfb\u7edf\u4e2d\u7684\u8ba1\u7b97\u788e\u7247\u5316\u548c\u4f18\u5316\u76ee\u6807\u51b2\u7a81\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8\u641c\u7d22\u7cfb\u7edf\u7684\u6027\u80fd\u4e0a\u9650\u3002", "method": "\u8be5\u6846\u67b6\u5f15\u5165\u4e86\u4e09\u9879\u521b\u65b0\uff1a\u5173\u952e\u8bcd\u589e\u5f3a\u5c42\u6b21\u91cf\u5316\u7f16\u7801\u6a21\u5757\u3001\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u6ce8\u5165\u7b56\u7565\u548c\u504f\u597d\u611f\u77e5\u5956\u52b1\u7cfb\u7edf\u3002", "result": "\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\uff0cOneSearch\u663e\u8457\u63d0\u9ad8\u4e86\u7269\u54c1\u70b9\u51fb\u7387\u3001\u8d2d\u4e70\u4eba\u6570\u548c\u8ba2\u5355\u91cf\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8fd0\u8425\u8d39\u7528\uff0c\u63d0\u9ad8\u4e86\u6a21\u578bFLOPs\u5229\u7528\u7387\u3002", "conclusion": "OneSearch\u63d0\u9ad8\u4e86\u7535\u5546\u641c\u7d22\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5e76\u6210\u529f\u5728Kuaishou\u591a\u4e2a\u641c\u7d22\u573a\u666f\u4e2d\u90e8\u7f72\u3002"}}
