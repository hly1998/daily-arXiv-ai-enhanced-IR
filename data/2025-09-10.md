<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 12]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Avoiding Over-Personalization with Rule-Guided Knowledge Graph Adaptation for LLM Recommendations](https://arxiv.org/abs/2509.07133)
*Fernando Spadea,Oshani Seneviratne*

Main category: cs.IR

TL;DR: 研究利用神经符号框架，通过调整用户知识图谱减少推荐系统中过度个性化问题，提高内容多样性。


<details>
  <summary>Details</summary>
Motivation: 动机在于解决由个性化信息环境(PIEs)引起的内容多样性受限问题，避免典型的过滤泡沫现象，而无需重新训练模型或依赖不透明的启发式方法。

Method: 本文介绍了一种轻量级的神经符号框架，通过在推理时调整用户端知识图谱(KGs)，以减少基于大型语言模型(LLM)的推荐系统中的过度个性化现象。此方法通过重构用户个性化知识图谱(PKG)，压制特征共现模式，防止算法引起的过滤泡沫限制内容多样性。同时，提出了软重加权、硬反转和有针对性地删除偏见三元组等符号适应策略，以及一个优化其每位用户应用的客户端学习算法。

Result: 在食谱推荐基准实验中，个性化知识图谱的调整显著增加了内容的新颖性，同时保持了推荐的质量，优于全局调整和简单的基于提示的方法。

Conclusion: 研究证明，通过调整用户的知识图谱结构，可以有效缓解过度个性化带来的负面影响，增加内容多样性，优化推荐系统性能。

Abstract: We present a lightweight neuro-symbolic framework to mitigate
over-personalization in LLM-based recommender systems by adapting user-side
Knowledge Graphs (KGs) at inference time. Instead of retraining models or
relying on opaque heuristics, our method restructures a user's Personalized
Knowledge Graph (PKG) to suppress feature co-occurrence patterns that reinforce
Personalized Information Environments (PIEs), i.e., algorithmically induced
filter bubbles that constrain content diversity. These adapted PKGs are used to
construct structured prompts that steer the language model toward more diverse,
Out-PIE recommendations while preserving topical relevance. We introduce a
family of symbolic adaptation strategies, including soft reweighting, hard
inversion, and targeted removal of biased triples, and a client-side learning
algorithm that optimizes their application per user. Experiments on a recipe
recommendation benchmark show that personalized PKG adaptations significantly
increase content novelty while maintaining recommendation quality,
outperforming global adaptation and naive prompt-based methods.

</details>


### [2] [Beyond Sequential Reranking: Reranker-Guided Search Improves Reasoning Intensive Retrieval](https://arxiv.org/abs/2509.07163)
*Haike Xu,Tong Chen*

Main category: cs.IR

TL;DR: RGS方法通过重排序器导向的检索避开传统方法的限制，在固定重排序文档数的条件下提高了检索性能。


<details>
  <summary>Details</summary>
Motivation: 传统的检索和重排序方法面临初始检索质量和LLM重排序器计算需求增加的限制，新的方法试图绕过这些限制。

Method: RGS通过直接根据重排序器偏好检索文档，使用近似最近邻算法生成的近邻图进行贪婪搜索，并基于文档相似性优先选择有潜力的文档进行重排序。

Result: 根据实验结果，RGS在多个基准上实现了显著的性能提升：在BRIGHT上提高3.5分，在FollowIR上提高2.9分，在M-BEIR上提高5.1分。

Conclusion: 提出的Reranker-Guided-Search (RGS)方法能在有限的reranker预算下显著提高检索准确性。

Abstract: The widely used retrieve-and-rerank pipeline faces two critical limitations:
they are constrained by the initial retrieval quality of the top-k documents,
and the growing computational demands of LLM-based rerankers restrict the
number of documents that can be effectively processed. We introduce
Reranker-Guided-Search (RGS), a novel approach that bypasses these limitations
by directly retrieving documents according to reranker preferences rather than
following the traditional sequential reranking method. Our method uses a greedy
search on proximity graphs generated by approximate nearest neighbor
algorithms, strategically prioritizing promising documents for reranking based
on document similarity. Experimental results demonstrate substantial
performance improvements across multiple benchmarks: 3.5 points on BRIGHT, 2.9
on FollowIR, and 5.1 on M-BEIR, all within a constrained reranker budget of 100
documents. Our analysis suggests that, given a fixed pair of embedding and
reranker models, strategically selecting documents to rerank can significantly
improve retrieval accuracy under limited reranker budget.

</details>


### [3] [Benchmarking Information Retrieval Models on Complex Retrieval Tasks](https://arxiv.org/abs/2509.07253)
*Julian Killingback,Hamed Zamani*

Main category: cs.IR

TL;DR: 研究复杂检索任务的模型，发现当前最好的检索模型仍然在复杂任务中表现不佳，特别是使用LLM扩展和重写技术的情况下。


<details>
  <summary>Details</summary>
Motivation: 想要研究检索模型如何才能处理复杂的检索任务，尤其是自然语言中的多部分查询、约束或要求，这些任务代表了从简单单方面查询到复杂查询的自然进化。

Method: 构建多样化且现实的复杂检索任务，并对一组最先进的检索模型进行基准测试。同时，探索基于大型语言模型的查询扩展和重写对检索质量的影响。

Result: 尽管大规模语言模型的查询扩展和重写可以帮助较弱的检索模型，但最强的模型在所有度量中使用所有重写技术后性能下降。我们构建了一组多样化且现实的复杂检索任务，并对一组先进的检索模型进行了基准测试。结果表明，即使是最好的模型在高质量检索结果上的平均nDCG@10仅为0.346，R@100仅为0.587。

Conclusion: 当前检索模型在复杂的真实世界检索任务上的表现有限，尤其是在现实设置中评估它们的能力时。

Abstract: Large language models (LLMs) are incredible and versatile tools for
text-based tasks that have enabled countless, previously unimaginable,
applications. Retrieval models, in contrast, have not yet seen such capable
general-purpose models emerge. To achieve this goal, retrieval models must be
able to perform complex retrieval tasks, where queries contain multiple parts,
constraints, or requirements in natural language. These tasks represent a
natural progression from the simple, single-aspect queries that are used in the
vast majority of existing, commonly used evaluation sets. Complex queries
naturally arise as people expect search systems to handle more specific and
often ambitious information requests, as is demonstrated by how people use
LLM-based information systems. Despite the growing desire for retrieval models
to expand their capabilities in complex retrieval tasks, there exist limited
resources to assess the ability of retrieval models on a comprehensive set of
diverse complex tasks. The few resources that do exist feature a limited scope
and often lack realistic settings making it hard to know the true capabilities
of retrieval models on complex real-world retrieval tasks. To address this
shortcoming and spur innovation in next-generation retrieval models, we
construct a diverse and realistic set of complex retrieval tasks and benchmark
a representative set of state-of-the-art retrieval models. Additionally, we
explore the impact of LLM-based query expansion and rewriting on retrieval
quality. Our results show that even the best models struggle to produce
high-quality retrieval results with the highest average nDCG@10 of only 0.346
and R@100 of only 0.587 across all tasks. Although LLM augmentation can help
weaker models, the strongest model has decreased performance across all metrics
with all rewriting techniques.

</details>


### [4] [Datasets for Navigating Sensitive Topics in Recommendation Systems](https://arxiv.org/abs/2509.07269)
*Amelia Kovacs,Jerry Chee,Kimia Kazemian,Sarah Dean*

Main category: cs.IR

TL;DR: 本文引入两个带有敏感标签的创新数据集，以评估个性化AI系统对用户暴露于敏感或有害内容的影响，提供新的评价标准。


<details>
  <summary>Details</summary>
Motivation: 当前个性化AI系统可能会使用户暴露于敏感或有害内容，影响总体幸福感，因此需要量化评估这些影响的指标。为此，有必要创建带有敏感度标签的数据集，以便研究人员能从除了用户参与度以外的指标评估个性化系统。

Method: 研究者创建两个新颖的数据集，这些数据集包含内容的敏感标签分类以及用户-内容评级。第一个数据集融合了MovieLens评级数据和来自Does the Dog Die?社区评级网站的内容警告，第二个数据集结合了来自Archive of Our Own的粉丝作品互动数据和用户生成的警告。

Result: 引入两个带有敏感标签的创新数据集，以帮助研究人员更好地分析和评估个性化系统的影响，超越了传统的参与度指标。

Conclusion: 本文提出的两个数据集可以帮助研究人员评估个性化系统对用户暴露于敏感或有害内容的影响，为个性化AI系统的效果评价提供新的视角。

Abstract: Personalized AI systems, from recommendation systems to chatbots, are a
prevalent method for distributing content to users based on their learned
preferences. However, there is growing concern about the adverse effects of
these systems, including their potential tendency to expose users to sensitive
or harmful material, negatively impacting overall well-being. To address this
concern quantitatively, it is necessary to create datasets with relevant
sensitivity labels for content, enabling researchers to evaluate personalized
systems beyond mere engagement metrics. To this end, we introduce two novel
datasets that include a taxonomy of sensitivity labels alongside user-content
ratings: one that integrates MovieLens rating data with content warnings from
the Does the Dog Die? community ratings website, and another that combines
fan-fiction interaction data and user-generated warnings from Archive of Our
Own.

</details>


### [5] [MEGG: Replay via Maximally Extreme GGscore in Incremental Learning for Neural Recommendation Models](https://arxiv.org/abs/2509.07319)
*Yunxiao Shi,Shuo Yang,Haimin Zhang,Li Wang,Yongze Wang,Qiang Wu,Min Xu*

Main category: cs.IR

TL;DR: 提出MEGG框架，通过极值样本重放改善神经推荐系统的增量学习。


<details>
  <summary>Details</summary>
Motivation: 传统神经推荐系统在动态环境中受到限制，需要提高其在数据稀疏情况下的适应性。

Method: 提出MEGG框架，使用最大极值GGscore进行样本重放，以进行增量学习。

Result: 在三个神经模型和四个基准数据集上的实验表现优于最先进的基线，具有较强的可扩展性、效率和鲁棒性。

Conclusion: MEGG框架通过创新的样本重放策略改善神经推荐系统的性能，并将在公开接受后发布。

Abstract: Neural Collaborative Filtering models are widely used in recommender systems
but are typically trained under static settings, assuming fixed data
distributions. This limits their applicability in dynamic environments where
user preferences evolve. Incremental learning offers a promising solution, yet
conventional methods from computer vision or NLP face challenges in
recommendation tasks due to data sparsity and distinct task paradigms. Existing
approaches for neural recommenders remain limited and often lack
generalizability. To address this, we propose MEGG, Replay Samples with
Maximally Extreme GGscore, an experience replay based incremental learning
framework. MEGG introduces GGscore, a novel metric that quantifies sample
influence, enabling the selective replay of highly influential samples to
mitigate catastrophic forgetting. Being model-agnostic, MEGG integrates
seamlessly across architectures and frameworks. Experiments on three neural
models and four benchmark datasets show superior performance over
state-of-the-art baselines, with strong scalability, efficiency, and
robustness. Implementation will be released publicly upon acceptance.

</details>


### [6] [Multi-view-guided Passage Reranking with Large Language Models](https://arxiv.org/abs/2509.07485)
*Jeongwoo Na,Jun Kwon,Eunseong Choi,Jongwuk Lee*

Main category: cs.IR

TL;DR: 本文提出了一种新型基于LLM的段落重排序模型MVP，能够在减少计算开销的同时克服外部偏倚问题，并实现业界领先的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然近期大语言模型在段落重排序任务中表现出色，但这些方法的效率和对外部偏倚的敏感性仍然是挑战。现有模型主要依赖自回归生成和滑动窗口策略进行段落排序，随着段落数量增加，这会带来沉重的计算开销。此外，外部偏倚，如位置或选择偏倚，会阻碍模型准确表示段落并增加输入顺序的敏感性。

Method: 该论文提出了一种名为MVP的新型段落重排序模型，它是一种基于大语言模型的非生成式重排序方法。MVP通过编码查询-段落信息到多个视图嵌入中，避免受到外部偏倚的影响。为每个视图，它结合查询感知段落嵌入来生成一个独特的锚定向量，然后在单步解码中直接计算相关性得分。此外，它采用正交损失来使视图更具区别性。

Result: 广泛的实验表明，MVP模型仅使用220M参数便能匹敌更大规模的7B级微调模型，同时将推理延迟减少100倍。值得注意的是，MVP的3B参数变体在领域内和领域外基准测试中实现了最新的业界最佳表现。

Conclusion: MVP模型展示了在不增加计算资源的情况下，能够匹敌甚至超越更大规模模型的能力。通过创新的设计，该模型有效地解决了当前段落重排序方法中的效率问题和偏倚问题。

Abstract: Recent advances in large language models (LLMs) have shown impressive
performance in passage reranking tasks. Despite their success, LLM-based
methods still face challenges in efficiency and sensitivity to external biases.
(1) Existing models rely mostly on autoregressive generation and sliding window
strategies to rank passages, which incur heavy computational overhead as the
number of passages increases. (2) External biases, such as position or
selection bias, hinder the model's ability to accurately represent passages and
increase input-order sensitivity. To address these limitations, we introduce a
novel passage reranking model, called Multi-View-guided Passage Reranking
(MVP). MVP is a non-generative LLM-based reranking method that encodes
query-passage information into diverse view embeddings without being influenced
by external biases. For each view, it combines query-aware passage embeddings
to produce a distinct anchor vector, which is then used to directly compute
relevance scores in a single decoding step. In addition, it employs an
orthogonal loss to make the views more distinctive. Extensive experiments
demonstrate that MVP, with just 220M parameters, matches the performance of
much larger 7B-scale fine-tuned models while achieving a 100x reduction in
inference latency. Notably, the 3B-parameter variant of MVP achieves
state-of-the-art performance on both in-domain and out-of-domain benchmarks.
The source code is available at: https://github.com/bulbna/MVP

</details>


### [7] [FLeW: Facet-Level and Adaptive Weighted Representation Learning of Scientific Documents](https://arxiv.org/abs/2509.07531)
*Zheng Dou,Deqing Wang,Fuzhen Zhuang,Jian Ren,Yanlin Hu*

Main category: cs.IR

TL;DR: 本文提出了FLeW方法，通过统一现有三种方法，为科学文档表示提供了更好的解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前的科学文档表示学习在对比训练、细粒度表示学习以及任务感知学习方法上面临不足。为解决这些问题，提出了新方法FLeW。

Method: 引入了一种新的三角采样方法，利用引用意图和频率增强引用结构信号，并采用简单的权重搜索将三级面级嵌入自适应整合为任务特定的文档嵌入。

Result: 实验结果表明，与先前模型相比，FLeW在多个科学任务和领域中展示了较好的适用性和鲁棒性。

Conclusion: FLeW方法通过统一三种方法，提供了更好的科学文档表示，展示了其在多个科学任务和领域中的适用性和鲁棒性。

Abstract: Scientific document representation learning provides powerful embeddings for
various tasks, while current methods face challenges across three approaches.
1) Contrastive training with citation-structural signals underutilizes citation
information and still generates single-vector representations. 2) Fine-grained
representation learning, which generates multiple vectors at the sentence or
aspect level, requires costly integration and lacks domain generalization. 3)
Task-aware learning depends on manually predefined task categorization,
overlooking nuanced task distinctions and requiring extra training data for
task-specific modules. To address these problems, we propose a new method that
unifies the three approaches for better representations, namely FLeW.
Specifically, we introduce a novel triplet sampling method that leverages
citation intent and frequency to enhance citation-structural signals for
training. Citation intents (background, method, result), aligned with the
general structure of scientific writing, facilitate a domain-generalized facet
partition for fine-grained representation learning. Then, we adopt a simple
weight search to adaptively integrate three facet-level embeddings into a
task-specific document embedding without task-aware fine-tuning. Experiments
show the applicability and robustness of FLeW across multiple scientific tasks
and fields, compared to prior models.

</details>


### [8] [ELEC: Efficient Large Language Model-Empowered Click-Through Rate Prediction](https://arxiv.org/abs/2509.07594)
*Rui Dong,Wentao Ouyang,Xiangzheng Liu*

Main category: cs.IR

TL;DR: ELEC框架结合LLM与协同CTR模型，提高了在线广告CTR预测效果和效率。


<details>
  <summary>Details</summary>
Motivation: 在线广告系统中的点击率预测面临传统模型不能处理文本语义、大型语言模型长推理时间的问题。

Method: 提出ELEC框架，结合LLM与协同CTR模型，通过伪孪生网络结构处理文本与表格数据。

Result: 实验表明ELEC在CTR预测任务中有效且高效。

Conclusion: ELEC成功融合LLM与传统CTR模型，提升预测效果并保持运行效率。

Abstract: Click-through rate (CTR) prediction plays an important role in online
advertising systems. On the one hand, traditional CTR prediction models capture
the collaborative signals in tabular data via feature interaction modeling, but
they lose semantics in text. On the other hand, Large Language Models (LLMs)
excel in understanding the context and meaning behind text, but they face
challenges in capturing collaborative signals and they have long inference
latency. In this paper, we aim to leverage the benefits of both types of models
and pursue collaboration, semantics and efficiency. We present ELEC, which is
an Efficient LLM-Empowered CTR prediction framework. We first adapt an LLM for
the CTR prediction task. In order to leverage the ability of the LLM but
simultaneously keep efficiency, we utilize the pseudo-siamese network which
contains a gain network and a vanilla network. We inject the high-level
representation vector generated by the LLM into a collaborative CTR model to
form the gain network such that it can take advantage of both tabular modeling
and textual modeling. However, its reliance on the LLM limits its efficiency.
We then distill the knowledge from the gain network to the vanilla network on
both the score level and the representation level, such that the vanilla
network takes only tabular data as input, but can still generate comparable
performance as the gain network. Our approach is model-agnostic. It allows for
the integration with various existing LLMs and collaborative CTR models.
Experiments on real-world datasets demonstrate the effectiveness and efficiency
of ELEC for CTR prediction.

</details>


### [9] [Towards End-to-End Model-Agnostic Explanations for RAG Systems](https://arxiv.org/abs/2509.07620)
*Viju Sudhi,Sinchana Ramakanth Bhat,Max Rudat,Roman Teucher,Nicolas Flores-Herr*

Main category: cs.IR

TL;DR: 开发了一种事后解释框架，提高RAG系统的解释能力。


<details>
  <summary>Details</summary>
Motivation: 随着RAG系统的流行，增强模型响应可靠性变得重要，但其可信性和可解释性仍是一大挑战。

Method: 利用基于扰动的技术，提出模型无关的事后解释框架，以解释RAG系统中的检索和生成过程。

Result: 提出了一种新的整体模型无关的事后解释框架，利用基于扰动的技术来解释RAG系统中的检索和生成过程。

Conclusion: 通过提出不同策略评估这些解释，讨论了模型无关解释在RAG系统中的充分性，旨在推动建立可靠且可解释的RAG系统的协作努力。

Abstract: Retrieval Augmented Generation (RAG) systems, despite their growing
popularity for enhancing model response reliability, often struggle with
trustworthiness and explainability. In this work, we present a novel, holistic,
model-agnostic, post-hoc explanation framework leveraging perturbation-based
techniques to explain the retrieval and generation processes in a RAG system.
We propose different strategies to evaluate these explanations and discuss the
sufficiency of model-agnostic explanations in RAG systems. With this work, we
further aim to catalyze a collaborative effort to build reliable and
explainable RAG systems.

</details>


### [10] [A Survey of Long-Document Retrieval in the PLM and LLM Era](https://arxiv.org/abs/2509.07759)
*Minghan Li,Miyang Luo,Tianrui Lv,Yishuai Zhang,Siqi Zhao,Ercong Nie,Guodong Zhou*

Main category: cs.IR

TL;DR: 这是首次全面处理长文档检索的综述，整合了三大时代的方法、挑战和应用。


<details>
  <summary>Details</summary>
Motivation: 长篇文档在信息检索中面临挑战，因为其长度、分散的证据和复杂结构要求专门的方法。

Method: 系统化了从经典词汇和早期神经网络模型到现代预训练模型和大型语言模型的发展。

Result: 涵盖了通道聚合、分层编码、高效注意力机制及最新的LLM驱动的重新排序和检索技术。

Conclusion: 本文旨在为长文档检索提供一个整合的参考，同时提出未来的发展方向。

Abstract: The proliferation of long-form documents presents a fundamental challenge to
information retrieval (IR), as their length, dispersed evidence, and complex
structures demand specialized methods beyond standard passage-level techniques.
This survey provides the first comprehensive treatment of long-document
retrieval (LDR), consolidating methods, challenges, and applications across
three major eras. We systematize the evolution from classical lexical and early
neural models to modern pre-trained (PLM) and large language models (LLMs),
covering key paradigms like passage aggregation, hierarchical encoding,
efficient attention, and the latest LLM-driven re-ranking and retrieval
techniques. Beyond the models, we review domain-specific applications,
specialized evaluation resources, and outline critical open challenges such as
efficiency trade-offs, multimodal alignment, and faithfulness. This survey aims
to provide both a consolidated reference and a forward-looking agenda for
advancing long-document retrieval in the era of foundation models.

</details>


### [11] [Query Expansion in the Age of Pre-trained and Large Language Models: A Comprehensive Survey](https://arxiv.org/abs/2509.07794)
*Minghan Li,Xinxuan Lv,Junjie Zou,Tongna Chen,Chao Zhang,Suchao An,Ercong Nie,Guodong Zhou*

Main category: cs.IR

TL;DR: 这篇综述文章探讨了现代信息检索中的查询扩展技术，综合不同的模型方法，提供实践指导和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现代信息检索（IR）需解决简短模糊查询与多样化且迅速变化的语料库之间的差距，而查询扩展（QE）是缓解词汇不匹配的关键机制。随着预训练语言模型（PLM）和大型语言模型（LLM）的发展，QE设计空间有了显著变化。

Method: 综述采用三角度分析方法：（i）查询扩展的四维框架；（ii）以模型为中心的分类法；（iii）实践导向的指导。

Result: 报告从查询扩展的四维框架、以模型为中心的分类法和实践导向的指导三方面综合了这一领域，并比较了传统的查询扩展和基于PLM/LLM的方法在七个关键方面。

Conclusion: 文章最后提出了质量控制、成本感知调用、领域/时间适应、超越终端任务的评估以及公平性和隐私方面的建议，作为选取和组合QE技术的原则性蓝图。

Abstract: Modern information retrieval (IR) must bridge short, ambiguous queries and
ever more diverse, rapidly evolving corpora. Query Expansion (QE) remains a key
mechanism for mitigating vocabulary mismatch, but the design space has shifted
markedly with pre-trained language models (PLMs) and large language models
(LLMs). This survey synthesizes the field from three angles: (i) a
four-dimensional framework of query expansion - from the point of injection
(explicit vs. implicit QE), through grounding and interaction (knowledge bases,
model-internal capabilities, multi-turn retrieval) and learning alignment, to
knowledge graph-based argumentation; (ii) a model-centric taxonomy spanning
encoder-only, encoder-decoder, decoder-only, instruction-tuned, and
domain/multilingual variants, highlighting their characteristic affordances for
QE (contextual disambiguation, controllable generation, zero-/few-shot
reasoning); and (iii) practice-oriented guidance on where and how neural QE
helps in first-stage retrieval, multi-query fusion, re-ranking, and
retrieval-augmented generation (RAG). We compare traditional query expansion
with PLM/LLM-based methods across seven key aspects, and we map applications
across web search, biomedicine, e-commerce, open-domain QA/RAG, conversational
and code search, and cross-lingual settings. The review distills design
grounding and interaction, alignment/distillation (SFT/PEFT/DPO), and KG
constraints - as robust remedies to topic drift and hallucination. We conclude
with an agenda on quality control, cost-aware invocation, domain/temporal
adaptation, evaluation beyond end-task metrics, and fairness/privacy.
Collectively, these insights provide a principled blueprint for selecting and
combining QE techniques under real-world constraints.

</details>


### [12] [KLIPA: A Knowledge Graph and LLM-Driven QA Framework for IP Analysis](https://arxiv.org/abs/2509.07860)
*Guanzhi Deng,Yi Xie,Yu-Keung Ng,Mingyang Liu,Peijun Zheng,Jie Liu,Dapeng Wu,Yinqiao Li,Linqi Song*

Main category: cs.IR

TL;DR: KLIPA通过知识图谱和大语言模型改进专利分析，提升知识提取和连接发现效率。


<details>
  <summary>Details</summary>
Motivation: 传统专利分析方法效率低下，难以揭示复杂的专利数据集中的关系，这影响了战略决策。

Method: KLIPA框架集成了结构化知识图谱、RAG系统和智能代理三大组件，用于揭示专利之间的复杂关系和动态处理用户查询。

Result: 在真实世界的专利数据库中进行验证，KLIPA在知识提取、新颖连接发现和操作效率方面表现出显著提升。

Conclusion: KLIPA框架通过结合知识图谱和大语言模型，大大提高了专利分析的效率和效果，减轻了对领域专家的依赖。

Abstract: Effectively managing intellectual property is a significant challenge.
Traditional methods for patent analysis depend on labor-intensive manual
searches and rigid keyword matching. These approaches are often inefficient and
struggle to reveal the complex relationships hidden within large patent
datasets, hindering strategic decision-making. To overcome these limitations,
we introduce KLIPA, a novel framework that leverages a knowledge graph and a
large language model (LLM) to significantly advance patent analysis. Our
approach integrates three key components: a structured knowledge graph to map
explicit relationships between patents, a retrieval-augmented generation(RAG)
system to uncover contextual connections, and an intelligent agent that
dynamically determines the optimal strategy for resolving user queries. We
validated KLIPA on a comprehensive, real-world patent database, where it
demonstrated substantial improvements in knowledge extraction, discovery of
novel connections, and overall operational efficiency. This combination of
technologies enhances retrieval accuracy, reduces reliance on domain experts,
and provides a scalable, automated solution for any organization managing
intellectual property, including technology corporations and legal firms,
allowing them to better navigate the complexities of strategic innovation and
competitive intelligence.

</details>
