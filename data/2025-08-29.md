<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 18]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [A Survey of Affective Recommender Systems: Modeling Attitudes, Emotions, and Moods for Personalization](https://arxiv.org/abs/2508.20289)
*Tonmoy Hasan,Razvan Bunescu*

Main category: cs.IR

TL;DR: 本文提供了关于情感推荐系统的全面系统回顾，引入了新的分类方案，并指出了未来的发展方向。


<details>
  <summary>Details</summary>
Motivation: 目前的情感推荐系统研究缺乏基于心理学的分类，且研究较为片面，仅关注特定情感状态或应用领域。

Method: 通过分析Scherer的情感状态分类法，建立一个分类系统，将情感推荐系统分为态度感知、情感感知、情绪感知和混合型四大类。

Result: 展示情感信号提取技术、系统架构和应用领域，并指明关键趋势、限制和开放性挑战。

Conclusion: 提出未来研究方向，包括开发大规模情感感知数据集和使用更精确的心理学术语。旨在为推动学术研究和工业应用中的情感驱动个性化提供参考。

Abstract: Affective Recommender Systems are an emerging class of intelligent systems
that aim to enhance personalization by aligning recommendations with users'
affective states. Reflecting a growing interest, a number of surveys have been
published in this area, however they lack an organizing taxonomy grounded in
psychology and they often study only specific types of affective states or
application domains. This survey addresses these limitations by providing a
comprehensive, systematic review of affective recommender systems across
diverse domains. Drawing from Scherer's typology of affective states, we
introduce a classification scheme that organizes systems into four main
categories: attitude aware, emotion aware, mood aware, and hybrid. We further
document affective signal extraction techniques, system architectures, and
application areas, highlighting key trends, limitations, and open challenges.
As future research directions, we emphasize hybrid models that leverage
multiple types of affective states across different modalities, the development
of large-scale affect-aware datasets, and the need to replace the folk
vocabulary of affective states with a more precise terminology grounded in
cognitive and social psychology. Through its systematic review of existing
research and challenges, this survey aims to serve as a comprehensive reference
and a useful guide for advancing academic research and industry applications in
affect-driven personalization.

</details>


### [2] [ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations](https://arxiv.org/abs/2508.20312)
*Ben Kabongo,Vincent Guigue,Pirmin Lemberger*

Main category: cs.IR

TL;DR: ELIXIR是一种结合评分预测与个性化评论生成的轻量级模型，在多任务学习下有效提高了推荐系统的文本生成质量。


<details>
  <summary>Details</summary>
Motivation: 随着用户对推荐透明度需求的增加，生成文本解释的任务变得重要。然而，现有方法存在模型效果不佳和忽视关键方面建模的问题。

Method: 提出了一种名为ELIXIR的多任务模型，该模型结合评分预测与个性化评论生成，通过同时学习用户和项目的全局和方面特定表示来优化评分和评论生成。

Result: 实验结果表明，ELIXIR在TripAdvisor和RateBeer平台上显著优于强基线模型，尤其是在评论生成方面。

Conclusion: ELIXIR有效结合了多任务学习来提高个性化推荐解释的质量，利用更轻量级的模型在文本生成任务上超越了现有方法。

Abstract: Collaborative filtering drives many successful recommender systems but
struggles with fine-grained user-item interactions and explainability. As users
increasingly seek transparent recommendations, generating textual explanations
through language models has become a critical research area. Existing methods
employ either RNNs or Transformers. However, RNN-based approaches fail to
leverage the capabilities of pre-trained Transformer models, whereas
Transformer-based methods often suffer from suboptimal adaptation and neglect
aspect modeling, which is crucial for personalized explanations. We propose
ELIXIR (Efficient and LIghtweight model for eXplaIning Recommendations), a
multi-task model combining rating prediction with personalized review
generation. ELIXIR jointly learns global and aspect-specific representations of
users and items, optimizing overall rating, aspect-level ratings, and review
generation, with personalized attention to emphasize aspect importance. Based
on a T5-small (60M) model, we demonstrate the effectiveness of our aspect-based
architecture in guiding text generation in a personalized context, where
state-of-the-art approaches exploit much larger models but fail to match user
preferences as well. Experimental results on TripAdvisor and RateBeer
demonstrate that ELIXIR significantly outperforms strong baseline models,
especially in review generation.

</details>


### [3] [Progressive Semantic Residual Quantization for Multimodal-Joint Interest Modeling in Music Recommendation](https://arxiv.org/abs/2508.20359)
*Shijia Wang,Tianpei Ouyang,Qiang Xiao,Dongjing Wang,Yintao Ren,Songpei Xu,Da Guo,Chuanjiang Luo*

Main category: cs.IR

TL;DR: 针对音乐推荐系统中的多模态兴趣学习，本文提出了一种新框架，通过渐进语义残差量化和多码簿交叉注意网络来提高推荐效果，并在实际平台上证实了其商业价值。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在语义漂移和模态建模缺陷的问题，导致用户兴趣建模不够全面。为了解决这些问题，本文提出了一种新的多模态推荐框架。

Method: 为了克服现有方法的不足，本文在第一阶段采用了渐进语义残差量化（PSRQ）方法，以生成特定模态和模态联合的语义ID，并在第二阶段利用多码簿交叉注意（MCCA）网络来捕捉模态特定兴趣和跨模态关联。

Result: 通过在多个真实世界数据集上进行广泛实验，本文的框架比最先进的基准方法表现更优。此外，该框架已在中国最大的音乐流媒体平台之一上部署，线上A/B测试结果显示商用指标有显著提升。

Conclusion: 本文提出的多模态推荐框架在音乐推荐系统中表现出优异的性能，显著提高了用户兴趣的捕捉能力，证明了其在工业规模的推荐系统中的实际价值。

Abstract: In music recommendation systems, multimodal interest learning is pivotal,
which allows the model to capture nuanced preferences, including textual
elements such as lyrics and various musical attributes such as different
instruments and melodies. Recently, methods that incorporate multimodal content
features through semantic IDs have achieved promising results. However,
existing methods suffer from two critical limitations: 1) intra-modal semantic
degradation, where residual-based quantization processes gradually decouple
discrete IDs from original content semantics, leading to semantic drift; and 2)
inter-modal modeling gaps, where traditional fusion strategies either overlook
modal-specific details or fail to capture cross-modal correlations, hindering
comprehensive user interest modeling. To address these challenges, we propose a
novel multimodal recommendation framework with two stages. In the first stage,
our Progressive Semantic Residual Quantization (PSRQ) method generates
modal-specific and modal-joint semantic IDs by explicitly preserving the prefix
semantic feature. In the second stage, to model multimodal interest of users, a
Multi-Codebook Cross-Attention (MCCA) network is designed to enable the model
to simultaneously capture modal-specific interests and perceive cross-modal
correlations. Extensive experiments on multiple real-world datasets demonstrate
that our framework outperforms state-of-the-art baselines. This framework has
been deployed on one of China's largest music streaming platforms, and online
A/B tests confirm significant improvements in commercial metrics, underscoring
its practical value for industrial-scale recommendation systems.

</details>


### [4] [A Case Study of Balanced Query Recommendation on Wikipedia](https://arxiv.org/abs/2508.20399)
*Harshit Mishra,Sucheta Soundarajan*

Main category: cs.IR

TL;DR: 本文介绍了一种处理多维度偏见的联合查询推荐方法，该方法在减少性别和区域偏见方面取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 解决查询推荐过程中因性别或种族等受保护类别导致的不当偏见问题，提供更公平的查询建议。

Method: 使用Pareto front方法以优化性别和区域偏见为目标，进行多目标优化以发现平衡查询，从而减少偏见。

Result: 在Wikipedia数据集上的实验证明了扩展版BalancedQR框架的有效性，并强调了查询措辞和语言选择对检索的显著影响。

Conclusion: 扩展版BalancedQR框架在处理多维度偏见方面表现出色，有效减少了查询推荐过程中的性别和区域偏见，同时保持结果的相关性。

Abstract: Modern IR systems are an extremely important tool for seeking information. In
addition to search, such systems include a number of query reformulation
methods, such as query expansion and query recommendations, to provide high
quality results. However, results returned by such methods sometimes exhibit
undesirable or wrongful bias with respect to protected categories such as
gender or race. Our earlier work considered the problem of balanced query
recommendation, where instead of re-ranking a list of results based on fairness
measures, the goal was to suggest queries that are relevant to a user's search
query but exhibit less bias than the original query. In this work, we present a
case study of BalancedQR using an extension of BalancedQR that handles biases
in multiple dimensions. It employs a Pareto front approach that finds balanced
queries, optimizing for multiple objectives such as gender bias and regional
bias, along with the relevance of returned results. We evaluate the extended
version of BalancedQR on a Wikipedia dataset.Our results demonstrate the
effectiveness of our extension to BalancedQR framework and highlight the
significant impact of subtle query wording,linguistic choice on retrieval.

</details>


### [5] [MPFormer: Adaptive Framework for Industrial Multi-Task Personalized Sequential Retriever](https://arxiv.org/abs/2508.20400)
*Yijia Sun,Shanshan Huang,Linxiao Che,Haitao Lu,Qiang Luo,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: MPFormer框架解决了多目标检索的语义差距问题，提高了推荐系统效率和用户参与度，已在快手短视频推荐系统中成功应用。


<details>
  <summary>Details</summary>
Motivation: 现代工业推荐系统在排名和检索阶段存在多阶段优化未对齐的问题，多重目标优化与单目标建模之间存在显著语义差距。

Method: 提出了一种动态多任务Transformer框架MPFormer，通过三个创新机制解决问题：目标条件Transformer，共同编码用户行为序列和多任务语义；引入个性化目标权重，实现动态调整检索结果；将用户个性化信息整合到令牌表示和Transformer结构中。

Result: 该框架已成功集成到快手短视频推荐系统中，稳定服务超过4亿每日活跃用户，显著提高用户日常互动和系统运营效率。实践部署验证表明，与传统解决方案相比，该框架有效优化了多目标检索的迭代范式。

Conclusion: MPFormer框架有效优化了多目标检索迭代范式，并在保持服务响应速度的同时，提供了可扩展的工业推荐系统解决方案。

Abstract: Modern industrial recommendation systems encounter a core challenge of
multi-stage optimization misalignment: a significant semantic gap exists
between the multi-objective optimization paradigm widely used in the ranking
phase and the single-objective modeling in the retrieve phase. Although the
mainstream industry solution achieves multi-objective coverage through parallel
multi-path single-objective retrieval, this approach leads to linear growth of
training and serving resources with the number of objectives and has inherent
limitations in handling loosely coupled objectives. This paper proposes the
MPFormer, a dynamic multi-task Transformer framework, which systematically
addresses the aforementioned issues through three innovative mechanisms. First,
an objective-conditioned transformer that jointly encodes user behavior
sequences and multi-task semantics through learnable attention modulation;
second, personalized target weights are introduced to achieve dynamic
adjustment of retrieval results; finally, user personalization information is
incorporated into token representations and the Transformer structure to
further enhance the model's representation ability. This framework has been
successfully integrated into Kuaishou short video recommendation system, stably
serving over 400 million daily active users. It significantly improves user
daily engagement and system operational efficiency. Practical deployment
verification shows that, compared with traditional solutions, it effectively
optimizes the iterative paradigm of multi-objective retrieval while maintaining
service response speed, providing a scalable multi-objective solution for
industrial recommendation systems.

</details>


### [6] [Revealing Potential Biases in LLM-Based Recommender Systems in the Cold Start Setting](https://arxiv.org/abs/2508.20401)
*Alexandre Andre,Gauthier Roy,Eva Dyer,Kai Wang*

Main category: cs.IR

TL;DR: 研究评估了在零上下文推荐中，LLM的公平性问题，发现其在音乐、电影和大学领域中存在性别和文化偏见。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型在推荐任务中的普遍使用引发了关注，特别是在冷启动场景中，模型可能依赖于预训练期间编码的社会偏见。

Method: 研究采用了一种模块化的管道系统，支持可配置的推荐领域和敏感属性，从而系统地审查任何开源的大规模语言模型。

Result: 经过对先进模型Gemma 3和Llama 3.2的评估，发现这些模型在推荐领域（音乐、电影和大学）中存在一致的性别和文化偏见。

Conclusion: 这项研究揭示了大规模语言模型在冷启动推荐场景中的公平性问题，尤其是在零上下文推荐中，包括性别和文化偏见。

Abstract: Large Language Models (LLMs) are increasingly used for recommendation tasks
due to their general-purpose capabilities. While LLMs perform well in
rich-context settings, their behavior in cold-start scenarios, where only
limited signals such as age, gender, or language are available, raises fairness
concerns because they may rely on societal biases encoded during pretraining.
We introduce a benchmark specifically designed to evaluate fairness in
zero-context recommendation. Our modular pipeline supports configurable
recommendation domains and sensitive attributes, enabling systematic and
flexible audits of any open-source LLM. Through evaluations of state-of-the-art
models (Gemma 3 and Llama 3.2), we uncover consistent biases across
recommendation domains (music, movies, and colleges) including gendered and
cultural stereotypes. We also reveal a non-linear relationship between model
size and fairness, highlighting the need for nuanced analysis.

</details>


### [7] [Fact or Facsimile? Evaluating the Factual Robustness of Modern Retrievers](https://arxiv.org/abs/2508.20408)
*Haoyu Wu,Qingcheng Zeng,Kaize Ding*

Main category: cs.IR

TL;DR: 嵌入模型显著损失了来自基础大语言模型的事实知识，尽管语义检索有改善，但事实推理表现不佳，且对干扰项敏感。


<details>
  <summary>Details</summary>
Motivation: 了解构建在大语言模型基础上的重排器与检索器在事实能力继承方面的表现，以加强RAG系统的可靠性并防止中毒。

Method: 研究通过评估12个公开发布的嵌入检查点与其原始大语言模型的表现，并使用事实性基准进行了详细的比较分析。

Result: 研究表明，嵌入变体在事实检索的准确性显著低于其基础模型，尤其在增加干扰项时，表现下降更为明显。语义相似性得分的推动下，预测主要由表层语义相近性决定而非事实推理，并且在消除词汇提示后，准确率大幅下降。

Conclusion: 该研究揭示了用于检索增强生成（RAG）的重排器与检索器继承大语言模型（LLM）中的事实能力存在显著损失。尽管在语义检索方面有所提升，但它们在检索准确性方面表现不佳。

Abstract: Dense retrievers and rerankers are central to retrieval-augmented generation
(RAG) pipelines, where accurately retrieving factual information is crucial for
maintaining system trustworthiness and defending against RAG poisoning.
However, little is known about how much factual competence these components
inherit or lose from the large language models (LLMs) they are based on. We
pair 12 publicly released embedding checkpoints with their original base LLMs
and evaluate both sets on a factuality benchmark. Across every model evaluated,
the embedding variants achieve markedly lower accuracy than their bases, with
absolute drops ranging from 12 to 43 percentage points (median 28 pts) and
typical retriever accuracies collapsing into the 25-35 % band versus the 60-70
% attained by the generative models. This degradation intensifies under a more
demanding condition: when the candidate pool per question is expanded from four
options to one thousand, the strongest retriever's top-1 accuracy falls from 33
% to 26 %, revealing acute sensitivity to distractor volume. Statistical tests
further show that, for every embedding model, cosine-similarity scores between
queries and correct completions are significantly higher than those for
incorrect ones (p < 0.01), indicating decisions driven largely by surface-level
semantic proximity rather than factual reasoning. To probe this weakness, we
employed GPT-4.1 to paraphrase each correct completion, creating a rewritten
test set that preserved factual truth while masking lexical cues, and observed
that over two-thirds of previously correct predictions flipped to wrong,
reducing overall accuracy to roughly one-third of its original level. Taken
together, these findings reveal a systematic trade-off introduced by
contrastive learning for retrievers: gains in semantic retrieval are paid for
with losses in parametric factual knowledge......

</details>


### [8] [Rethinking Purity and Diversity in Multi-Behavior Sequential Recommendation from the Frequency Perspective](https://arxiv.org/abs/2508.20427)
*Yongqiang Han,Kai Cheng,Kefan Wang,Enhong Chen*

Main category: cs.IR

TL;DR: 该研究提出PDB4Rec模型，通过处理频率信息并优化推荐性能，提升推荐系统的表现。


<details>
  <summary>Details</summary>
Motivation: 传统的多行为序列推荐可能由于行为数据噪声影响用户兴趣建模准确度，需要更好地处理数据噪声。

Method: 提出模型PDB4Rec，利用频率段数据并结合引导平衡机制来提高推荐性能。

Result: 实验结果表明PDB4Rec模型在处理频率信息和优化推荐性能方面表现良好。

Conclusion: 提出了一种新模型PDB4Rec，通过处理不同频段的信息来提升推荐系统性能。实验在真实数据集上验证了模型的有效性和高效性。

Abstract: In recommendation systems, users often exhibit multiple behaviors, such as
browsing, clicking, and purchasing. Multi-behavior sequential recommendation
(MBSR) aims to consider these different behaviors in an integrated manner to
improve the recommendation performance of the target behavior. However, some
behavior data will also bring inevitable noise to the modeling of user
interests. Some research efforts focus on data denoising from the frequency
domain perspective to improve the accuracy of user preference prediction. These
studies indicate that low-frequency information tends to be valuable and
reliable, while high-frequency information is often associated with noise. In
this paper, we argue that high-frequency information is by no means
insignificant. Further experimental results highlight that low frequency
corresponds to the purity of user interests, while high frequency corresponds
to the diversity of user interests. Building upon this finding, we proposed our
model PDB4Rec, which efficiently extracts information across various frequency
bands and their relationships, and introduces Boostrapping Balancer mechanism
to balance their contributions for improved recommendation performance.
Sufficient experiments on real-world datasets demonstrate the effectiveness and
efficiency of our model.

</details>


### [9] [Multistakeholder Fairness in Tourism: What can Algorithms learn from Tourism Management?](https://arxiv.org/abs/2508.20496)
*Peter Muellner,Anna Schreuer,Simone Kopeinik,Bernhard Wieser,Dominik Kowald*

Main category: cs.IR

TL;DR: 本研究结合旅游管理和计算机科学文献，强调跨学科合作以改进算法推荐系统的公平性。


<details>
  <summary>Details</summary>
Motivation: 当前推荐系统可能对环境和当地社区造成负面影响，亟需解决算法在旅游决策支持中的不公平问题。

Method: 通过半系统文献综述将旅游管理与计算机科学的文献结合，分析算法决策支持的多利益相关者公平性。

Result: 旅游管理领域尝试识别利益相关者需求并从规范性和整体研究角度使用定性、包容和参与性方法研究公平性，而计算机科学领域则缺乏对利益相关者需求的理解。

Conclusion: 推动跨学科合作，提升算法决策支持系统在旅游领域中的多利益相关者公平性。

Abstract: Algorithmic decision-support systems, i.e., recommender systems, are popular
digital tools that help tourists decide which places and attractions to
explore. However, algorithms often unintentionally direct tourist streams in a
way that negatively affects the environment, local communities, or other
stakeholders. This issue can be partly attributed to the computer science
community's limited understanding of the complex relationships and trade-offs
among stakeholders in the real world.
  In this work, we draw on the practical findings and methods from tourism
management to inform research on multistakeholder fairness in algorithmic
decision-support. Leveraging a semi-systematic literature review, we synthesize
literature from tourism management as well as literature from computer science.
Our findings suggest that tourism management actively tries to identify the
specific needs of stakeholders and utilizes qualitative, inclusive and
participatory methods to study fairness from a normative and holistic research
perspective. In contrast, computer science lacks sufficient understanding of
the stakeholder needs and primarily considers fairness through descriptive
factors, such as measureable discrimination, while heavily relying on few
mathematically formalized fairness criteria that fail to capture the
multidimensional nature of fairness in tourism.
  With the results of this work, we aim to illustrate the shortcomings of
purely algorithmic research and stress the potential and particular need for
future interdisciplinary collaboration. We believe such a collaboration is a
fundamental and necessary step to enhance algorithmic decision-support systems
towards understanding and supporting true multistakeholder fairness in tourism.

</details>


### [10] [Enhancing Semantic Document Retrieval- Employing Group Steiner Tree Algorithm with Domain Knowledge Enrichment](https://arxiv.org/abs/2508.20543)
*Apurva Kulkarni,Chandrashekar Ramanathan,Vinu E Venugopal*

Main category: cs.IR

TL;DR: 开发并实施了一种新的文档检索算法，显著提高了系统的精确度和准确度，精确度和准确度分别达到了90%和82%。


<details>
  <summary>Details</summary>
Motivation: 解决文件检索系统在从多种数据源中检索相关文件时所遇到的复杂问题，特别是其语义关系和领域知识的挑战。现有检索系统的精确度可能受到缺乏领域信息和依赖过时知识来源的影响。

Method: 开发了一种通用算法'基于语义的概念检索使用组合斯坦纳树'，该算法整合领域信息以增强语义感知的知识表示和数据访问，并在文档检索系统中实施该算法。

Result: 通过使用170个真实世界搜索查询的基准进行性能评估，结果显示与基线系统相比取得了重大进展，精确度和准确度分别达到了90%和82%。

Conclusion: 该研究在开发和实施新的文档检索算法上取得了显著进展，提高了检索系统的精确度和准确度。通过领域专家验证和评估，结果显示优于基线系统。

Abstract: Retrieving pertinent documents from various data sources with diverse
characteristics poses a significant challenge for Document Retrieval Systems.
The complexity of this challenge is further compounded when accounting for the
semantic relationship between data and domain knowledge. While existing
retrieval systems using semantics (usually represented as Knowledge Graphs
created from open-access resources and generic domain knowledge) hold promise
in delivering relevant outcomes, their precision may be compromised due to the
absence of domain-specific information and reliance on outdated knowledge
sources. In this research, the primary focus is on two key contributions- a)
the development of a versatile algorithm- 'Semantic-based Concept Retrieval
using Group Steiner Tree' that incorporates domain information to enhance
semantic-aware knowledge representation and data access, and b) the practical
implementation of the proposed algorithm within a document retrieval system
using real-world data. To assess the effectiveness of the SemDR system,
research work conducts performance evaluations using a benchmark consisting of
170 real-world search queries. Rigorous evaluation and verification by domain
experts are conducted to ensure the validity and accuracy of the results. The
experimental findings demonstrate substantial advancements when compared to the
baseline systems, with precision and accuracy achieving levels of 90% and 82%
respectively, signifying promising improvements.

</details>


### [11] [SUMMA: A Multimodal Large Language Model for Advertisement Summarization](https://arxiv.org/abs/2508.20582)
*Weitao Jia,Shuo Yin,Zhoufutu Wen,Han Wang,Zehui Dai,Kun Zhang,Zhenyu Li,Tao Zeng,Xiaohui Lv*

Main category: cs.IR

TL;DR: 提出了SUMMA多模态模型，通过摘要提升广告内容理解和排名，提高广告收入。


<details>
  <summary>Details</summary>
Motivation: 提升短视频平台上的广告查询匹配和相关性排序，以改善广告效果和用户体验。

Method: 通过视频帧和语音识别/光学字符识别文本进行多模态监督微调，然后使用带有混合奖励机制的强化学习进行二阶段训练。

Result: 在线实验结果显示广告收入显著增加了1.5%，同时离线和在线实验均显示效果优于基准。

Conclusion: SUMMA模型实现了将多模态视频广告内容浓缩为具有高商业价值的摘要，并用于提升搜索广告系统的效果。

Abstract: Understanding multimodal video ads is crucial for improving query-ad matching
and relevance ranking on short video platforms, enhancing advertising
effectiveness and user experience. However, the effective utilization of
multimodal information with high commercial value still largely constrained by
reliance on highly compressed video embeddings-has long been inadequate. To
address this, we propose SUMMA (the abbreviation of Summarizing MultiModal
Ads), a multimodal model that automatically processes video ads into summaries
highlighting the content of highest commercial value, thus improving their
comprehension and ranking in Douyin search-advertising systems. SUMMA is
developed via a two-stage training strategy-multimodal supervised fine-tuning
followed by reinforcement learning with a mixed reward mechanism-on
domain-specific data containing video frames and ASR/OCR transcripts,
generating commercially valuable and explainable summaries. We integrate
SUMMA-generated summaries into our production pipeline, directly enhancing the
candidate retrieval and relevance ranking stages in real search-advertising
systems. Both offline and online experiments show substantial improvements over
baselines, with online results indicating a statistically significant 1.5%
increase in advertising revenue. Our work establishes a novel paradigm for
condensing multimodal information into representative texts, effectively
aligning visual ad content with user query intent in retrieval and
recommendation scenarios.

</details>


### [12] [SemSR: Semantics aware robust Session-based Recommendations](https://arxiv.org/abs/2508.20587)
*Jyoti Narwariya,Priyanka Gupta,Muskan Gupta,Jyotsana Khatri,Lovekesh Vig*

Main category: cs.IR

TL;DR: 本文利用大型语言模型提升会话推荐，实现高召回和排序性能，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的会话推荐模型常无法有效利用简单物品标题或描述中的语义信息，影响了会话意图的识别及可解释性。利用大型语言模型（LLMs）可以解决这一问题并提升推荐性能。

Method: 本文提出了一系列利用LLMs的方法用于会话推荐，包括：LLMs的上下文推荐代理、用于深度学习SR模型语义初始化的LLMs生成表示，以及LLMs与数据驱动的SR模型相结合。

Result: 通过两个公开的真实世界数据集的实验，展示了LLMs方法在粗级检索（高召回值）上的优势，而传统数据驱动技术在细粒度排序（高平均倒数排名值）上表现良好。此外，将LLMs与数据驱动SR模型结合的方式显著优于单独使用LLMs的方法和数据驱动深度学习模型。

Conclusion: 在会话推荐中，结合大型语言模型（LLMs）与数据驱动的SR模型能够显著提升推荐性能。

Abstract: Session-based recommendation (SR) models aim to recommend items to anonymous
users based on their behavior during the current session. While various SR
models in the literature utilize item sequences to predict the next item, they
often fail to leverage semantic information from item titles or descriptions
impeding session intent identification and interpretability. Recent research
has explored Large Language Models (LLMs) as promising approaches to enhance
session-based recommendations, with both prompt-based and fine-tuning based
methods being widely investigated. However, prompt-based methods struggle to
identify optimal prompts that elicit correct reasoning and lack task-specific
feedback at test time, resulting in sub-optimal recommendations. Fine-tuning
methods incorporate domain-specific knowledge but incur significant
computational costs for implementation and maintenance. In this paper, we
present multiple approaches to utilize LLMs for session-based recommendation:
(i) in-context LLMs as recommendation agents, (ii) LLM-generated
representations for semantic initialization of deep learning SR models, and
(iii) integration of LLMs with data-driven SR models. Through comprehensive
experiments on two real-world publicly available datasets, we demonstrate that
LLM-based methods excel at coarse-level retrieval (high recall values), while
traditional data-driven techniques perform well at fine-grained ranking (high
Mean Reciprocal Rank values). Furthermore, the integration of LLMs with
data-driven SR models significantly out performs both standalone LLM approaches
and data-driven deep learning models, as well as baseline SR models, in terms
of both Recall and MRR metrics.

</details>


### [13] [SEAL: Structure and Element Aware Learning to Improve Long Structured Document Retrieval](https://arxiv.org/abs/2508.20778)
*Xinhao Huang,Zhibo Ren,Yipeng Yu,Ying Zhou,Zulong Chen,Zeyi Wen*

Main category: cs.IR

TL;DR: 提出了结构感知学习的对比学习框架\our，并发布了包含丰富结构注释的数据集\dataset，显著提升了文档检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能有效利用结构特征和元素层语义，并且缺乏包含结构元数据的数据集。

Method: 使用\our的结构感知学习和遮蔽元素对齐技术来细化语义区分。并提供一个名为\dataset的新的检索数据集，其中包含丰富的结构注释。

Result: 实验表明，所提出的方法在多个现代预训练语言模型和在线A/B测试中均表现出一致的性能提升，将BGE-M3上的NDCG@10从73.96%提升至77.84%。

Conclusion: 本文提出了一种新的对比学习框架\our，用于长结构文档检索，能够有效利用结构特征并保持语义层次。

Abstract: In long structured document retrieval, existing methods typically fine-tune
pre-trained language models (PLMs) using contrastive learning on datasets
lacking explicit structural information. This practice suffers from two
critical issues: 1) current methods fail to leverage structural features and
element-level semantics effectively, and 2) the lack of datasets containing
structural metadata. To bridge these gaps, we propose \our, a novel contrastive
learning framework. It leverages structure-aware learning to preserve semantic
hierarchies and masked element alignment for fine-grained semantic
discrimination. Furthermore, we release \dataset, a long structured document
retrieval dataset with rich structural annotations. Extensive experiments on
both released and industrial datasets across various modern PLMs, along with
online A/B testing, demonstrate consistent performance improvements, boosting
NDCG@10 from 73.96\% to 77.84\% on BGE-M3. The resources are available at
https://github.com/xinhaoH/SEAL.

</details>


### [14] [Addressing Personalized Bias for Unbiased Learning to Rank](https://arxiv.org/abs/2508.20798)
*Zechun Niu,Lang Mei,Liu Yang,Ziyuan Zhao,Qiang Yan,Jiaxin Mao,Ji-Rong Wen*

Main category: cs.IR

TL;DR: 引入用户因素到无偏学习排序框架中，提出用户感知估计器以降低偏差与方差，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的无偏学习排序方法通常假设行为日志是从“平均”用户收集的，忽略了不同用户在搜索和浏览行为上的差异。

Method: 提出一种新颖的用户感知逆倾向得分估计器，通过对每个查询的用户浏览行为进行建模，并聚合用户加权的检查概率以确定倾向性。

Result: 理论上证明了用户感知估计器在一些温和假设下是无偏的，并且与直接计算用户依赖倾向的方法相比，方差更低。通过对两个半合成数据集和一个真实世界数据集进行广泛实验，验证了用户感知估计器的有效性。

Conclusion: 个性化因素在无偏排序学习中具有重要作用，通过引入用户感知框架，可以克服传统方法中的偏差问题。

Abstract: Unbiased learning to rank (ULTR), which aims to learn unbiased ranking models
from biased user behavior logs, plays an important role in Web search. Previous
research on ULTR has studied a variety of biases in users' clicks, such as
position bias, presentation bias, and outlier bias. However, existing work
often assumes that the behavior logs are collected from an ``average'' user,
neglecting the differences between different users in their search and browsing
behaviors. In this paper, we introduce personalized factors into the ULTR
framework, which we term the user-aware ULTR problem. Through a formal causal
analysis of this problem, we demonstrate that existing user-oblivious methods
are biased when different users have different preferences over queries and
personalized propensities of examining documents. To address such a
personalized bias, we propose a novel user-aware inverse-propensity-score
estimator for learning-to-rank objectives. Specifically, our approach models
the distribution of user browsing behaviors for each query and aggregates
user-weighted examination probabilities to determine propensities. We
theoretically prove that the user-aware estimator is unbiased under some mild
assumptions and shows lower variance compared to the straightforward way of
calculating a user-dependent propensity for each impression. Finally, we
empirically verify the effectiveness of our user-aware estimator by conducting
extensive experiments on two semi-synthetic datasets and a real-world dataset.

</details>


### [15] [Deep Multiple Quantization Network on Long Behavior Sequence for Click-Through Rate Prediction](https://arxiv.org/abs/2508.20865)
*Zhuoxing Wei,Qi Liu,Qingchen Xie*

Main category: cs.IR

TL;DR: 本文提出了深度多量化网络(DMQN)以端到端处理长行为序列，并显著提升了CTR预测的效果和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在目标注意力与完整长行为序列中的相关性分布存在差异，导致性能下降。

Method: 提出深度多量化网络(DMQN)，通过多重独立代码本将长行为序列量化为多个代码字序列，并使用层次化序列传递单元促进代码字序列间的交互，最终生成兴趣向量。

Result: 通过工业和公共数据集的大量实验验证DMQN的有效性和效率，A/B测试表明DMQN提高CTR 3.5%和RPM 2.0%。

Conclusion: DMQN能够缓解目标注意力相关性分布的差异，提升CTR预测性能和效率。

Abstract: In Click-Through Rate (CTR) prediction, the long behavior sequence,
comprising the user's long period of historical interactions with items has a
vital influence on assessing the user's interest in the candidate item.
Existing approaches strike efficiency and effectiveness through a two-stage
paradigm: first retrieving hundreds of candidate-related items and then
extracting interest intensity vector through target attention. However, we
argue that the discrepancy in target attention's relevance distribution between
the retrieved items and the full long behavior sequence inevitably leads to a
performance decline. To alleviate the discrepancy, we propose the Deep Multiple
Quantization Network (DMQN) to process long behavior sequence end-to-end
through compressing the long behavior sequence. Firstly, the entire spectrum of
long behavior sequence will be quantized into multiple codeword sequences based
on multiple independent codebooks. Hierarchical Sequential Transduction Unit is
incorporated to facilitate the interaction of reduced codeword sequences. Then,
attention between the candidate and multiple codeword sequences will output the
interest vector. To enable online serving, intermediate representations of the
codeword sequences are cached, significantly reducing latency. Our extensive
experiments on both industrial and public datasets confirm the effectiveness
and efficiency of DMQN. The A/B test in our advertising system shows that DMQN
improves CTR by 3.5% and RPM by 2.0%.

</details>


### [16] [OneRec-V2 Technical Report](https://arxiv.org/abs/2508.20900)
*Guorui Zhou,Hengrui Hu,Hongtao Cheng,Huanjie Wang,Jiaxin Deng,Jinghao Zhang,Kuo Cai,Lejian Ren,Lu Ren,Liao Yu,Pengfei Zheng,Qiang Luo,Qianqian Wang,Qigen Hu,Rui Huang,Ruiming Tang,Shiyao Wang,Shujie Yang,Tao Wu,Wuchao Li,Xinchen Luo,Xingmei Wang,Yi Su,Yunfan Wu,Zexuan Cheng,Zhanyu Liu,Zixing Zhang,Bin Zhang,Boxuan Wang,Chaoyi Ma,Chengru Song,Chenhui Wang,Chenglong Chu,Di Wang,Dongxue Meng,Dunju Zang,Fan Yang,Fangyu Zhang,Feng Jiang,Fuxing Zhang,Gang Wang,Guowang Zhang,Han Li,Honghui Bao,Hongyang Cao,Jiaming Huang,Jiapeng Chen,Jiaqiang Liu,Jinghui Jia,Kun Gai,Lantao Hu,Liang Zeng,Qiang Wang,Qidong Zhou,Rongzhou Zhang,Shengzhe Wang,Shihui He,Shuang Yang,Siyang Mao,Sui Huang,Tiantian He,Tingting Gao,Wei Yuan,Xiao Liang,Xiaoxiao Xu,Xugang Liu,Yan Wang,Yang Zhou,Yi Wang,Yiwu Liu,Yue Song,Yufei Zhang,Yunfeng Zhao,Zhixin Ling,Ziming Li*

Main category: cs.IR

TL;DR: OneRec-V2 enhances scalability and alignment in generative recommendation systems by innovating its architecture and learning from user interactions, overcoming previous computational and alignment challenges.


<details>
  <summary>Details</summary>
Motivation: This research is motivated by the need to overcome the inefficiencies and limitations in scalability and real-world applicability in OneRec-V1, primarily due to computational allocation issues and reinforcement learning limitations relying solely on reward models.

Method: OneRec-V2 introduces a Lazy Decoder-Only Architecture to eliminate encoder bottlenecks and reduces computational resources significantly. It also incorporates Duration-Aware Reward Shaping and Adaptive Ratio Clipping for better alignment with user preferences.

Result: The implementation of OneRec-V2 led to a significant improvement in App Stay Time by 0.467%/0.741% during extensive A/B testing on Kuaishou, demonstrating its effectiveness and balance in multi-objective recommendations.

Conclusion: OneRec-V2 significantly improves the scalability and performance of generative recommendation systems by addressing previous inefficiencies and aligning recommendations with real-world user interactions.

Abstract: Recent breakthroughs in generative AI have transformed recommender systems
through end-to-end generation. OneRec reformulates recommendation as an
autoregressive generation task, achieving high Model FLOPs Utilization. While
OneRec-V1 has shown significant empirical success in real-world deployment, two
critical challenges hinder its scalability and performance: (1) inefficient
computational allocation where 97.66% of resources are consumed by sequence
encoding rather than generation, and (2) limitations in reinforcement learning
relying solely on reward models.
  To address these challenges, we propose OneRec-V2, featuring: (1) Lazy
Decoder-Only Architecture: Eliminates encoder bottlenecks, reducing total
computation by 94% and training resources by 90%, enabling successful scaling
to 8B parameters. (2) Preference Alignment with Real-World User Interactions:
Incorporates Duration-Aware Reward Shaping and Adaptive Ratio Clipping to
better align with user preferences using real-world feedback.
  Extensive A/B tests on Kuaishou demonstrate OneRec-V2's effectiveness,
improving App Stay Time by 0.467%/0.741% while balancing multi-objective
recommendations. This work advances generative recommendation scalability and
alignment with real-world feedback, representing a step forward in the
development of end-to-end recommender systems.

</details>


### [17] [Efficient Large-Scale Cross-Domain Sequential Recommendation with Dynamic State Representations](https://arxiv.org/abs/2508.20945)
*Manuel V. Loureiro,Steven Derby,Aleksei Medvedev,Alejandro Ariza-Casabona,Gonzalo Fiz Pontiveros,Tri Kurniawan Wijaya*

Main category: cs.IR

TL;DR: 本文提出了一种可扩展的多域推荐系统解决方案，通过创新机制减少计算瓶颈，提高系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归推荐模型在多域场景中存在注意力图计算瓶颈，需高效处理域间和域内知识转移。

Method: 采用两种创新机制：过渡感知位置嵌入（TAPE）和动态域状态表示（DDSR），分别处理域内和跨域信息的转移。

Result: 新方法在大规模多域推荐系统中取得显著的检索性能提升。

Conclusion: 本文提出了一种新颖的方法，通过替换完整跨域注意力机制，解决多域推荐系统中的计算瓶颈问题，提高检索任务的性能。

Abstract: Recently, autoregressive recommendation models (ARMs), such as Meta's HSTU
model, have emerged as a major breakthrough over traditional Deep Learning
Recommendation Models (DLRMs), exhibiting the highly sought-after scaling law
behaviour. However, when applied to multi-domain scenarios, the transformer
architecture's attention maps become a computational bottleneck, as they attend
to all items across every domain. To tackle this challenge, systems must
efficiently balance inter and intra-domain knowledge transfer. In this work, we
introduce a novel approach for scalable multi-domain recommendation systems by
replacing full inter-domain attention with two innovative mechanisms: 1)
Transition-Aware Positional Embeddings (TAPE): We propose novel positional
embeddings that account for domain-transition specific information. This allows
attention to be focused solely on intra-domain items, effectively reducing the
unnecessary computational cost associated with attending to irrelevant domains.
2) Dynamic Domain State Representation (DDSR): We introduce a dynamic state
representation for each domain, which is stored and accessed during subsequent
token predictions. This enables the efficient transfer of relevant domain
information without relying on full attention maps. Our method offers a
scalable solution to the challenges posed by large-scale, multi-domain
recommendation systems and demonstrates significant improvements in retrieval
tasks by separately modelling and combining inter- and intra-domain
representations.

</details>


### [18] [On the Theoretical Limitations of Embedding-Based Retrieval](https://arxiv.org/abs/2508.21038)
*Orion Weller,Michael Boratko,Iftekhar Naim,Jinhyuk Lee*

Main category: cs.IR

TL;DR: 嵌入模型在单矢量范式下存在理论限制，部分情况下不切实际查询之外的简单查询也会遇到这一问题。即使最先进的模型也无法处理LIMIT数据集中简单任务。


<details>
  <summary>Details</summary>
Motivation: 随着嵌入的应用场景扩展到推理、任务指导等，对任意查询的相关性进行处理成为嵌入的一项重要任务。然而，理论上的限制可能不是仅由不切实际的查询导致的，更好的训练数据和模型规模可能无法解决这些问题。

Method: 将学习理论中的已知结果与实际查询相结合，实验验证了理论限制的存在，并创造了一个名为LIMIT的数据集进行模型的压力测试。

Result: 实验展示即使在k=2的限制下，这种理论限制依然有效，并且即便直接在测试集上优化参数化嵌入，模型也难以应对。即便是最先进的模型在LIMIT数据集上的表现也不佳。

Conclusion: 嵌入模型在现有的单矢量范式下存在限制，未来的研究需要开发能够解决这一基本限制的方法。

Abstract: Vector embeddings have been tasked with an ever-increasing set of retrieval
tasks over the years, with a nascent rise in using them for reasoning,
instruction-following, coding, and more. These new benchmarks push embeddings
to work for any query and any notion of relevance that could be given. While
prior works have pointed out theoretical limitations of vector embeddings,
there is a common assumption that these difficulties are exclusively due to
unrealistic queries, and those that are not can be overcome with better
training data and larger models. In this work, we demonstrate that we may
encounter these theoretical limitations in realistic settings with extremely
simple queries. We connect known results in learning theory, showing that the
number of top-k subsets of documents capable of being returned as the result of
some query is limited by the dimension of the embedding. We empirically show
that this holds true even if we restrict to k=2, and directly optimize on the
test set with free parameterized embeddings. We then create a realistic dataset
called LIMIT that stress tests models based on these theoretical results, and
observe that even state-of-the-art models fail on this dataset despite the
simple nature of the task. Our work shows the limits of embedding models under
the existing single vector paradigm and calls for future research to develop
methods that can resolve this fundamental limitation.

</details>
