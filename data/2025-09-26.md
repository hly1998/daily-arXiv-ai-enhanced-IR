<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [DELM: a Python toolkit for Data Extraction with Language Models](https://arxiv.org/abs/2509.20617)
*Eric Fithian,Kirill Skobelev*

Main category: cs.IR

TL;DR: 介绍DELM，一个改进LLM数据提取工作流的工具包，以解决可重现性和评估问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有工作流中存在的随意性脚本导致的可重现性、健壮性和系统评估困难的问题。

Method: DELM是一种用于快速实验迭代的Python工具包，旨在改进基于大型语言模型（LLM）的数据提取工作流。

Result: 通过两个案例展示了DELM的功能：一个是新颖的提示优化算法，另一个是如何通过DELM量化成本与覆盖率之间的权衡。

Conclusion: DELM提供了一个模块化框架，支持高效的数据处理和与LLM API的强大集成，适合进行快速实验迭代和量化权衡。

Abstract: Large Language Models (LLMs) have become powerful tools for annotating
unstructured data. However, most existing workflows rely on ad hoc scripts,
making reproducibility, robustness, and systematic evaluation difficult. To
address these challenges, we introduce DELM (Data Extraction with Language
Models), an open-source Python toolkit designed for rapid experimental
iteration of LLM-based data extraction pipelines and for quantifying the
trade-offs between them. DELM minimizes boilerplate code and offers a modular
framework with structured outputs, built-in validation, flexible data-loading
and scoring strategies, and efficient batch processing. It also includes robust
support for working with LLM APIs, featuring retry logic, result caching,
detailed cost tracking, and comprehensive configuration management. We showcase
DELM's capabilities through two case studies: one featuring a novel prompt
optimization algorithm, and another illustrating how DELM quantifies trade-offs
between cost and coverage when selecting keywords to decide which paragraphs to
pass to an LLM. DELM is available at
\href{https://github.com/Center-for-Applied-AI/delm}{\texttt{github.com/Center-for-Applied-AI/delm}}.

</details>


### [2] [Provenance Analysis of Archaeological Artifacts via Multimodal RAG Systems](https://arxiv.org/abs/2509.20769)
*Tuo Zhang,Yuechun Sun,Ruiliang Liu*

Main category: cs.IR

TL;DR: 本研究提出了一种基于RAG的系统，用于考古文物的出处分析，能有效支持专家推理。


<details>
  <summary>Details</summary>
Motivation: 设计该系统是为了在考古文物的出处分析中支持专家推理，减轻他们在处理海量信息时的认知负担。

Method: 系统采用双模态知识库，结合视觉、边缘增强和语义检索，从参考文本和图像中识别风格相似的对象，并由视觉语言模型生成结构化推理。

Result: 该系统通过整合多模态检索和大规模视觉语言模型，支持专家对考古文物的推理分析。通过对参考文本和图像构建双模知识库，可实现原始视觉、边缘增强和语义检索，以识别风格相似的对象。

Conclusion: 专家评估显示，该系统能够生成有意义且可解释的输出，为学者提供了具体的分析起点，并显著减轻了处理海量比较语料库的认知负担。

Abstract: In this work, we present a retrieval-augmented generation (RAG)-based system
for provenance analysis of archaeological artifacts, designed to support expert
reasoning by integrating multimodal retrieval and large vision-language models
(VLMs). The system constructs a dual-modal knowledge base from reference texts
and images, enabling raw visual, edge-enhanced, and semantic retrieval to
identify stylistically similar objects. Retrieved candidates are synthesized by
the VLM to generate structured inferences, including chronological,
geographical, and cultural attributions, alongside interpretive justifications.
We evaluate the system on a set of Eastern Eurasian Bronze Age artifacts from
the British Museum. Expert evaluation demonstrates that the system produces
meaningful and interpretable outputs, offering scholars concrete starting
points for analysis and significantly alleviating the cognitive burden of
navigating vast comparative corpora.

</details>


### [3] [Performance Consistency of Learning Methods for Information Retrieval Tasks](https://arxiv.org/abs/2509.20804)
*Meng Yuan,Justin Zobel*

Main category: cs.IR

TL;DR: 研究发现在不同种子的情况下，Transformer模型的表现差异显著，强调了其训练不稳定性及对其评估结果可靠性的担忧。


<details>
  <summary>Details</summary>
Motivation: 评估IR方法性能的准确性和稳健性，并比较传统统计学习模型与基于Transformer的学习模型在不同种子下的表现。

Method: 使用测试集的自助法（bootstrapping）和随机种子集分析IR方法的性能变化。

Result: 传统统计模型稳定，而Transformer模型在种子变化时表现出巨大差异。在进行的11项测试中，有9项F1分数的标准差超过0.075；11项测试中有7项精度值的标准差超过0.125。

Conclusion: Transformer模型在训练稳定性方面存在显著问题，需要更严格的评估方法以确保结果的可靠性。

Abstract: A range of approaches have been proposed for estimating the accuracy or
robustness of the measured performance of IR methods. One is to use
bootstrapping of test sets, which, as we confirm, provides an estimate of
variation in performance. For IR methods that rely on a seed, such as those
that involve machine learning, another approach is to use a random set of seeds
to examine performance variation. Using three different IR tasks we have used
such randomness to examine a range of traditional statistical learning models
and transformer-based learning models. While the statistical models are stable,
the transformer models show huge variation as seeds are changed. In 9 of 11
cases the F1-scores (in the range 0.0--1.0) had a standard deviation of over
0.075; while 7 of 11 precision values (also in the range 0.0--1.0) had a
standard deviation of over 0.125. This is in a context where differences of
less than 0.02 have been used as evidence of method improvement. Our findings
highlight the vulnerability of transformer models to training instabilities and
moreover raise questions about the reliability of previous results, thus
underscoring the need for rigorous evaluation practices.

</details>


### [4] [RecIS: Sparse to Dense, A Unified Training Framework for Recommendation Models](https://arxiv.org/abs/2509.20883)
*Hua Zong,Qingtao Zeng,Zhengxiong Zhou,Zhihua Han,Zhensong Yan,Mingjie Liu,Hechen Sun,Jiawei Liu,Yiwen Hu,Qi Wang,YiHan Xian,Wenjie Guo,Houyuan Xiang,Zhiyuan Zeng,Xiangrong Sheng,Bencheng Yan,Nan Hu,Yuheng Huang,Jinqing Lian,Ziru Xu,Yan Zhang,Ju Huang,Siran Yang,Huimin Yi,Jiamang Wang,Pengjie Wang,Han Zhu,Jian Wu,Dan Ou,Jian Xu,Haihong Tang,Yuning Jiang,Bo Zheng,Lin Qu*

Main category: cs.IR

TL;DR: 提出RecIS，一个基于PyTorch生态系统的统一稀疏-密集训练框架，以优化系统组件并提升效率。


<details>
  <summary>Details</summary>
Motivation: 设计一个统一的稀疏-密集训练框架来满足集成大型模型的工业级推荐模型的训练需求。

Method: RecIS框架集成稀疏组件优化和PyTorch生态系统中的密集组件优化技术。

Result: RecIS在阿里巴巴被用于众多大型模型增强的推荐训练任务，同时也开始训练一些传统的稀疏模型。

Conclusion: RecIS成功地满足了工业级推荐模型训练的需求，并在实际应用中展示了其优势。

Abstract: In this paper, we propose RecIS, a unified Sparse-Dense training framework
designed to achieve two primary goals: 1. Unified Framework To create a Unified
sparse-dense training framework based on the PyTorch ecosystem that meets the
training needs of industrial-grade recommendation models that integrated with
large models. 2.System Optimization To optimize the sparse component, offering
superior efficiency over the TensorFlow-based recommendation models. The dense
component, meanwhile, leverages existing optimization technologies within the
PyTorch ecosystem. Currently, RecIS is being used in Alibaba for numerous
large-model enhanced recommendation training tasks, and some traditional sparse
models have also begun training in it.

</details>


### [5] [FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial Datasets](https://arxiv.org/abs/2509.20904)
*Kairui Fu,Tao Zhang,Shuwen Xiao,Ziyang Wang,Xinming Zhang,Chenchi Zhang,Yuliang Yan,Junjun Zheng,Yu Li,Zhihong Chen,Jian Wu,Xiangheng Kong,Shengyu Zhang,Kun Kuang,Yuning Jiang,Bo Zheng*

Main category: cs.IR

TL;DR: FORGE基准通过提供大规模工业数据集并优化语义标识符生成，提升推荐性能及加快在线收敛。


<details>
  <summary>Details</summary>
Motivation: 解决当前语义标识符生成研究中的数据集缺乏、优化策略有限以及工业部署缓慢的问题。

Method: 利用淘宝平台提供的海量多模态数据集，进行离线实验验证和在线分析，并引入了两种新的语义标识符评估指标以及离线预训练架构。

Result: 通过离线实验和在线分析，FORGE展示了语义标识符优化后的推荐性能提升，并通过离线预训练减少在线收敛时间。

Conclusion: FORGE基准提供了大型工业数据集，优化了语义标识符构建，并提高了推荐性能，减少了在线收敛时间。

Abstract: Semantic identifiers (SIDs) have gained increasing attention in generative
retrieval (GR) due to their meaningful semantic discriminability. However,
current research on SIDs faces three main challenges: (1) the absence of
large-scale public datasets with multimodal features, (2) limited investigation
into optimization strategies for SID generation, which typically rely on costly
GR training for evaluation, and (3) slow online convergence in industrial
deployment. To address these challenges, we propose FORGE, a comprehensive
benchmark for FOrming semantic identifieR in Generative rEtrieval with
industrial datasets. Specifically, FORGE is equipped with a dataset comprising
14 billion user interactions and multimodal features of 250 million items
sampled from Taobao, one of the biggest e-commerce platforms in China.
Leveraging this dataset, FORGE explores several optimizations to enhance the
SID construction and validates their effectiveness via offline experiments
across different settings and tasks. Further online analysis conducted on our
platform, which serves over 300 million users daily, reveals a 0.35% increase
in transaction count, highlighting the practical impact of our method.
Regarding the expensive SID validation accompanied by the full training of GRs,
we propose two novel metrics of SID that correlate positively with
recommendation performance, enabling convenient evaluations without any GR
training. For real-world applications, FORGE introduces an offline pretraining
schema that reduces online convergence by half. The code and data are available
at https://github.com/selous123/al_sid.

</details>


### [6] [Markup Language Modeling for Web Document Understanding](https://arxiv.org/abs/2509.20940)
*Su Liu,Bin Bi,Jan Bakus,Paritosh Kumar Velalam,Vijay Yella,Vinod Hegde*

Main category: cs.IR

TL;DR: 通过开发MarkupLM++，提高了从购物评论网站提取产品信息的准确性，尽管扩展预测到DOM内部节点会稍微降低整体性能，但有助于某些属性的提取。最终模型性能达到了较高水平。


<details>
  <summary>Details</summary>
Motivation: 解决通过从购物评论网站提取详细信息来构建最新产品数据库的问题，为电子商务系统中的客户分析和产品推荐任务提供支持。

Method: 微调MarkupLM模型，并开发了一个称为MarkupLM++的变体，将预测扩展到DOM树的内部节点。通过实验验证了该方法的有效性。

Result: 最终模型达到了0.906的准确率，0.724的召回率和0.805的F1分数。

Conclusion: 使用更大规模和更多样化的训练集可以整体提高信息提取的准确性。虽然在DOM树内部节点上扩展预测会导致整体性能略有下降，但有助于某些产品属性的提取。

Abstract: Web information extraction (WIE) is an important part of many e-commerce
systems, supporting tasks like customer analysis and product recommendation. In
this work, we look at the problem of building up-to-date product databases by
extracting detailed information from shopping review websites. We fine-tuned
MarkupLM on product data gathered from review sites of different sizes and then
developed a variant we call MarkupLM++, which extends predictions to internal
nodes of the DOM tree. Our experiments show that using larger and more diverse
training sets improves extraction accuracy overall. We also find that including
internal nodes helps with some product attributes, although it leads to a
slight drop in overall performance. The final model reached a precision of
0.906, recall of 0.724, and an F1 score of 0.805.

</details>


### [7] [Rejuvenating Cross-Entropy Loss in Knowledge Distillation for Recommender Systems](https://arxiv.org/abs/2509.20989)
*Zhangchi Zhu,Wei Zhang*

Main category: cs.IR

TL;DR: 本论文分析了知识蒸馏中的交叉熵损失在推荐系统中的应用。即使交叉熵损失最大化了NDCG的下限，但在蒸馏教师模型排名时需要满足一个假设，而这种假设与目标相悖。提出了一种新的蒸馏方法RCE-KD以解决此问题。


<details>
  <summary>Details</summary>
Motivation: 交叉熵损失虽然在特定条件下最大化了NDCG的下限，但这种条件与想要蒸馏教师模型排名的目标相悖。因此需要开发一种新的方法来解决这一矛盾。

Method: 该论文提出了一种名为RCE-KD的新方法，它通过将教师给予的顶级项目分为两个子集，并对那些不符合条件的子集使用采样策略进行处理，结合教师与学生的合作以接近闭合假设，从而更好地进行知识蒸馏。

Result: 实验结果表明，提出的RCE-KD方法在填补交叉熵损失与蒸馏目标之间的差距上是有效的。

Conclusion: 提出了一种名为RCE-KD的新方法，成功填补了交叉熵损失与目标之间的巨大差距，该方法在实验中证明是有效的。

Abstract: This paper analyzes Cross-Entropy (CE) loss in knowledge distillation (KD)
for recommender systems. KD for recommender systems targets at distilling
rankings, especially among items most likely to be preferred, and can only be
computed on a small subset of items. Considering these features, we reveal the
connection between CE loss and NDCG in the field of KD. We prove that when
performing KD on an item subset, minimizing CE loss maximizes the lower bound
of NDCG, only if an assumption of closure is satisfied. It requires that the
item subset consists of the student's top items. However, this contradicts our
goal of distilling rankings of the teacher's top items. We empirically
demonstrate the vast gap between these two kinds of top items. To bridge the
gap between our goal and theoretical support, we propose Rejuvenated
Cross-Entropy for Knowledge Distillation (RCE-KD). It splits the top items
given by the teacher into two subsets based on whether they are highly ranked
by the student. For the subset that defies the condition, a sampling strategy
is devised to use teacher-student collaboration to approximate our assumption
of closure. We also combine the losses on the two subsets adaptively. Extensive
experiments demonstrate the effectiveness of our method. Our code is available
at https://anonymous.4open.science/r/RCE-KD.

</details>


### [8] [IntSR: An Integrated Generative Framework for Search and Recommendation](https://arxiv.org/abs/2509.21179)
*Huimin Yan,Longfei Xu,Junjie Sun,Ni Ou,Wei Luo,Xing Tan,Ran Cheng,Kaikui Liu,Xiangxiang Chu*

Main category: cs.IR

TL;DR: 提出了一种整合搜索和推荐任务的生成框架IntSR，成功应用于Amap，提升了多个指标。


<details>
  <summary>Details</summary>
Motivation: 现有系统主要关注统一检索和排名，而忽略了搜索和推荐任务的整合。搜索和推荐的区别在于查询的形成方式：搜索使用显式的用户请求，而推荐依赖于隐式的用户兴趣。

Method: 提出了一种名为IntSR的集成生成框架，该框架通过不同的查询模态来整合搜索和推荐任务，并解决了集成搜索和推荐行为所带来的计算复杂性问题以及动态变化的语料库引入的错误模式学习问题。

Result: IntSR在Amap平台的多个场景中成功部署，显著提升了数字资产的GMV（+3.02%）、POI推荐的CTR（+2.76%）以及出行方式建议的ACC（+5.13%）。

Conclusion: 该框架在多种工业场景中表现出色，证明了将搜索与推荐任务整合的有效性。

Abstract: Generative recommendation has emerged as a promising paradigm, demonstrating
remarkable results in both academic benchmarks and industrial applications.
However, existing systems predominantly focus on unifying retrieval and ranking
while neglecting the integration of search and recommendation (S&R) tasks. What
makes search and recommendation different is how queries are formed: search
uses explicit user requests, while recommendation relies on implicit user
interests. As for retrieval versus ranking, the distinction comes down to
whether the queries are the target items themselves. Recognizing the query as
central element, we propose IntSR, an integrated generative framework for S&R.
IntSR integrates these disparate tasks using distinct query modalities. It also
addresses the increased computational complexity associated with integrated S&R
behaviors and the erroneous pattern learning introduced by a dynamically
changing corpus. IntSR has been successfully deployed across various scenarios
in Amap, leading to substantial improvements in digital asset's GMV(+3.02%),
POI recommendation's CTR(+2.76%), and travel mode suggestion's ACC(+5.13%).

</details>


### [9] [Interactive Recommendation Agent with Active User Commands](https://arxiv.org/abs/2509.21317)
*Jiakai Tang,Yujie Luo,Xunke Xi,Fei Sun,Xueyang Feng,Sunhao Dai,Chao Yi,Dian Chen,Zhujin Gao,Yang Li,Xu Chen,Wen Chen,Jian Wu,Yuning Jiang,Bo Zheng*

Main category: cs.IR

TL;DR: 本文引入互动推荐流（IRF），通过自然语言命令提升推荐系统用户控制能力，开发了RecBot实现提高用户满意度和商业效果。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统过于依赖简单的反馈机制（如喜欢或不喜欢），无法捕捉用户的复杂行为动机和意图，导致偏好建模不准确。此类系统难以识别具体的条目属性对用户满意度的驱动，形成用户意图与系统解释之间的差距。

Method: 采用双智能体架构，RecBot通过解析代理将语言表达转换为结构化偏好，并通过规划代理动态协调工具链以实时调整推荐策略。为实现高效部署，采用模拟增强的知识蒸馏技术，确保性能与推理能力兼备。

Result: RecBot在广泛的离线和长时间在线实验中表现出了显著的用户满意度和商业收益提升。

Conclusion: RecBot exhibits notable enhancements in user satisfaction and business performance, validating its efficacy in improving recommendation systems.

Abstract: Traditional recommender systems rely on passive feedback mechanisms that
limit users to simple choices such as like and dislike. However, these
coarse-grained signals fail to capture users' nuanced behavior motivations and
intentions. In turn, current systems cannot also distinguish which specific
item attributes drive user satisfaction or dissatisfaction, resulting in
inaccurate preference modeling. These fundamental limitations create a
persistent gap between user intentions and system interpretations, ultimately
undermining user satisfaction and harming system effectiveness.
  To address these limitations, we introduce the Interactive Recommendation
Feed (IRF), a pioneering paradigm that enables natural language commands within
mainstream recommendation feeds. Unlike traditional systems that confine users
to passive implicit behavioral influence, IRF empowers active explicit control
over recommendation policies through real-time linguistic commands. To support
this paradigm, we develop RecBot, a dual-agent architecture where a Parser
Agent transforms linguistic expressions into structured preferences and a
Planner Agent dynamically orchestrates adaptive tool chains for on-the-fly
policy adjustment. To enable practical deployment, we employ
simulation-augmented knowledge distillation to achieve efficient performance
while maintaining strong reasoning capabilities. Through extensive offline and
long-term online experiments, RecBot shows significant improvements in both
user satisfaction and business outcomes.

</details>
