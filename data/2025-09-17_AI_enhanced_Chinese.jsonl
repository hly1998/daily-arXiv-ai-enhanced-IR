{"id": "2509.12350", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.12350", "abs": "https://arxiv.org/abs/2509.12350", "authors": ["Ke Sun", "Mayi Xu"], "title": "Knowledge Graph Tokenization for Behavior-Aware Generative Next POI Recommendation", "comment": null, "summary": "Generative paradigm, especially powered by Large Language Models (LLMs), has\nemerged as a new solution to the next point-of-interest (POI) recommendation.\nPioneering studies usually adopt a two-stage pipeline, starting with a\ntokenizer converting POIs into discrete identifiers that can be processed by\nLLMs, followed by POI behavior prediction tasks to instruction-tune LLM for\nnext POI recommendation. Despite of remarkable progress, they still face two\nlimitations: (1) existing tokenizers struggle to encode heterogeneous signals\nin the recommendation data, suffering from information loss issue, and (2)\nprevious instruction-tuning tasks only focus on users' POI visit behavior while\nignore other behavior types, resulting in insufficient understanding of\nmobility. To address these limitations, we propose KGTB (Knowledge Graph\nTokenization for Behavior-aware generative next POI recommendation).\nSpecifically, KGTB organizes the recommendation data in a knowledge graph (KG)\nformat, of which the structure can seamlessly preserve the heterogeneous\ninformation. Then, a KG-based tokenizer is developed to quantize each node into\nan individual structural ID. This process is supervised by the KG's structure,\nthus reducing the loss of heterogeneous information. Using generated IDs, KGTB\nproposes multi-behavior learning that introduces multiple behavior-specific\nprediction tasks for LLM fine-tuning, e.g., POI, category, and region visit\nbehaviors. Learning on these behavior tasks provides LLMs with comprehensive\ninsights on the target POI visit behavior. Experiments on four real-world city\ndatasets demonstrate the superior performance of KGTB.", "AI": {"tldr": "\u4e00\u7bc7\u5173\u4e8e\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u6807\u8bb0\u548c\u591a\u884c\u4e3a\u5b66\u4e60\u6539\u8fdbPOI\u63a8\u8350\u7684\u8bba\u6587\uff0c\u63d0\u51fa\u7684KGTB\u65b9\u6cd5\u63d0\u9ad8\u4e86\u63a8\u8350\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684POI\u63a8\u8350\u7cfb\u7edf\u5728\u91c7\u7528\u4e24\u4e2a\u9636\u6bb5\u7684\u7ba1\u9053\u65f6\u5b58\u5728\u4fe1\u606f\u4e22\u5931\u548c\u7528\u6237\u884c\u4e3a\u7406\u89e3\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u7814\u7a76\u8005\u5c1d\u8bd5\u901a\u8fc7LLM\u6765\u6539\u5584\u63a8\u8350\u6548\u679c\uff0c\u4f46\u4ecd\u9762\u4e34\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86KGTB\uff08\u884c\u4e3a\u611f\u77e5\u7684\u77e5\u8bc6\u56fe\u8c31\u6807\u8bb0\u751f\u6210\u5668\uff09\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u7ec4\u7ec7\u63a8\u8350\u6570\u636e\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u6807\u8bb0\u5668\u6765\u7f16\u7801\u6570\u636e\uff0c\u51cf\u5c11\u4fe1\u606f\u4e22\u5931\uff0c\u5e76\u91c7\u7528\u591a\u884c\u4e3a\u5b66\u4e60\u8fdb\u884cLLM\u5fae\u8c03\u3002", "result": "KGTB\u5728\u56db\u4e2a\u771f\u5b9e\u57ce\u5e02\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "KGTB\u80fd\u591f\u6709\u6548\u89e3\u51b3\u73b0\u6709POI\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u4fe1\u606f\u4e22\u5931\u548c\u884c\u4e3a\u7406\u89e3\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u884c\u4e3a\u5b66\u4e60\u63d0\u9ad8LLM\u7684\u8868\u73b0\u3002"}}
{"id": "2509.12361", "categories": ["cs.IR", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.12361", "abs": "https://arxiv.org/abs/2509.12361", "authors": ["Karl Higley", "Robin Burke", "Michael D. Ekstrand", "Bart P. Knijnenburg"], "title": "What News Recommendation Research Did (But Mostly Didn't) Teach Us About Building A News Recommender", "comment": null, "summary": "One of the goals of recommender systems research is to provide insights and\nmethods that can be used by practitioners to build real-world systems that\ndeliver high-quality recommendations to actual people grounded in their genuine\ninterests and needs. We report on our experience trying to apply the news\nrecommendation literature to build POPROX, a live platform for news\nrecommendation research, and reflect on the extent to which the current state\nof research supports system-building efforts. Our experience highlights several\nunexpected challenges encountered in building personalization features that are\ncommonly found in products from news aggregators and publishers, and shows how\nthose difficulties are connected to surprising gaps in the literature. Finally,\nwe offer a set of lessons learned from building a live system with a persistent\nuser base and highlight opportunities to make future news recommendation\nresearch more applicable and impactful in practice.", "AI": {"tldr": "\u62a5\u544a\u4e86\u6784\u5efa\u65b0\u95fb\u63a8\u8350\u76f4\u64ad\u5e73\u53f0\u7684\u7ecf\u9a8c\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u7684\u60ca\u4eba\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u672a\u6765\u7814\u7a76\u7684\u5efa\u8bae\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u7814\u7a76\u7684\u76ee\u6807\u662f\u63d0\u4f9b\u89c1\u89e3\u548c\u65b9\u6cd5\uff0c\u5e2e\u52a9\u4ece\u4e1a\u8005\u6784\u5efa\u73b0\u5b9e\u4e16\u754c\u7cfb\u7edf\uff0c\u4ee5\u6ee1\u8db3\u7528\u6237\u7684\u771f\u5b9e\u9700\u6c42\u3002", "method": "\u6784\u5efa\u4e86\u65b0\u95fb\u63a8\u8350\u7814\u7a76\u5e73\u53f0POPROX\uff0c\u5e76\u5c1d\u8bd5\u5e94\u7528\u73b0\u6709\u6587\u732e\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u5728\u6784\u5efa\u4e2a\u6027\u5316\u529f\u80fd\u65f6\u9047\u5230\u4e86\u610f\u5916\u6311\u6218\uff0c\u8fd9\u4e9b\u529f\u80fd\u5728\u65b0\u95fb\u805a\u5408\u548c\u51fa\u7248\u4ea7\u54c1\u4e2d\u5e38\u5e38\u5b58\u5728\u3002", "conclusion": "\u6784\u5efa\u6301\u4e45\u7528\u6237\u57fa\u7840\u7684\u5b9e\u65f6\u7cfb\u7edf\u8fc7\u7a0b\u4e2d\u603b\u8ba1\u83b7\u5f97\u4e86\u4e00\u7cfb\u5217\u7ecf\u9a8c\u6559\u8bad\u3002"}}
{"id": "2509.12539", "categories": ["cs.IR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12539", "abs": "https://arxiv.org/abs/2509.12539", "authors": ["Robin Vujanic", "Thomas Rueckstiess"], "title": "LEAF: Knowledge Distillation of Text Embedding Models with Teacher-Aligned Representations", "comment": "17 pages, 12 figures", "summary": "We present LEAF (\"Lightweight Embedding Alignment Framework\"), a knowledge\ndistillation framework for text embedding models. A key distinguishing feature\nis that our distilled leaf models are aligned to their teacher. In the context\nof information retrieval, this allows for flexible asymmetric architectures\nwhere documents are encoded with the larger teacher model, while queries can be\nserved with the smaller leaf models. We also show that leaf models\nautomatically inherit MRL and robustness to output quantization whenever these\nproperties are present in the teacher model, without explicitly training for\nthem. To demonstrate the capability of our framework we publish leaf-ir, a 23M\nparameters information retrieval oriented text embedding model trained using\nLEAF, which sets a new state-of-the-art (SOTA) on BEIR, ranking #1 on the\npublic leaderboard for this benchmark and for models of its size. When run in\nasymmetric mode, its retrieval performance is further increased. Our scheme is\nhowever not restricted to the information retrieval setting, and we demonstrate\nits wider applicability by synthesizing the multi-task leaf-mt model. This also\nsets a new SOTA, ranking #1 on the public MTEB v2 (English) leaderboard for its\nsize. LEAF is applicable to black-box models and in contrast to other embedding\nmodel training frameworks, it does not require judgments nor hard negatives,\nand training can be conducted using small batch sizes. Thus, dataset and\ntraining infrastructure requirements for our framework are modest. We make our\nmodels publicly available under a permissive Apache 2.0 license.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86LEAF\u6846\u67b6\uff0c\u4e00\u79cd\u5141\u8bb8\u7075\u6d3b\u7684\u6587\u672c\u5d4c\u5165\u6a21\u578b\u77e5\u8bc6\u84b8\u998f\u7684\u65b9\u6848\uff0c\u5c24\u5176\u5728\u4fe1\u606f\u68c0\u7d22\u548c\u591a\u4efb\u52a1\u60c5\u666f\u4e2d\u8868\u73b0\u5353\u8d8a\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u4fe1\u606f\u68c0\u7d22\u573a\u666f\u4e2d\u9700\u8981\u5728\u8f83\u5927\u7f16\u7801\u6a21\u578b\uff08\u6587\u6863\uff09\u548c\u8f83\u5c0f\u54cd\u5e94\u6a21\u578b\uff08\u67e5\u8be2\uff09\u4e4b\u95f4\u7075\u6d3b\u5207\u6362\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u77e5\u8bc6\u84b8\u998f\u6846\u67b6LEAF\uff0c\u5141\u8bb8\u5c06\u67e5\u8be2\u548c\u6587\u6863\u5206\u522b\u7528\u4e0d\u540c\u5927\u5c0f\u7684\u6a21\u578b\u7f16\u7801\uff0c\u4ee5\u5728\u4e0d\u589e\u52a0\u590d\u6742\u5ea6\u7684\u60c5\u51b5\u4e0b\u6539\u5584\u6027\u80fd\u3002", "result": "\u57fa\u4e8eLEAF\u6846\u67b6\u8bad\u7ec3\u7684\u6a21\u578b\u5728BEIR\u548cMTEB v2\uff08\u82f1\u8bed\uff09\u7684\u5c0f\u6a21\u578b\u5206\u7c7b\u4e2d\u5747\u53d6\u5f97\u7b2c\u4e00\uff0c\u5728\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5177\u5907\u591a\u4efb\u52a1\u5b66\u4e60\u80fd\u529b\u3002", "conclusion": "\u6211\u4eec\u6210\u529f\u5c55\u793a\u4e86LEAF\u6846\u67b6\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5c24\u5176\u662f\u5728\u4fe1\u606f\u68c0\u7d22\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\uff0c\u5b83\u4e3a\u540c\u7c7b\u5927\u5c0f\u7684\u6a21\u578b\u8bbe\u5b9a\u4e86\u65b0\u7684SOTA\uff0c\u5e76\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u548c\u5b9e\u9645\u6027\u3002"}}
{"id": "2509.12765", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.12765", "abs": "https://arxiv.org/abs/2509.12765", "authors": ["Zihan Wang", "Zihan Liang", "Zhou Shao", "Yufei Ma", "Huangyu Dai", "Ben Chen", "Lingtao Mao", "Chenyi Lei", "Yuqing Ding", "Han Li"], "title": "InfoGain-RAG: Boosting Retrieval-Augmented Generation via Document Information Gain-based Reranking and Filtering", "comment": "EMNLP'25 Oral Presentation. Contact: benchen4395@gmail.com", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a promising approach to\naddress key limitations of Large Language Models (LLMs), such as hallucination,\noutdated knowledge, and lacking reference. However, current RAG frameworks\noften struggle with identifying whether retrieved documents meaningfully\ncontribute to answer generation. This shortcoming makes it difficult to filter\nout irrelevant or even misleading content, which notably impacts the final\nperformance. In this paper, we propose Document Information Gain (DIG), a novel\nmetric designed to quantify the contribution of retrieved documents to correct\nanswer generation. DIG measures a document's value by computing the difference\nof LLM's generation confidence with and without the document augmented.\nFurther, we introduce InfoGain-RAG, a framework that leverages DIG scores to\ntrain a specialized reranker, which prioritizes each retrieved document from\nexact distinguishing and accurate sorting perspectives. This approach can\neffectively filter out irrelevant documents and select the most valuable ones\nfor better answer generation. Extensive experiments across various models and\nbenchmarks demonstrate that InfoGain-RAG can significantly outperform existing\napproaches, on both single and multiple retrievers paradigm. Specifically on\nNaturalQA, it achieves the improvements of 17.9%, 4.5%, 12.5% in exact match\naccuracy against naive RAG, self-reflective RAG and modern ranking-based RAG\nrespectively, and even an average of 15.3% increment on advanced proprietary\nmodel GPT-4o across all datasets. These results demonstrate the feasibility of\nInfoGain-RAG as it can offer a reliable solution for RAG in multiple\napplications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5ea6\u91cf\u6307\u6807\u548c\u6846\u67b6\uff0c\u901a\u8fc7\u6587\u6863\u4fe1\u606f\u589e\u76ca\u4f18\u5316\u68c0\u7d22\u548c\u751f\u6210\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u5f53\u524dRAG\u6846\u67b6\u5728\u8bc6\u522b\u68c0\u7d22\u5230\u7684\u6587\u6863\u662f\u5426\u6709\u52a9\u4e8e\u7b54\u6848\u751f\u6210\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4ee5\u53ca\u8fc7\u6ee4\u65e0\u5173\u6216\u8bef\u5bfc\u5185\u5bb9\u7684\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6307\u6807\u2014\u2014\u6587\u6863\u4fe1\u606f\u589e\u76ca\uff08DIG\uff09\uff0c\u7528\u4e8e\u91cf\u5316\u68c0\u7d22\u6587\u6863\u5bf9\u6b63\u786e\u7b54\u6848\u751f\u6210\u7684\u8d21\u732e\uff0c\u5e76\u5f15\u5165\u4e86InfoGain-RAG\u6846\u67b6\uff0c\u901a\u8fc7\u8bad\u7ec3\u4e00\u4e2a\u7279\u5316\u7684\u91cd\u65b0\u6392\u5e8f\u5668\u6765\u4f18\u5148\u6392\u5e8f\u68c0\u7d22\u5230\u7684\u6587\u6863\u3002", "result": "\u901a\u8fc7\u591a\u79cd\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cInfoGain-RAG\u5728\u5355\u4e00\u548c\u591a\u68c0\u7d22\u5668\u6a21\u5f0f\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u5c24\u5176\u662f\u5728NaturalQA\u4e0a\uff0c\u7cbe\u786e\u5339\u914d\u7684\u51c6\u786e\u6027\u76f8\u8f83\u4e8e\u5176\u4ed6RAG\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "InfoGain-RAG\u6846\u67b6\u4e3a\u591a\u4e2a\u5e94\u7528\u4e2d\u7684RAG\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2509.12824", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.12824", "abs": "https://arxiv.org/abs/2509.12824", "authors": ["Zechao Liu", "Zheng Zhou", "Xiangkun Chen", "Tao Liang", "Dapeng Lang"], "title": "DiffHash: Text-Guided Targeted Attack via Diffusion Models against Deep Hashing Image Retrieval", "comment": null, "summary": "Deep hashing models have been widely adopted to tackle the challenges of\nlarge-scale image retrieval. However, these approaches face serious security\nrisks due to their vulnerability to adversarial examples. Despite the\nincreasing exploration of targeted attacks on deep hashing models, existing\napproaches still suffer from a lack of multimodal guidance, reliance on\nlabeling information and dependence on pixel-level operations for attacks. To\naddress these limitations, we proposed DiffHash, a novel diffusion-based\ntargeted attack for deep hashing. Unlike traditional pixel-based attacks that\ndirectly modify specific pixels and lack multimodal guidance, our approach\nfocuses on optimizing the latent representations of images, guided by text\ninformation generated by a Large Language Model (LLM) for the target image.\nFurthermore, we designed a multi-space hash alignment network to align the\nhigh-dimension image space and text space to the low-dimension binary hash\nspace. During reconstruction, we also incorporated text-guided attention\nmechanisms to refine adversarial examples, ensuring them aligned with the\ntarget semantics while maintaining visual plausibility. Extensive experiments\nhave demonstrated that our method outperforms state-of-the-art (SOTA) targeted\nattack methods, achieving better black-box transferability and offering more\nexcellent stability across datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u653b\u51fb\u65b9\u6cd5DiffHash\uff0c\u901a\u8fc7\u4f18\u5316\u6f5c\u5728\u8868\u793a\u548c\u6587\u672c\u6307\u5bfc\uff0c\u63d0\u9ad8\u4e86\u653b\u51fb\u6709\u6548\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u591a\u6a21\u6001\u6307\u5bfc\uff0c\u4f9d\u8d56\u6807\u7b7e\u4fe1\u606f\u548c\u50cf\u7d20\u7ea7\u64cd\u4f5c\uff0c\u5b89\u5168\u6027\u5dee\u3002", "method": "\u63d0\u51faDiffHash\uff0c\u4e00\u79cd\u65b0\u578b\u57fa\u4e8e\u6269\u6563\u7684\u6df1\u5ea6\u54c8\u5e0c\u6709\u9488\u5bf9\u6027\u653b\u51fb\u65b9\u6cd5\uff0c\u4f18\u5316\u56fe\u50cf\u7684\u6f5c\u5728\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u6587\u672c\u4fe1\u606f\u4f5c\u4e3a\u6307\u5bfc\u3002\u8bbe\u8ba1\u4e86\u591a\u7a7a\u95f4\u54c8\u5e0c\u5bf9\u9f50\u7f51\u7edc\u6765\u5bf9\u9f50\u9ad8\u7ef4\u56fe\u50cf\u7a7a\u95f4\u548c\u4f4e\u7ef4\u4e8c\u8fdb\u5236\u54c8\u5e0c\u7a7a\u95f4\u3002\u91cd\u5efa\u8fc7\u7a0b\u4e2d\uff0c\u52a0\u5165\u4e86\u6587\u672c\u5f15\u5bfc\u7684\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u6709\u9488\u5bf9\u6027\u653b\u51fb\u65b9\u6cd5\uff0c\u5728\u9ed1\u7bb1\u53ef\u8fc1\u79fb\u6027\u548c\u6570\u636e\u96c6\u7a33\u5b9a\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "DiffHash\u63d0\u9ad8\u4e86\u9ed1\u7bb1\u653b\u51fb\u7684\u8fc1\u79fb\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u5c55\u73b0\u4e86\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2509.12948", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.12948", "abs": "https://arxiv.org/abs/2509.12948", "authors": ["Chao Xiong", "Xianwen Yu", "Wei Xu", "Lei Cheng", "Chuan Yuan", "Linjian Mo"], "title": "A Learnable Fully Interacted Two-Tower Model for Pre-Ranking System", "comment": null, "summary": "Pre-ranking plays a crucial role in large-scale recommender systems by\nsignificantly improving the efficiency and scalability within the constraints\nof providing high-quality candidate sets in real time. The two-tower model is\nwidely used in pre-ranking systems due to a good balance between efficiency and\neffectiveness with decoupled architecture, which independently processes user\nand item inputs before calculating their interaction (e.g. dot product or\nsimilarity measure). However, this independence also leads to the lack of\ninformation interaction between the two towers, resulting in less\neffectiveness. In this paper, a novel architecture named learnable Fully\nInteracted Two-tower Model (FIT) is proposed, which enables rich information\ninteractions while ensuring inference efficiency. FIT mainly consists of two\nparts: Meta Query Module (MQM) and Lightweight Similarity Scorer (LSS).\nSpecifically, MQM introduces a learnable item meta matrix to achieve expressive\nearly interaction between user and item features. Moreover, LSS is designed to\nfurther obtain effective late interaction between the user and item towers.\nFinally, experimental results on several public datasets show that our proposed\nFIT significantly outperforms the state-of-the-art baseline pre-ranking models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6539\u8fdb\u7684\u4e24\u5854\u6a21\u578bFIT\uff0c\u901a\u8fc7\u589e\u52a0\u4fe1\u606f\u4ea4\u4e92\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u6548\u679c\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u5728\u5927\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u4e2d\u9884\u6392\u5e8f\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u80fd\u591f\u5728\u5b9e\u65f6\u63d0\u4f9b\u9ad8\u8d28\u91cf\u5019\u9009\u96c6\u5408\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u9ad8\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u53ef\u5b66\u4e60\u7684\u5b8c\u5168\u4ea4\u4e92\u4e24\u5854\u6a21\u578b\uff08FIT\uff09\u7684\u65b0\u67b6\u6784\uff0c\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u90e8\u5206\uff1a\u5143\u67e5\u8be2\u6a21\u5757\uff08MQM\uff09\u548c\u8f7b\u91cf\u5316\u76f8\u4f3c\u5ea6\u8bc4\u5206\u5668\uff08LSS\uff09\u3002", "result": "FIT\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5176\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u9884\u6392\u5e8f\u6a21\u578b\u3002", "conclusion": "FIT\u80fd\u591f\u5728\u786e\u4fdd\u63a8\u7406\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e30\u5bcc\u7684\u4fe1\u606f\u4ea4\u4e92\uff0c\u663e\u8457\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u6548\u679c\u3002"}}
{"id": "2509.12950", "categories": ["cs.IR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2509.12950", "abs": "https://arxiv.org/abs/2509.12950", "authors": ["Pietro Armenante", "Kai Huang", "Nikhil Jha", "Luca Vassio"], "title": "Protecting participants or population? Comparison of k-anonymous Origin-Destination matrices", "comment": "Accepted at NetMob 2025 Data Challenge (full report)", "summary": "Origin-Destination (OD) matrices are a core component of research on users'\nmobility and summarize how individuals move between geographical regions. These\nregions should be small enough to be representative of user mobility, without\nincurring substantial privacy risks. There are two added values of the\nNetMob2025 challenge dataset. Firstly, the data is extensive and contains a lot\nof socio-demographic information that can be used to create multiple OD\nmatrices, based on the segments of the population. Secondly, a participant is\nnot merely a record in the data, but a statistically weighted proxy for a\nsegment of the real population. This opens the door to a fundamental shift in\nthe anonymization paradigm. A population-based view of privacy is central to\nour contribution. By adjusting our anonymization framework to account for\nrepresentativeness, we are also protecting the inferred identity of the actual\npopulation, rather than survey participants alone. The challenge addressed in\nthis work is to produce and compare OD matrices that are k-anonymous for survey\nparticipants and for the whole population. We compare several traditional\nmethods of anonymization to k-anonymity by generalizing geographical areas.\nThese include generalization over a hierarchy (ATG and OIGH) and the classical\nMondrian. To this established toolkit, we add a novel method, i.e., ODkAnon, a\ngreedy algorithm aiming at balancing speed and quality. Unlike previous\napproaches, which primarily address the privacy aspects of the given datasets,\nwe aim to contribute to the generation of privacy-preserving OD matrices\nenriched with socio-demographic segmentation that achieves k-anonymity on the\nactual population.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7k-\u533f\u540d\u6027\u65b9\u6cd5\u548c\u521b\u65b0\u7b97\u6cd5\u751f\u6210\u53ef\u9690\u79c1\u4fdd\u62a4\u7684OD\u77e9\u9635\uff0c\u540c\u65f6\u5b9e\u73b0\u5bf9\u6574\u4e2a\u4eba\u53e3\u53ca\u5176\u793e\u4f1a\u4eba\u53e3\u7ec6\u5206\u7684\u533f\u540d\u5316\u5904\u7406\u3002", "motivation": "\u7814\u7a76\u7528\u6237\u6d41\u52a8\u6027\u7684OD\u77e9\u9635\u5177\u6709\u91cd\u8981\u6027\uff0c\u4f46\u9700\u8981\u5728\u7ec6\u5206\u7528\u6237\u6d41\u52a8\u6027\u548c\u786e\u4fdd\u9690\u79c1\u98ce\u9669\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002NetMob2025\u6311\u6218\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u5e7f\u6cdb\u7684\u793e\u4f1a\u4eba\u53e3\u4fe1\u606f\uff0c\u80fd\u591f\u57fa\u4e8e\u4e0d\u540c\u4eba\u53e3\u7247\u6bb5\u521b\u5efa\u591a\u4e2aOD\u77e9\u9635\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u7edf\u8ba1\u52a0\u6743\u7684\u65b9\u6cd5\uff0c\u4f7f\u53c2\u4e0e\u8005\u4e0d\u4ec5\u4ec5\u662f\u6570\u636e\u8bb0\u5f55\uff0c\u800c\u662f\u4e0e\u771f\u5b9e\u4eba\u53e3\u7247\u6bb5\u76f8\u5173\u7684\u4ee3\u7406\uff0c\u4ece\u800c\u5728\u533f\u540d\u5316\u7684\u8303\u5f0f\u4e2d\u8fdb\u884c\u6839\u672c\u6027\u8f6c\u53d8\u3002", "method": "\u6211\u4eec\u6bd4\u8f83\u4e86\u591a\u79cd\u533f\u540d\u5316\u65b9\u6cd5\uff0c\u5305\u62ec\u901a\u8fc7\u4e00\u4e2a\u5c42\u6b21\u7ed3\u6784\uff08ATG\u548cOIGH\uff09\u8fdb\u884c\u7684\u6cdb\u5316\u548c\u7ecf\u5178Mondrian\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5ODkAnon\u3002", "result": "\u901a\u8fc7\u6bd4\u8f83\u591a\u79cd\u4f20\u7edf\u7684\u6a2a\u5411\u533f\u540d\u5316\u65b9\u6cd5\uff0c\u6211\u4eec\u63d0\u51fa\u4e86ODkAnon\uff0c\u4e00\u79cd\u65e8\u5728\u5e73\u8861\u901f\u5ea6\u4e0e\u8d28\u91cf\u7684\u8d2a\u5fc3\u7b97\u6cd5\uff0c\u4ece\u800c\u80fd\u591f\u751f\u6210\u5177\u6709\u793e\u4f1a\u4eba\u53e3\u7ec6\u5206\u7684\u9690\u79c1\u4fdd\u62a4OD\u77e9\u9635\uff0c\u5e76\u5b9e\u73b0k-\u533f\u540d\u6027\u3002", "conclusion": "\u6211\u4eec\u7684\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u533f\u540d\u5316\u89c6\u89d2\uff0c\u4fdd\u62a4\u63a8\u65ad\u51fa\u7684\u5b9e\u9645\u4eba\u53e3\u8eab\u4efd\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u8c03\u67e5\u53c2\u4e0e\u8005\u7684\u9690\u79c1\u3002"}}
{"id": "2509.13001", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.13001", "abs": "https://arxiv.org/abs/2509.13001", "authors": ["Lukas Wegmeth", "Tobias Vente", "Alan Said", "Joeran Beel"], "title": "Green Recommender Systems: Understanding and Minimizing the Carbon Footprint of AI-Powered Personalization", "comment": "Just Accepted at ACM TORS. arXiv admin note: substantial text overlap\n  with arXiv:2408.08203", "summary": "As global warming soars, the need to assess and reduce the environmental\nimpact of recommender systems is becoming increasingly urgent. Despite this,\nthe recommender systems community hardly understands, addresses, and evaluates\nthe environmental impact of their work. In this study, we examine the\nenvironmental impact of recommender systems research by reproducing typical\nexperimental pipelines. Based on our results, we provide guidelines for\nresearchers and practitioners on how to minimize the environmental footprint of\ntheir work and implement green recommender systems - recommender systems\ndesigned to minimize their energy consumption and carbon footprint. Our\nanalysis covers 79 papers from the 2013 and 2023 ACM RecSys conferences,\ncomparing traditional \"good old-fashioned AI\" models with modern deep learning\nmodels. We designed and reproduced representative experimental pipelines for\nboth years, measuring energy consumption using a hardware energy meter and\nconverting it into CO2 equivalents. Our results show that papers utilizing deep\nlearning models emit approximately 42 times more CO2 equivalents than papers\nusing traditional models. On average, a single deep learning-based paper\ngenerates 2,909 kilograms of CO2 equivalents - more than the carbon emissions\nof a person flying from New York City to Melbourne or the amount of CO2\nsequestered by one tree over 260 years. This work underscores the urgent need\nfor the recommender systems and wider machine learning communities to adopt\ngreen AI principles, balancing algorithmic advancements and environmental\nresponsibility to build a sustainable future with AI-powered personalization.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5bf9\u73af\u5883\u7684\u5f71\u54cd\u663e\u8457\uff0c\u9ad8\u4e8e\u4f20\u7edfAI\u6a21\u578b\uff0c\u5e76\u5efa\u8bae\u91c7\u7528\u7eff\u8272AI\u539f\u5219\u3002", "motivation": "\u968f\u7740\u5168\u7403\u53d8\u6696\u52a0\u5267\uff0c\u51cf\u5c11\u63a8\u8350\u7cfb\u7edf\u5bf9\u73af\u5883\u7684\u5f71\u54cd\u53d8\u5f97\u8d8a\u6765\u8d8a\u8feb\u5207\u3002\u7136\u800c\uff0c\u63a8\u8350\u7cfb\u7edf\u793e\u533a\u51e0\u4e4e\u6ca1\u6709\u7406\u89e3\u3001\u89e3\u51b3\u548c\u8bc4\u4f30\u5176\u5de5\u4f5c\u7684\u73af\u5883\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u91cd\u73b0\u5178\u578b\u7684\u5b9e\u9a8c\u6d41\u7a0b\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u7814\u7a76\u7684\u73af\u5883\u5f71\u54cd\uff0c\u5e76\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u51cf\u5c11\u5de5\u4f5c\u73af\u5883\u8db3\u8ff9\u7684\u6307\u5357\u3002\u5206\u6790\u4e862013\u548c2023\u5e74ACM RecSys\u4f1a\u8bae\u4e0a\u768479\u7bc7\u8bba\u6587\uff0c\u6bd4\u8f83\u4f20\u7edf\u7684AI\u6a21\u578b\u4e0e\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u8bba\u6587\u6bd4\u4f7f\u7528\u4f20\u7edf\u6a21\u578b\u7684\u8bba\u6587\u6392\u653e\u7684CO2\u5f53\u91cf\u7ea6\u9ad842\u500d\u3002\u5e73\u5747\u800c\u8a00\uff0c\u5355\u7bc7\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8bba\u6587\u4ea7\u751f2,909\u516c\u65a4\u7684CO2\u5f53\u91cf\u3002", "conclusion": "\u63a8\u8350\u7cfb\u7edf\u53ca\u66f4\u5e7f\u6cdb\u7684\u673a\u5668\u5b66\u4e60\u793e\u533a\u9700\u91c7\u7528\u7eff\u8272AI\u539f\u5219\uff0c\u5728\u7b97\u6cd5\u8fdb\u6b65\u4e0e\u73af\u5883\u8d23\u4efb\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u4ee5\u5efa\u7acb\u53ef\u6301\u7eed\u7684\u672a\u6765\u3002"}}
{"id": "2509.13179", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13179", "abs": "https://arxiv.org/abs/2509.13179", "authors": ["Yushang Zhao", "Xinyue Han", "Qian Leng", "Qianyi Sun", "Haotian Lyu", "Chengrui Zhou"], "title": "Efficient Cold-Start Recommendation via BPE Token-Level Embedding Initialization with LLM", "comment": null, "summary": "The cold-start issue is the challenge when we talk about recommender systems,\nespecially in the case when we do not have the past interaction data of new\nusers or new items. Content-based features or hybrid solutions are common as\nconventional solutions, but they can only work in a sparse metadata environment\nwith shallow patterns. In this paper, the efficient cold-start recommendation\nstrategy is presented, which is based on the sub word-level representations by\napplying Byte Pair Encoding (BPE) tokenization and pre-trained Large Language\nModel (LLM) embedding in the initialization procedure. We obtain fine-grained\ntoken-level vectors that are aligned with the BPE vocabulary as opposed to\nusing coarse-grained sentence embeddings. Together, these token embeddings can\nbe used as dense semantic priors on unseen entities, making immediate\nrecommendation performance possible without user-item interaction history. Our\nmechanism can be compared to collaborative filtering systems and tested over\nbenchmark datasets with stringent cold-start assumptions. Experimental findings\nshow that the given BPE-LLM method achieves higher Recall@k, NDCG@k, and Hit\nRate measurements compared to the standard baseline and displays the same\ncapability of sufficient computational performance. Furthermore, we demonstrate\nthat using subword-aware embeddings yields better generalizability and is more\ninterpretable, especially within a multilingual and sparse input setting. The\npractical application of token-level semantic initialization as a lightweight,\nbut nevertheless effective extension to modern recommender systems in the\nzero-shot setting is indicated within this work.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7BPE\u5206\u8bcd\u548cLLM\u5d4c\u5165\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u51b7\u542f\u52a8\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u6027\u80fd\u6307\u6807\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5f53\u6211\u4eec\u6ca1\u6709\u65b0\u7528\u6237\u6216\u65b0\u9879\u76ee\u7684\u4ea4\u4e92\u6570\u636e\u65f6\u662f\u4e00\u4e2a\u6311\u6218\u3002\u4f20\u7edf\u5185\u5bb9\u9a71\u52a8\u6216\u6df7\u5408\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u4ec5\u5728\u7a00\u758f\u7684\u5143\u6570\u636e\u73af\u5883\u4e2d\u6709\u6548\u3002", "method": "\u5e94\u7528\u5b57\u7b26\u5bf9\u7f16\u7801\uff08BPE\uff09\u5206\u8bcd\u548c\u9884\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5d4c\u5165\u6765\u8fdb\u884c\u521d\u59cb\u5316\uff0c\u83b7\u53d6\u4e0eBPE\u8bcd\u6c47\u8868\u5bf9\u9f50\u7684\u7cbe\u7ec6\u5316\u7684\u8bcd\u5143\u7ea7\u5411\u91cf\u3002\u8fd9\u4e9b\u8bcd\u5143\u5d4c\u5165\u53ef\u7528\u4f5c\u5bc6\u96c6\u7684\u8bed\u4e49\u5148\u9a8c\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e25\u683c\u7684\u51b7\u542f\u52a8\u5047\u8bbe\u4e0b\u901a\u8fc7\u6d4b\u8bd5\uff0c\u5e76\u5728Recall@k\u3001NDCG@k\u548cHit Rate\u7b49\u8bc4\u4ef7\u6307\u6807\u4e0a\u4f18\u4e8e\u6807\u51c6\u57fa\u7ebf\uff0c\u4e14\u5177\u6709\u8db3\u591f\u7684\u8ba1\u7b97\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b50\u8bcd\u7ea7\u522b\u8868\u793a\u7684\u9ad8\u6548\u51b7\u542f\u52a8\u63a8\u8350\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u5728\u4e0d\u5177\u5907\u7528\u6237-\u9879\u76ee\u4ea4\u4e92\u5386\u53f2\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u5373\u65f6\u63a8\u8350\u6027\u80fd\uff0c\u5e76\u5728\u591a\u8bed\u8a00\u548c\u7a00\u758f\u8f93\u5165\u73af\u5883\u4e2d\u5177\u6709\u826f\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u9879\u8bc4\u4ef7\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u5177\u5907\u8db3\u591f\u7684\u8ba1\u7b97\u6027\u80fd\u3002"}}
