{"id": "2509.04694", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.04694", "abs": "https://arxiv.org/abs/2509.04694", "authors": ["Wei Xu", "Jiasen Zheng", "Junjiang Lin", "Mingxuan Han", "Junliang Du"], "title": "Unified Representation Learning for Multi-Intent Diversity and Behavioral Uncertainty in Recommender Systems", "comment": null, "summary": "This paper addresses the challenge of jointly modeling user intent diversity\nand behavioral uncertainty in recommender systems. A unified representation\nlearning framework is proposed. The framework builds a multi-intent\nrepresentation module and an uncertainty modeling mechanism. It extracts\nmulti-granularity interest structures from user behavior sequences. Behavioral\nambiguity and preference fluctuation are captured using Bayesian distribution\nmodeling. In the multi-intent modeling part, the model introduces multiple\nlatent intent vectors. These vectors are weighted and fused using an attention\nmechanism to generate semantically rich representations of long-term user\npreferences. In the uncertainty modeling part, the model learns the mean and\ncovariance of behavior representations through Gaussian distributions. This\nreflects the user's confidence in different behavioral contexts. Next, a\nlearnable fusion strategy is used to combine long-term intent and short-term\nbehavior signals. This produces the final user representation, improving both\nrecommendation accuracy and robustness. The method is evaluated on standard\npublic datasets. Experimental results show that it outperforms existing\nrepresentative models across multiple metrics. It also demonstrates greater\nstability and adaptability under cold-start and behavioral disturbance\nscenarios. The approach alleviates modeling bottlenecks faced by traditional\nmethods when dealing with complex user behavior. These findings confirm the\neffectiveness and practical value of the unified modeling strategy in\nreal-world recommendation tasks."}
{"id": "2509.04751", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.04751", "abs": "https://arxiv.org/abs/2509.04751", "authors": ["Yushang Zhao", "Yike Peng", "Li Zhang", "Qianyi Sun", "Zhihui Zhang", "Yingying Zhuang"], "title": "Multimodal Foundation Model-Driven User Interest Modeling and Behavior Analysis on Short Video Platforms", "comment": null, "summary": "With the rapid expansion of user bases on short video platforms, personalized\nrecommendation systems are playing an increasingly critical role in enhancing\nuser experience and optimizing content distribution. Traditional interest\nmodeling methods often rely on unimodal data, such as click logs or text\nlabels, which limits their ability to fully capture user preferences in a\ncomplex multimodal content environment. To address this challenge, this paper\nproposes a multimodal foundation model-based framework for user interest\nmodeling and behavior analysis. By integrating video frames, textual\ndescriptions, and background music into a unified semantic space using\ncross-modal alignment strategies, the framework constructs fine-grained user\ninterest vectors. Additionally, we introduce a behavior-driven feature\nembedding mechanism that incorporates viewing, liking, and commenting sequences\nto model dynamic interest evolution, thereby improving both the timeliness and\naccuracy of recommendations. In the experimental phase, we conduct extensive\nevaluations using both public and proprietary short video datasets, comparing\nour approach against multiple mainstream recommendation algorithms and modeling\ntechniques. Results demonstrate significant improvements in behavior prediction\naccuracy, interest modeling for cold-start users, and recommendation\nclick-through rates. Moreover, we incorporate interpretability mechanisms using\nattention weights and feature visualization to reveal the model's decision\nbasis under multimodal inputs and trace interest shifts, thereby enhancing the\ntransparency and controllability of the recommendation system."}
{"id": "2509.04820", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.04820", "abs": "https://arxiv.org/abs/2509.04820", "authors": ["Huifeng Lin", "Gang Su", "Jintao Liang", "You Wu", "Rui Zhao", "Ziyue Li"], "title": "Fishing for Answers: Exploring One-shot vs. Iterative Retrieval Strategies for Retrieval Augmented Generation", "comment": "under Review of EMNLP 2025", "summary": "Retrieval-Augmented Generation (RAG) based on Large Language Models (LLMs) is\na powerful solution to understand and query the industry's closed-source\ndocuments. However, basic RAG often struggles with complex QA tasks in legal\nand regulatory domains, particularly when dealing with numerous government\ndocuments. The top-$k$ strategy frequently misses golden chunks, leading to\nincomplete or inaccurate answers. To address these retrieval bottlenecks, we\nexplore two strategies to improve evidence coverage and answer quality. The\nfirst is a One-SHOT retrieval method that adaptively selects chunks based on a\ntoken budget, allowing as much relevant content as possible to be included\nwithin the model's context window. Additionally, we design modules to further\nfilter and refine the chunks. The second is an iterative retrieval strategy\nbuilt on a Reasoning Agentic RAG framework, where a reasoning LLM dynamically\nissues search queries, evaluates retrieved results, and progressively refines\nthe context over multiple turns. We identify query drift and retrieval laziness\nissues and further design two modules to tackle them. Through extensive\nexperiments on a dataset of government documents, we aim to offer practical\ninsights and guidance for real-world applications in legal and regulatory\ndomains."}
{"id": "2509.05115", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.05115", "abs": "https://arxiv.org/abs/2509.05115", "authors": ["Hao Chen", "Wenming Ma", "Zihao Chu", "Mingqi Li"], "title": "Hybrid Matrix Factorization Based Graph Contrastive Learning for Recommendation System", "comment": null, "summary": "In recent years, methods that combine contrastive learning with graph neural\nnetworks have emerged to address the challenges of recommendation systems,\ndemonstrating powerful performance and playing a significant role in this\ndomain. Contrastive learning primarily tackles the issue of data sparsity by\nemploying data augmentation strategies, effectively alleviating this problem\nand showing promising results. Although existing research has achieved\nfavorable outcomes, most current graph contrastive learning methods are based\non two types of data augmentation strategies: the first involves perturbing the\ngraph structure, such as by randomly adding or removing edges; and the second\napplies clustering techniques. We believe that the interactive information\nobtained through these two strategies does not fully capture the user-item\ninteractions. In this paper, we propose a novel method called HMFGCL (Hybrid\nMatrix Factorization Based Graph Contrastive Learning), which integrates two\ndistinct matrix factorization techniques-low-rank matrix factorization (MF) and\nsingular value decomposition (SVD)-to complementarily acquire global\ncollaborative information, thereby constructing enhanced views. Experimental\nresults on multiple public datasets demonstrate that our model outperforms\nexisting baselines, particularly on small-scale datasets."}
