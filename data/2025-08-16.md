<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 10]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Bridging Modality Gaps in e-Commerce Products via Vision-Language Alignment](https://arxiv.org/abs/2508.10116)
*Yipeng Zhang,Hongju Yu,Aritra Mandal,Canran Xu,Qunzhi Zhou,Zhe Wu*

Main category: cs.IR

TL;DR: OPAL框架通过微调的多模态大型语言模型，从图像生成符合结构模式要求的高质量商品描述，解决了多模态电子商务应用中的关键挑战，并在评估中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 手动或半手动输入结构化商品信息常会导致质量不一致、错误和缓慢的周转，尤其对于Customer-to-Customer卖家来说。直接从商品图像生成准确描述提供了一种有前景的替代方案。

Method: 使用优化的偏好优化结合视觉指令调优来微调多模态大型语言模型（MLLM），以减少虚假成分，并在不同的基础架构中提高健壮性。

Result: OPAL在真实世界的电子商务数据集上评估时，展示出在描述质量和模式完成率方面持续胜过基线方法。

Conclusion: OPAL能够有效地在视觉和文本模式之间架起桥梁，提供更丰富、更准确、更一致的商品描述。这项工作推进了自动化列表优化，并支持电子商务平台中可扩展的高质量内容生成。

Abstract: Item information, such as titles and attributes, is essential for effective
user engagement in e-commerce. However, manual or semi-manual entry of
structured item specifics often produces inconsistent quality, errors, and slow
turnaround, especially for Customer-to-Customer sellers. Generating accurate
descriptions directly from item images offers a promising alternative. Existing
retrieval-based solutions address some of these issues but often miss
fine-grained visual details and struggle with niche or specialized categories.
  We propose Optimized Preference-Based AI for Listings (OPAL), a framework for
generating schema-compliant, high-quality item descriptions from images using a
fine-tuned multimodal large language model (MLLM). OPAL addresses key
challenges in multimodal e-commerce applications, including bridging modality
gaps and capturing detailed contextual information. It introduces two data
refinement methods: MLLM-Assisted Conformity Enhancement, which ensures
alignment with structured schema requirements, and LLM-Assisted Contextual
Understanding, which improves the capture of nuanced and fine-grained
information from visual inputs.
  OPAL uses visual instruction tuning combined with direct preference
optimization to fine-tune the MLLM, reducing hallucinations and improving
robustness across different backbone architectures. We evaluate OPAL on
real-world e-commerce datasets, showing that it consistently outperforms
baseline methods in both description quality and schema completion rates. These
results demonstrate that OPAL effectively bridges the gap between visual and
textual modalities, delivering richer, more accurate, and more consistent item
descriptions. This work advances automated listing optimization and supports
scalable, high-quality content generation in e-commerce platforms.

</details>


### [2] [DS4RS: Community-Driven and Explainable Dataset Search Engine for Recommender System Research](https://arxiv.org/abs/2508.10238)
*Xinyang Shao,Tri Kurniawan Wijaya*

Main category: cs.IR

TL;DR: 提出了一个社区驱动的可解释搜索平台，提升推荐系统数据集的发现和搜索解释性。


<details>
  <summary>Details</summary>
Motivation: 由于数据源分散和元数据不一致，难以找到匹配特定推荐任务或领域的数据集。

Method: 提出了一个面向推荐系统研究的社区驱动和可解释的数据集搜索引擎，实现了对多个数据集属性（如名称、描述、推荐领域）的语义搜索，并提供搜索相关性的解释。

Result: 系统通过改进数据集的可发现性和搜索的解释性，促进了更高效的研究再现。

Conclusion: 该系统通过社区参与和可解释性搜索引擎，显著提高了推荐系统研究中的数据集可发现性和解释性，促进了研究的高效再现。

Abstract: Accessing suitable datasets is critical for research and development in
recommender systems. However, finding datasets that match specific
recommendation task or domains remains a challenge due to scattered sources and
inconsistent metadata. To address this gap, we propose a community-driven and
explainable dataset search engine tailored for recommender system research. Our
system supports semantic search across multiple dataset attributes, such as
dataset names, descriptions, and recommendation domain, and provides
explanations of search relevance to enhance transparency. The system encourages
community participation by allowing users to contribute standardized dataset
metadata in public repository. By improving dataset discoverability and search
interpretability, the system facilitates more efficient research reproduction.
The platform is publicly available at: https://ds4rs.com.

</details>


### [3] [Clicks Versus Conversion: Choosing a Recommender's Training Objective in E-Commerce](https://arxiv.org/abs/2508.10377)
*Michael Weiss,Robert Rosenbach,Christian Eggenberger*

Main category: cs.IR

TL;DR: 研究比较了电商品推荐优化目标，发现优化订单提交率（OSR）比点击率（CTR）可实现更高的GMV提升。


<details>
  <summary>Details</summary>
Motivation: 在电子商务中，优化推荐系统以提高点击率（CTR）或转化率（如添加购物车率和订单提交率）是常见的做法。本研究旨在探索优化哪一种转化率目标对业务效果更有帮助。

Method: 通过在线A/B测试对比点击率（CTR）与添加购物车率（ACR）及订单提交率（OSR）对电商推荐系统的影响。

Result: 研究结果表明，针对订单提交率（OSR）进行优化可实现超过五倍于点击率（CTR）的总商品交易额（GMV）提升，同时不影响新产品的发掘。

Conclusion: 优化产品推荐以提高订单提交率（OSR）较点击率（CTR）能够显著提升总商品交易额（GMV）。

Abstract: Ranking product recommendations to optimize for a high click-through rate
(CTR) or for high conversion, such as add-to-cart rate (ACR) and
Order-Submit-Rate (OSR, view-to-purchase conversion) are standard practices in
e-commerce. Optimizing for CTR appears like a straightforward choice: Training
data (i.e., click data) are simple to collect and often available in large
quantities. Additionally, CTR is used far beyond e-commerce, making it a
generalist, easily implemented option. ACR and OSR, on the other hand, are more
directly linked to a shop's business goals, such as the Gross Merchandise Value
(GMV). In this paper, we compare the effects of using either of these
objectives using an online A/B test. Among our key findings, we demonstrate
that in our shops, optimizing for OSR produces a GMV uplift more than five
times larger than when optimizing for CTR, without sacrificing new product
discovery. Our results also provide insights into the different feature
importances for each of the objectives.

</details>


### [4] [Proxy Model-Guided Reinforcement Learning for Client Selection in Federated Recommendation](https://arxiv.org/abs/2508.10401)
*Liang Qu,Jianxin Li,Wei Yuan,Penghui Ruan,Yuhui Shi,Hongzhi Yin*

Main category: cs.IR

TL;DR: 本文提出了一种用于联邦推荐系统的优化客户端选择策略ProxyRL-FRS，实验表明其有效改善了推荐精度。


<details>
  <summary>Details</summary>
Motivation: 当前联邦推荐系统存在的一个问题是，它们在选择参与训练的客户端时是随机的，这导致忽略了用户数据的统计异质性，从而造成模型性能的欠佳。为了解决这个问题，本文提出了一种新的方法来优化客户端选择过程。

Method: 提出了ProxyRL-FRS框架，其中包括一个创新性的双分支模型ProxyNCF，用于轻量级贡献估计以及一个基于奖励函数的强化学习代理，用以平衡推荐准确性和嵌入陈旧性。

Result: 实验结果表明，ProxyRL-FRS在公开推荐数据集上的效果显著，说明这种方法有效地改善了客户端选择策略。

Conclusion: ProxyRL-FRS框架成功解决了联邦推荐系统在客户端选择上的挑战，特别是考虑到用户数据的统计异质性，通过引入代理模型和强化学习机制提高了推荐准确性。

Abstract: Federated recommender systems have emerged as a promising privacy-preserving
paradigm, enabling personalized recommendation services without exposing users'
raw data. By keeping data local and relying on a central server to coordinate
training across distributed clients, FedRSs protect user privacy while
collaboratively learning global models. However, most existing FedRS frameworks
adopt fully random client selection strategy in each training round,
overlooking the statistical heterogeneity of user data arising from diverse
preferences and behavior patterns, thereby resulting in suboptimal model
performance. While some client selection strategies have been proposed in the
broader federated learning literature, these methods are typically designed for
generic tasks and fail to address the unique challenges of recommendation
scenarios, such as expensive contribution evaluation due to the large number of
clients, and sparse updates resulting from long-tail item distributions. To
bridge this gap, we propose ProxyRL-FRS, a proxy model-guided reinforcement
learning framework tailored for client selection in federated recommendation.
Specifically, we first introduce ProxyNCF, a dual-branch model deployed on each
client, which augments standard Neural Collaborative Filtering with an
additional proxy model branch that provides lightweight contribution
estimation, thus eliminating the need for expensive per-round local training
traditionally required to evaluate a client's contribution. Furthermore, we
design a staleness-aware SA reinforcement learning agent that selects clients
based on the proxy-estimated contribution, and is guided by a reward function
balancing recommendation accuracy and embedding staleness, thereby enriching
the update coverage of item embeddings. Experiments conducted on public
recommendation datasets demonstrate the effectiveness of ProxyRL-FRS.

</details>


### [5] [Semantic IDs for Joint Generative Search and Recommendation](https://arxiv.org/abs/2508.10478)
*Gustavo Penha,Edoardo D'Amico,Marco De Nadai,Enrico Palumbo,Alexandre Tamborrino,Ali Vardasbi,Max Lefarov,Shawn Lin,Timothy Heath,Francesco Fabbri,Hugues Bouchard*

Main category: cs.IR

TL;DR: 研究如何在生成模型中构建统一的语义ID，以提升搜索和推荐任务的表现。


<details>
  <summary>Details</summary>
Motivation: 为搜索和推荐任务提供统一解决方案的大型语言模型驱动的生成模型中，一个关键的设计选择是如何表示项目。

Method: 探索如何构建同时在搜索和推荐任务中表现出色的语义ID。比较多种构建语义ID的策略，包括任务特定和跨任务的方法，以及在联合搜索和推荐生成模型中是否每个任务都应该有自己的语义ID标记。

Result: 使用一个双编码器模型在搜索和推荐任务上进行微调以获得项目嵌入，然后构建统一的语义ID空间，提供了有效的权衡，使得在两项任务中表现强劲。

Conclusion: 使用在搜索和推荐任务上共同微调的双编码器模型可以获得项目嵌入，然后构建统一的语义ID空间，能够在两项任务中实现强性能。

Abstract: Generative models powered by Large Language Models (LLMs) are emerging as a
unified solution for powering both recommendation and search tasks. A key
design choice in these models is how to represent items, traditionally through
unique identifiers (IDs) and more recently with Semantic IDs composed of
discrete codes, obtained from embeddings. While task-specific embedding models
can improve performance for individual tasks, they may not generalize well in a
joint setting. In this paper, we explore how to construct Semantic IDs that
perform well both in search and recommendation when using a unified model. We
compare a range of strategies to construct Semantic IDs, looking into
task-specific and cross-tasks approaches, and also whether each task should
have its own semantic ID tokens in a joint search and recommendation generative
model. Our results show that using a bi-encoder model fine-tuned on both search
and recommendation tasks to obtain item embeddings, followed by the
construction of a unified Semantic ID space provides an effective trade-off,
enabling strong performance in both tasks. We hope these findings spark
follow-up work on generalisable, semantically grounded ID schemes and inform
the next wave of unified generative recommender architectures.

</details>


### [6] [Efficient Patent Searching Using Graph Transformers](https://arxiv.org/abs/2508.10496)
*Krzysztof Daniell,Igor Buzhinsky,Sebastian Björkqvist*

Main category: cs.IR

TL;DR: 提出一种基于图形变换器的稠密检索专利搜索方法，利用图输入提高效率，利用引用学习特定相似性，提高检索质量。


<details>
  <summary>Details</summary>
Motivation: 寻找相关的现有技术对于决定是否提交新的专利申请或使现有专利无效至关重要。然而，由于专利文档数量庞大且需要进行细致的比较来确定新颖性，这使得寻找相关的现有技术变得极具挑战性。

Method: 我们提出了一种基于图形变换器的稠密检索方法进行专利搜索，其中每个发明通过描述其特征及其关系的图来表示。我们的模型使用专利办公室审查员的现有技术引用作为相关性信号来处理这些发明图，并进行训练。

Result: 利用图作为输入显著提高了处理长文档的计算效率，同时利用审查员引用使得模型能够学习超越简单文本匹配的领域特定相似性。搜索引擎能够模拟专业专利审查员的工作方式识别相关文档。

Conclusion: 我们的方法与公开可用的文本嵌入模型进行比较，并显示在现有技术检索质量和计算效率方面都有显著的改进。

Abstract: Finding relevant prior art is crucial when deciding whether to file a new
patent application or invalidate an existing patent. However, searching for
prior art is challenging due to the large number of patent documents and the
need for nuanced comparisons to determine novelty. An accurate search engine is
therefore invaluable for speeding up the process. We present a Graph
Transformer-based dense retrieval method for patent searching where each
invention is represented by a graph describing its features and their
relationships. Our model processes these invention graphs and is trained using
prior art citations from patent office examiners as relevance signals. Using
graphs as input significantly improves the computational efficiency of
processing long documents, while leveraging examiner citations allows the model
to learn domain-specific similarities beyond simple text-based matching. The
result is a search engine that emulates how professional patent examiners
identify relevant documents. We compare our approach against publicly available
text embedding models and show substantial improvements in both prior art
retrieval quality and computational efficiency.

</details>


### [7] [DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System](https://arxiv.org/abs/2508.10584)
*Wencai Ye,Mingjie Sun,Shaoyun Shi,Peng Wang,Wenjin Wu,Peng Jiang*

Main category: cs.IR

TL;DR: 提出了一种简单而灵活的DAS方法来解决多模态推荐系统中语义ID的对齐问题并成功应用。


<details>
  <summary>Details</summary>
Motivation: 现有的两阶段框架设计导致的信息损失和缺乏灵活性的问题限制了对齐过程中的互信息最大化，因此需要一种新的方法来解决这些问题。

Method: 采用了一种新的一阶段双对齐语义ID（DAS）方法，以同时优化量化和对齐。

Result: 在Kuaishou App上成功部署应用，每日为超过400万用户提供服务，证明了其在多个广告场景中的有效性。

Conclusion: 本文提出了一种新的单阶段DAS方法，能够同时优化量化和对齐，从而在保持语义完整性的同时提高对齐质量，避免了两阶段方法常见的信息损失。

Abstract: Semantic IDs are discrete identifiers generated by quantizing the Multi-modal
Large Language Models (MLLMs) embeddings, enabling efficient multi-modal
content integration in recommendation systems. However, their lack of
collaborative signals results in a misalignment with downstream discriminative
and generative recommendation objectives. Recent studies have introduced
various alignment mechanisms to address this problem, but their two-stage
framework design still leads to two main limitations: (1) inevitable
information loss during alignment, and (2) inflexibility in applying adaptive
alignment strategies, consequently constraining the mutual information
maximization during the alignment process. To address these limitations, we
propose a novel and flexible one-stage Dual-Aligned Semantic IDs (DAS) method
that simultaneously optimizes quantization and alignment, preserving semantic
integrity and alignment quality while avoiding the information loss typically
associated with two-stage methods. Meanwhile, DAS achieves more efficient
alignment between the semantic IDs and collaborative signals, with the
following two innovative and effective approaches: (1) Multi-view Constrative
Alignment: To maximize mutual information between semantic IDs and
collaborative signals, we first incorporate an ID-based CF debias module, and
then design three effective contrastive alignment methods: dual user-to-item
(u2i), dual item-to-item/user-to-user (i2i/u2u), and dual co-occurrence
item-to-item/user-to-user (i2i/u2u). (2) Dual Learning: By aligning the dual
quantizations of users and ads, the constructed semantic IDs for users and ads
achieve stronger alignment. Finally, we conduct extensive offline experiments
and online A/B tests to evaluate DAS's effectiveness, which is now successfully
deployed across various advertising scenarios at Kuaishou App, serving over 400
million users daily.

</details>


### [8] [FuXi-β: Towards a Lightweight and Fast Large-Scale Generative Recommendation Model](https://arxiv.org/abs/2508.10615)
*Yufei Ye,Wei Guo,Hao Wang,Hong Zhu,Yuyang Ye,Yong Liu,Huifeng Guo,Ruiming Tang,Defu Lian,Enhong Chen*

Main category: cs.IR

TL;DR: 提出了一种新的推荐模型框架，通过改善注意力机制，提高了推荐性能和训练推理速度，表现超过了现有模型。


<details>
  <summary>Details</summary>
Motivation: 加快训练和推理速度，解决生成推荐模型中的效率瓶颈，提升推荐任务的性能。

Method: 提出了一种新的框架，适用于Transformer型推荐模型，引入了功能相对注意偏置及无注意力令牌混合模块。

Result: FuXi-β 在大规模工业数据集的 NDCG@10 指标上相比 FuXi-α 提升了 27% 到 47%。

Conclusion: FuXi-β 在多项实验中超过了之前的最先进模型，并且相比于 FuXi-α 极大提高了速度，同时遵循了扩展定律。

Abstract: Scaling laws for autoregressive generative recommenders reveal potential for
larger, more versatile systems but mean greater latency and training costs. To
accelerate training and inference, we investigated the recent generative
recommendation models HSTU and FuXi-$\alpha$, identifying two efficiency
bottlenecks: the indexing operations in relative temporal attention bias and
the computation of the query-key attention map. Additionally, we observed that
relative attention bias in self-attention mechanisms can also serve as
attention maps. Previous works like Synthesizer have shown that alternative
forms of attention maps can achieve similar performance, naturally raising the
question of whether some attention maps are redundant. Through empirical
experiments, we discovered that using the query-key attention map might degrade
the model's performance in recommendation tasks. To address these bottlenecks,
we propose a new framework applicable to Transformer-like recommendation
models. On one hand, we introduce Functional Relative Attention Bias, which
avoids the time-consuming operations of the original relative attention bias,
thereby accelerating the process. On the other hand, we remove the query-key
attention map from the original self-attention layer and design a new
Attention-Free Token Mixer module. Furthermore, by applying this framework to
FuXi-$\alpha$, we introduce a new model, FuXi-$\beta$. Experiments across
multiple datasets demonstrate that FuXi-$\beta$ outperforms previous
state-of-the-art models and achieves significant acceleration compared to
FuXi-$\alpha$, while also adhering to the scaling law. Notably, FuXi-$\beta$
shows an improvement of 27% to 47% in the NDCG@10 metric on large-scale
industrial datasets compared to FuXi-$\alpha$. Our code is available in a
public repository: https://github.com/USTC-StarTeam/FuXi-beta

</details>


### [9] [Hypercomplex Prompt-aware Multimodal Recommendation](https://arxiv.org/abs/2508.10753)
*Zheyu Chen,Jinfeng Xu,Hewei Wang,Shuo Yang,Zitong Wan,Haibo Hu*

Main category: cs.IR

TL;DR: HPMRec框架优化了多模态推荐系统，通过超复数嵌入和自监督学习提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统面临信息过载处理和多模态表征学习固有局限性的挑战。

Method: 提出了一种新颖的Hypercomplex Prompt-aware Multimodal Recommendation框架，即HPMRec，利用多组件的超复数嵌入来增强多模态特征的表征多样性。进行跨模态特征探索。引入了提示感知补偿机制以解决模态特定特征丢失问题，并设计了自监督学习任务以增强表征多样性并对齐不同的模态。

Result: 在四个公共数据集上的广泛实验表明，HPMRec实现了先进的推荐性能。

Conclusion: HPMRec框架有效地解决了现有推荐系统中多模态特征表征不足、未考虑非线性模态融合以及过度平滑问题，从而提高了推荐系统整体性能。

Abstract: Modern recommender systems face critical challenges in handling information
overload while addressing the inherent limitations of multimodal representation
learning. Existing methods suffer from three fundamental limitations: (1)
restricted ability to represent rich multimodal features through a single
representation, (2) existing linear modality fusion strategies ignore the deep
nonlinear correlations between modalities, and (3) static optimization methods
failing to dynamically mitigate the over-smoothing problem in graph
convolutional network (GCN). To overcome these limitations, we propose HPMRec,
a novel Hypercomplex Prompt-aware Multimodal Recommendation framework, which
utilizes hypercomplex embeddings in the form of multi-components to enhance the
representation diversity of multimodal features. HPMRec adopts the hypercomplex
multiplication to naturally establish nonlinear cross-modality interactions to
bridge semantic gaps, which is beneficial to explore the cross-modality
features. HPMRec also introduces the prompt-aware compensation mechanism to aid
the misalignment between components and modality-specific features loss, and
this mechanism fundamentally alleviates the over-smoothing problem. It further
designs self-supervised learning tasks that enhance representation diversity
and align different modalities. Extensive experiments on four public datasets
show that HPMRec achieves state-of-the-art recommendation performance.

</details>


### [10] [CrossDenoise: Denoising Implicit Feedback via a Lightweight Entity-Aware Synergistic Framework](https://arxiv.org/abs/2508.10851)
*Ze Liu,Xianquan Wang,Shuochen Liu,Jie Ma,Huibo Xu,Yupeng Han,Zhe Yang,Kai Zhang,Longfei Li,Jun Zhou*

Main category: cs.IR

TL;DR: CrossDenoise是用于推荐系统隐式反馈去噪的轻量级框架，解决了现有方法的高计算开销及参数调节问题，显著提升了推荐的准确性。


<details>
  <summary>Details</summary>
Motivation: 推荐系统严重依赖隐式反馈，但这种反馈由于存在大量错误正负样本而本质上很嘈杂，这严重影响了推荐的准确性。现有的去噪策略往往忽略实体感知建模，导致高计算开销或需过多的超参数调节，限制了其在实际应用中的可行性。

Method: 我们提出了CrossDenoise，一个新颖且轻量化的框架，通过对噪声估计进行用户、项目和交互特定因素的解耦来解决上述挑战。此设计是模型不可知的、计算高效的，并且仅需两个直观超参数。

Result: CrossDenoise在ML-1M、Yelp和Amazon-book数据集上的实验中，在GMF、NeuMF和CDAE模型上，始终显著地优于最新的基线。它在Yelp上使用NeuMF时，在NDCG@50指标上获得了最高27.01%的提升，同时计算和内存开销可忽略不计。

Conclusion: CrossDenoise提供了一种实际可行且可扩展的隐式反馈去噪解决方案。分析证明其有效分离了清晰样本和噪声样本，并在各种超参数设置下保持鲁棒性。

Abstract: Recommender systems heavily rely on implicit feedback, which is inherently
noisy due to false positives and negatives, severely degrading recommendation
accuracy. Existing denoising strategies often overlook entity-aware modeling,
suffer from high computational overhead, or demand excessive hyperparameter
tuning, limiting their real-world applicability. We propose CrossDenoise, a
novel and lightweight framework that addresses these challenges by
disentangling noise estimation into user-, item-, and interaction-specific
factors. Leveraging empirical observations that show significant heterogeneity
in user and item noise propensities, CrossDenoise computes entity reputation
factors (user/item reliability) via a rank-based linear mapping of average
training losses. These are fused with interaction-level weights derived from an
empirical cumulative distribution function (ECDF) of individual losses. This
design is model-agnostic, computationally efficient, and requires only two
intuitive hyperparameters. Extensive experiments on ML-1M, Yelp, and
Amazon-book datasets, across GMF, NeuMF, and CDAE backbones, demonstrate that
CrossDenoise consistently and significantly outperforms state-of-the-art
baselines. For instance, it achieves up to 27.01% NDCG@50 gain on Yelp with
NeuMF, while incurring negligible computational and memory overhead. Our
analysis confirms that CrossDenoise effectively separates clean from noisy
samples and remains robust under varied hyperparameter settings. It offers a
practical and scalable solution for denoising implicit feedback.

</details>
