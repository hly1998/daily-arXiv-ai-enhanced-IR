<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 10]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Bridging Modality Gaps in e-Commerce Products via Vision-Language Alignment](https://arxiv.org/abs/2508.10116)
*Yipeng Zhang,Hongju Yu,Aritra Mandal,Canran Xu,Qunzhi Zhou,Zhe Wu*

Main category: cs.IR

TL;DR: OPAL通过优化的多模态语言模型来生成高质量和合规的商品描述，显著提升了电商平台的内容质量。


<details>
  <summary>Details</summary>
Motivation: 人工或半人工录入的商品信息质量不一致、错误较多并且处理速度慢，特别是对于C2C卖家。从商品图像生成准确的描述是解决此问题的有效方法。

Method: 使用优化的偏好驱动AI框架(OPAL)，通过多模态大型语言模型(MLLM)生成商品描述。该框架结合视觉指令调优和直接偏好优化来微调MLLM。引入了两种数据改进方法：MLLM辅助的合规性增强和LLM辅助的上下文理解。

Result: OPAL在真实电商数据集上的评估结果显示，对商品描述质量和模式完成率均表现优于基线方法。OPAL有效缩小了视觉与文本模态之间的差距，实现了更丰富、更准确和更一致的商品描述。

Conclusion: OPAL框架在生成高质量和符合结构化模式的商品描述方面表现出色，有助于优化电子商务平台上的自动化商品信息发布。

Abstract: Item information, such as titles and attributes, is essential for effective
user engagement in e-commerce. However, manual or semi-manual entry of
structured item specifics often produces inconsistent quality, errors, and slow
turnaround, especially for Customer-to-Customer sellers. Generating accurate
descriptions directly from item images offers a promising alternative. Existing
retrieval-based solutions address some of these issues but often miss
fine-grained visual details and struggle with niche or specialized categories.
  We propose Optimized Preference-Based AI for Listings (OPAL), a framework for
generating schema-compliant, high-quality item descriptions from images using a
fine-tuned multimodal large language model (MLLM). OPAL addresses key
challenges in multimodal e-commerce applications, including bridging modality
gaps and capturing detailed contextual information. It introduces two data
refinement methods: MLLM-Assisted Conformity Enhancement, which ensures
alignment with structured schema requirements, and LLM-Assisted Contextual
Understanding, which improves the capture of nuanced and fine-grained
information from visual inputs.
  OPAL uses visual instruction tuning combined with direct preference
optimization to fine-tune the MLLM, reducing hallucinations and improving
robustness across different backbone architectures. We evaluate OPAL on
real-world e-commerce datasets, showing that it consistently outperforms
baseline methods in both description quality and schema completion rates. These
results demonstrate that OPAL effectively bridges the gap between visual and
textual modalities, delivering richer, more accurate, and more consistent item
descriptions. This work advances automated listing optimization and supports
scalable, high-quality content generation in e-commerce platforms.

</details>


### [2] [DS4RS: Community-Driven and Explainable Dataset Search Engine for Recommender System Research](https://arxiv.org/abs/2508.10238)
*Xinyang Shao,Tri Kurniawan Wijaya*

Main category: cs.IR

TL;DR: 提出一种社区驱动的数据集搜索引擎，以提高推荐系统研究数据集的可发现性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 为了解决数据集来源分散和元数据不一致导致的推荐任务或领域匹配数据集困难的问题。

Method: 我们提出了一种面向推荐系统研究的社区驱动和可解释的数据集搜索引擎。该系统支持跨多种数据集属性进行语义搜索，并提供搜索相关性的解释以增强透明度。

Result: 系统支持跨数据集属性的语义搜索，并提供搜索相关性解释，同时鼓励用户参与贡献标准化数据集元数据。

Conclusion: 通过改进数据集的可发现性和搜索可解释性，系统促进了更高效的研究再现。

Abstract: Accessing suitable datasets is critical for research and development in
recommender systems. However, finding datasets that match specific
recommendation task or domains remains a challenge due to scattered sources and
inconsistent metadata. To address this gap, we propose a community-driven and
explainable dataset search engine tailored for recommender system research. Our
system supports semantic search across multiple dataset attributes, such as
dataset names, descriptions, and recommendation domain, and provides
explanations of search relevance to enhance transparency. The system encourages
community participation by allowing users to contribute standardized dataset
metadata in public repository. By improving dataset discoverability and search
interpretability, the system facilitates more efficient research reproduction.
The platform is publicly available at: https://ds4rs.com.

</details>


### [3] [Clicks Versus Conversion: Choosing a Recommender's Training Objective in E-Commerce](https://arxiv.org/abs/2508.10377)
*Michael Weiss,Robert Rosenbach,Christian Eggenberger*

Main category: cs.IR

TL;DR: 优化订单提交率比优化点击率能够更有效提升商业价值，并且不会影响新产品的发现。


<details>
  <summary>Details</summary>
Motivation: 探讨不同优化目标对电子商务业务目标的影响，以提升商业价值。

Method: 通过在线A/B测试，比对选用不同目标对优化结果的影响。

Result: 优化OSR能在不影响新产品发现的情况下，使商品总价值（GMV）提升五倍以上。

Conclusion: 优化订单提交率（OSR）可以显著提升商品总价值（GMV），效果超过优化点击率（CTR）。

Abstract: Ranking product recommendations to optimize for a high click-through rate
(CTR) or for high conversion, such as add-to-cart rate (ACR) and
Order-Submit-Rate (OSR, view-to-purchase conversion) are standard practices in
e-commerce. Optimizing for CTR appears like a straightforward choice: Training
data (i.e., click data) are simple to collect and often available in large
quantities. Additionally, CTR is used far beyond e-commerce, making it a
generalist, easily implemented option. ACR and OSR, on the other hand, are more
directly linked to a shop's business goals, such as the Gross Merchandise Value
(GMV). In this paper, we compare the effects of using either of these
objectives using an online A/B test. Among our key findings, we demonstrate
that in our shops, optimizing for OSR produces a GMV uplift more than five
times larger than when optimizing for CTR, without sacrificing new product
discovery. Our results also provide insights into the different feature
importances for each of the objectives.

</details>


### [4] [Proxy Model-Guided Reinforcement Learning for Client Selection in Federated Recommendation](https://arxiv.org/abs/2508.10401)
*Liang Qu,Jianxin Li,Wei Yuan,Penghui Ruan,Yuhui Shi,Hongzhi Yin*

Main category: cs.IR

TL;DR: 提出了ProxyRL-FRS框架，通过代理模型和强化学习有效选择客户端，提升联邦推荐系统性能。


<details>
  <summary>Details</summary>
Motivation: 目前的联邦推荐系统采用随机选择客户端的策略，忽视了用户数据的统计异质性，这导致模型性能不佳。现有的客户端选择策略无法解决推荐场景的独特挑战。

Method: 提出了ProxyRL-FRS框架，通过代理模型引导的强化学习进行客户端选择。包括ProxyNCF双分支模型，和一个考虑陈旧性的SA强化学习代理。

Result: 实验证明ProxyRL-FRS在公共推荐数据集上效果显著。

Conclusion: ProxyRL-FRS能够通过更有效的客户端选择策略提高联邦推荐系统的性能，同时解决了推荐场景中的独特挑战。

Abstract: Federated recommender systems have emerged as a promising privacy-preserving
paradigm, enabling personalized recommendation services without exposing users'
raw data. By keeping data local and relying on a central server to coordinate
training across distributed clients, FedRSs protect user privacy while
collaboratively learning global models. However, most existing FedRS frameworks
adopt fully random client selection strategy in each training round,
overlooking the statistical heterogeneity of user data arising from diverse
preferences and behavior patterns, thereby resulting in suboptimal model
performance. While some client selection strategies have been proposed in the
broader federated learning literature, these methods are typically designed for
generic tasks and fail to address the unique challenges of recommendation
scenarios, such as expensive contribution evaluation due to the large number of
clients, and sparse updates resulting from long-tail item distributions. To
bridge this gap, we propose ProxyRL-FRS, a proxy model-guided reinforcement
learning framework tailored for client selection in federated recommendation.
Specifically, we first introduce ProxyNCF, a dual-branch model deployed on each
client, which augments standard Neural Collaborative Filtering with an
additional proxy model branch that provides lightweight contribution
estimation, thus eliminating the need for expensive per-round local training
traditionally required to evaluate a client's contribution. Furthermore, we
design a staleness-aware SA reinforcement learning agent that selects clients
based on the proxy-estimated contribution, and is guided by a reward function
balancing recommendation accuracy and embedding staleness, thereby enriching
the update coverage of item embeddings. Experiments conducted on public
recommendation datasets demonstrate the effectiveness of ProxyRL-FRS.

</details>


### [5] [Semantic IDs for Joint Generative Search and Recommendation](https://arxiv.org/abs/2508.10478)
*Gustavo Penha,Edoardo D'Amico,Marco De Nadai,Enrico Palumbo,Alexandre Tamborrino,Ali Vardasbi,Max Lefarov,Shawn Lin,Timothy Heath,Francesco Fabbri,Hugues Bouchard*

Main category: cs.IR

TL;DR: 探索如何构建搜索和推荐任务的语义ID，使用经过微调的bi-encoder模型表现优异。


<details>
  <summary>Details</summary>
Motivation: 在推荐和搜索任务中使用统一的生成模型具有潜力，但如何在这种设置中有效表示物品是个关键设计问题。传统的使用唯一标识符(ID)的方法可能不适用于联合模型，因此需要探讨如何构建语义ID。

Method: 使用bi-encoder模型对搜索和推荐任务进行微调以获得项目嵌入，然后构建统一的语义ID空间。

Result: 构建的统一语义ID空间提供了有效的权衡，使得在搜索和推荐任务中的表现都很强。

Conclusion: 对于搜索和推荐任务，使用统一的语义ID空间可以实现良好的性能，同时激发后续关于通用语义ID方案的研究。

Abstract: Generative models powered by Large Language Models (LLMs) are emerging as a
unified solution for powering both recommendation and search tasks. A key
design choice in these models is how to represent items, traditionally through
unique identifiers (IDs) and more recently with Semantic IDs composed of
discrete codes, obtained from embeddings. While task-specific embedding models
can improve performance for individual tasks, they may not generalize well in a
joint setting. In this paper, we explore how to construct Semantic IDs that
perform well both in search and recommendation when using a unified model. We
compare a range of strategies to construct Semantic IDs, looking into
task-specific and cross-tasks approaches, and also whether each task should
have its own semantic ID tokens in a joint search and recommendation generative
model. Our results show that using a bi-encoder model fine-tuned on both search
and recommendation tasks to obtain item embeddings, followed by the
construction of a unified Semantic ID space provides an effective trade-off,
enabling strong performance in both tasks. We hope these findings spark
follow-up work on generalisable, semantically grounded ID schemes and inform
the next wave of unified generative recommender architectures.

</details>


### [6] [Efficient Patent Searching Using Graph Transformers](https://arxiv.org/abs/2508.10496)
*Krzysztof Daniell,Igor Buzhinsky,Sebastian Björkqvist*

Main category: cs.IR

TL;DR: 提出了一种基于图的Transformer专利搜索方法，通过先前技术引用训练模型，提高了检索效果和效率。


<details>
  <summary>Details</summary>
Motivation: 寻找相关的先前技术对于是否提交专利申请或使现有专利无效至关重要，但由于专利文档数量庞大且需要细致的比较，因此这项工作充满挑战。

Method: 本文使用基于图的Transformer方法进行密集检索，每个发明用描述其特征和关系的图来表示。模型利用专利局审查员的引用作为相关性信号进行训练。

Result: 我们的搜索引擎不仅能更好地模拟专业审查员的文件识别过程，还在先前技术检索质量和计算效率上相较于公共文本嵌入模型有显著提升。

Conclusion: 使用基于图的Transformer密集检索方法可以显著提高专利搜索的效率和质量。

Abstract: Finding relevant prior art is crucial when deciding whether to file a new
patent application or invalidate an existing patent. However, searching for
prior art is challenging due to the large number of patent documents and the
need for nuanced comparisons to determine novelty. An accurate search engine is
therefore invaluable for speeding up the process. We present a Graph
Transformer-based dense retrieval method for patent searching where each
invention is represented by a graph describing its features and their
relationships. Our model processes these invention graphs and is trained using
prior art citations from patent office examiners as relevance signals. Using
graphs as input significantly improves the computational efficiency of
processing long documents, while leveraging examiner citations allows the model
to learn domain-specific similarities beyond simple text-based matching. The
result is a search engine that emulates how professional patent examiners
identify relevant documents. We compare our approach against publicly available
text embedding models and show substantial improvements in both prior art
retrieval quality and computational efficiency.

</details>


### [7] [DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System](https://arxiv.org/abs/2508.10584)
*Wencai Ye,Mingjie Sun,Shaoyun Shi,Peng Wang,Wenjin Wu,Peng Jiang*

Main category: cs.IR

TL;DR: 本文提出了一种名为DAS的单阶段双对齐语义ID的方法，提高推荐系统中多模态内容的整合效率，并解决由两阶段框架设计带来的信息丢失和缺乏自适应性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的方法使用由多模态语言模型生成的离散语义ID，但其缺乏协作信号，导致与下游推荐目标的不对齐。两阶段框架设计存在信息丢失和缺乏灵活性的主要限制。

Method: 提出了一种单阶段双对齐语义ID（DAS）的方法，同时优化量化和对齐过程，保留语义完整性和对齐质量。使用多视图对比对齐和双重学习来提高语义ID和协作信号之间的对齐。

Result: DAS改进了语义ID和协作信号之间的对齐，通过离线实验和线上A/B测试验证其有效性，并在快手应用成功部署，为超过4亿用户提供服务。

Conclusion: DAS方法有效解决了两阶段方法导致的信息丢失问题，并实现了更高效的对齐，成功应用于大规模广告场景。

Abstract: Semantic IDs are discrete identifiers generated by quantizing the Multi-modal
Large Language Models (MLLMs) embeddings, enabling efficient multi-modal
content integration in recommendation systems. However, their lack of
collaborative signals results in a misalignment with downstream discriminative
and generative recommendation objectives. Recent studies have introduced
various alignment mechanisms to address this problem, but their two-stage
framework design still leads to two main limitations: (1) inevitable
information loss during alignment, and (2) inflexibility in applying adaptive
alignment strategies, consequently constraining the mutual information
maximization during the alignment process. To address these limitations, we
propose a novel and flexible one-stage Dual-Aligned Semantic IDs (DAS) method
that simultaneously optimizes quantization and alignment, preserving semantic
integrity and alignment quality while avoiding the information loss typically
associated with two-stage methods. Meanwhile, DAS achieves more efficient
alignment between the semantic IDs and collaborative signals, with the
following two innovative and effective approaches: (1) Multi-view Constrative
Alignment: To maximize mutual information between semantic IDs and
collaborative signals, we first incorporate an ID-based CF debias module, and
then design three effective contrastive alignment methods: dual user-to-item
(u2i), dual item-to-item/user-to-user (i2i/u2u), and dual co-occurrence
item-to-item/user-to-user (i2i/u2u). (2) Dual Learning: By aligning the dual
quantizations of users and ads, the constructed semantic IDs for users and ads
achieve stronger alignment. Finally, we conduct extensive offline experiments
and online A/B tests to evaluate DAS's effectiveness, which is now successfully
deployed across various advertising scenarios at Kuaishou App, serving over 400
million users daily.

</details>


### [8] [FuXi-β: Towards a Lightweight and Fast Large-Scale Generative Recommendation Model](https://arxiv.org/abs/2508.10615)
*Yufei Ye,Wei Guo,Hao Wang,Hong Zhu,Yuyang Ye,Yong Liu,Huifeng Guo,Ruiming Tang,Defu Lian,Enhong Chen*

Main category: cs.IR

TL;DR: 通过新框架和模型FuXi-$\beta$实现了推荐系统的性能提升和加速，显著提高了工业数据集上的指标表现。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型系统带来的潜在延迟和训练成本的增加，提升推荐模型的效率。

Method: 提出了一个新框架应用于类Transformer推荐模型，包括引入功能性相对注意偏差和移除原自注意层中的查询-键注意图，从而设计新的Attention-Free Token Mixer模块。

Result: FuXi-$\beta$模型在保留扩展法则的同时显著加速了FuXi-$\alpha$，并且在多个数据集上表现优于之前的最先进模型。

Conclusion: FuXi-$\beta$模型显著提高了性能，并在多个数据集上表现优于现有模型，特别是在工业规模的数据集上NDCG@10指标提高了27%到47%。

Abstract: Scaling laws for autoregressive generative recommenders reveal potential for
larger, more versatile systems but mean greater latency and training costs. To
accelerate training and inference, we investigated the recent generative
recommendation models HSTU and FuXi-$\alpha$, identifying two efficiency
bottlenecks: the indexing operations in relative temporal attention bias and
the computation of the query-key attention map. Additionally, we observed that
relative attention bias in self-attention mechanisms can also serve as
attention maps. Previous works like Synthesizer have shown that alternative
forms of attention maps can achieve similar performance, naturally raising the
question of whether some attention maps are redundant. Through empirical
experiments, we discovered that using the query-key attention map might degrade
the model's performance in recommendation tasks. To address these bottlenecks,
we propose a new framework applicable to Transformer-like recommendation
models. On one hand, we introduce Functional Relative Attention Bias, which
avoids the time-consuming operations of the original relative attention bias,
thereby accelerating the process. On the other hand, we remove the query-key
attention map from the original self-attention layer and design a new
Attention-Free Token Mixer module. Furthermore, by applying this framework to
FuXi-$\alpha$, we introduce a new model, FuXi-$\beta$. Experiments across
multiple datasets demonstrate that FuXi-$\beta$ outperforms previous
state-of-the-art models and achieves significant acceleration compared to
FuXi-$\alpha$, while also adhering to the scaling law. Notably, FuXi-$\beta$
shows an improvement of 27% to 47% in the NDCG@10 metric on large-scale
industrial datasets compared to FuXi-$\alpha$. Our code is available in a
public repository: https://github.com/USTC-StarTeam/FuXi-beta

</details>


### [9] [Hypercomplex Prompt-aware Multimodal Recommendation](https://arxiv.org/abs/2508.10753)
*Zheyu Chen,Jinfeng Xu,Hewei Wang,Shuo Yang,Zitong Wan,Haibo Hu*

Main category: cs.IR

TL;DR: HPMRec improves multimodal recommendation by using hypercomplex embeddings, prompt-aware mechanisms, and self-supervised learning, showing superior performance in experiments.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome limitations such as restricted multimodal feature representation, neglected nonlinear modality interactions, and static optimization in recommender systems.

Method: HPMRec utilizes hypercomplex embeddings and hypercomplex multiplication for nonlinear cross-modality interaction, and incorporates a prompt-aware compensation mechanism. It also designs self-supervised learning tasks to enhance diversity and alignment of representations.

Result: Extensive experiments on four public datasets demonstrate HPMRec's superior recommendation performance.

Conclusion: HPMRec achieves state-of-the-art recommendation performance by addressing limitations in multimodal representation learning.

Abstract: Modern recommender systems face critical challenges in handling information
overload while addressing the inherent limitations of multimodal representation
learning. Existing methods suffer from three fundamental limitations: (1)
restricted ability to represent rich multimodal features through a single
representation, (2) existing linear modality fusion strategies ignore the deep
nonlinear correlations between modalities, and (3) static optimization methods
failing to dynamically mitigate the over-smoothing problem in graph
convolutional network (GCN). To overcome these limitations, we propose HPMRec,
a novel Hypercomplex Prompt-aware Multimodal Recommendation framework, which
utilizes hypercomplex embeddings in the form of multi-components to enhance the
representation diversity of multimodal features. HPMRec adopts the hypercomplex
multiplication to naturally establish nonlinear cross-modality interactions to
bridge semantic gaps, which is beneficial to explore the cross-modality
features. HPMRec also introduces the prompt-aware compensation mechanism to aid
the misalignment between components and modality-specific features loss, and
this mechanism fundamentally alleviates the over-smoothing problem. It further
designs self-supervised learning tasks that enhance representation diversity
and align different modalities. Extensive experiments on four public datasets
show that HPMRec achieves state-of-the-art recommendation performance.

</details>


### [10] [CrossDenoise: Denoising Implicit Feedback via a Lightweight Entity-Aware Synergistic Framework](https://arxiv.org/abs/2508.10851)
*Ze Liu,Xianquan Wang,Shuochen Liu,Jie Ma,Huibo Xu,Yupeng Han,Zhe Yang,Kai Zhang,Longfei Li,Jun Zhou*

Main category: cs.IR

TL;DR: CrossDenoise是一种轻量级的去噪框架，通过区分用户、项目和交互噪声来提高推荐系统精度，实验表明其优于其他方法，且计算开销低。


<details>
  <summary>Details</summary>
Motivation: 现有的去噪策略通常忽视实体感知建模，存在计算开销高或需要过多超参数调整的问题，限制了其实际应用。

Method: CrossDenoise采用实体声誉因子（用户/项目可靠性）计算，通过一种基于排名的线性映射平均训练损失方式实现。这些因子与通过个体损失的经验累积分布函数（ECDF）推导的交互水平权重相结合。该设计是模型无关的，计算效率高，并且仅需要两个直观的超参数。

Result: CrossDenoise在多个数据集（ML-1M、Yelp和Amazon-book）以及不同模型（GMF、NeuMF和CDAE）基线上进行的广泛实验中，表现优于最新的基线。例如，在Yelp上与NeuMF结合使用时，其NDCG@50提升了高达27.01%。同时，它的计算和内存开销可忽略不计。

Conclusion: CrossDenoise是一种实用且可扩展的解决方案，可以有效地清理隐式反馈中的噪声数据，同时保持在不同超参数设置下的鲁棒性。

Abstract: Recommender systems heavily rely on implicit feedback, which is inherently
noisy due to false positives and negatives, severely degrading recommendation
accuracy. Existing denoising strategies often overlook entity-aware modeling,
suffer from high computational overhead, or demand excessive hyperparameter
tuning, limiting their real-world applicability. We propose CrossDenoise, a
novel and lightweight framework that addresses these challenges by
disentangling noise estimation into user-, item-, and interaction-specific
factors. Leveraging empirical observations that show significant heterogeneity
in user and item noise propensities, CrossDenoise computes entity reputation
factors (user/item reliability) via a rank-based linear mapping of average
training losses. These are fused with interaction-level weights derived from an
empirical cumulative distribution function (ECDF) of individual losses. This
design is model-agnostic, computationally efficient, and requires only two
intuitive hyperparameters. Extensive experiments on ML-1M, Yelp, and
Amazon-book datasets, across GMF, NeuMF, and CDAE backbones, demonstrate that
CrossDenoise consistently and significantly outperforms state-of-the-art
baselines. For instance, it achieves up to 27.01% NDCG@50 gain on Yelp with
NeuMF, while incurring negligible computational and memory overhead. Our
analysis confirms that CrossDenoise effectively separates clean from noisy
samples and remains robust under varied hyperparameter settings. It offers a
practical and scalable solution for denoising implicit feedback.

</details>
