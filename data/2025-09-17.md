<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Knowledge Graph Tokenization for Behavior-Aware Generative Next POI Recommendation](https://arxiv.org/abs/2509.12350)
*Ke Sun,Mayi Xu*

Main category: cs.IR

TL;DR: 一篇关于通过知识图谱标记和多行为学习改进POI推荐的论文，提出的KGTB方法提高了推荐的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的POI推荐系统在采用两个阶段的管道时存在信息丢失和用户行为理解不足的问题。研究者尝试通过LLM来改善推荐效果，但仍面临这些挑战。

Method: 提出了KGTB（行为感知的知识图谱标记生成器），通过知识图谱组织推荐数据，并开发了一种基于知识图谱的标记器来编码数据，减少信息丢失，并采用多行为学习进行LLM微调。

Result: KGTB在四个真实城市数据集上的实验表现优异。

Conclusion: KGTB能够有效解决现有POI推荐系统中的信息丢失和行为理解问题，通过多行为学习提高LLM的表现。

Abstract: Generative paradigm, especially powered by Large Language Models (LLMs), has
emerged as a new solution to the next point-of-interest (POI) recommendation.
Pioneering studies usually adopt a two-stage pipeline, starting with a
tokenizer converting POIs into discrete identifiers that can be processed by
LLMs, followed by POI behavior prediction tasks to instruction-tune LLM for
next POI recommendation. Despite of remarkable progress, they still face two
limitations: (1) existing tokenizers struggle to encode heterogeneous signals
in the recommendation data, suffering from information loss issue, and (2)
previous instruction-tuning tasks only focus on users' POI visit behavior while
ignore other behavior types, resulting in insufficient understanding of
mobility. To address these limitations, we propose KGTB (Knowledge Graph
Tokenization for Behavior-aware generative next POI recommendation).
Specifically, KGTB organizes the recommendation data in a knowledge graph (KG)
format, of which the structure can seamlessly preserve the heterogeneous
information. Then, a KG-based tokenizer is developed to quantize each node into
an individual structural ID. This process is supervised by the KG's structure,
thus reducing the loss of heterogeneous information. Using generated IDs, KGTB
proposes multi-behavior learning that introduces multiple behavior-specific
prediction tasks for LLM fine-tuning, e.g., POI, category, and region visit
behaviors. Learning on these behavior tasks provides LLMs with comprehensive
insights on the target POI visit behavior. Experiments on four real-world city
datasets demonstrate the superior performance of KGTB.

</details>


### [2] [What News Recommendation Research Did (But Mostly Didn't) Teach Us About Building A News Recommender](https://arxiv.org/abs/2509.12361)
*Karl Higley,Robin Burke,Michael D. Ekstrand,Bart P. Knijnenburg*

Main category: cs.IR

TL;DR: 报告了构建新闻推荐直播平台的经验，揭示了现有研究中的惊人差距，并提出改进未来研究的建议。


<details>
  <summary>Details</summary>
Motivation: 推荐系统研究的目标是提供见解和方法，帮助从业者构建现实世界系统，以满足用户的真实需求。

Method: 构建了新闻推荐研究平台POPROX，并尝试应用现有文献进行研究。

Result: 在构建个性化功能时遇到了意外挑战，这些功能在新闻聚合和出版产品中常常存在。

Conclusion: 构建持久用户基础的实时系统过程中总计获得了一系列经验教训。

Abstract: One of the goals of recommender systems research is to provide insights and
methods that can be used by practitioners to build real-world systems that
deliver high-quality recommendations to actual people grounded in their genuine
interests and needs. We report on our experience trying to apply the news
recommendation literature to build POPROX, a live platform for news
recommendation research, and reflect on the extent to which the current state
of research supports system-building efforts. Our experience highlights several
unexpected challenges encountered in building personalization features that are
commonly found in products from news aggregators and publishers, and shows how
those difficulties are connected to surprising gaps in the literature. Finally,
we offer a set of lessons learned from building a live system with a persistent
user base and highlight opportunities to make future news recommendation
research more applicable and impactful in practice.

</details>


### [3] [LEAF: Knowledge Distillation of Text Embedding Models with Teacher-Aligned Representations](https://arxiv.org/abs/2509.12539)
*Robin Vujanic,Thomas Rueckstiess*

Main category: cs.IR

TL;DR: 介绍了LEAF框架，一种允许灵活的文本嵌入模型知识蒸馏的方案，尤其在信息检索和多任务情景中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 为了解决在信息检索场景中需要在较大编码模型（文档）和较小响应模型（查询）之间灵活切换的问题。

Method: 提出了一种轻量级的知识蒸馏框架LEAF，允许将查询和文档分别用不同大小的模型编码，以在不增加复杂度的情况下改善性能。

Result: 基于LEAF框架训练的模型在BEIR和MTEB v2（英语）的小模型分类中均取得第一，在信息检索任务中表现优异，并具备多任务学习能力。

Conclusion: 我们成功展示了LEAF框架在不同任务中的表现，尤其是在信息检索和多任务学习中，它为同类大小的模型设定了新的SOTA，并具有广泛的适用性和实际性。

Abstract: We present LEAF ("Lightweight Embedding Alignment Framework"), a knowledge
distillation framework for text embedding models. A key distinguishing feature
is that our distilled leaf models are aligned to their teacher. In the context
of information retrieval, this allows for flexible asymmetric architectures
where documents are encoded with the larger teacher model, while queries can be
served with the smaller leaf models. We also show that leaf models
automatically inherit MRL and robustness to output quantization whenever these
properties are present in the teacher model, without explicitly training for
them. To demonstrate the capability of our framework we publish leaf-ir, a 23M
parameters information retrieval oriented text embedding model trained using
LEAF, which sets a new state-of-the-art (SOTA) on BEIR, ranking #1 on the
public leaderboard for this benchmark and for models of its size. When run in
asymmetric mode, its retrieval performance is further increased. Our scheme is
however not restricted to the information retrieval setting, and we demonstrate
its wider applicability by synthesizing the multi-task leaf-mt model. This also
sets a new SOTA, ranking #1 on the public MTEB v2 (English) leaderboard for its
size. LEAF is applicable to black-box models and in contrast to other embedding
model training frameworks, it does not require judgments nor hard negatives,
and training can be conducted using small batch sizes. Thus, dataset and
training infrastructure requirements for our framework are modest. We make our
models publicly available under a permissive Apache 2.0 license.

</details>


### [4] [InfoGain-RAG: Boosting Retrieval-Augmented Generation via Document Information Gain-based Reranking and Filtering](https://arxiv.org/abs/2509.12765)
*Zihan Wang,Zihan Liang,Zhou Shao,Yufei Ma,Huangyu Dai,Ben Chen,Lingtao Mao,Chenyi Lei,Yuqing Ding,Han Li*

Main category: cs.IR

TL;DR: 提出了一种新的度量指标和框架，通过文档信息增益优化检索和生成的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决当前RAG框架在识别检索到的文档是否有助于答案生成方面的不足，以及过滤无关或误导内容的困难。

Method: 提出了一种新颖的指标——文档信息增益（DIG），用于量化检索文档对正确答案生成的贡献，并引入了InfoGain-RAG框架，通过训练一个特化的重新排序器来优先排序检索到的文档。

Result: 通过多种模型和基准测试进行的广泛实验表明，InfoGain-RAG在单一和多检索器模式下显著优于现有方法。尤其是在NaturalQA上，精确匹配的准确性相较于其他RAG方法有显著提升。

Conclusion: InfoGain-RAG框架为多个应用中的RAG提供了可靠的解决方案，显著提高了现有方法的性能。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to
address key limitations of Large Language Models (LLMs), such as hallucination,
outdated knowledge, and lacking reference. However, current RAG frameworks
often struggle with identifying whether retrieved documents meaningfully
contribute to answer generation. This shortcoming makes it difficult to filter
out irrelevant or even misleading content, which notably impacts the final
performance. In this paper, we propose Document Information Gain (DIG), a novel
metric designed to quantify the contribution of retrieved documents to correct
answer generation. DIG measures a document's value by computing the difference
of LLM's generation confidence with and without the document augmented.
Further, we introduce InfoGain-RAG, a framework that leverages DIG scores to
train a specialized reranker, which prioritizes each retrieved document from
exact distinguishing and accurate sorting perspectives. This approach can
effectively filter out irrelevant documents and select the most valuable ones
for better answer generation. Extensive experiments across various models and
benchmarks demonstrate that InfoGain-RAG can significantly outperform existing
approaches, on both single and multiple retrievers paradigm. Specifically on
NaturalQA, it achieves the improvements of 17.9%, 4.5%, 12.5% in exact match
accuracy against naive RAG, self-reflective RAG and modern ranking-based RAG
respectively, and even an average of 15.3% increment on advanced proprietary
model GPT-4o across all datasets. These results demonstrate the feasibility of
InfoGain-RAG as it can offer a reliable solution for RAG in multiple
applications.

</details>


### [5] [DiffHash: Text-Guided Targeted Attack via Diffusion Models against Deep Hashing Image Retrieval](https://arxiv.org/abs/2509.12824)
*Zechao Liu,Zheng Zhou,Xiangkun Chen,Tao Liang,Dapeng Lang*

Main category: cs.IR

TL;DR: 提出了一种新型攻击方法DiffHash，通过优化潜在表示和文本指导，提高了攻击有效性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏多模态指导，依赖标签信息和像素级操作，安全性差。

Method: 提出DiffHash，一种新型基于扩散的深度哈希有针对性攻击方法，优化图像的潜在表示，并通过大型语言模型生成的文本信息作为指导。设计了多空间哈希对齐网络来对齐高维图像空间和低维二进制哈希空间。重建过程中，加入了文本引导的注意力机制。

Result: 大量实验表明，该方法优于现有最先进的有针对性攻击方法，在黑箱可迁移性和数据集稳定性方面表现出色。

Conclusion: DiffHash提高了黑箱攻击的迁移性和稳定性，展现了优于传统方法的性能。

Abstract: Deep hashing models have been widely adopted to tackle the challenges of
large-scale image retrieval. However, these approaches face serious security
risks due to their vulnerability to adversarial examples. Despite the
increasing exploration of targeted attacks on deep hashing models, existing
approaches still suffer from a lack of multimodal guidance, reliance on
labeling information and dependence on pixel-level operations for attacks. To
address these limitations, we proposed DiffHash, a novel diffusion-based
targeted attack for deep hashing. Unlike traditional pixel-based attacks that
directly modify specific pixels and lack multimodal guidance, our approach
focuses on optimizing the latent representations of images, guided by text
information generated by a Large Language Model (LLM) for the target image.
Furthermore, we designed a multi-space hash alignment network to align the
high-dimension image space and text space to the low-dimension binary hash
space. During reconstruction, we also incorporated text-guided attention
mechanisms to refine adversarial examples, ensuring them aligned with the
target semantics while maintaining visual plausibility. Extensive experiments
have demonstrated that our method outperforms state-of-the-art (SOTA) targeted
attack methods, achieving better black-box transferability and offering more
excellent stability across datasets.

</details>


### [6] [A Learnable Fully Interacted Two-Tower Model for Pre-Ranking System](https://arxiv.org/abs/2509.12948)
*Chao Xiong,Xianwen Yu,Wei Xu,Lei Cheng,Chuan Yuan,Linjian Mo*

Main category: cs.IR

TL;DR: 提出一种改进的两塔模型FIT，通过增加信息交互提高推荐系统的效果，并在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 在大规模推荐系统中预排序至关重要，因为它能够在实时提供高质量候选集合的情况下显著提高效率和可扩展性。

Method: 提出了一种名为可学习的完全交互两塔模型（FIT）的新架构，包含两个主要部分：元查询模块（MQM）和轻量化相似度评分器（LSS）。

Result: FIT在多个公开数据集上的实验结果表明，其性能显著优于最先进的基线预排序模型。

Conclusion: FIT能够在确保推理效率的同时实现丰富的信息交互，显著提高推荐系统的效果。

Abstract: Pre-ranking plays a crucial role in large-scale recommender systems by
significantly improving the efficiency and scalability within the constraints
of providing high-quality candidate sets in real time. The two-tower model is
widely used in pre-ranking systems due to a good balance between efficiency and
effectiveness with decoupled architecture, which independently processes user
and item inputs before calculating their interaction (e.g. dot product or
similarity measure). However, this independence also leads to the lack of
information interaction between the two towers, resulting in less
effectiveness. In this paper, a novel architecture named learnable Fully
Interacted Two-tower Model (FIT) is proposed, which enables rich information
interactions while ensuring inference efficiency. FIT mainly consists of two
parts: Meta Query Module (MQM) and Lightweight Similarity Scorer (LSS).
Specifically, MQM introduces a learnable item meta matrix to achieve expressive
early interaction between user and item features. Moreover, LSS is designed to
further obtain effective late interaction between the user and item towers.
Finally, experimental results on several public datasets show that our proposed
FIT significantly outperforms the state-of-the-art baseline pre-ranking models.

</details>


### [7] [Protecting participants or population? Comparison of k-anonymous Origin-Destination matrices](https://arxiv.org/abs/2509.12950)
*Pietro Armenante,Kai Huang,Nikhil Jha,Luca Vassio*

Main category: cs.IR

TL;DR: 本文探讨如何通过k-匿名性方法和创新算法生成可隐私保护的OD矩阵，同时实现对整个人口及其社会人口细分的匿名化处理。


<details>
  <summary>Details</summary>
Motivation: 研究用户流动性的OD矩阵具有重要性，但需要在细分用户流动性和确保隐私风险之间取得平衡。NetMob2025挑战数据集提供了广泛的社会人口信息，能够基于不同人口片段创建多个OD矩阵。同时，通过统计加权的方法，使参与者不仅仅是数据记录，而是与真实人口片段相关的代理，从而在匿名化的范式中进行根本性转变。

Method: 我们比较了多种匿名化方法，包括通过一个层次结构（ATG和OIGH）进行的泛化和经典Mondrian方法，并提出了一种新方法ODkAnon。

Result: 通过比较多种传统的横向匿名化方法，我们提出了ODkAnon，一种旨在平衡速度与质量的贪心算法，从而能够生成具有社会人口细分的隐私保护OD矩阵，并实现k-匿名性。

Conclusion: 我们的贡献是提出了一种新的匿名化视角，保护推断出的实际人口身份，而不仅仅是调查参与者的隐私。

Abstract: Origin-Destination (OD) matrices are a core component of research on users'
mobility and summarize how individuals move between geographical regions. These
regions should be small enough to be representative of user mobility, without
incurring substantial privacy risks. There are two added values of the
NetMob2025 challenge dataset. Firstly, the data is extensive and contains a lot
of socio-demographic information that can be used to create multiple OD
matrices, based on the segments of the population. Secondly, a participant is
not merely a record in the data, but a statistically weighted proxy for a
segment of the real population. This opens the door to a fundamental shift in
the anonymization paradigm. A population-based view of privacy is central to
our contribution. By adjusting our anonymization framework to account for
representativeness, we are also protecting the inferred identity of the actual
population, rather than survey participants alone. The challenge addressed in
this work is to produce and compare OD matrices that are k-anonymous for survey
participants and for the whole population. We compare several traditional
methods of anonymization to k-anonymity by generalizing geographical areas.
These include generalization over a hierarchy (ATG and OIGH) and the classical
Mondrian. To this established toolkit, we add a novel method, i.e., ODkAnon, a
greedy algorithm aiming at balancing speed and quality. Unlike previous
approaches, which primarily address the privacy aspects of the given datasets,
we aim to contribute to the generation of privacy-preserving OD matrices
enriched with socio-demographic segmentation that achieves k-anonymity on the
actual population.

</details>


### [8] [Green Recommender Systems: Understanding and Minimizing the Carbon Footprint of AI-Powered Personalization](https://arxiv.org/abs/2509.13001)
*Lukas Wegmeth,Tobias Vente,Alan Said,Joeran Beel*

Main category: cs.IR

TL;DR: 研究发现推荐系统中的深度学习模型对环境的影响显著，高于传统AI模型，并建议采用绿色AI原则。


<details>
  <summary>Details</summary>
Motivation: 随着全球变暖加剧，减少推荐系统对环境的影响变得越来越迫切。然而，推荐系统社区几乎没有理解、解决和评估其工作的环境影响。

Method: 通过重现典型的实验流程评估推荐系统研究的环境影响，并为研究人员和从业者提供减少工作环境足迹的指南。分析了2013和2023年ACM RecSys会议上的79篇论文，比较传统的AI模型与现代深度学习模型。

Result: 使用深度学习模型的论文比使用传统模型的论文排放的CO2当量约高42倍。平均而言，单篇基于深度学习的论文产生2,909公斤的CO2当量。

Conclusion: 推荐系统及更广泛的机器学习社区需采用绿色AI原则，在算法进步与环境责任之间取得平衡，以建立可持续的未来。

Abstract: As global warming soars, the need to assess and reduce the environmental
impact of recommender systems is becoming increasingly urgent. Despite this,
the recommender systems community hardly understands, addresses, and evaluates
the environmental impact of their work. In this study, we examine the
environmental impact of recommender systems research by reproducing typical
experimental pipelines. Based on our results, we provide guidelines for
researchers and practitioners on how to minimize the environmental footprint of
their work and implement green recommender systems - recommender systems
designed to minimize their energy consumption and carbon footprint. Our
analysis covers 79 papers from the 2013 and 2023 ACM RecSys conferences,
comparing traditional "good old-fashioned AI" models with modern deep learning
models. We designed and reproduced representative experimental pipelines for
both years, measuring energy consumption using a hardware energy meter and
converting it into CO2 equivalents. Our results show that papers utilizing deep
learning models emit approximately 42 times more CO2 equivalents than papers
using traditional models. On average, a single deep learning-based paper
generates 2,909 kilograms of CO2 equivalents - more than the carbon emissions
of a person flying from New York City to Melbourne or the amount of CO2
sequestered by one tree over 260 years. This work underscores the urgent need
for the recommender systems and wider machine learning communities to adopt
green AI principles, balancing algorithmic advancements and environmental
responsibility to build a sustainable future with AI-powered personalization.

</details>


### [9] [Efficient Cold-Start Recommendation via BPE Token-Level Embedding Initialization with LLM](https://arxiv.org/abs/2509.13179)
*Yushang Zhao,Xinyue Han,Qian Leng,Qianyi Sun,Haotian Lyu,Chengrui Zhou*

Main category: cs.IR

TL;DR: 该论文提出了一种通过BPE分词和LLM嵌入解决推荐系统冷启动问题的方法，实验表明其在性能指标上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在推荐系统中，冷启动问题，尤其是当我们没有新用户或新项目的交互数据时是一个挑战。传统内容驱动或混合解决方案通常仅在稀疏的元数据环境中有效。

Method: 应用字符对编码（BPE）分词和预训练大型语言模型（LLM）的嵌入来进行初始化，获取与BPE词汇表对齐的精细化的词元级向量。这些词元嵌入可用作密集的语义先验。

Result: 该方法在严格的冷启动假设下通过测试，并在Recall@k、NDCG@k和Hit Rate等评价指标上优于标准基线，且具有足够的计算性能。

Conclusion: 提出了一种基于子词级别表示的高效冷启动推荐策略，该策略在不具备用户-项目交互历史的情况下，实现了即时推荐性能，并在多语言和稀疏输入环境中具有良好的可解释性。实验结果表明，该方法在多项评价指标上均优于传统方法，并具备足够的计算性能。

Abstract: The cold-start issue is the challenge when we talk about recommender systems,
especially in the case when we do not have the past interaction data of new
users or new items. Content-based features or hybrid solutions are common as
conventional solutions, but they can only work in a sparse metadata environment
with shallow patterns. In this paper, the efficient cold-start recommendation
strategy is presented, which is based on the sub word-level representations by
applying Byte Pair Encoding (BPE) tokenization and pre-trained Large Language
Model (LLM) embedding in the initialization procedure. We obtain fine-grained
token-level vectors that are aligned with the BPE vocabulary as opposed to
using coarse-grained sentence embeddings. Together, these token embeddings can
be used as dense semantic priors on unseen entities, making immediate
recommendation performance possible without user-item interaction history. Our
mechanism can be compared to collaborative filtering systems and tested over
benchmark datasets with stringent cold-start assumptions. Experimental findings
show that the given BPE-LLM method achieves higher Recall@k, NDCG@k, and Hit
Rate measurements compared to the standard baseline and displays the same
capability of sufficient computational performance. Furthermore, we demonstrate
that using subword-aware embeddings yields better generalizability and is more
interpretable, especially within a multilingual and sparse input setting. The
practical application of token-level semantic initialization as a lightweight,
but nevertheless effective extension to modern recommender systems in the
zero-shot setting is indicated within this work.

</details>
