<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 12]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Location Matters: Leveraging Multi-Resolution Geo-Embeddings for Housing Search](https://arxiv.org/abs/2510.01196)
*Ivo Silva,Pedro Nogueira,Guilherme Bonaldo*

Main category: cs.IR

TL;DR: QuintoAndar Group通过地理感知嵌入框架改善了数字租赁平台的房屋推荐质量，强调了位置的重要性，并提升了推荐效果。


<details>
  <summary>Details</summary>
Motivation: 住房位置对于房产价值、便利设施的获取和生活质量有重大影响。为了提高推荐的有效性，需要将地理位置考虑进去。

Method: 提出了一种地理感知嵌入框架，将分层H3网格嵌入到双塔神经结构中，并与传统的矩阵分解基线和单分辨率变体进行比较。

Result: 嵌入性特定评价揭示了更丰富和平衡的嵌入表现，离线排名模拟显示推荐质量显著提升。

Conclusion: 通过提出的地理感知嵌入框架，可以改善数字租赁平台的房屋推荐质量，尤其是在数据稀疏性和空间特性挑战存在的情况下。

Abstract: QuintoAndar Group is Latin America's largest housing platform,
revolutionizing property rentals and sales. Headquartered in Brazil, it
simplifies the housing process by eliminating paperwork and enhancing
accessibility for tenants, buyers, and landlords. With thousands of houses
available for each city, users struggle to find the ideal home. In this
context, location plays a pivotal role, as it significantly influences property
value, access to amenities, and life quality. A great location can make even a
modest home highly desirable. Therefore, incorporating location into
recommendations is essential for their effectiveness. We propose a geo-aware
embedding framework to address sparsity and spatial nuances in housing
recommendations on digital rental platforms. Our approach integrates an
hierarchical H3 grid at multiple levels into a two-tower neural architecture.
We compare our method with a traditional matrix factorization baseline and a
single-resolution variant using interaction data from our platform. Embedding
specific evaluation reveals richer and more balanced embedding representations,
while offline ranking simulations demonstrate a substantial uplift in
recommendation quality.

</details>


### [2] [Are LLMs ready to help non-expert users to make charts of official statistics data?](https://arxiv.org/abs/2510.01197)
*Gadir Suleymanli,Alexander Rogiers,Lucas Lageweg,Jefrey Lijffijt*

Main category: cs.IR

TL;DR: 本文研究了当前生成式AI模型是否能自动生成用户查询所需的图表，评估多个大型语言模型在识别数据和生成可视化方面的能力，结果显示经过适当的指导可显著提升表现。


<details>
  <summary>Details</summary>
Motivation: 在当今信息偏见、虚假信息和宣传泛滥的时代，可靠数据源的可访问性变得比以往任何时候都重要。国家统计机构提供了包含广泛主题的定量信息的精选数据，但这些信息通常分散在许多表格中，难以处理。开放数据可能实际上不可访问。

Method: 对现有大型语言模型（LLMs）进行结构化评估，以评估其根据用户查询从复杂数据中生成图表的能力。采用来自荷兰统计局的多样化公共数据，评估多个LLM在识别相关数据表、执行必要操作和自主生成适当的可视化方面的能力。

Result: 结果显示定位和处理正确数据是最主要的挑战。此外，LLMs在没有明确指导时很少能实施可视化最佳实践。一旦提供关于有效图表设计的信息，模型在表示评分上表现出显著改善。迭代自评的代理方法在所有评估维度上表现优异。

Conclusion: LLMs自动生成图表的有效性可以通过适当的支撑结构和反馈机制得到增强，同时系统在三个评估维度上已经可以达到必要的准确性。

Abstract: In this time when biased information, deep fakes, and propaganda proliferate,
the accessibility of reliable data sources is more important than ever.
National statistical institutes provide curated data that contain quantitative
information on a wide range of topics. However, that information is typically
spread across many tables and the plain numbers may be arduous to process.
Hence, this open data may be practically inaccessible. We ask the question "Are
current Generative AI models capable of facilitating the identification of the
right data and the fully-automatic creation of charts to provide information in
visual form, corresponding to user queries?". We present a structured
evaluation of recent large language models' (LLMs) capabilities to generate
charts from complex data in response to user queries. Working with diverse
public data from Statistics Netherlands, we assessed multiple LLMs on their
ability to identify relevant data tables, perform necessary manipulations, and
generate appropriate visualizations autonomously. We propose a new evaluation
framework spanning three dimensions: data retrieval & pre-processing, code
quality, and visual representation. Results indicate that locating and
processing the correct data represents the most significant challenge.
Additionally, LLMs rarely implement visualization best practices without
explicit guidance. When supplemented with information about effective chart
design, models showed marked improvement in representation scores. Furthermore,
an agentic approach with iterative self-evaluation led to excellent performance
across all evaluation dimensions. These findings suggest that LLMs'
effectiveness for automated chart generation can be enhanced through
appropriate scaffolding and feedback mechanisms, and that systems can already
reach the necessary accuracy across the three evaluation dimensions.

</details>


### [3] [Optimal signals assignment for eBay View Item page](https://arxiv.org/abs/2510.01198)
*Matan Mandelbrod,Biwei Jiang,Giald Wagner,Tal Franji,Guy Feigenblat*

Main category: cs.IR

TL;DR: 本文提出两种优化eBay页面信号显示的方法，并通过A/B测试验证其有效性，对业务提升有积极作用。


<details>
  <summary>Details</summary>
Motivation: eBay的VI页面通过显示信号来提供额外的上下文信息，以促进智能购买并激励用户互动。

Method: 本文提出了两种方法来开发统计模型，以优化VI页面的信号显示。这两种方法进行了A/B测试。

Result: A/B测试显示，两种方法显著提高了业务指标。

Conclusion: 展示信号可以提升用户的购买体验，并对业务指标产生积极影响。

Abstract: Signals are short textual or visual snippets displayed on the eBay View-Item
(VI) page, providing additional, contextual information for users about the
viewed item. The aim in displaying the signals is to facilitate intelligent
purchase and to incentivise engagement. In this paper, we present two
approaches for developing statistical models that optimally populate the VI
page with signals. Both approaches were A/B tested, and yielded significant
increase in business metrics.

</details>


### [4] [MetaSynth: Multi-Agent Metadata Generation from Implicit Feedback in Black-Box Systems](https://arxiv.org/abs/2510.01523)
*Shreeranjani Srirangamsridharan,Ali Abavisani,Reza Yousefi Maragheh,Ramin Giahi,Kai Zhao,Jason Cho,Sushant Kumar*

Main category: cs.IR

TL;DR: MetaSynth通过隐性信号优化排名表现，在电子商务和亚马逊评论数据上超越现有方法，提高CTR和点击率。


<details>
  <summary>Details</summary>
Motivation: 当前的元数据优化方法缺乏多样性、可能生成虚假属性或忽略历史成功的候选短语，缺乏直接利用观察结果的隐性信号，MetaSynth旨在解决这些问题。

Method: MetaSynth采用多代理检索增强生成框架，利用隐性搜索反馈进行学习。通过从高排名结果中构建示例库，生成受产品内容和示例约束的候选片段，并通过评估-生成器循环迭代优化输出。

Result: MetaSynth在专有电子商务数据和亚马逊评论语料库中，在NDCG、MRR和排名指标方面优于强基线；大规模A/B测试显示其提升了10.26%的CTR和7.51%的点击率。

Conclusion: MetaSynth不仅在现有的基准测试中表现优于其他方法，还提供了一种优化黑箱系统内容的通用范式。

Abstract: Meta titles and descriptions strongly shape engagement in search and
recommendation platforms, yet optimizing them remains challenging. Search
engine ranking models are black box environments, explicit labels are
unavailable, and feedback such as click-through rate (CTR) arrives only
post-deployment. Existing template, LLM, and retrieval-augmented approaches
either lack diversity, hallucinate attributes, or ignore whether candidate
phrasing has historically succeeded in ranking. This leaves a gap in directly
leveraging implicit signals from observable outcomes. We introduce MetaSynth, a
multi-agent retrieval-augmented generation framework that learns from implicit
search feedback. MetaSynth builds an exemplar library from top-ranked results,
generates candidate snippets conditioned on both product content and exemplars,
and iteratively refines outputs via evaluator-generator loops that enforce
relevance, promotional strength, and compliance. On both proprietary e-commerce
data and the Amazon Reviews corpus, MetaSynth outperforms strong baselines
across NDCG, MRR, and rank metrics. Large-scale A/B tests further demonstrate
10.26% CTR and 7.51% clicks. Beyond metadata, this work contributes a general
paradigm for optimizing content in black-box systems using implicit signals.

</details>


### [5] [IoDResearch: Deep Research on Private Heterogeneous Data via the Internet of Data](https://arxiv.org/abs/2510.01553)
*Zhuofan Shi,Zijie Guo,Xinjian Ma,Gang Huang,Yun Ma,Xiang Jing*

Main category: cs.IR

TL;DR: 提出IoDResearch框架，解决传统数据管理在处理私人数据时的效率和FAIR原则遵循问题，并在检索、问答和报告生成任务上显示出优异表现。


<details>
  <summary>Details</summary>
Motivation: 传统数据管理面临多源、异构和多模态科学数据的限制，现有的深度研究框架在检索效率和遵循FAIR原则方面表现不佳，尤其是在处理私人数据时。因此，该研究旨在解决这个问题。

Method: 通过提出IoDResearch框架，将异构资源封装为符合FAIR原则的数字对象，并进一步细化为原子知识单位和知识图谱，形成用于多粒度检索的异构图索引。此外，一个多代理系统支持可靠的问答和结构化科学报告生成。

Result: IoDResearch框架在检索、问答和报告书写任务上优于代表性RAG和深度研究基线。实验结果表明，该框架在IoD情境下的私密数据专注深度研究是可行的，促进了更可信、可重用和自动化的科学发现。

Conclusion: IoDResearch框架展示了在IoD模式下进行私人数据专注深度研究的可行性，推动了更可信、可重用和自动化的科学发现。

Abstract: The rapid growth of multi-source, heterogeneous, and multimodal scientific
data has increasingly exposed the limitations of traditional data management.
Most existing DeepResearch (DR) efforts focus primarily on web search while
overlooking local private data. Consequently, these frameworks exhibit low
retrieval efficiency for private data and fail to comply with the FAIR
principles, ultimately resulting in inefficiency and limited reusability. To
this end, we propose IoDResearch (Internet of Data Research), a private
data-centric Deep Research framework that operationalizes the Internet of Data
paradigm. IoDResearch encapsulates heterogeneous resources as FAIR-compliant
digital objects, and further refines them into atomic knowledge units and
knowledge graphs, forming a heterogeneous graph index for multi-granularity
retrieval. On top of this representation, a multi-agent system supports both
reliable question answering and structured scientific report generation.
Furthermore, we establish the IoD DeepResearch Benchmark to systematically
evaluate both data representation and Deep Research capabilities in IoD
scenarios. Experimental results on retrieval, QA, and report-writing tasks show
that IoDResearch consistently surpasses representative RAG and Deep Research
baselines. Overall, IoDResearch demonstrates the feasibility of
private-data-centric Deep Research under the IoD paradigm, paving the way
toward more trustworthy, reusable, and automated scientific discovery.

</details>


### [6] [Synthetic Prefixes to Mitigate Bias in Real-Time Neural Query Autocomplete](https://arxiv.org/abs/2510.01574)
*Adithya Rajan,Xiaoyu Liu,Prateek Verma,Vibhu Arora*

Main category: cs.IR

TL;DR: 本文提出一种使用合成前缀的数据中心方法来改善实时查询自动完成系统中的偏差，并在电子商务环境中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决实时查询自动完成互动中的固有偏差，优化神经排序器以在严格的延迟限制下进行实时部署。

Method: 通过生成来自完整用户查询的合成前缀来丰富训练数据。为高效训练，我们简化了列表损失，降低计算复杂性。

Result: 在大规模电子商务环境中部署后，系统表现出在用户参与度方面的显著改进。

Conclusion: 本文介绍了一种数据中心的方法，通过使用合成前缀来减轻实时神经查询自动完成系统中的展示偏差。这种方法可以改进训练数据的多样性，减少偏见，从而对用户参与度产生显著影响。

Abstract: We introduce a data-centric approach for mitigating presentation bias in
real-time neural query autocomplete systems through the use of synthetic
prefixes. These prefixes are generated from complete user queries collected
during regular search sessions where autocomplete was not active. This allows
us to enrich the training data for learning to rank models with more diverse
and less biased examples. This method addresses the inherent bias in engagement
signals collected from live query autocomplete interactions, where model
suggestions influence user behavior. Our neural ranker is optimized for
real-time deployment under strict latency constraints and incorporates a rich
set of features, including query popularity, seasonality, fuzzy match scores,
and contextual signals such as department affinity, device type, and vertical
alignment with previous user queries. To support efficient training, we
introduce a task-specific simplification of the listwise loss, reducing
computational complexity from $O(n^2)$ to $O(n)$ by leveraging the query
autocomplete structure of having only one ground-truth selection per prefix.
Deployed in a large-scale e-commerce setting, our system demonstrates
statistically significant improvements in user engagement, as measured by mean
reciprocal rank and related metrics. Our findings show that synthetic prefixes
not only improve generalization but also provide a scalable path toward bias
mitigation in other low-latency ranking tasks, including related searches and
query recommendations.

</details>


### [7] [Bridging Collaborative Filtering and Large Language Models with Dynamic Alignment, Multimodal Fusion and Evidence-grounded Explanations](https://arxiv.org/abs/2510.01606)
*Bo Ma,LuYao Liu,Simon Lau,Chandler Yuan,and XueY Cui,Rosie Zhang*

Main category: cs.IR

TL;DR: 研究通过一个新的框架结合大语言模型和协作过滤知识解决推荐任务中的挑战。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推荐任务中的使用面临挑战，包括无法应对快速变化的用户偏好，缺乏对富媒体内容的处理能力，以及解释的可信度问题。

Method: 开发了一种在线适应机制，通过轻量级模块不断整合新的用户交互；创建了一种统一表示，结合协作信号与视觉和音频特征；设计了一种解释系统，提供具体的协作模式和项目属性作为推荐的基础。

Result: 提出的框架可以保持大模型的效率，增加较少的计算负担，适合实际应用。

Conclusion: 提出了一个新的框架\model{}，通过三项关键创新来解决大语言模型在推荐任务中的局限性。

Abstract: Recent research has explored using Large Language Models for recommendation
tasks by transforming user interaction histories and item metadata into text
prompts, then having the LLM produce rankings or recommendations. A promising
approach involves connecting collaborative filtering knowledge to LLM
representations through compact adapter networks, which avoids expensive
fine-tuning while preserving the strengths of both components. Yet several
challenges persist in practice: collaborative filtering models often use static
snapshots that miss rapidly changing user preferences; many real-world items
contain rich visual and audio content beyond textual descriptions; and current
systems struggle to provide trustworthy explanations backed by concrete
evidence. Our work introduces \model{}, a framework that tackles these
limitations through three key innovations. We develop an online adaptation
mechanism that continuously incorporates new user interactions through
lightweight modules, avoiding the need to retrain large models. We create a
unified representation that seamlessly combines collaborative signals with
visual and audio features, handling cases where some modalities may be
unavailable. Finally, we design an explanation system that grounds
recommendations in specific collaborative patterns and item attributes,
producing natural language rationales users can verify. Our approach maintains
the efficiency of frozen base models while adding minimal computational
overhead, making it practical for real-world deployment.

</details>


### [8] [LLM4Rec: Large Language Models for Multimodal Generative Recommendation with Causal Debiasing](https://arxiv.org/abs/2510.01622)
*Bo Ma,Hang Li,ZeHua Hu,XiaoFan Gui,LuYao Liu,Simon Lau*

Main category: cs.IR

TL;DR: 本文提出了一种增强型生成推荐框架，通过多模态融合架构、检索增强生成机制、基于因果推理的去偏以及可解释推荐生成和实时自适应学习能力解决了生成推荐系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前的生成推荐系统在处理多模态数据、消除算法偏差和提供透明决策过程方面面临重大挑战。

Method: 该框架通过多模态融合架构、检索增强生成机制、因果推理去偏、解释性推荐生成和实时自适应学习能力进行增强，并利用先进的大型语言模型作为骨干，结合模块化的跨模态理解、上下文知识整合、偏差减缓、解释合成及持续模型适应等功能。

Result: 在三个基准数据集（MovieLens-25M、Amazon-Electronics、Yelp-2023）上的广泛实验表明，与现有方法相比，该系统在推荐准确性、公平性和多样性方面均有持续改善，在NDCG@10指标上提高了最高2.3%，多样性指标上提高了1.4%。

Conclusion: 本文提出的框架显著提高了推荐系统的准确性、公平性和多样性，并且通过优化推理策略保持了计算效率。

Abstract: Contemporary generative recommendation systems face significant challenges in
handling multimodal data, eliminating algorithmic biases, and providing
transparent decision-making processes. This paper introduces an enhanced
generative recommendation framework that addresses these limitations through
five key innovations: multimodal fusion architecture, retrieval-augmented
generation mechanisms, causal inference-based debiasing, explainable
recommendation generation, and real-time adaptive learning capabilities. Our
framework leverages advanced large language models as the backbone while
incorporating specialized modules for cross-modal understanding, contextual
knowledge integration, bias mitigation, explanation synthesis, and continuous
model adaptation. Extensive experiments on three benchmark datasets
(MovieLens-25M, Amazon-Electronics, Yelp-2023) demonstrate consistent
improvements in recommendation accuracy, fairness, and diversity compared to
existing approaches. The proposed framework achieves up to 2.3% improvement in
NDCG@10 and 1.4% enhancement in diversity metrics while maintaining
computational efficiency through optimized inference strategies.

</details>


### [9] [TalkPlay-Tools: Conversational Music Recommendation with LLM Tool Calling](https://arxiv.org/abs/2510.01698)
*Seungheon Doh,Keunwoo Choi,Juhan Nam*

Main category: cs.IR

TL;DR: 提出了一种基于大语言模型的音乐推荐系统，通过调用多种工具，实现了高效、精准的音乐推荐。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在生成式推荐系统中已有较大进展，但推荐行为仍存在局限，特别是在元数据或属性过滤方面未得到充分利用。为了提升这方面的能力，作者提出了新的系统。

Method: 该系统将LLM作为端到端推荐系统，能够解析用户意图，规划工具调用，并协调布尔过滤(SQL)、稀疏检索(BM25)、稠密检索(嵌入相似性)和生成检索(语义ID)这几种专门组件。通过工具规划，系统预测使用的工具类型、执行顺序及参数以便找到符合用户偏好的音乐。

Result: 通过该系统的工具调用框架，实现了根据用户查询选择适当检索方法，进而在不同推荐场景下取得了具有竞争力的表现。

Conclusion: 该系统实现了一种新的会话音乐推荐系统范式，通过有机结合多种数据库过滤方法，支持多样的数据模式，表现出色。

Abstract: While the recent developments in large language models (LLMs) have
successfully enabled generative recommenders with natural language
interactions, their recommendation behavior is limited, leaving other simpler
yet crucial components such as metadata or attribute filtering underutilized in
the system. We propose an LLM-based music recommendation system with tool
calling to serve as a unified retrieval-reranking pipeline. Our system
positions an LLM as an end-to-end recommendation system that interprets user
intent, plans tool invocations, and orchestrates specialized components:
boolean filters (SQL), sparse retrieval (BM25), dense retrieval (embedding
similarity), and generative retrieval (semantic IDs). Through tool planning,
the system predicts which types of tools to use, their execution order, and the
arguments needed to find music matching user preferences, supporting diverse
modalities while seamlessly integrating multiple database filtering methods. We
demonstrate that this unified tool-calling framework achieves competitive
performance across diverse recommendation scenarios by selectively employing
appropriate retrieval methods based on user queries, envisioning a new paradigm
for conversational music recommendation systems.

</details>


### [10] [Ranking Items from Discrete Ratings: The Cost of Unknown User Thresholds](https://arxiv.org/abs/2510.01871)
*Oscar Villemaud,Suryanarayana Sankagiri,Matthias Grossglauser*

Main category: cs.IR

TL;DR: 本文探讨如何从粗粒度评分中恢复细粒度项目排名。我们将项目建模为分数，将用户建模为阈值，并研究用户对项目评分的机制。我们证明实现接近完美排名需要 $\Theta(n^2)$ 用户，这比通过比较获得排名所需的 $O(n\log n)$ 查询要糟糕得多。我们的研究揭示了在线排名中的阈值多样性与排名精细度之间的紧张关系。


<details>
  <summary>Details</summary>
Motivation: 探讨如何从用户的粗粒度评分中恢复项目的细粒度排名，从而提高信息检索和推荐系统的排名准确性。

Method: 我们模型化项目和用户行为，利用用户到来的顺序，通过询问新用户来细化当前排名。我们证明需要 $\Theta(n^2)$ 的用户来实现几乎完美的排名，并设计了一个查询复杂度与理论界限一致的排名算法来验证我们的结果。

Result: 我们证明从粗粒度评分恢复细粒度排名需要 $\Theta(n^2)$ 的用户，且提供了一个查询复杂度匹配理论界限的算法。研究揭示了在阈值分布不匹配时，通过二次差异因子量化影响。

Conclusion: 研究揭示了在线排名中的阈值多样性与排名精细度之间的权衡关系。为了将粗粒度评分整合为细粒度排名，需要阈值的多样性，但如果阈值未知这会导致额外的成本。我们的排名算法的查询复杂度与我们的理论界限匹配，差距仅为对数因子。

Abstract: Ranking items is a central task in many information retrieval and recommender
systems. User input for the ranking task often comes in the form of ratings on
a coarse discrete scale. We ask whether it is possible to recover a
fine-grained item ranking from such coarse-grained ratings. We model items as
having scores and users as having thresholds; a user rates an item positively
if the item's score exceeds the user's threshold. Although all users agree on
the total item order, estimating that order is challenging when both the scores
and the thresholds are latent. Under our model, any ranking method naturally
partitions the $n$ items into bins; the bins are ordered, but the items inside
each bin are still unordered. Users arrive sequentially, and every new user can
be queried to refine the current ranking. We prove that achieving a
near-perfect ranking, measured by Spearman distance, requires $\Theta(n^2)$
users (and therefore $\Omega(n^2)$ queries). This is significantly worse than
the $O(n\log n)$ queries needed to rank from comparisons; the gap reflects the
additional queries needed to identify the users who have the appropriate
thresholds. Our bound also quantifies the impact of a mismatch between score
and threshold distributions via a quadratic divergence factor. To show the
tightness of our results, we provide a ranking algorithm whose query complexity
matches our bound up to a logarithmic factor. Our work reveals a tension in
online ranking: diversity in thresholds is necessary to merge coarse ratings
from many users into a fine-grained ranking, but this diversity has a cost if
the thresholds are a priori unknown.

</details>


### [11] [Contrastive Retrieval Heads Improve Attention-Based Re-Ranking](https://arxiv.org/abs/2510.02219)
*Linh Tran,Yulong Li,Radu Florian,Wei Sun*

Main category: cs.IR

TL;DR: 本文介绍了一种名为CoRe的检索头，使得大型语言模型在重新排序中取得更好的效果。通过对比得分矩阵来识别这些检索头，从而提高相关文档的注意力，同时降低与不相关文档相关的节点的关注，最终提高排序准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的注意力机制在重新排序中的表现受一些低效的注意力头限制，影响整体性能。

Method: 通过一种对比评分矩阵识别出一组检索头，高度关注相关文档，同时减少不相关文档的关注。

Result: CoRe检索头仅占注意力头的1%却显着提高排序准确性，且集中于中间层，减少最后50%层的计算量可保持准确性同时减少推理时间和内存使用。

Conclusion: 使用CoRe检索头能够有效改善大语言模型的重新排序准确性，并减少耗时和内存需求。

Abstract: The strong zero-shot and long-context capabilities of recent Large Language
Models (LLMs) have paved the way for highly effective re-ranking systems.
Attention-based re-rankers leverage attention weights from transformer heads to
produce relevance scores, but not all heads are created equally: many
contribute noise and redundancy, thus limiting performance. To address this, we
introduce CoRe heads, a small set of retrieval heads identified via a
contrastive scoring metric that explicitly rewards high attention heads that
correlate with relevant documents, while downplaying nodes with higher
attention that correlate with irrelevant documents. This relative ranking
criterion isolates the most discriminative heads for re-ranking and yields a
state-of-the-art list-wise re-ranker. Extensive experiments with three LLMs
show that aggregated signals from CoRe heads, constituting less than 1% of all
heads, substantially improve re-ranking accuracy over strong baselines. We
further find that CoRe heads are concentrated in middle layers, and pruning the
computation of final 50% of model layers preserves accuracy while significantly
reducing inference time and memory usage.

</details>


### [12] [Study on LLMs for Promptagator-Style Dense Retriever Training](https://arxiv.org/abs/2510.02241)
*Daniel Gwon,Nour Jedidi,Jimmy Lin*

Main category: cs.IR

TL;DR: 开放源码的小型LLM可以替代大规模LLM，用于生成任务特定的查询，并有效进行领域密集检索模型微调。


<details>
  <summary>Details</summary>
Motivation: 原来的Promptagator方法依赖于专有的大规模LLM，这些模型用户可能无法访问或禁止与敏感数据一起使用。

Method: 通过使用开放源码的LLM（参数数量不超过14B）作为任务特定的查询生成器，对领域专用的密集检索模型进行微调。

Result: 研究表明，开放源码的LLM，即使只有3B参数，也能够作为有效的Promptagator风格查询生成器。

Conclusion: 这项工作为从业者提供了可靠的合成数据生成替代方案，并提供了针对领域特定应用最大化微调结果的见解。

Abstract: Promptagator demonstrated that Large Language Models (LLMs) with few-shot
prompts can be used as task-specific query generators for fine-tuning
domain-specialized dense retrieval models. However, the original Promptagator
approach relied on proprietary and large-scale LLMs which users may not have
access to or may be prohibited from using with sensitive data. In this work, we
study the impact of open-source LLMs at accessible scales ($\leq$14B
parameters) as an alternative. Our results demonstrate that open-source LLMs as
small as 3B parameters can serve as effective Promptagator-style query
generators. We hope our work will inform practitioners with reliable
alternatives for synthetic data generation and give insights to maximize
fine-tuning results for domain-specific applications.

</details>
